[
  {
    "objectID": "subscribe.html",
    "href": "subscribe.html",
    "title": "Subscribe",
    "section": "",
    "text": "Get New Posts in Your Inbox\nNo spam. Just espresso-strength insights on LLMs, robotics, and building real AI systems."
  },
  {
    "objectID": "technical-content.html",
    "href": "technical-content.html",
    "title": "Technical Blog",
    "section": "",
    "text": "What I have been reading: What is a ml compiler\n\n\n\nC++\n\nMachine Learning\n\nApplied Engineering\n\n\n\nLately, I’ve been digging into machine learning (ML) compilers and how they differ from traditional software compilers.\n\n\n\n\n\nAug 31, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nChoosing the Right Metric for Classification Models\n\n\n\nMachine Learning\n\nData Science\n\n\n\nIn this post, we explore various classification metrics: accuracy, precision, recall, F1-score, and AUC-ROC.\n\n\n\n\n\nAug 29, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nAvoiding Python version chaos in ML\n\n\n\nMachine Learning\n\nSoftware Engineering\n\nPython\n\n\n\nWorking with machine learning often means juggling multiple Python versions, CUDA drivers, TensorFlow/PyTorch builds, and environment conflicts. Let’s checkout how docker can help us to ease the version pain. Say goodbye to “works on my machine” and Python hell.\n\n\n\n\n\nAug 28, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nFrom damping factor to learning rate\n\n\n\nMachine Learning\n\nApplied Engineering\n\n\n\nMachine learning is in the center of the AI hype. But what does “learning” actually mean? We look behind the jargon and compare to another popular field computational mechanics.\n\n\n\n\n\nJul 5, 2025\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nBe careful using python’s dataclass\n\n\n\nPython\n\nSoftware Engineering\n\n\n\nPython’s @dataclass is a powerful tool for creating data containers with minimal boilerplate code. However, it introduces a subtle pitfall when working with mutable defaults like lists or NumPy arrays. This article explores this common issue, its root cause, and how to fix it effectively.\n\n\n\n\n\nFeb 18, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nPrecision/Recall vs FN/TN/FP/TP\n\n\n\nMachine Learning\n\nData Science\n\n\n\nPrecision, recall, and the confusion matrix help evaluate machine learning models. Learn to Understand their tradeoffs, especially in imbalanced datasets, and optimize your classifier for better results.\n\n\n\n\n\nFeb 10, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nHow technical is too technical\n\n\n\nC++\n\nSoftware Engineering\n\n\n\nWhen you read and write about software, there is always a balance to be struck how technical the books should be. I have read Effective Modern C++, which I found a little too technical.\n\n\n\n\n\nOct 28, 2021\n\n4 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers\n\n\n\n\n\nNov 21, 2025\n\n\n\n\n\n\n\nKubernetes for the seasoned non-cloud software developer\n\n\n\n\n\nNov 21, 2025\n\n\n\n\n\n\n\nC++ in your Browser. Is WebAssembly worth the effort?\n\n\n\n\n\nNov 19, 2025\n\n\n\n\n\n\n\nWriting, Doing, and Building an ML Productivity Pipeline\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\n\n\nThe Hidden Cost of “Magic” Schemas\n\n\n\n\n\nNov 8, 2025\n\n\n\n\n\n\n\nCan AI fix your shopping list?\n\n\n\n\n\nNov 4, 2025\n\n\n\n\n\n\n\nWhen to use pydantic in your app?\n\n\n\n\n\nOct 28, 2025\n\n\n\n\n\n\n\nHow LLMs help and don’t help developing software\n\n\n\n\n\nOct 25, 2025\n\n\n\n\n\n\n\nPage Segmentation: The easy and the hard way\n\n\n\n\n\nOct 24, 2025\n\n\n\n\n\n\n\nIs training your own classifier really worth it?\n\n\n\n\n\nOct 2, 2025\n\n\n\n\n\n\n\nText or Image\n\n\n\n\n\nSep 29, 2025\n\n\n\n\n\n\n\nBeauty is in the eye of the beholder\n\n\n\n\n\nSep 5, 2025\n\n\n\n\n\n\n\nWhat I have been reading: What is a ml compiler\n\n\n\n\n\nAug 31, 2025\n\n\n\n\n\n\n\nChoosing the Right Metric for Classification Models\n\n\n\n\n\nAug 29, 2025\n\n\n\n\n\n\n\nAvoiding Python version chaos in ML\n\n\n\n\n\nAug 28, 2025\n\n\n\n\n\n\n\nHow Neural Networks Hear Music\n\n\n\n\n\nJul 15, 2025\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner - part 2\n\n\n\n\n\nJul 7, 2025\n\n\n\n\n\n\n\nFrom damping factor to learning rate\n\n\n\n\n\nJul 5, 2025\n\n\n\n\n\n\n\nBlog Update July 2025\n\n\n\n\n\nJul 4, 2025\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner\n\n\n\n\n\nJul 3, 2025\n\n\n\n\n\n\n\nDo you know the hidden paths of your code?\n\n\n\n\n\nMay 14, 2025\n\n\n\n\n\n\n\nBreaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication\n\n\n\n\n\nApr 27, 2025\n\n\n\n\n\n\n\nStreet view game - hit the road\n\n\n\n\n\nApr 26, 2025\n\n\n\n\n\n\n\nWhat I learned about risk management\n\n\n\n\n\nApr 24, 2025\n\n\n\n\n\n\n\nThe triangle of trust reveals your projects issues.\n\n\n\n\n\nApr 20, 2025\n\n\n\n\n\n\n\nWhy the Fishbone Diagram Triumphs Over 5 Whys\n\n\n\n\n\nApr 17, 2025\n\n\n\n\n\n\n\nHow to avoid burying the lead\n\n\n\n\n\nApr 15, 2025\n\n\n\n\n\n\n\nThe road less travelled - from the dijkstras shortest path to the least visited path\n\n\n\n\n\nMar 25, 2025\n\n\n\n\n\n\n\nHow domain driven design makes software development concrete and abstract\n\n\n\n\n\nMar 24, 2025\n\n\n\n\n\n\n\nEngineering presentations that stick\n\n\n\n\n\nMar 23, 2025\n\n\n\n\n\n\n\nWhich cheese are we eating?\n\n\n\n\n\nMar 13, 2025\n\n\n\n\n\n\n\nYour mind and machine learning, the base rate effect\n\n\n\n\n\nMar 12, 2025\n\n\n\n\n\n\n\nSuccessful teams strike the right Balance between Immediate Needs with Long-Term Architecture\n\n\n\n\n\nMar 7, 2025\n\n\n\n\n\n\n\nObject oriented programming for AI Projects\n\n\n\n\n\nMar 6, 2025\n\n\n\n\n\n\n\nHow Poor Architectural Understanding is Impacting the German Software Industry\n\n\n\n\n\nFeb 25, 2025\n\n\n\n\n\n\n\nTop-Down Thinking is Holding Back Software Innovation\n\n\n\n\n\nFeb 22, 2025\n\n\n\n\n\n\n\nBe careful using python’s dataclass\n\n\n\n\n\nFeb 18, 2025\n\n\n\n\n\n\n\nMilestone vs Activity Planning: Finding the Right Approach for Your Project Management\n\n\n\n\n\nFeb 15, 2025\n\n\n\n\n\n\n\nDecision paralysis at a McDonalds\n\n\n\n\n\nFeb 12, 2025\n\n\n\n\n\n\n\nPrecision/Recall vs FN/TN/FP/TP\n\n\n\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\nWhat is wrong about the pattern tell them what you are going to tell, tell and then tell what you told\n\n\n\n\n\nFeb 6, 2025\n\n\n\n\n\n\n\nThe Stickiness Improvement Plan\n\n\n\n\n\nFeb 3, 2025\n\n\n\n\n\n\n\nGet huge benefits for minimal costs after reading\n\n\n\n\n\nJan 28, 2025\n\n\n\n\n\n\n\nThe one thing missing in your perfect presentation\n\n\n\n\n\nJan 27, 2025\n\n\n\n\n\n\n\nThree basic plots - my take\n\n\n\n\n\nJan 25, 2025\n\n\n\n\n\n\n\nBlogging with quarto\n\n\n\n\n\nJan 17, 2025\n\n\n\n\n\n\n\nScience2Art, a lesson in artful prompt engineering\n\n\n\n\n\nJan 15, 2025\n\n\n\n\n\n\n\nClean coders use lambda expressions\n\n\n\n\n\nJan 10, 2025\n\n\n\n\n\n\n\nHow to fight computer eye strain\n\n\n\n\n\nDec 3, 2024\n\n\n\n\n\n\n\nPremature optimization and the importance of algorithms\n\n\n\n\n\nAug 10, 2024\n\n\n\n\n\n\n\nHere is what I learned from thinking fast and slow.\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\nTaylorism in complex environments\n\n\n\n\n\nMar 9, 2024\n\n\n\n\n\n\n\nFrom Challenges to Champions: Unsticking Negative Workplace Stories\n\n\n\n\n\nMay 15, 2023\n\n\n\n\n\n\n\nUnlock the Power of Metaphors at Work to Captivate Your Listeners!\n\n\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\nWaterfall management is a strict recipe, while agility is improvisational cooking.\n\n\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\nEffective Story Spotting\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n\nHow Playing Zelda Teaches Us the Importance of Audience Engagement in Interactive Storytelling\n\n\n\n\n\nApr 16, 2023\n\n\n\n\n\n\n\nIntellectual Dishonesty: Recognizing and Combating Toxic meeting culture\n\n\n\n\n\nMar 4, 2023\n\n\n\n\n\n\n\nUse risk policies and avoid common planning fallacies in software development\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nInvestors are living from the greatest of all treasures, which is Hope\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nThe story of Covid and Plato’s cave allegory\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nSticking in a shitty job, deprives you of rich experiences\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nEverybody wants more money and thinks inflation is unfair\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nGood managers are immune to survivorship bias\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n\nThe perfect way that projects will never be planned\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\nTrust me; I am an expert\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n\nLook at your industry’s state and then decide if you want to become an expert\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n\nThe SAFe confidence vote reveals the state of emotional security in your project\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n\nYou should go back to the office, to help your boss understand you\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\nUse mental anchors to determine the start position of high-stakes discussions\n\n\n\n\n\nNov 1, 2022\n\n\n\n\n\n\n\nTry to establish your next planning predictions on well-defined reference points\n\n\n\n\n\nOct 29, 2022\n\n\n\n\n\n\n\nThe good storyteller is a travel guide through the listener’s memories.\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\nYou are most likely overinsured\n\n\n\n\n\nOct 26, 2022\n\n\n\n\n\n\n\nThere are no losses; just costs for profits\n\n\n\n\n\nOct 26, 2022\n\n\n\n\n\n\n\nRegression to the mean reshapes our memories\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\nWhy engineers do not understand stories\n\n\n\n\n\nOct 19, 2022\n\n\n\n\n\n\n\nExperienced engineers stay away from the flow zone\n\n\n\n\n\nOct 17, 2022\n\n\n\n\n\n\n\nAvoid spending mental energy as if would be limitless\n\n\n\n\n\nOct 12, 2022\n\n\n\n\n\n\n\nA new writer’s easy guide to find the perfect headline\n\n\n\n\n\nOct 12, 2022\n\n\n\n\n\n\n\nProviding fake reliability with statistics\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\nAny fool can criticize, condemn and complain - and most fools do\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\nWorld Sensation, Why remarkably nobody has built your leadership\n\n\n\n\n\nJul 6, 2022\n\n\n\n\n\n\n\nEffective leaders listen for stories that touch the heart and mind\n\n\n\n\n\nJun 20, 2022\n\n\n\n\n\n\n\n4 powerful secrets medium user need to know about leadership\n\n\n\n\n\nJun 5, 2022\n\n\n\n\n\n\n\nThe world requires influential engineers with a passion for stories\n\n\n\n\n\nMay 18, 2022\n\n\n\n\n\n\n\nSuccessful cross-functional teams need the luxury of confidence and trust\n\n\n\n\n\nMay 11, 2022\n\n\n\n\n\n\n\nThree old but trusted ways to reveal your team’s common story\n\n\n\n\n\nMay 9, 2022\n\n\n\n\n\n\n\nGood presenters embrace these psycho tips in their life\n\n\n\n\n\nApr 19, 2022\n\n\n\n\n\n\n\nThe science of influence and storytelling\n\n\n\n\n\nApr 13, 2022\n\n\n\n\n\n\n\nTry these 9 tips to get more and stronger follower growth\n\n\n\n\n\nApr 13, 2022\n\n\n\n\n\n\n\nKnowledge advice: 2 Ways to read a book and improve your understanding\n\n\n\n\n\nApr 9, 2022\n\n\n\n\n\n\n\nTry these priceless mental tricks to gain the upper hand in pointless conflicts\n\n\n\n\n\nFeb 20, 2022\n\n\n\n\n\n\n\nQuotes about storytelling\n\n\n\n\n\nNov 28, 2021\n\n\n\n\n\n\n\nHow find material to read and how to dig through it.\n\n\n\n\n\nNov 26, 2021\n\n\n\n\n\n\n\nUnder construction Gut ist der Vorsatz\n\n\n\n\n\nNov 23, 2021\n\n\n\n\n\n\n\nHow technical is too technical\n\n\n\n\n\nOct 28, 2021\n\n\n\n\n\n\n\nWhy yet another storytelling blog\n\n\n\n\n\nJul 18, 2021\n\n\n\n\n\n\n\nI only understand trainstation\n\n\n\n\n\nJul 7, 2021\n\n\n\n\n\n\n\nFinding your personal blogs purpose and name\n\n\n\n\n\nJul 4, 2021\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#get-away-with-your-weak-points",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#get-away-with-your-weak-points",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "1 Get away with your weak points",
    "text": "1 Get away with your weak points\nLet’s admit it, our chain of reasoning often has a weak point. The art of persuasion consists in getting around those weak points.\nA common strategy is first to explain the most significant negative point and then some smaller ones later. The less negative will stand in the shadow of the bigger. You can use this to your advantage by artificially inflating a negative point. Let’s call it the most obvious negative point. Be prepared to have some solution for this negative point. Then you can reap the reward of hiding your other negative points. However, the most critical part is to focus on the positive news, even if the positive news weighs little. What counts is that you talk more about the positive aspects of your solution than about the negative.\nIf you want to trigger a particular action, but the actual reason to do so is small:\n\nExaggerate the problem.\nContrast it to ridiculously high numbers if the argument is expressible in numbers.\nPresent your solution to the small and unimportant problem.\n\n“Millions of students drink milk, 1000 alone in our community school. Therefore I want to offer free milk.”\nA quick win: use the word “because” in illogical reasoning. The term indicates causality, and its use might make the listener accept a flaw."
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#give-something-to-get-something",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#give-something-to-get-something",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "2 Give something to get something",
    "text": "2 Give something to get something\nProviding free stuff is one of the pillars of the influencer economy. Once your audience is engaged, ask for something in return: a product purchase or a newsletter subscription. The person accepting your offer will feel obliged to return you a favor.\nThe identical process applies to oral presentations. Ask the audience to influence the story. You offer the audience an option. As this seems like a concession on your part, the audience feels obliged to believe you, and you get better buy-in. The trick is that you set up the choices and thus heavily influence the direction."
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#be-a-dealer-of-stories",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#be-a-dealer-of-stories",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "3 Be a dealer of stories",
    "text": "3 Be a dealer of stories\nThere is no one big success in growing your influence. On the contrary, it is better to use many small stories to build a following. Many people only follow to be consistent with their past behavior. Be the dealer who brings the new stuff.\nBonus point: raise expectations. Ask what the reader wants to raise his attention. The receiver of your story thinks he was waiting for it as he committed to it early. It is less important whether he still would decide the same."
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#it-is-the-number-of-followers-that-count",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#it-is-the-number-of-followers-that-count",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "4 It is the number of followers that count",
    "text": "4 It is the number of followers that count\nSocial proof is the driving force behind social media. This was a great secret a few years ago, but today everybody knows it. News with followers attracts attention, regardless of truth or importance.\nSadly, little can be done to be better than the rest of the crowd. Regularly delivering valuable content is the only way to success."
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#the-chameleon-effect",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#the-chameleon-effect",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "5 The chameleon effect",
    "text": "5 The chameleon effect\nIf you want to persuade someone, it helps to be perceived as similar.\nYour message is of secondary importance; what counts is the messenger.\nYou often need to create a bond with the audience before placing your actual message.\nResearch the audience. Be one of them. At best, you are already known to the audience. If necessary, introduce yourself to the audience. Be dressed appropriately.\nThis tip is the essential discipline for every politician. The more varied your audience becomes, the more adaptive you need to be. Important for politicians.\nThe bonus tip: Watch your language. Collectivize any fact using the pronoun “we” instead of “I.”"
  },
  {
    "objectID": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#the-fear-of-missing-out",
    "href": "posts/influence-articles/good-presenters-embrace-these-psycho-tips-in-their-life.html#the-fear-of-missing-out",
    "title": "Good presenters embrace these psycho tips in their life",
    "section": "6 The fear of missing out",
    "text": "6 The fear of missing out\nThe main mantra of the advertisement industry: “7 things you never heard of but need to know.” “Unique chance to learn something.” You need to create an illusion of a once-in-a-lifetime opportunity.\nIf your arguments oppose another topic, you can create a sense of oppressed followers. Instead of providing your opinions, raise the issue that nobody wants to oppose the topic. It seems like false censorship. As a result, the listener feels that your information is more precious than other information."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "",
    "text": "It is not about the message. It is about the messenger.\nIn good old Persia, the messenger was either rewarded for good news or killed for bringing bad news. Even today, the messenger’s image influences the message. The other way round, the messenger draws influence from the message. This relationship is known as the halo effect.\nIt is crucial to have a positive image in other people’s heads. We are all messengers of our ideas. So how can we be liked more?\nThe good news: there are some marvelous tricks. These are known as compliance techniques.\nThe bad news: they largely depend on the predisposition of your communication partner. Do not try them with your arch-enemy. All techniques work best if applied in a neutral or a positive setting."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-bad",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-bad",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "1 The Bad",
    "text": "1 The Bad\n\nUse false concessions to trick the other person into a reciprocating action. This approach certainly is a technique for the master manipulator.\nHow it works: ask for a big favor. If the favor is declined, ask for a much smaller favor. The smaller favor is usually performed. The trick is that the smaller favor was your intended outcome all along. If applied subtle enough, you can increase the gains every time."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-marathon",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-marathon",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "2 The marathon",
    "text": "2 The marathon\n\nBe around long enough, and people will be your friend, just because you were always there. Many countryside neighborhoods work this way: A newcomer is always a stranger, and a long-living inhabitant is always a friend—the essence of many club membership friends.\nHow it works: Every time you meet someone, you create a shared experience; many people stick together because it always used to be like this."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-chameleon",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-chameleon",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "3 The chameleon",
    "text": "3 The chameleon\n\nWhen in Rome, do as the Romans do. Be familiar with the other person. The mirror and match technique of salespeople falls in this category. An advertisement convinces many people to buy something because it addresses their specific way of living.\nHow it works: familiarity makes us lower our guards and throw away any caution. Most people trust their family and friends without question."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-predator",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-predator",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "4 The predator",
    "text": "4 The predator\n\nIf you want to be a friend of someone, it is best to single him out and create an extra room where the two of you spend time together. You might not become friends if you are together at a massive concert hall. On the contrary, there is a much higher chance that you will become friends in a small art venue.\nHow it works: Direct personal communication is most effective if you want something. Group ignorance kicks in if you request something from a group."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-classic-socializer",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-classic-socializer",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "5 The classic socializer",
    "text": "5 The classic socializer\n\nThere are, of course, the good old classic tips. Dale Carnegie has written an extensive list about this category. Be similar to the other person or appear to be (a chameleon). Be well-groomed and make compliments.\nHow it works: This is purely attributable to the halo effect. Because we behave friendly and polite, we certainly are nice and trustful."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-team-player",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-team-player",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "6 The team player",
    "text": "6 The team player\n\nBe in a team with the other person and strive to achieve a higher goal.\nHow it works: This alone will make many principles work for you. The collaboration principle is undoubtedly the most important. You are working publicly and effortful towards a common goal."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-specialist",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-specialist",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "7 The specialist",
    "text": "7 The specialist\n\nThis stereotype is one of the more controversial ones. Sometimes people seem impressive because they hold a fancy title or a called an expert in something. We all need a friend we can call if our computer stops working. Who does not ask his doctor-friend about some illness?\nHow it works: Obeying an authority can make life easy. And such authority symbolizes power. Associating us to power rubs some of it on ourselves."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-dressman",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-dressman",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "8 The Dressman",
    "text": "8 The Dressman\n\nThe shiny uniform of the policeman seems more attractive than the rags of the hobo. Dress to impress.\nHow it works: This is another classic. Because we look lovely, we certainly are a pleasant fellow."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-diva",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#the-diva",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "9 The Diva",
    "text": "9 The Diva\n\nPresent yourself as a rare resource. You only have time this very day. It is extraordinary that you are even in town—some people’s dating technique.\nHow it works: Be available for some time. Then suddenly be less present, creating a scarcity of you. The desire for you will increase."
  },
  {
    "objectID": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#learning-from-other-people",
    "href": "posts/influence-articles/try-these-tips-to-get-more-and-stronger-follower-growth.html#learning-from-other-people",
    "title": "Try these 9 tips to get more and stronger follower growth",
    "section": "10 Learning from other people",
    "text": "10 Learning from other people\nDo you recognize yourself in any of those? Go to a well-frequented coffee shop. Sit down and do some people-watching. Do you recognize any of those stereotypes? Try to be inspired by other people."
  },
  {
    "objectID": "posts/influence-articles/the-science-of-influence-and-storytelling.html",
    "href": "posts/influence-articles/the-science-of-influence-and-storytelling.html",
    "title": "The science of influence and storytelling",
    "section": "",
    "text": "In my previous blog post, I asked different questions.\nI want to start with the last one: \nWhy apply the principles of psychological influence in your communication?\nThere are two reasons why to use them.\n\nBy getting more familiar with their application, we get more sensitive if other people want to exploit us.\nWe can use these principles can also be used to help other people understand our viewpoint better. As Cialdini originally stated, there are too valuable to be abused to our disadvantage. But we can use them with a more positive intention that enables a win-win for our partner and us.\n\nAnd with this, I want to answer the two initial questions:\n How to apply these principles? How to defend against triggers?\nThe principles have many applications. Therefore, I want to look to the purpose of this blog: storytelling. I came up with the following questions:\n\nHow to use these principles to become a better storyteller?\nHow to form stories at the workplace from a social context?\nThe messenger’s image influences the message and vice-versa. It is therefore vital to be likable. How can we be liked more?\nHow to use the principles to transport business ideas better? How to use them to promote our ideas in technology and social engineering?"
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "",
    "text": "Imagine your last stressful situation. Your face is getting red. You start to stammer and justify yourself. What if you had some superpowers that prevent these things from happening?\nThe book “Influence” by R. Cialdini deals with the psychology of influencing other people. He describes the conscious and unconscious actions to sway other people in our desired direction. My intention is not to provide a summary of the book. Different people have done an excellent job on this, such as this one.\nUnderstanding is always the first step. I will point out where you might have come under the influence of these principles. And how you can defend against it the next time."
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#we-give-and-we-take",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#we-give-and-we-take",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "1. We give, and we take,",
    "text": "1. We give, and we take,\nCommunication is about giving and taking. We listen, and we expect to be listened to in return. Communication can also consist of following someone and being followed. This action relates to the principle of reciprocation. It relies on the fact that favor is to be met with favor. A frequent exploitation is to provide “false” favors. Sometimes your adversary will present this favor as a concession on his part. Then you feel obliged to meet it with a reciprocal concession.\nA genuinely gifted exploiter can not be spotted. He will always find the sweet spot of having his advantage. Worse, did you ever wonder why some people never give something in some groups? And why do they get away with it? The explanation is that we adapt to unfavorable give-take balances. This misbalance is especially treacherous as there is no defense over a longer time frame. If you conclude that you are always on the losing side one day, this principle could have been at work.\n\nDefend against hidden agendas\nIn my opinion, a robust value system is essential. Actively remind yourself what you want to achieve. Why do you do something? In what manner do you want to accomplish a task?"
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#little-strokes-fell-great-oaks",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#little-strokes-fell-great-oaks",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "2. Little strokes fell great oaks",
    "text": "2. Little strokes fell great oaks\nWe all want our actions to chain to each other like a red thread. We want to be consistent with our past actions. Our actions are repeated commitments to ourselves. And if we’re going to have a strong story, we need consistency in our commitments.\nA strong story and red thread is the path to a fulfilled life.\nHowever, it makes us predictable and, in consequence, exploitable. Your aggressor will use an elaborated strategy to move you to a particular action. Somebody else can ask you to perform acts of ever-increasing size, which are more to his advantage than to yours. Long periods with repeated commitments are required.\nUsually, you start this chain of your own choice. So eventually, everything seems to have been your choice. At work, many group meetings work with this principle. In addition, “commitments are most effective when they are active, public, and effortful.” That is why you have such a hard time getting out of the situation.\n\nReflection is the key\nLuckily there are two good defenses. First, listen to your stomach. If it tells you there is something wrong early on, take a step back. Secondly, while listening deeply into your body, ask the following questions: “With all I know now, would I decide differently?”, “Would I make the same choice again?”. Your subconsciousness will answer with a feeling of uneasiness. You then can clearly explain to the other party why you will back out of the deal without getting angry."
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#nobody-wants-to-be-alone",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#nobody-wants-to-be-alone",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "3. Nobody wants to be alone",
    "text": "3. Nobody wants to be alone\nWe laugh if other people laugh. We are brave if other people are brave. We are social animals, and as such, we have a social autopilot that usually guides us. This primitive part of our brain is the power source of group dynamics. People exploit this by fake triggers or false authenticity.\n\nLearn to read the crowd\nA natural resistance comes with the label of a loner. But try this: Become sensitive to situations where the autopilot works with inaccurate information—false laughter, rehearsed dialogues, and the key trigger in a business context: fake authenticity.\nYou will require a good knowledge of humans. Looking at a group of people, do you notice something strange in their behavior? Do words and action not fit together?"
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#we-all-want-to-be-liked",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#we-all-want-to-be-liked",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "4. We all want to be liked…",
    "text": "4. We all want to be liked…\n… and we all want to like other people.\n“He was such a nice person…” is the quote regarding your local neighborhood serial killer. Being liked is something we all desire. Many know that attractiveness, similarity, familiarity, and compliments make us more desirable.\nIn addition to these four, there is also a less known fifth factor: cooperation. Cooperation is an active association of ourselves to somebody. There is also guilt by association; the famous reputation is all about this. This effect is known as the halo effect. It works for things and attitudes, even the language. Suppose your opponent is saying “We” vs. “You” or “They.” in that case. In that case, they try to shift possession of the subject under discussion. The messenger is associated with the message.\n\nThe art of the deal\nMaybe that is not what Donald Trump meant but focus on the deal. Separate the message from the messenger. This approach will protect you against the lighter cases.\nThe more notable cases are easier to spot.\nIf you like somebody quicker than expected, reflect on whether he stands to gain. The stronger the effects, the more likely you will discover them with this defense. Think insurance broker or car dealership."
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#following-is-easy",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#following-is-easy",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "5. Following is easy",
    "text": "5. Following is easy\nAuthority has a place in the world. No order without authority. The fraudulent authority also concerns the designation of experts and therefore is highly relevant in work environments. The trick is to tell apart the real from the fraudulent authority.\n\nLearn to read humans\nTwo questions reveal the manipulator: “Is this authority truly an expert?”, “How truthful can we expect the expert to be here?” Car dealerships, advertisements, clothing styles, and titles are just the tip of the iceberg. Many applications are much more subtle. Especially in work environments, people quickly title themself as an expert."
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#fear-of-missing-out",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#fear-of-missing-out",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "6. Fear of missing out",
    "text": "6. Fear of missing out\nThe final principle is widely in action today—the principle of scarcity. “Last item in stock, no new delivered” - this slogan tries to coerce you into spot buying?\nThis human reaction to such an offer results from a limitation of future freedom of choice—the choice to buy.\nThere are many examples: restricted teenage love or media manipulation-exceptional messages seem more critical than abundant messages.\nThis principle relates to the contrast principle. Everything in the world is relative. The bad news needs to be even worse if everything else is terrible.\n\n“There is neither luck nor bad luck in the world, there is only the comparison from one state to the other”\n— Monte Christo\n\n\nBe self-aware\nFor buying stuff, the defense is easy:\n\n\nListen for the internal arousal that accompanies the perception of scarcity. “The joy is not in experiencing a scarce commodity but in possessing it.”\n\n\nAsk yourself why do you want it. Owning or using?\n\n\nFor information, we need to treat the messenger as an authority. As such, the defense against authority comes into play."
  },
  {
    "objectID": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#how-to-apply-the-principles-without-being-unfair",
    "href": "posts/influence-articles/try-these-priceless-mental-tricks-to-gain-the-upper-hand-in-pointless-conflicts.html#how-to-apply-the-principles-without-being-unfair",
    "title": "Try these priceless mental tricks to gain the upper hand in pointless conflicts",
    "section": "How to apply the principles without being unfair",
    "text": "How to apply the principles without being unfair\nThe best defense is the offense. How can you use the principles to frame ideas? In a series of articles, I will not only show how the principle influences you but how you can influence others in your communication."
  },
  {
    "objectID": "posts/made-to-stick/how-to-avoid-burying-the-lead.html",
    "href": "posts/made-to-stick/how-to-avoid-burying-the-lead.html",
    "title": "How to avoid burying the lead",
    "section": "",
    "text": "Learn to nail it"
  },
  {
    "objectID": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#how-not-to-present",
    "href": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#how-not-to-present",
    "title": "How to avoid burying the lead",
    "section": "1 How not to present",
    "text": "1 How not to present\nThere I was, standing in front of my peers and supervisors, poised to deliver a presentation on the science of metal strength. But it was going to be a failure of mental strength. My slides were thorough, my research meticulous—I was ready. Or so I thought. What unfolded next was a crash course in how not to deliver a presentation.\nAs I launched into the technical intricacies of metals, I saw it happening: glazed eyes, shifting seats, and disinterested glances. I soldiered on, believing that more context would do the job. When the session concluded, I received a blunt critique from my supervisor that hit me hard.\n“That was horrible. You lost them within the first five minutes.”\nAt that moment, I realized he was right. I had failed to connect. I hadn’t just buried the lead—I’d buried the audience under a mountain of unnecessary details. They didn’t need a crash course in material science; they needed the essentials, presented clearly and engagingly.\nIn an effort to improve, I sought inspiration from an unexpected place: journalism. Journalists excel at presenting complex information in a way that captures attention and keeps readers engaged. The most important thing for a journalist is: do not bury the lead."
  },
  {
    "objectID": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#start-with-the-most-important-information",
    "href": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#start-with-the-most-important-information",
    "title": "How to avoid burying the lead",
    "section": "2 Start with the Most Important Information",
    "text": "2 Start with the Most Important Information\nJournalists use the “Five Ws and One H” — who, what, when, where, why, and how. Hook the audience by answering their most pressing questions upfront, and leave the deep dives for later.\n\n2.1 One sentence you have\nNot all information is equally valuable. Through a method called “Forced Prioritization,” I began ranking my talking points by significance. What does the audience really need to know? If you only have one sentence, drop what can wait. If you say three things, you say nothing.\n\n\n2.2 The Inverted Pyramid\nBecause burying the lead is undesirable, journalists place the most significant details first in their stories. Layer more information as fundament.\nApplying this “Inverted Pyramid” in presentations allows your audience to grasp the key points even if their attention wanes. For me, this meant reordering my slides and ensuring the big ideas were front and center."
  },
  {
    "objectID": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#the-takeaway",
    "href": "posts/made-to-stick/how-to-avoid-burying-the-lead.html#the-takeaway",
    "title": "How to avoid burying the lead",
    "section": "3 The Takeaway",
    "text": "3 The Takeaway\nThe sting of failure taught me the value of clear communication.\nThese techniques transformed my approach. Forced Prioritization ensured I addressed what mattered most, while the Inverted Pyramid helped me build my delivery for clarity.\nApplying journalistic principles to my presentations didn’t just make them better—it made them resonate. Whether you’re presenting science, pitching an idea, or telling a story, the formula is simple: lead with what matters and only tell one thing\nMy audience may not remember every detail about metal strength, but now, they’ll remember me as someone who knows how to deliver a message."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html",
    "title": "Engineering presentations that stick",
    "section": "",
    "text": "As an engineer, it is important to deliver good presentations to a non technical audience"
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#storytelling-for-engineers",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#storytelling-for-engineers",
    "title": "Engineering presentations that stick",
    "section": "1 Storytelling for engineers",
    "text": "1 Storytelling for engineers\nTeaching is an art and science. Made to Stick by Chip and Dan Heath provides powerful strategies to help educators create lessons that students will remember. Let’s unpack some practical ideas from the book in the context of engineering."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#simple-anchor-new-ideas-in-existing-knowledge",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#simple-anchor-new-ideas-in-existing-knowledge",
    "title": "Engineering presentations that stick",
    "section": "2 Simple: Anchor New Ideas in Existing Knowledge",
    "text": "2 Simple: Anchor New Ideas in Existing Knowledge\n\nAutomobile = Horseless Carriage\nSimplify concepts by connecting them to what students already know. Analogies like “Automobile = Horseless Carriage” help students grasp unfamiliar ideas quickly.\nGenerative Analogies\nUse creative comparisons. For instance, mugs as variables explain type-safe programming: A mug (container) can only hold coffee if it’s designed for coffee. Similarly, a variable can only hold data of a specific type.\nSchemas Simplify Complexity: The Pomelo Schema\nTeach complex ideas by creating schemas. For example, explain that a pomelo is “like a big grapefruit” before adding more details.\nThe Inverted Pyramid: Burying the Lead\nStart lessons with the most important takeaways (the lead) and add details later, mirroring effective journalism.\nSimplicity, Storytelling, and Sensory Learning\nStrip away jargon and focus on what matters. Use storytelling to engage emotions and sensory details to reinforce memory."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#unexpected-hook-students-with-curiosity-gaps",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#unexpected-hook-students-with-curiosity-gaps",
    "title": "Engineering presentations that stick",
    "section": "3 Unexpected: Hook Students with Curiosity Gaps",
    "text": "3 Unexpected: Hook Students with Curiosity Gaps\n\nThe Gap Theory\nOpen lessons with a mystery or curiosity gap to ignite interest. Example: “Why don’t Saturn’s rings fall apart?” Engage students by solving the mystery together.\nStories Like the San Diego Zoo’s Food-Stealing Pony\nUnexpected anecdotes, like a pony stealing food from visitors, captivate attention and make abstract concepts memorable.\nLessons from Nora Ephron’s Journalism Teacher\nEphron’s teacher taught storytelling by asking students to focus on what really matters. (Headline: “Governor’s Press Secretary Says No School Next Thursday.”)"
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#concrete-make-lessons-tangible",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#concrete-make-lessons-tangible",
    "title": "Engineering presentations that stick",
    "section": "4 Concrete: Make Lessons Tangible",
    "text": "4 Concrete: Make Lessons Tangible\n\nTeaching Functions with Crickets\nInstead of abstract math problems, use relatable examples like counting cricket chirps to estimate temperature. Students understand faster when lessons are grounded in the real world.\nThe Velcro Theory of Memory\nFacts stick when they’re tied to vivid sensory or emotional experiences. Use concrete objects, stories, or metaphors in lessons.\nRole-playing\nElliott’s “Brown Eyes, Blue Eyes” exercise made abstract concepts like discrimination tangible for elementary students. Role-playing fosters empathy and deep learning."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#credibile-build-trust-in-your-lessons",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#credibile-build-trust-in-your-lessons",
    "title": "Engineering presentations that stick",
    "section": "5 Credibile: Build Trust in Your Lessons",
    "text": "5 Credibile: Build Trust in Your Lessons\n\nThe NBA and AIDS Education\nStudents trusted AIDS education campaigns endorsed by NBA players because credible messengers shared the message. Invite relatable figures to reinforce important lessons.\nThe Bacteria-Drinking Scientist\nA scientist proving his theory by drinking bacteria emphasizes conviction and credibility. Use demonstrations to drive home your point.\nThe Human Scale Principle\nTeach big numbers (like population growth) by relating them to human experiences. For example, “If the world were a village of 100 people…” makes statistics meaningful."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#emotional-tug-on-heartstrings",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#emotional-tug-on-heartstrings",
    "title": "Engineering presentations that stick",
    "section": "6 Emotional: Tug on Heartstrings",
    "text": "6 Emotional: Tug on Heartstrings\n\nThe Dilution of Sportsmanship\nUse real-life examples, like fading sportsmanship, to connect lessons to values students care about.\nWhy Study Algebra?\nAnswer students’ existential “why” questions with relatable, inspiring examples that connect the subject to real-life applications.\nVoters Who Vote Against Self-Interest\nDiscussing surprising human behaviors fosters deep thinking and emotional engagement."
  },
  {
    "objectID": "posts/made-to-stick/engineering-presentations-that-stick.html#stories-inspire-and-teach-through-narratives",
    "href": "posts/made-to-stick/engineering-presentations-that-stick.html#stories-inspire-and-teach-through-narratives",
    "title": "Engineering presentations that stick",
    "section": "7 Stories: Inspire and Teach Through Narratives",
    "text": "7 Stories: Inspire and Teach Through Narratives\n\nStories as Flight Simulators\nStories allow students to mentally rehearse scenarios, just as pilots train with flight simulators. Use case studies, role plays, and simulations to build real-world skills.\nThe Three Inspiring Story Types\n\nChallenge Stories: Overcoming obstacles (e.g., “The Wright Brothers’ First Flight”).\nConnection Stories: Building relationships (e.g., teamwork in the NBA).\nCreativity Stories: Innovating solutions (e.g., Velcro’s invention)."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html",
    "title": "Three basic plots - my take",
    "section": "",
    "text": "The hero’s journey is central to many stories."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html#storytelling-templates",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html#storytelling-templates",
    "title": "Three basic plots - my take",
    "section": "1 Storytelling templates",
    "text": "1 Storytelling templates\nIn storytelling, most of us think of classics like Overcoming the Monster, Rags to Riches, or The Quest.. We can relate many of these templates to the hero’s journey. The authors of Made to Stick argue for three different plots that create sticky, impactful stories: the Challenge Plot, the Connection Plot, and the Creativity Plot.\nHere’s how these plots work and why they might just be the key to your next breakthrough moment."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html#the-challenge-plot-david-vs.-goliath",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html#the-challenge-plot-david-vs.-goliath",
    "title": "Three basic plots - my take",
    "section": "2 The Challenge Plot: David vs. Goliath",
    "text": "2 The Challenge Plot: David vs. Goliath\nThe Challenge Plot is about defying the odds. Think of underdog stories. Think of Rosa Parks taking a stand or the rebels in Star Wars fighting against the Empire. The key? The obstacles must appear enormous.\nChallenge plots are powerful because they inspire us to dig deep, persevere, and take bold action. They make us believe that we, too, can overcome adversity—whether it’s launching a startup or finishing a marathon. It helps to turn your message into a proverb.\nUse this plot when you want to inspire courage and grit. Examples are a high-stakes team kickoff or when motivating people to embrace ambitious goals. Use it, if you face a group of yes sayers."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html#the-connection-plot-building-bridges",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html#the-connection-plot-building-bridges",
    "title": "Three basic plots - my take",
    "section": "3 The Connection Plot: Building Bridges",
    "text": "3 The Connection Plot: Building Bridges\nConnection Plots are about relationships. They bridge gaps—racial, social, religious, or even generational. Think of the parable of the Good Samaritan or stories of unlikely friendships overcoming prejudice.\nThese plots appeal to our humanity, encouraging compassion and collaboration. It does not matter if it’s a heartwarming tale of neighbors helping each other after a disaster or a story about a team uniting for a cause. Connection Plots make us want to be better people.\nUse this plot when your goal is to foster teamwork, empathy, or unity—perfect for a company celebration or a social campaign."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html#the-creativity-plot-aha-moments",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html#the-creativity-plot-aha-moments",
    "title": "Three basic plots - my take",
    "section": "4 The Creativity Plot: Aha! Moments",
    "text": "4 The Creativity Plot: Aha! Moments\nThe Creativity Plot is about ingenuity and problem-solving. Think Newton’s apple moment or a health worker in Zambia who solved a complex logistics issue by thinking outside the box. These are stories of innovation, where cleverness triumphs over constraints.\nSpringboard stories fall under this category. They help people see possibilities, combat skepticism, and foster buy-in. No dry statistics needed—just a compelling narrative that sparks a “What if?”\nUse this plot when introducing new ideas, launching projects, or overcoming resistance to change."
  },
  {
    "objectID": "posts/made-to-stick/three-basic-plots-my-take.html#making-it-stick",
    "href": "posts/made-to-stick/three-basic-plots-my-take.html#making-it-stick",
    "title": "Three basic plots - my take",
    "section": "5 Making It Stick",
    "text": "5 Making It Stick\nWant to inspire action? Tailor your plot to your audience and goal:\n\nChallenge Plots: Inspire perseverance.\nConnection Plots: Build relationships.\nCreativity Plots: Foster innovation.\n\nForget generic plots like Rags to Riches. The Challenge, Connection, and Creativity Plots from Made to Stick are your secret weapon to create stories that resonate—and inspire change.\nSo, which plot will you use next?"
  },
  {
    "objectID": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html",
    "href": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html",
    "title": "Breaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication",
    "section": "",
    "text": "Maybe the little boy is you, when you listened to your teachers and could not understand a word and rather wanted to go home and play video games?"
  },
  {
    "objectID": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#how-antoine-became-stupid",
    "href": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#how-antoine-became-stupid",
    "title": "Breaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication",
    "section": "1 How Antoine became stupid",
    "text": "1 How Antoine became stupid\nAntoine believed his intelligence was his greatest obstacle to happiness. Tired of feeling out of sync with the world, he embarked on a bizarre journey to simplify his mind. He tried alcohol, therapy, even surgery—all to silence his overthinking and live a more “normal” life.\nAntoine is the protagonist of How I Became Stupid by Martin Page. This satire-filled story isn’t just a critique of modern consumerism, but illustrates how over-complication can lead to paralysis. Antoine’s struggle reflects a deeper issue we all face: the Curse of Knowledge."
  },
  {
    "objectID": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#being-simple-is-difficult",
    "href": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#being-simple-is-difficult",
    "title": "Breaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication",
    "section": "2 Being simple is difficult",
    "text": "2 Being simple is difficult\nAn accurate idea that’s useless remains just that—useless. This is the core of the Curse of Knowledge. As we gain ability, it becomes harder to communicate our insights so others can understand. What’s obvious to us feels obscure to everyone else. Like Antoine, trapped in his hyper-analytical mind, experts and leaders often get stuck, unable to simplify their knowledge into actionable insights.\nMade to Stick’s SUCCES principles (Simple, Unexpected, Concrete, Credible, Emotional, Stories) rely on clarity, yet the Curse of Knowledge undermines them. It’s the classic “tapper-listener” problem: tappers, who know the song they’re tapping, can’t imagine what it’s like for listeners to not know it. This misalignment crops up everywhere—from CEOs giving instructions to engineers explaining technicalities. The disconnect isn’t mutual. The burden falls on the expert to simplify."
  },
  {
    "objectID": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#how-to-break-the-curse-of-knowledge",
    "href": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#how-to-break-the-curse-of-knowledge",
    "title": "Breaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication",
    "section": "3 How to Break the Curse of Knowledge",
    "text": "3 How to Break the Curse of Knowledge\nYou have two choices:\n\nLearn Nothing (or Pretend You Don’t Know): While Antoine’s extreme approach isn’t recommended, you can mimic it by actively recalling what it was like not to know something. Step into your audience’s shoes.\nTransform Your Ideas: Translate complex insights into their simplest form. Don’t assume context—create it."
  },
  {
    "objectID": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#the-curse-of-knowledge-affecting-your-job",
    "href": "posts/made-to-stick/breaking-the-curse-of-knowledge-why-simplicity-is-the-ultimate-sophistication.html#the-curse-of-knowledge-affecting-your-job",
    "title": "Breaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication",
    "section": "4 The curse of knowledge affecting your job",
    "text": "4 The curse of knowledge affecting your job\nDid you ever fail to explain a complex topic to a superior?\n\n\n\n\n\n\nNote\n\n\n\nThe fault lies with the experts that need to come down to the basic level. \n\n\nAt first glance, hierarchy plays a role. The expert can always teach his students. But what about an everyday situation where the expert has to explain to his superior?\nAs highlighted in The Ferrari’s Go to Disney World, this isn’t about hierarchy. Here, the customer is the novice.\nWhether the expert holds a higher or lower position, the challenge remains the same: convey ideas in a way that resonates. The customer might be the novice, but they hold decision-making power.\n\n4.1 Use Simplification to bridge the gap\nThere are two stages to solving a problem. The answer stage and the telling to others stage.\nMost organizations heavily invest in teaching people how to arrive at answers, but teach little how to communicate those answers. Factors that help develop expertise—nuance, depth, and precision—become liabilities in communication. Success isn’t just about finding answers; it’s about telling them in ways others can hear.\nAntoine’s first reflex is to just focus on stage 2. As the book shows, he becomes successful but not happy. Somewhere in the middle ground is the key. Antoine’s extreme journey shows a truth: intelligence and insight are insignificant without effective sharing. Simplicity, not complexity, is often the key to success."
  },
  {
    "objectID": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html",
    "href": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html",
    "title": "Decision paralysis at a McDonalds",
    "section": "",
    "text": "Yummy."
  },
  {
    "objectID": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#i-always-go-for-the-cheeseburger",
    "href": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#i-always-go-for-the-cheeseburger",
    "title": "Decision paralysis at a McDonalds",
    "section": "I always go for the cheeseburger",
    "text": "I always go for the cheeseburger\nEver walked into McDonald’s, stared at the vast menu, and ended up ordering your default choice? That’s me. I always go for the double cheeseburger. Despite the tempting offers, I rarely stray from my go-to. Why? Decision paralysis combined with pressure. And it’s not just about fast food; it sneaks into our work lives, too. Let me show you how."
  },
  {
    "objectID": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#decision-paralysis-leads-to-irrational-choices",
    "href": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#decision-paralysis-leads-to-irrational-choices",
    "title": "Decision paralysis at a McDonalds",
    "section": "Decision Paralysis Leads to Irrational Choices",
    "text": "Decision Paralysis Leads to Irrational Choices\nOn a recent project, my team faced a critical decision: choosing the material for modular dishwasher rack joints. We had several solid options. Each supplier provided a material according to our specification. However, the contract specifics were different. We devoted weeks to analyze sales forecasts and market trends to make the “perfect” choice.\nThen, an unexpected email arrived. A previously unavailable supplier offered the best material by far. We jumped at it, feeling an odd sense of relief, even though the price was quite high and the contract had a long duration. But was this the right decision? Not really, it was irrational.\nHere’s why: the material was great, but all the other materials were sufficient for our use case. Our exhaustive analysis led to a mental gridlock, and when a simple answer appeared, we grabbed it. This is a textbook case of decision paralysis leading to irrational actions."
  },
  {
    "objectID": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#how-to-beat-decision-paralysis",
    "href": "posts/made-to-stick/decision-paralysis-at-a-mcdonalds.html#how-to-beat-decision-paralysis",
    "title": "Decision paralysis at a McDonalds",
    "section": "How to Beat Decision Paralysis",
    "text": "How to Beat Decision Paralysis\n\n1. Set Clear Goals\nEstablish time boundaries for decision-making. If we had set a timeline to review supplier data and complete our choice, the late offer wouldn’t have derailed us. Goals provide focus and reduce the overwhelm of endless options.\n\n\n2. Adopt Simple Policies\nPolicies streamline choices. For example, at McDonald’s, a personal policy like “always pick the promotion” adds variety and saves mental energy. At work, policies guide teams to prioritize action over analysis paralysis.\n\n\n3. Setting policies for others\nIf you’re crafting policies for others, make them memorable. A simple proverb can work wonders. Think: _ “Under the Golden Arches’ care, find a tasty deal and a moment to share.” _ The message stresses the deal, the promotion offer, and fosters adherence without overthinking."
  },
  {
    "objectID": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html",
    "href": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html",
    "title": "What is wrong about the pattern tell them what you are going to tell, tell and then tell what you told",
    "section": "",
    "text": "flight-anouncement.jpg"
  },
  {
    "objectID": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-problem-with-repetition",
    "href": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-problem-with-repetition",
    "title": "What is wrong about the pattern tell them what you are going to tell, tell and then tell what you told",
    "section": "1 The Problem with Repetition",
    "text": "1 The Problem with Repetition\nIf you have visited a communication seminar, you may have come across the old communication formula: “tell them what you’re going to tell, tell them, and then tell them what you told”. This formulaic approach to communication relies on repetition, which often flattens engagement.\nBeginners will find this perfectly suitable, as it clarifies points. However, it lacks emotional impact and quickly becomes predictable.\nToday’s audiences, that are subjected to constant information overload, need more than just facts: they want stories, surprises, and insights that cut through the noise.\nFlight safety announcements illustrate this principle perfectly. Traditional ones, filled with the same old safety reminders, cause passengers to tune out. But when airlines add humor, dramatize scenarios, or weave in storytelling, they break the pattern and seize attention."
  },
  {
    "objectID": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-power-of-surprise-and-interest",
    "href": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-power-of-surprise-and-interest",
    "title": "What is wrong about the pattern tell them what you are going to tell, tell and then tell what you told",
    "section": "2 The Power of Surprise and Interest",
    "text": "2 The Power of Surprise and Interest\nHumans adapt to new consistent patterns rapidly. To constantly surprise, you must break expectations and thus trigger genuine focus.Take a car add that ends with a tragic accident, and is in fact an add for road safety.\nSurprise instantly disrupts the brain’s “guessing machine” and forces people to think actively (raising eyebrows, dropping jaws).\nInterest keeps us engaged once we’ve been surprised. Conspiracy theories and gossip thrive because they create knowledge gaps that we feel compelled to fill.\nThe challenge for every communicator with an important message: strategic “planned unexpectedness” should strengthen a core message rather than just generate cheap thrills."
  },
  {
    "objectID": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#breaking-and-rebuilding-the-guessing-machine",
    "href": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#breaking-and-rebuilding-the-guessing-machine",
    "title": "What is wrong about the pattern tell them what you are going to tell, tell and then tell what you told",
    "section": "3 Breaking and Rebuilding the Guessing Machine",
    "text": "3 Breaking and Rebuilding the Guessing Machine\nSurprise alone is not enough. To make ideas stick, you must first break people’s assumptions and then help them rebuild their mental models.\nBegin by clarifying the one thing you want them to remember, then expose an unexpected truth that challenges their beliefs. Present it in a way that forces them to pause and reconsider. Finally, guide them toward a realization that feels obvious in hindsight.\nPsychologists call this obvious hindsight “postdictability.” In contrast, common sense, the enemy of sticky messages, lulls people into complacency. By deliberately violating it, you engage the audience’s deeper reasoning processes (their “System 2”) and lead them to an “I could have guessed that” moment once the surprise is explained. Here again, the challenge is to do it without descending into gimmicks. Suprise alone is not enough"
  },
  {
    "objectID": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-gap-theory-of-curiosity",
    "href": "posts/made-to-stick/what-is-wrong-about-the-pattern-tell-them-what-you-are-going-to-tell-tell-and-then-tell-what-you-told.html#the-gap-theory-of-curiosity",
    "title": "What is wrong about the pattern tell them what you are going to tell, tell and then tell what you told",
    "section": "4 The Gap Theory of Curiosity",
    "text": "4 The Gap Theory of Curiosity\nOnce you have your audience’s attention, the challenge becomes to keep it. You need to kindle their curiosity. Whenever we perceive a gap between what we know and what we want to know, we experience a mental itch we’re driven to scratch.\nTo harness this, open with a puzzle or a provocative claim: “There’s an invisible chemical in your home—and it might kill you right now.”\nYou can suggest that someone else holds crucial information, hint at unresolved mysteries, or you can challenge the audience to predict an outcome.\nThis approach works in everything from sports events to fundraising campaigns, even daily politics.\nThere are two extreme cases: people who think they know everything and those who know nothing. For the first, make them publically commit to a prediction. This makes them more curious as they have had an active say. The second group is best told some points that act as a reference system on their blank canvas.\nInstead of spoon-feeding the facts in chronological order, start with a haunting question or puzzling hypothesis. Actively hide information to reveal it later. Use mystery in your presentation. Only after you’ve sparked curiosity do you reveal the facts. Ensure your audience stays hooked until the gap is closed and your message sticks."
  },
  {
    "objectID": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#meta-what",
    "href": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#meta-what",
    "title": "Unlock the Power of Metaphors at Work to Captivate Your Listeners!",
    "section": "1 Meta-what?",
    "text": "1 Meta-what?\nAs a schoolboy, I often found myself grappling with the concept of metaphors. While trying to decipher their meanings in literary texts, the idea of crafting my own metaphors seemed like a daunting task.\nIf you’ve ever felt overwhelmed or confused when someone talks about metaphors, fear not! I’ve been in your shoes. Like many others, I struggled to understand how to make meaningful comparisons that would bring life to my expression. So, let’s dive right in and unlock the world of metaphors together!’"
  },
  {
    "objectID": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#the-metaphor-crafting-table",
    "href": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#the-metaphor-crafting-table",
    "title": "Unlock the Power of Metaphors at Work to Captivate Your Listeners!",
    "section": "2 The metaphor crafting table",
    "text": "2 The metaphor crafting table\nThe metaphor crafting table consists of six categories. Each category comes with a rule that you should follow. Follow the two examples for a general understanding.\n\n\n\n\n\n\n\n\n\nTip\nRule\nExample 1\nExample 2\n\n\n\n\n1. Look for connections\nConsider qualities/characteristics of the subject and find similarities in other objects, people, or concepts.\nShe is a rubber band, always bouncing back from adversity.\nHis life is like a speeding train, always rushing forward.\n\n\n2. Use your senses\nRelate the subject to your senses (sight, sound, taste, touch, smell) for unique and vivid comparisons.\nHer voice was like velvet, soothing and comforting.\nThe city was a symphony, with each neighborhood playing its own unique tune.\n\n\n3. Explore idioms and proverbs\nLook up idioms and proverbs related to the theme or subject and use them to inspire a metaphor.\nHe found himself between a rock and a hard place, unable to choose between his career and his family.\nAs a new employee, she was still green behind the ears, learning the ropes of the job.\n\n\n4. Tap into emotions\nThink about the emotions evoked by the subject and find other things that elicit the same emotions for an emotional connection.\nHer absence was like an empty chair, a constant reminder of the love that was missing.\nReaching his goal felt like standing on the summit, breathing in the crisp air of accomplishment.\n\n\n5. Get inspired by nature\nRelate the subject to natural phenomena found in nature, such as life cycles, seasons, and natural events.\nHis personal growth was like a caterpillar becoming a butterfly, emerging stronger and more beautiful than before.\nHer beauty was like cherry blossoms, delicate and ephemeral.\n\n\n6. Observe the world around you\nPay attention to the environment, people, and situations around you for inspiration from everyday life.\nThe office was like a busy marketplace, with people shouting and scurrying in all directions.\nHe was like a Swiss Army knife, always having the right tool for any situation."
  },
  {
    "objectID": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#the-secret-to-applying-metaphors",
    "href": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#the-secret-to-applying-metaphors",
    "title": "Unlock the Power of Metaphors at Work to Captivate Your Listeners!",
    "section": "3 The secret to applying metaphors",
    "text": "3 The secret to applying metaphors\nEverybody knows that practice makes permanent. That’s the secret. Use them. And what better place than using them at work.\nHere is your Mission, should you choose to accept it. Read through the tables. Pick one category per week. Try to apply metaphors when those situations arise.\n\n3.1 Challenges or Difficult Situations\n\n\n\n\n\n\n\nMetaphor\nExplanation\n\n\n\n\nNavigating a minefield\nFacing a difficult or sensitive situation\n\n\nSwimming with sharks\nDealing with ruthless or cunning colleagues\n\n\nHitting a glass ceiling\nFacing barriers to career progression\n\n\nWalking on eggshells\nBeing cautious to avoid offending others\n\n\nStepping on toes\nInadvertently offending or upsetting others\n\n\n\n\n\n3.2 Teamwork, Collaboration, and Management\n\n\n\n\n\n\n\nMetaphor\nExplanation\n\n\n\n\nThe office is a beehive\nBusy and bustling with activity\n\n\nClimbing the corporate ladder\nAdvancing in one’s career\n\n\nRunning a tight ship\nManaging a team or project efficiently\n\n\nHerding cats\nManaging a group with diverse personalities\n\n\nBreaking down silos\nEncouraging collaboration between departments\n\n\nA well-oiled machine\nA team or department working smoothly and efficiently\n\n\nLeveling the playing field\nEnsuring equal opportunities or fairness for all\n\n\n\n\n\n3.3 Motivation, Change, and Growth\n\n\n\n\n\n\n\nMetaphor\nExplanation\n\n\n\n\nLighting a fire under someone\nMotivating a coworker to take action\n\n\nPlanting the seeds of change\nInitiating new ideas or strategies\n\n\nGoing the extra mile\nPutting in extra effort or going above and beyond\n\n\nTurning over a new leaf\nMaking positive changes or improvements\n\n\nPlanting the seeds of success\nLaying the groundwork for future achievements\n\n\nA breath of fresh air\nA new employee or idea that brings positive change\n\n\n\n\n\n3.4 Problem-solving, Multitasking, and Prioritization\n\n\n\n\n\n\n\nMetaphor\nExplanation\n\n\n\n\nSpinning plates\nJuggling multiple tasks or projects\n\n\nPutting out fires\nAddressing urgent problems or crises\n\n\nThinking outside the box\nComing up with creative solutions\n\n\nNipping a problem in the bud\nAddressing an issue before it escalates\n\n\nWearing multiple hats\nHandling various roles or responsibilities\n\n\nJuggling priorities\nBalancing multiple important tasks\n\n\n\n\n\n3.5 Communication, Relationships, and Conflicts\n\n\n\n\n\n\n\nMetaphor\nExplanation\n\n\n\n\nThe rumor mill is churning\nGossip circulating in the workplace\n\n\nThrowing someone under the bus\nBlaming a coworker to protect oneself\n\n\nWeathering the storm\nPersevering through tough times\n\n\nClearing the air\nResolving misunderstandings or conflicts\n\n\nPicking low-hanging fruit\nFocusing on easy tasks or quick wins\n\n\nThe calm before the storm\nA period of quiet before a busy or chaotic time"
  },
  {
    "objectID": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#my-metaphorical-bonus-list",
    "href": "posts/made-to-stick/unlock-the-power-of-metaphors-at-work-to-captivate-your-listeners.html#my-metaphorical-bonus-list",
    "title": "Unlock the Power of Metaphors at Work to Captivate Your Listeners!",
    "section": "4 My metaphorical bonus list",
    "text": "4 My metaphorical bonus list\nHere is a list of 50 Metaphors\n\nLife is a rollercoaster.\nTime is a thief.\nHer smile was a ray of sunshine.\nFear is a shadow that lurks in the dark.\nThe world is a stage.\nHis heart is a fortress.\nIdeas are seeds waiting to sprout.\nThe city is a concrete jungle.\nHis patience was a ticking time bomb.\nLaughter is the best medicine.\nThe stars are the universe’s diamonds.\nHer eyes were deep pools of mystery.\nThe mind is a garden.\nThe classroom was a zoo.\nThe rumor spread like wildfire.\nThe moon is a silent witness.\nChange is the only constant.\nLove is a double-edged sword.\nMemories are echoes of the past.\nThe library is a treasure trove of knowledge.\nYouth is a fleeting blossom.\nHope is an anchor in the storm.\nFriendship is a warm blanket on a cold night.\nSleep is a temporary escape from reality.\nHis mind was a labyrinth of thoughts.\nHer voice was like honey, sweet and soothing.\nTheir relationship was a delicate dance.\nSilence is a blank canvas.\nThe future is an unwritten book.\nTrust is a fragile vase, easily shattered.\nSuccess is a mountain peak to be conquered.\nGrief is a heavy chain that binds the heart.\nLoneliness is a barren desert.\nCreativity is a colorful kaleidoscope.\nThe internet is a global village.\nDreams are keys to unlock the subconscious.\nForgiveness is a gift to yourself.\nCourage is a shield against fear.\nThe past is a ghost that haunts us.\nRegret is a bitter pill to swallow.\nFamily is a tapestry woven with love.\nThe night sky is an infinite canvas.\nSociety is a mirror reflecting our values.\nTradition is a bridge between generations.\nWisdom is a guiding star.\nSolitude is a peaceful island in a sea of chaos.\nEmotions are the colors of the soul.\nResilience is a rubber band that bounces back.\nRevenge is a poison that consumes the avenger.\nCuriosity is a compass that leads to discovery."
  },
  {
    "objectID": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html",
    "href": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html",
    "title": "Why the Fishbone Diagram Triumphs Over 5 Whys",
    "section": "",
    "text": "The Ishikawa method can be suppior to 5xWhy, Wikipedia"
  },
  {
    "objectID": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#the-5xwhy-a-path-to-simplicity-or-a-trail-to-blame",
    "href": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#the-5xwhy-a-path-to-simplicity-or-a-trail-to-blame",
    "title": "Why the Fishbone Diagram Triumphs Over 5 Whys",
    "section": "1 The 5xWhy: A Path to Simplicity or a Trail to Blame?",
    "text": "1 The 5xWhy: A Path to Simplicity or a Trail to Blame?\nMany praise the simplicity of the 5xWhy method, rooted in the principles of lean manufacturing. It involves asking “Why?”. People repeat the question until they find the problem’s root cause.\nHowever, this apparent simplicity can be deceptive. Often the root cause is human error or a decision-making error, done by humans. This singular focus, while useful in pinpointing individual causes, can inadvertently cultivate a culture of blame and finger-pointing.\nThe issue with this approach is multifold. First, it oversimplifies complex problems. In the intricate web of corporate operations, issues are seldom the result of a single cause. Second, the spotlight on individuals rather than processes can lead to a defensive atmosphere. Employees may feel targeted and stressed, fearing that each session of 5xWhy could turn into a fault-finding mission.\nAs a result, nobody will cooperate."
  },
  {
    "objectID": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#the-fishbone-diagram-casting-a-wider-net",
    "href": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#the-fishbone-diagram-casting-a-wider-net",
    "title": "Why the Fishbone Diagram Triumphs Over 5 Whys",
    "section": "2 The Fishbone Diagram: Casting a Wider Net",
    "text": "2 The Fishbone Diagram: Casting a Wider Net\nEnter the Fishbone Diagram, also known as the Ishikawa Diagram. This method takes a distinctly different approach. It’s a tool that encourages teams to explore multiple potential causes of problems, categorized into various ‘bones’ like Methods, Machines, People, Materials, Measurements, and Environment.\nThe beauty of the Fishbone Diagram lies in its collaborative and holistic nature. By involving team members across different functions and perspectives, it fosters a sense of collective problem-solving. The focus shifts from individual blame to system-wide inefficiencies and process improvements.\nThis approach promotes a positive atmosphere where team members feel encouraged to contribute. The visual nature of the diagram aids in this. The teams can see at a glance how various factors interplay."
  },
  {
    "objectID": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#towards-learning-organizations",
    "href": "posts/management/why-the-fishbone-diagram-triumphs-over-whys.html#towards-learning-organizations",
    "title": "Why the Fishbone Diagram Triumphs Over 5 Whys",
    "section": "3 Towards learning organizations",
    "text": "3 Towards learning organizations\nThe Fishbone Diagram, with its emphasis on systems and processes, aligns well with the objectives of creating a learning culture within organizations. It steers the conversation towards constructive feedback and improvement rather than pointing fingers.\nIn contrast, the 5xWhy, though effective in certain scenarios, can fall short in fostering this positive environment, especially when dealing with complex, multifaceted issues.\nSo if it clearly is a technical problem: 5xWhy. Otherwise, Fishbone."
  },
  {
    "objectID": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html",
    "href": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html",
    "title": "Milestone vs Activity Planning: Finding the Right Approach for Your Project Management",
    "section": "",
    "text": "Is micromanaging the dominating paradigm?"
  },
  {
    "objectID": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#failure-is-not-an-option",
    "href": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#failure-is-not-an-option",
    "title": "Milestone vs Activity Planning: Finding the Right Approach for Your Project Management",
    "section": "Failure is not an option",
    "text": "Failure is not an option\nThe project was more than just another task on my list; it was a make-or-break opportunity for our construction company. We had been tasked with completing a state-of-the-art residential complex within a tight deadline, which would significantly impact our reputation in the industry. The project was a complex blend of innovative architectural design, sustainable materials, and cutting-edge technology. The pressure was immense, and the tight deadline only amplified the stakes. Failure was not an option.\nAs the project progressed, I noticed my team was struggling to stay motivated. We were so focused on the end goal that it became overwhelming. Coordinating subcontractors, navigating supply chain disruptions, and ensuring compliance with stringent building codes and regulations took a toll on my team’s morale. The sheer magnitude of the project was causing anxiety, and we were losing sight of the smaller steps that would lead us to success. I knew I had to act quickly and find a solution to turn things around.\nIn my search for an effective approach, I stumbled upon the idea of breaking down our seemingly insurmountable goal into smaller, more manageable tasks. Desperate to see a change, I implemented this strategy, but the initial results were disappointing. My team remained overwhelmed, and progress was still slow. In my desperation to get things back on track, I found myself micromanaging the team, scrutinizing their every move, and unintentionally creating a toxic work environment.\nRealizing that my micromanagement was only making matters worse, I knew I needed to find a more structured and efficient way to organize and prioritize tasks without suffocating my team. That’s when I discovered a systematic approach to managing activities, which promised to streamline our workflow and keep us focused on the most critical tasks while fostering a healthy team dynamic.\nI decided to give it a shot, and the transformation in my team was nothing short of miraculous. By adopting this method, we were able to concentrate on one task at a time, celebrating each small win along the way. The sense of accomplishment and progress brought the team closer together, and we began to work more efficiently. As we tackled each activity, from obtaining permits and coordinating with subcontractors to managing onsite safety and quality control, the once-distant goal suddenly felt within reach.\nThe project’s success not only saved our company but also solidified our reputation as a construction firm that could rise to any challenge. The experience taught me the power of a structured approach to managing activities, the importance of adaptability in the face of adversity, and the value of trusting and empowering my team. It was a turning point in my career, and it’s a lesson I’ll never forget."
  },
  {
    "objectID": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#how-to-choose-between-milestones-and-activities",
    "href": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#how-to-choose-between-milestones-and-activities",
    "title": "Milestone vs Activity Planning: Finding the Right Approach for Your Project Management",
    "section": "How to choose between milestones and activities",
    "text": "How to choose between milestones and activities\n\n\n\n\n\n\n\n\nApproach\nAdvantages\nDisadvantages\n\n\n\n\nTracking Milestones\n- Provides a sense of progress towards a larger goal\n- Can lead to discouragement if progress is slow\n\n\n\n- Helps identify potential issues or delays\n- May overlook other important achievements\n\n\n\n- Builds a sense of community and accountability\n- Can become too fixated on meeting specific milestones\n\n\n\n\n\n\n\nTracking Activities\n- Provides structure and focus\n- Can become too focused on the details and lose sight of the bigger picture\n\n\n\n- Breaks a larger goal down into smaller, more manageable tasks\n- May overlook other opportunities or ideas\n\n\n\n- Provides a sense of satisfaction and progress\n- Can become too fixated on completing individual tasks\n\n\n\n- Helps identify areas where additional support or resources are needed"
  },
  {
    "objectID": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#key-factors-to-consider-when-choosing",
    "href": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#key-factors-to-consider-when-choosing",
    "title": "Milestone vs Activity Planning: Finding the Right Approach for Your Project Management",
    "section": "Key Factors to Consider When Choosing",
    "text": "Key Factors to Consider When Choosing\n\n1. Project Scope\nIs the project relatively simple with a clear end goal or is it complex with multiple phases or sub-projects?\n\n\n2. Timeline\nIs the project expected to take a long time or is it a shorter-term effort?\n\n\n3. Team Size\nWill you be working alone or with a team? If working with a team, will everyone be involved in all aspects of the project, or will tasks be delegated?\n\n\n4. Available Resources\nDo you have all the resources you need to complete the project or will you need to acquire additional resources along the way?\n\n\n5. Dependencies\nAre there any tasks that are dependent on others being completed first?\n\n\n6. Flexibility\nHow flexible can you be with your timeline or task list if unexpected challenges arise?\n\n\n7. Stakeholder Expectations\nAre there any specific expectations or milestones that have been set by stakeholders or clients that need to be met?\n\n\n8. Motivation Style\nWhat type of motivation style works best for you and your team? Do you prefer to work towards smaller, achievable goals, or larger, long-term goals?\n\n\n9. Measure of Success\nHow will you measure success for this project? Will it be based on the achievement of specific milestones, the completion of individual tasks, or other factors?\n\n\n10. Communication\nHow will you communicate progress with stakeholders and team members? Will tracking milestones, activities, or both help you communicate progress more effectively?"
  },
  {
    "objectID": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#finding-the-right-balance",
    "href": "posts/management/milestone-vs-activity-planning-finding-the-right-approach-for-your-project-management.html#finding-the-right-balance",
    "title": "Milestone vs Activity Planning: Finding the Right Approach for Your Project Management",
    "section": "Finding the Right Balance",
    "text": "Finding the Right Balance\nIn conclusion, both milestone and activity planning have their unique advantages and disadvantages. The right approach for your project will depend on various factors, such as project scope, timeline, team size, available resources, and stakeholder expectations. By carefully considering these factors, you can choose the most effective approach for your project and ensure its success.\n\n\n\n\n\n\nTipCall to Action\n\n\n\nAre you currently using milestone or activity planning for your projects? Share your experiences with me by mail! Comments and newsletter section will be coming soon."
  },
  {
    "objectID": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html",
    "href": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html",
    "title": "Effective leaders listen for stories that touch the heart and mind",
    "section": "",
    "text": "The leader you should strive to become"
  },
  {
    "objectID": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#leadership-and-the-knowledge-economy",
    "href": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#leadership-and-the-knowledge-economy",
    "title": "Effective leaders listen for stories that touch the heart and mind",
    "section": "1 Leadership and the knowledge economy",
    "text": "1 Leadership and the knowledge economy\nThe management literature has known it for a long time. The management consultants realized it quite some time ago. And finally, the cooperate management world itself seems to have noticed:\nLeadership is not identical to management.\nThe number of presentations about good leadership increases steadily. Leadership is the new buzzword. The leadership team is everywhere. Even though often it is little more than the core/top management. Often, leadership translates to being in the lead—the responsible person.\nHowever, slowly but increasingly, the new reality seems to dawn on many people:\nLeadership ≠ Management.\nWhy is that so?"
  },
  {
    "objectID": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#effect-of-the-knowledge-worker",
    "href": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#effect-of-the-knowledge-worker",
    "title": "Effective leaders listen for stories that touch the heart and mind",
    "section": "2 Effect of the knowledge worker",
    "text": "2 Effect of the knowledge worker\nAs Drucker already pointed out: The number of knowledge workers is steadily increasing. Today’s work organization work is a recent invention of a mere 200 years. Before the industrial revolution, professionals organized themselves in guilds and were often still doing a lot of manual labor. The most experienced worker was leading the others and showed the ropes.\nOnly when unskilled labor started to increase did another work organization become necessary. The foreman was born. The job consisted mainly in telling others what to do. As the jobs became more specialized, knowledge work steadily increased. It was enough for a steel worker in the 19th century to have big muscles. Today he needs to know metallurgies. What has remained constant is the way we organize people.\nThis managing of people has produced ever-larger hierarchies. Commonly, the person at the top is utterly unfamiliar with the work at the bottom. Over the last 100 years, our society has accepted this paradigm. Chief executives are excused from having a profound IT background in the IT industry by saying their work requires another skill set.\nBut if we started with a clean slate, how should we organize the work if only skilled people would be working in the trade?\nDirect supervision only allows organizations of limited size, like in the middle ages.\nThe solution is clear, and everybody is already talking about leadership. Authentic leadership understands the problems of the simple craftsman as it is not too far away from his problems. At the same time is far enough above his daily trials and has a broader scope and vision."
  },
  {
    "objectID": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#the-essence-of-leadership-is-to-influence",
    "href": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#the-essence-of-leadership-is-to-influence",
    "title": "Effective leaders listen for stories that touch the heart and mind",
    "section": "3 The essence of leadership is to influence",
    "text": "3 The essence of leadership is to influence\nIn the book 21 Laws of leadership C. Maxwell talks about the principles that enable good leadership.\nFor him, the essence of leadership is influence. With influence, you can create positive change.\nInfluence requires good communication. One aspect of communication is searching for answers outside yourself and your team. This search can happen verbally, but you must also listen to non-verbal language. How do people behave? How do people act in groups? You need to tune into the room. Are people attentive, or is everybody just on duty?"
  },
  {
    "objectID": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#good-communicators-search-for-stories.",
    "href": "posts/21-laws-leadership/effective-leaders-listen-for-stories-that-touch-the-heart-and-mind.html#good-communicators-search-for-stories.",
    "title": "Effective leaders listen for stories that touch the heart and mind",
    "section": "4 Good communicators search for stories.",
    "text": "4 Good communicators search for stories.\nThe most prominent of being a good communicator is listening to other people’s stories and retelling those stories. By retelling their stories, you act on the emotions of everybody.\n“People don’t care how much you know until they know how much you care.”\nLet’s assume you know a lot of details about a new cross-platform programming framework. You are convinced your audience should start using this framework.\nThese three steps will make your undertaking a success.\n\nKnow the audience and discover their stories. Discover if they need your framework.\nFind the correct formulation of your message. What is the one thing about your framework everybody needs to know?\nAdapt the message to the audience by using their stories\n\nUsing the audience’s stories allows them to see the framework from their perspective."
  },
  {
    "objectID": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html",
    "href": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html",
    "title": "World Sensation, Why remarkably nobody has built your leadership",
    "section": "",
    "text": "You as a leader\nMaybe you have picked up a leadership book or visited some talks? Great! You know what makes a good leader? Fantastic!\nDid you wonder why nobody tried to teach you better leadership skills?\nMy confession to you: I did not.\nThen I faced an astonishing statement in C. Maxwell’s book “21 laws of leadership”: leaders are taught by other leaders.\nAfter this, I started to wonder why nobody taught me.\nWe, leadership midgets, face two explanations:\nLet’s explore these two options and how they go together with you not focusing on accomplishments and not empowering others.\nIf you already wonder, please send me a message as I am curious about your thoughts."
  },
  {
    "objectID": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html#you-have-not-met-any-other-leader.",
    "href": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html#you-have-not-met-any-other-leader.",
    "title": "World Sensation, Why remarkably nobody has built your leadership",
    "section": "1 You have not met any other leader.",
    "text": "1 You have not met any other leader.\nWhy do you think you have not met any other leader? The law of magnetism provides a possible explanation: “Who you are is who you attract.” In other words, try to lead people, and other leaders will be attracted to you by social dynamics.\nMaybe other people in your organization face the same issues. They struggle to build up influence. Hence positional leadership is dominant. Positional leadership is not real leadership as it relies on extrinsic motivation: we all need to earn money from somewhere.\nAnother option is that you did not perceive other leaders as leaders.\n“The more leadership ability a person has, the more quickly he recognizes leadership – or its lack – in others.” Not spotting any other leaders maybe means you are an incompetent leader yourself.\nBut I am doing so much to be successful, says the little voice in your head.\nIf you are already active, think that “activity is not necessarily accomplishment.” Reflect on Requirement, Return, and Reward. Map your activities to the three Rs.\n\nWhat is required of me?\nWhat gives the greatest return?\nWhat brings the greatest reward?\n\n\n1.1 How to meet other leaders\nFirst and foremost: be yourself. “Leaders go their way.” Only by doing so can they maintain direction when a group comes together.\nBeing a better leader for yourself will attract other like-minded people.\nThe essential difference is also a leader is initializing the connection.\nEven though you do not perceive somebody as a leader, you can still connect to him. Think about if you think they have value for the organization and your cause.\nIn a hierarchical organization, that also includes leading upwards. What can you do for the person above you to help them grow as leaders and in their careers? This approach is tricky as it requires balancing their needs and your own goals. Once you have identified their goals, look for your side’s best effort/reward action. Be aware that their goals are not necessarily as transparent as they seem."
  },
  {
    "objectID": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html#you-are-not-considered-worthy.",
    "href": "posts/21-laws-leadership/world-sensation-why-remarkably-nobody-has-built-your-leadership.html#you-are-not-considered-worthy.",
    "title": "World Sensation, Why remarkably nobody has built your leadership",
    "section": "2 You are not considered worthy.",
    "text": "2 You are not considered worthy.\nIn the second case, you have identified somebody as a leadership person. Sadly she/he remains ignorant of your existence. The law of the inner circle means that a leader will surround himself with people that he thinks are capable of helping him with his vision. A strong leader will surround himself with other leaders.\nBut looking a little closer, your “leaders” may not be “secure leaders” who “give others power.” Perhaps the leaders you have met try to foster their position first by building a good team. Growing a team of teams might not be in their interest. These leaders may not follow a strategy of “explosive growth.” Instead, they aim at linear growth by keeping things under control.\n\n2.1 How to improve\nStart with yourself. Foster your character strength and then build up relationships. Character is defined by being consistent with your principles. Easier said then done. Get up and do the work.\nThese three steps can help you:\n\nRelationships are fundamentally relying on respect. Without respect, you can not build trust. Without trust, there is no relationship. Pay respect to others, especially those with even less power than you. Try to give away power yourself. Everybody has some little influence.\nFollow your development plan; for example, one book a month, one youtube talk a week, and one conference a year.\nHelp others follow their development plan. Do they have one? Why not? Be their mentor in the first steps or by navigating complex issues."
  },
  {
    "objectID": "posts/how-playing-zelda-teaches-us-the-importance-of-audience-engagement-in-interactive-storytelling.html",
    "href": "posts/how-playing-zelda-teaches-us-the-importance-of-audience-engagement-in-interactive-storytelling.html",
    "title": "How Playing Zelda Teaches Us the Importance of Audience Engagement in Interactive Storytelling",
    "section": "",
    "text": "It’s been countless hours since I first embarked on my journey in the magical land of Hyrule, and I can’t help but ask myself, “Why is this game so addicting?” Zelda, at first glance, may not seem to possess the qualities that make a game truly engaging. However, as I delved deeper into the enchanting world, I discovered a myriad of elements that keep players like me coming back for more."
  },
  {
    "objectID": "posts/how-playing-zelda-teaches-us-the-importance-of-audience-engagement-in-interactive-storytelling.html#practical-insights-from-zeldas-success",
    "href": "posts/how-playing-zelda-teaches-us-the-importance-of-audience-engagement-in-interactive-storytelling.html#practical-insights-from-zeldas-success",
    "title": "How Playing Zelda Teaches Us the Importance of Audience Engagement in Interactive Storytelling",
    "section": "Practical Insights from Zelda’s Success",
    "text": "Practical Insights from Zelda’s Success\nSo, what can we learn from Zelda’s success in terms of interactive storytelling? The key takeaway is the crucial need to listen and adapt to our audience. Stories must not progress faster than the audience can comprehend, and the storyteller must recognize when the audience is evolving during the narrative.\nFailure to understand and cater to the audience’s needs can lead to disengagement and a lack of impact. Let’s consider an example: if a speaker aims to promote the principles of constellation networks, they must first understand that their listeners might be more accustomed to a heliocentric, pyramid-based mindset. To effectively convey their message, the speaker must start by addressing the factors that hold the pyramid together and gradually introduce the concept of a flexible, rotating pyramid.\nAs creators of interactive stories, it’s our responsibility to:\n\nUnderstand our audience: Know their interests, background, and expectations.\nEngage from the start: Capture their attention early and maintain it with a steady stream of compelling details.\nEncourage active participation: The audience can explore and interact with the story, fostering a deeper connection.\nAdapt to the audience’s transformation: Modify the narrative to cater to the audience’s evolving needs and understanding.\n\nFollowing these principles, we can create captivating interactive stories that keep our audience engaged and invested in the narrative. The enchanting world of Zelda has taught us the importance of audience engagement in interactive storytelling – now it’s time for us to put these lessons into practice. Embrace the challenge, and create unforgettable experiences that resonate with our audience!"
  },
  {
    "objectID": "posts/finding-your-personal-blogs-purpose-and-name.html",
    "href": "posts/finding-your-personal-blogs-purpose-and-name.html",
    "title": "Finding your personal blogs purpose and name",
    "section": "",
    "text": "Welcome to Story Melange.\nWhat is Story Melange?\nStory Melange is my personal blog where I write about topics that I am interested in.\nIn this article I want to share some thoughts about creating a personal blog.\nA blog needs two things:\n- The blogs main purpose\n- A name for the blog\n\n\nSo you want to start a blog? Great. Frequently, personal blogs feature a collection of diverse topics. Countless are the numbers of blogs that were started, but later abandoned. Hopefully this blog will survive at least several years.\nIn my research on blog creation I found one important aspect touching the heart of the blog: its purpose.\nHosting and website creation are important, the content is far more important.\nAs already mentioned, many personal blogs write about various topics. However, over time it is easier to create new content and attract followers, if you have a purpose. Having a purpose does not necessarily mean that you always write about about the same topic. The different topics can be slightly related. And of course you can explore side-topics. Think about computer roll playing games. There is the main story-line and there are many big and small side quests.\nOnly you can discover your blog’s purpose. Good points to start the exploration of the purpose: What was your motivation when you decided that you want to create a blog? Do you intended to help someone with your blog?\nMy main idea for the blog was storytelling. I want to write about the topic of effective communication and getting the point across. How to not get lost in the myriad of options that we have today.\nThe next blog post will shed some more light on this.\nIf you are not able to identify your blog’s purpose, but still feel the urge to write a blog, go for it.\nA frequent tip is to just start and see what works.\n\n\n\nOnce you answered the question of the blog’s purpose, it is time to name your blog.\nYou need a name for several reasons. My non exclusive list:\n\nYour own identification with your blog.\nYou need to host the blog somewhere.\nIf you want people to read the blog, the name should be intelligible and easy to remember. If you do not want anybody to find your blog go for “x2s5qm24”.\n\nThere are many good resources to help you.\nSee for example: https://www.ryrob.com/how-name-blog/ or https://bloggingwizard.com/choose-a-blog-name/.\nThere are different flavors of blog naming:\n\n\nMany people choose their own name or add a profession, e.g. mrsmithwriter.\nUse an abbreviation of your name: dolind.\nIf you are an engineer or software developer, a good option to include .tech in the domain name., your-name.tech.\nThis is also helpful for your CV. Consider the two email addresses and which one looks more professional.\ninfo@mrsmithwriter.tech\nj.smith75@bestmailproviderever.com\nFor the first address, the conveyed message hopefully is: I know my way around in the internet and in technology.\n\n\n\nThe other route followed by many blog creators. Name the blog after your business idea. However, considering specific ideas the idea is best represented by its very own domain. Chances are high that you pick something you will later abandon for something else.\n\n\n\nClosely related but slightly different: name the blog with regard to its purpose.\nThis should help the readers of the blog to associate the blog with a specific solution or a reliable source of information.\nMy blog’s purpose is storytelling. As I currently do not want to limit the blog the much, the scope will still be quite large.\nSome names already existed or were even registered as a trademark. Other names were quite artsy and on second thought too complicated, gallimaufry, Story Entangled or Story Potpouri.\nReflecting on different blog names I was sipping my wiener melange when it dawned on me:\nI had found my blog name.\n\n\n\nphoto by unsplash\n\n\nWith the choices we make in our lives, we create our very own mixtures from the possibilities and flavors the society offers. These mixtures, these melanges, which we create are the stories of our lives.\nWelcome to Story Melange and enjoy your coffee."
  },
  {
    "objectID": "posts/finding-your-personal-blogs-purpose-and-name.html#journey-to-a-personal-blog",
    "href": "posts/finding-your-personal-blogs-purpose-and-name.html#journey-to-a-personal-blog",
    "title": "Finding your personal blogs purpose and name",
    "section": "",
    "text": "Welcome to Story Melange.\nWhat is Story Melange?\nStory Melange is my personal blog where I write about topics that I am interested in.\nIn this article I want to share some thoughts about creating a personal blog.\nA blog needs two things:\n- The blogs main purpose\n- A name for the blog\n\n\nSo you want to start a blog? Great. Frequently, personal blogs feature a collection of diverse topics. Countless are the numbers of blogs that were started, but later abandoned. Hopefully this blog will survive at least several years.\nIn my research on blog creation I found one important aspect touching the heart of the blog: its purpose.\nHosting and website creation are important, the content is far more important.\nAs already mentioned, many personal blogs write about various topics. However, over time it is easier to create new content and attract followers, if you have a purpose. Having a purpose does not necessarily mean that you always write about about the same topic. The different topics can be slightly related. And of course you can explore side-topics. Think about computer roll playing games. There is the main story-line and there are many big and small side quests.\nOnly you can discover your blog’s purpose. Good points to start the exploration of the purpose: What was your motivation when you decided that you want to create a blog? Do you intended to help someone with your blog?\nMy main idea for the blog was storytelling. I want to write about the topic of effective communication and getting the point across. How to not get lost in the myriad of options that we have today.\nThe next blog post will shed some more light on this.\nIf you are not able to identify your blog’s purpose, but still feel the urge to write a blog, go for it.\nA frequent tip is to just start and see what works.\n\n\n\nOnce you answered the question of the blog’s purpose, it is time to name your blog.\nYou need a name for several reasons. My non exclusive list:\n\nYour own identification with your blog.\nYou need to host the blog somewhere.\nIf you want people to read the blog, the name should be intelligible and easy to remember. If you do not want anybody to find your blog go for “x2s5qm24”.\n\nThere are many good resources to help you.\nSee for example: https://www.ryrob.com/how-name-blog/ or https://bloggingwizard.com/choose-a-blog-name/.\nThere are different flavors of blog naming:\n\n\nMany people choose their own name or add a profession, e.g. mrsmithwriter.\nUse an abbreviation of your name: dolind.\nIf you are an engineer or software developer, a good option to include .tech in the domain name., your-name.tech.\nThis is also helpful for your CV. Consider the two email addresses and which one looks more professional.\ninfo@mrsmithwriter.tech\nj.smith75@bestmailproviderever.com\nFor the first address, the conveyed message hopefully is: I know my way around in the internet and in technology.\n\n\n\nThe other route followed by many blog creators. Name the blog after your business idea. However, considering specific ideas the idea is best represented by its very own domain. Chances are high that you pick something you will later abandon for something else.\n\n\n\nClosely related but slightly different: name the blog with regard to its purpose.\nThis should help the readers of the blog to associate the blog with a specific solution or a reliable source of information.\nMy blog’s purpose is storytelling. As I currently do not want to limit the blog the much, the scope will still be quite large.\nSome names already existed or were even registered as a trademark. Other names were quite artsy and on second thought too complicated, gallimaufry, Story Entangled or Story Potpouri.\nReflecting on different blog names I was sipping my wiener melange when it dawned on me:\nI had found my blog name.\n\n\n\nphoto by unsplash\n\n\nWith the choices we make in our lives, we create our very own mixtures from the possibilities and flavors the society offers. These mixtures, these melanges, which we create are the stories of our lives.\nWelcome to Story Melange and enjoy your coffee."
  },
  {
    "objectID": "posts/blog-update-july.html",
    "href": "posts/blog-update-july.html",
    "title": "Blog Update July 2025",
    "section": "",
    "text": "I decided to give the blog a long planned overhaul.\nLet’s start with the different topics"
  },
  {
    "objectID": "posts/blog-update-july.html#blog-updates",
    "href": "posts/blog-update-july.html#blog-updates",
    "title": "Blog Update July 2025",
    "section": "",
    "text": "I decided to give the blog a long planned overhaul.\nLet’s start with the different topics"
  },
  {
    "objectID": "posts/blog-update-july.html#comments",
    "href": "posts/blog-update-july.html#comments",
    "title": "Blog Update July 2025",
    "section": "2 Comments",
    "text": "2 Comments\nI decided to enable comments via https://utteranc.es/. It seems the most lightweight approach to comments. Comments only work if you have a Github account. Bad for the non-techies. Good to keep the spamers away.\nFor any follow bloggers. Put the utterance section in the _metadata.yml in posts. To limit it to sites with content and not on the listing sites.\nIn addition, I use a small comments header to visually separate the comments.\n&lt;h2&gt;Comments&lt;/h2&gt;  \n&lt;p&gt;Join the discussion below.&lt;/p&gt;\nImplementation is straightforward use\nformat:  \n  html:  \n    include-after-body: comments-header.html  \n    comments:  \n      utterances:  \n        repo: dolind/dolind.github.io  \n        issue-term: pathname  \n        label: comment  \n        theme: github-light"
  },
  {
    "objectID": "posts/blog-update-july.html#blog-theme",
    "href": "posts/blog-update-july.html#blog-theme",
    "title": "Blog Update July 2025",
    "section": "3 Blog theme",
    "text": "3 Blog theme\nGoing strong on coffee, I opted for\nReal stories of building systems and leading teams, from quick espresso shots to slow pours."
  },
  {
    "objectID": "posts/blog-update-july.html#rss-feed",
    "href": "posts/blog-update-july.html#rss-feed",
    "title": "Blog Update July 2025",
    "section": "4 RSS Feed",
    "text": "4 RSS Feed\nIt was enabled before, but i did not have a button in the navbar. Now it is there."
  },
  {
    "objectID": "posts/blog-update-july.html#newsletter",
    "href": "posts/blog-update-july.html#newsletter",
    "title": "Blog Update July 2025",
    "section": "5 Newsletter",
    "text": "5 Newsletter\nBiggest update. I have a RSS based Newsletter. You can signup here:\nI followed this guide: https://forbo7.github.io/forblog/posts/7_blog_subscriptions.html\nSadly, the layout is a bit off, I will fix that another time."
  },
  {
    "objectID": "posts/technical/precisionrecall-vs-fntnfptp.html",
    "href": "posts/technical/precisionrecall-vs-fntnfptp.html",
    "title": "Precision/Recall vs FN/TN/FP/TP",
    "section": "",
    "text": "While writing this post, i noticed that there is far better article on GeeksforGeeks\n\n\n\nPrecision and recall are evaluation metrics used in machine learning to measure the performance of a binary classification model. The concepts of false negatives (FN), true negatives (TN), false positives (FP), and true positives (TP) are closely related to these metrics.\n\n\n\n\n\n\n\n\nClassification\nAbr.\nOccur When a\n\n\n\n\nTrue positives\nTP\npositive instance is correctly classified as positive.\n\n\nTrue negatives\nTN\nnegative instance is correctly classified as negative\n\n\nFalse negatives\nFN\npositive instance is incorrectly classified as negative\n\n\nFalse positives\nFP\nnegative instance is incorrectly classified as positive"
  },
  {
    "objectID": "posts/technical/precisionrecall-vs-fntnfptp.html#measuring-classification-results",
    "href": "posts/technical/precisionrecall-vs-fntnfptp.html#measuring-classification-results",
    "title": "Precision/Recall vs FN/TN/FP/TP",
    "section": "",
    "text": "While writing this post, i noticed that there is far better article on GeeksforGeeks\n\n\n\nPrecision and recall are evaluation metrics used in machine learning to measure the performance of a binary classification model. The concepts of false negatives (FN), true negatives (TN), false positives (FP), and true positives (TP) are closely related to these metrics.\n\n\n\n\n\n\n\n\nClassification\nAbr.\nOccur When a\n\n\n\n\nTrue positives\nTP\npositive instance is correctly classified as positive.\n\n\nTrue negatives\nTN\nnegative instance is correctly classified as negative\n\n\nFalse negatives\nFN\npositive instance is incorrectly classified as negative\n\n\nFalse positives\nFP\nnegative instance is incorrectly classified as positive"
  },
  {
    "objectID": "posts/technical/precisionrecall-vs-fntnfptp.html#precision-and-recall",
    "href": "posts/technical/precisionrecall-vs-fntnfptp.html#precision-and-recall",
    "title": "Precision/Recall vs FN/TN/FP/TP",
    "section": "2 Precision and recall",
    "text": "2 Precision and recall\nThese numbers are expressed in absolute terms. Sometimes it is more helpfull to focus on relative numbers. If we are interested in how many of the positive values should have been positive, we are interested in the precision. Precision is the ratio of true positives to the total number of instances that are classified as positive by the model. It is given by:\nPrecision = TP / (TP + FP)\nIf we are interested in model ability to identify all positive instances, we look for recall. Recall is the ratio of true positives to the total number of actual positive instances in the data.\nRecall = TP / (TP + FN)\nThese metrics are important because in many cases, precision and recall have an inverse relationship. That is, improving one metric may come at the cost of the other. For example, a model that is overly conservative in making positive predictions may have high precision but low recall, as it is less likely to make false positive errors but may also miss many true positive instances. On the other hand, a model that is more aggressive in making positive predictions may have high recall but low precision, as it may capture more true positives but also generate more false positives.\nBy considering the confusion matrix with FN/TN/FP/TP, precision and recall can be calculated to evaluate the performance of a classification model. The confusion matrix shows the number of true and false predictions for each class, and it can be used to calculate metrics such as accuracy, precision, and recall."
  },
  {
    "objectID": "posts/technical/precisionrecall-vs-fntnfptp.html#confusion-matrix",
    "href": "posts/technical/precisionrecall-vs-fntnfptp.html#confusion-matrix",
    "title": "Precision/Recall vs FN/TN/FP/TP",
    "section": "3 Confusion matrix",
    "text": "3 Confusion matrix\nA confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the correct classifcations are known. Here is an example of a confusion matrix:\n\n\n\n\nPredicted A\nPredicted B\n\n\n\n\nActual A\n4\n34\n\n\nActual B\n23\n35\n\n\n\nThe columns represent the predicted class labels and the rows represent the actual class labels. This can be generalized to n labels.\nIn the binary classification the confusion matrix simplifies itself to\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\nTN (true negative)\nFP (false positive)\n\n\nActual Positive\nFN (false negative)\nTP (true positive)\n\n\n\nAs can be seen the, the confusion matrix shows the number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions made by a classification model."
  },
  {
    "objectID": "posts/technical/precisionrecall-vs-fntnfptp.html#what-is-better",
    "href": "posts/technical/precisionrecall-vs-fntnfptp.html#what-is-better",
    "title": "Precision/Recall vs FN/TN/FP/TP",
    "section": "4 What is better?",
    "text": "4 What is better?\nPrecision measures accuracy of positive predictions while recall measures the ability to identify all positive instances. The confusion matrix provides a detailed breakdown of predictions including true positive, true negative, false positive, and false negative counts. The choice of metric depends on the context and purpose of the analysis. Precision/recall are useful when the cost of false positives and false negatives is different, while confusion matrix is useful when costs are similar and to identify specific areas of model performance, especially on imbalanced datasets."
  },
  {
    "objectID": "posts/technical/from-damping-factor-to-learning-rate.html",
    "href": "posts/technical/from-damping-factor-to-learning-rate.html",
    "title": "From damping factor to learning rate",
    "section": "",
    "text": "When I first heard about machine learning in the middle of the 2010s, it occurred as a big black box for me. I have a PhD in computational material science, and as such, find the concepts quite easy to grasp. Yet, I am often stunned how similar yet how different the fields are.\nThe core difference is that people in these fields receive different training and have developed aptitudes for different terms and jargon.\nI often find the ML jargon difficult to understand. However, once you get your head around it, it actually becomes easier to understand.\nBefore getting deeper in the field, I found it hard to accept the pretentious term of learning.\nHow were systems supposed to learn, as we humans learn? When you scratch the surface, you clearly recognize that the learning is an optimization algorithm.\nIn this blog I want to focus on the particular technical term of the learning rate. From the outside, this is the rate of learning of our algorithm. But what does it mean for the mathematically learned fellow? Especially, what does it mean to all the computational scientists?\nIn the following, I will contrast the concept in ML with the very similar approach in the finite element method, known too many physical computational scientists."
  },
  {
    "objectID": "posts/technical/from-damping-factor-to-learning-rate.html#my-journey-in-the-land-of-machine-learning",
    "href": "posts/technical/from-damping-factor-to-learning-rate.html#my-journey-in-the-land-of-machine-learning",
    "title": "From damping factor to learning rate",
    "section": "",
    "text": "When I first heard about machine learning in the middle of the 2010s, it occurred as a big black box for me. I have a PhD in computational material science, and as such, find the concepts quite easy to grasp. Yet, I am often stunned how similar yet how different the fields are.\nThe core difference is that people in these fields receive different training and have developed aptitudes for different terms and jargon.\nI often find the ML jargon difficult to understand. However, once you get your head around it, it actually becomes easier to understand.\nBefore getting deeper in the field, I found it hard to accept the pretentious term of learning.\nHow were systems supposed to learn, as we humans learn? When you scratch the surface, you clearly recognize that the learning is an optimization algorithm.\nIn this blog I want to focus on the particular technical term of the learning rate. From the outside, this is the rate of learning of our algorithm. But what does it mean for the mathematically learned fellow? Especially, what does it mean to all the computational scientists?\nIn the following, I will contrast the concept in ML with the very similar approach in the finite element method, known too many physical computational scientists."
  },
  {
    "objectID": "posts/technical/from-damping-factor-to-learning-rate.html#fem",
    "href": "posts/technical/from-damping-factor-to-learning-rate.html#fem",
    "title": "From damping factor to learning rate",
    "section": "2 FEM",
    "text": "2 FEM\n\n2.1 Background\nThe Finite Element Method (FEM) began in the 1940s for aerospace structural analysis and grew with computing advances in the 1950s–60s. It works by breaking down complex structures into smaller, manageable elements, solving equations over these elements, and assembling the results. Today, FEM is vital in simulating real-world physics across engineering and science.\n\n\n2.2 FEM and the step size in line search\nIn mechanical application of the finite element method, we are interest to solve the equation: \\[\\mathbf{K} \\mathbf{u} = \\mathbf{f}_{\\text{ext}}\\]\nwhere:\n\n\\(\\mathbf{K}\\) is the global stiffness matrix.\n\\(\\mathbf{u}\\) are the nodal displacements (unknowns).\n\\(\\mathbf{f}_{\\text{ext}}\\) are the nodal forces.\n\nThe residual is \\(\\mathbf{r}=\\mathbf{f}_{\\text{ext}}-\\mathbf{K}\\mathbf{u}\\).\nA gradient-descent-based update rule takes the form:\n\\[\n\\mathbf{u}_{t+1} = \\mathbf{u}_t - \\alpha (\\mathbf{K} \\mathbf{u}_t-\\mathbf{f}_{\\text{ext}})\n\\]\nwhere \\(\\alpha\\) is the step size or damping factor, which controls update magnitude.\nIn a linear system we can use a potential to describe this\n\\[\\nabla_{\\mathbf{u}} \\Pi=\\mathbf{K} \\mathbf{u}_t-\\mathbf{f}_{\\text{ext}}\\]\nso we get\n\\[\n\\mathbf{u}_{t+1} = \\mathbf{u}_t - \\alpha \\nabla_{\\mathbf{u}} \\Pi\n\\]\nAn illustration is in the following picture.\n\n\n\nThe step size is the length of each arrow.\n\n\nIf computational resources allow and the matrix \\(\\mathbf{K}\\) is not too large, a direct solution can be obtained using:\n\\[\\mathbf{u} = \\mathbf{K}^{-1} \\mathbf{f}_{\\text{ext}}\\]\n\n\n\n\n\n\nNoteNotation\n\n\n\nIn this document I use \\(\\mathbf{x}\\) for a vector and \\(\\mathbf{X}\\) for a matrix.\n\n\n\n\n2.3 Influence of Nonlinearity\nFor linear mechanics, the solution is straightforward. The issue arises only when we introduce non-linearity.\nNonlinearities arise from\n\nlarge displacement paths,\nlarge rotations\nenergy dissipating process (plasticity)\ndamping\n\nIn the presence of large displacements, these non-linearities lead to ill-conditioning of the matrix \\(K\\). A tiny step size would be necessary unless matrix K is adapted. Many solution algorithms exist.\n\\[\\mathbf{u}_{t+1} = \\mathbf{u}_t + \\alpha_t \\mathbf{K}^{-1} \\mathbf{r}_t\\]\nWe find the optimal \\(\\alpha_t\\) by minimizing the strain energy functional.\n\\[\\alpha_t = \\arg\\min_{\\alpha} J(\\mathbf{u}_t  - \\alpha \\mathbf{K}^{-1} \\mathbf{r}_t)\\]\nOne major issue is that the stiffness matrix is variable, there is only a tangent stiffness matrix, \\(\\mathbf{K}_t\\), which requires frequent recomputation. This tangent matrix is also called in more general terms the Hessian, which describes the second-order curvature. We will not get into the details here, but we will get back to it below.\n\n\n\n\n\n\nNoteIll-conditioning\n\n\n\nThe following picture shows geometry as one of the ill-conditioning causes. One element is a lot bigger than the other.\n.\nHere’s an example of an ill-conditioned matrix:\n\\[\\mathbf{K} = \\begin{bmatrix} 10 & 10 \\\\ 10 & 10.0001 \\end{bmatrix}\\]\nThis matrix has a high condition number, making it sensitive to small changes in input, which can lead to large errors in numerical computations."
  },
  {
    "objectID": "posts/technical/from-damping-factor-to-learning-rate.html#machine-learning",
    "href": "posts/technical/from-damping-factor-to-learning-rate.html#machine-learning",
    "title": "From damping factor to learning rate",
    "section": "3 Machine learning",
    "text": "3 Machine learning\n\n3.1 Linear models\nMachine learning began with linear models like the equation:\n\\[\\mathbf{y}=\\mathbf{X}\\mathbf{w}+\\mathbf{b}\\].\nIt draws from statistics and early perceptron models of the 1950s.\nHere\n\n\\(\\mathbf{y}\\) is the vector of output labels (dependent variable)\n\\(\\mathbf{X}\\) is the feature matrix, the input data, or independent variable\n\\(\\mathbf{w}\\) are the weights(model parameters)\n\\(\\mathbf{b}\\) are biases, which we can include in w\n\nYou can write this as: \\[\\mathbf{X}\\mathbf{w}=\\mathbf{y}\\]\nA direct solution equivalent to the FEM equation\n\\[\\mathbf{u} = \\mathbf{K}^{-1} \\mathbf{r}\\]\nis the equivalent least squares solution is:\n\\[\\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\\]\nwhere (\\(\\mathbf{X}^T \\mathbf{X})^{-1}\\) is like the inverse of the stiffness matrix, \\(\\mathbf{K}^{-1}\\) .\n\n\n3.2 Influence of size and non-linearity\nHowever, ML problems usually have many more parameters than than FEM problems. This brings a few drawbacks for the direct solution.\n\nmatrix inversion is costly and works at \\(O(n^3)\\) in time.\nand requires \\(O(n^2)\\) in space.\ncorrelated features, can lead to near-singular matrices making inversion impossible.\n\nIn addition, it would only work for linear problems, whereas many issues are non-linear, expressed as:\n\\[\\mathbf{y} = f(\\mathbf{X}, \\mathbf{w})\\]\nwhere - \\(\\mathbf{y}\\) is the output vector - \\(f(\\mathbf{X}, \\mathbf{w})\\) is a general function\nDevelopment has focused on iterative methods. Here, the same solvers exist as for FEM: gradient descent, conjugate gradient, or L-BFGS. Mini-batches solve the space requirement issue by analyzing only a small subset. This is then called stochastic gradient descent.\n\n\n3.3 Gradient descent\nInstead of direct inversion, ML often uses gradient descent``, similar toiterative solvers in FEM` (like conjugate gradient method):\n\\[\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\alpha \\nabla J(\\mathbf{w}_t)\\],\nwhere \\(J(\\mathbf{w})\\) is the loss function (analogous to potential energy in FEM). Now \\(\\alpha\\) is the learning rate, but you can see the equation is identical to the FEM equation.\nIn our analogy, the stiffness matrix \\(\\mathbf{K}\\) is replaced by the loss function. A common choice for regression problems is the Mean Squared Error (MSE):\n\\[J(\\mathbf{w}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\mathbf{X}_i \\mathbf{w})^2\\]\nwhere:\n\n\\(N\\) is the number of samples.\n\\(y_i\\) is the true label.\n\\(\\mathbf{X}_i\\) is the feature vector (row) for sample i in the matrix.\n\nThe gradient of the loss function is:\n\\[\\nabla J(\\mathbf{w}) = -\\frac{2}{N} \\sum_{i=1}^{N} (y_i - \\mathbf{X}_i \\mathbf{w}) \\mathbf{X}_i\\]\nFor more complex problems, first order gradient descent is not enough, we need second order approaches. We examine the curvature and then it is called the Hessian. But again, as for FEM, this is too complex for this article.\n\n\n3.4 Batch size\nAs already mentioned, ML problems use a lot of parameters and a lot of data. The size of the data, which is filled in the matrix is called the batch. Using a batch size smaller than the full data is called a mini-batch. We then use a stochastic gradient descent. It is called stochastic as we use a sample of the full data.\nIn theory, the mini-batch can go down to 1. In practice this is rare.\n\\[\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\alpha \\frac{1}{|B|} \\sum_{i \\in B} \\nabla J_i(\\mathbf{w}_t)\\]\nwhere\n\n\\(|B|\\) is the batch size\n\\(\\nabla J_i\\) is the evaluation of the loss function for the batch sample\n\nThis approach of divide and conquer is a classic in computer science. In the FEM similar approaches have been developed for large-scale problems, see for example the PGD and other reduced order modeling techniques.\n\n\n3.5 The learning rate, limits progress\nWe have previously examined analogies between many optimization equations. One concept that remains to be discussed is the damping factor—a critical component in both numerical methods and machine learning.\nReturning to the idea of line search, we can observe that a similar approach to what is used in FEM can also be applied in machine learning. In this context, the learning rate becomes variable, adapting at each iteration to minimize the objective function along the descent direction:\n\\[\\alpha_t = \\arg\\min_{\\alpha} J(\\mathbf{w}_t - \\alpha \\nabla J(\\mathbf{w}_t))\\]\nFor small to medium ml problems, this is an excellent solution. This approach ensures a stable convergence of the training process. The issue is that each extra forward/backward pass doubles cost. If your package offers “line search”, this is often backtracking or heuristic scaling.\nFor deep learning tasks, inventive folks have come up with explicit prescriptive updates, like the ADAM optimizer. It handles the update rate for each parameter solely based on the gradients.\n\\[m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla J(\\mathbf{w}_t)\\]\n\\[v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla J(\\mathbf{w}_t))^2\\]\n\\[\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\frac{\\alpha m_t}{\\sqrt{v_t} + \\epsilon}\\]\nwhere:\n\n\\(m_t\\) is the moving average of gradients (momentum-like behavior).\n\\(v_t\\) tracks the moving average of squared gradients (scales learning rates).\n\\(\\beta_1\\) and \\(\\beta_2\\) control exponential decay rates.\n\nFor the FEM guys reading this: this approach resembles explicit dynamics mass scaling of the time step. There, we calculate the permissible step size for each element and then add any artificial mass to each element. This artificial mass brings the global step size to a desired target.\nNumerically, the approaches differ. Some ensure convergence directly or iteratively; others use update rules and heuristics.\nIterative solvers, such as BFGS and L-BFGS, still have their place in more specialized fields that have higher demands on accuracy or suffer from greater instability.\nThe major advantage is that L-BFGS can converge faster than SGD.\nPeople use it on classic ML problems, with datasets that fit in memory, that is no mini-batch and especially reinforcement learning to handle the instabilities better.\nAnother field where a BFGS could be better is fine tuning, small networks, hyper parameter optimization, and word embeddings.\nThe field of machine learning is much less mature than FEM, in terms of terminology and also in the development of new numerical methods."
  },
  {
    "objectID": "posts/technical/from-damping-factor-to-learning-rate.html#final-comparison",
    "href": "posts/technical/from-damping-factor-to-learning-rate.html#final-comparison",
    "title": "From damping factor to learning rate",
    "section": "4 Final comparison",
    "text": "4 Final comparison\nWe explored the basics of both fields and pointed out analogies. The analogies often stem from the fact that the underlying optimization math was used. If you are deeped interested in the basics, start here.\nHere is a final comparison table\n\n\n\n\n\n\n\nFEM\nML\n\n\n\n\nDamping / time step \\(\\alpha\\)\nLearning rate \\(\\alpha\\)\n\n\nLoad vector \\(\\mathbf{f}_{\\text{ext}}\\)\nLabels \\(\\mathbf{y}\\)\n\n\nDisplacements \\(\\mathbf{u}\\)\nParameters \\(\\mathbf{w}\\)\n\n\nResidual \\(\\nabla_{\\mathbf{u}} \\Pi=\\mathbf{K} \\mathbf{u}_t-\\mathbf{f}_{\\text{ext}}\\)\nGradient \\(\\nabla J(\\mathbf{w})\\)\n\n\nTangent Stiffness matrix \\(\\mathbf{K}_t\\)\nHessian / curvature of loss \\(\\mathbf{H}\\)"
  },
  {
    "objectID": "posts/technical/how-technical-is-too-technical.html",
    "href": "posts/technical/how-technical-is-too-technical.html",
    "title": "How technical is too technical",
    "section": "",
    "text": "Everyone agrees that reading books on software engineering is beneficial. But what should you read?\nFocusing solely on books about software management or architecture can lead to being trapped in an ivory tower, disconnected from the hands-on work of coding itself.\nWhat about taking the opposite approach?\nAs a professional C++ programmer, there are two key ways to improve your coding skills:\n\nExperiment with APIs: Explore different APIs and test solutions to find the most elegant approach. Why aim for elegance? Because while there are often multiple ways to solve a problem, elegant solutions are typically more readable, maintainable, and intuitive.\nLearn from others: Read books and articles that share the experiences of other developers. These resources often highlight various approaches, sparing you the time of discovering them all on your own."
  },
  {
    "objectID": "posts/technical/how-technical-is-too-technical.html#reading-books-on-software-engineering",
    "href": "posts/technical/how-technical-is-too-technical.html#reading-books-on-software-engineering",
    "title": "How technical is too technical",
    "section": "",
    "text": "Everyone agrees that reading books on software engineering is beneficial. But what should you read?\nFocusing solely on books about software management or architecture can lead to being trapped in an ivory tower, disconnected from the hands-on work of coding itself.\nWhat about taking the opposite approach?\nAs a professional C++ programmer, there are two key ways to improve your coding skills:\n\nExperiment with APIs: Explore different APIs and test solutions to find the most elegant approach. Why aim for elegance? Because while there are often multiple ways to solve a problem, elegant solutions are typically more readable, maintainable, and intuitive.\nLearn from others: Read books and articles that share the experiences of other developers. These resources often highlight various approaches, sparing you the time of discovering them all on your own."
  },
  {
    "objectID": "posts/technical/how-technical-is-too-technical.html#what-did-i-learn-from-modern-c",
    "href": "posts/technical/how-technical-is-too-technical.html#what-did-i-learn-from-modern-c",
    "title": "How technical is too technical",
    "section": "What did i learn from modern c++?",
    "text": "What did i learn from modern c++?\nI read Effective Modern C++ by Scott Meyers to learn the ins and outs of c++11 and 14.\n\nTemplate and auto deduction\nTemplate type deduction can sometimes ignore reference types, especially when dealing with complex, chained types. This behavior can lead to unexpected results.\nWith C++11, the most common instance of this is the auto keyword, which operates similarly to template type deduction. You might have encountered cases where you expected a specific type, but the compiler deduced a different type, causing compatibility issues later. One key difference is the use of braces {}, which indicate a std::initializer_list.\nThe auto keyword also introduces an interesting debate between conservative and progressive tool usage. Advocates of vi-style text editors often prefer explicit types, as they can infer the type directly from the source code. With auto, this is no longer possible.\nHowever, in modern IDEs, explicit type inference is unnecessary because type deduction is readily available via features like hover-over tooltips. This implicit deduction shifts focus to the variable’s purpose rather than its type—provided the variables are well-named.\n\n\nBrace yourself\nHaving picked up my c++ skills after 2011, I used braced or universal initialization as much as I can. It has many advantages and the confusion that arises from the dual use of braces and parantheses is limited to a few cases: std::vector initialization and templates.\n\n\nTypedefs are for Nulls\nLegacy C++ code, especially from older colleagues, often includes NULL and typedefs.\n\nReplace NULL with nullptr. NULL is essentially a compiler directive and less safe compared to nullptr.\nStrive for self-documenting code, which is easier to read and maintain. Avoid standard types when possible and define your own types for clarity.\n\nThe using keyword offers a cleaner, more intuitive syntax compared to typedef: It reads like an assignment and conceptually replaces typedef, functioning to the class keyword.\nFor constants, prefer constexpr over #define to ensure type safety and better integration with modern C++ features.\n\n\nKeep it in order\nNamespace pollution is a common issue in unstructured code. This applies to classic 2000-line functions, but also to modern tools which can lack proper scoping mechanisms, for example early versions of CMake.\nIn C++, scoped enums (enum class) help address this problem by making enums behave more like classes. With enum class, you must explicitly specify the scope to access a value, like telling the compiler which “drawer” to look in for the red_card. For example:\nenum class Color { Red, Green, Blue };\nColor myColor = Color::Red;\nThis prevents naming conflicts and keeps the codebase cleaner.\n\n\nconst correctness\nIf you worked with classes you surely have come accross const correctness. New to me was the fact that the iterators can be const in C++14.\n\n\nBeing smart\nBy now, everyone is familiar with smart pointers and their advantages. However, I often encounter code that exclusively uses shared_ptr. While this doesn’t usually impact performance, it significantly reduces readability.\nMy take aways: Use a standard type. If you get problems think about who is using the variable. If there is only owner and user of the variable use a unique pointer and move it. If you are not sure use a shared pointer. Always use make_shared/unique. All other rules cover the 1 % of all use cases.\n\n\nWe are many\nConcurrent programming is a big topic. My key take away is the prefered usage of std::async instead of threads. Only keep the default launch policy in mind. If you have simultanous access to a member variable use std::atomic.\n\n\nAnd then it got too much\nMuch about the second half of the book is about the difference between lvalue and rvalue and when to move or forward something. I am rarely exposed with the more exotic cases in my work."
  },
  {
    "objectID": "posts/technical/how-technical-is-too-technical.html#my-next-read",
    "href": "posts/technical/how-technical-is-too-technical.html#my-next-read",
    "title": "How technical is too technical",
    "section": "My next read",
    "text": "My next read\nI hope my next book in this area will be far more useful : C++17 STL Cookbook by Jacek Galowicz."
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html",
    "title": "Object oriented programming for AI Projects",
    "section": "",
    "text": "The way we structure our code can make or break a project. But how do you decide when one object should own another, simply use it, or have a more flexible association? Traditionally, software engineering also places a chief focus on code architecture. However, in AI projects there is usually so much to take care o and so much new third party software that the SW architecture often comes last. Even more, many AI engineers have little education in traditional software engineering. Instead, there come from data driven fields in engineering or science.\nThings are getting worse by the choice of the language. Python is AI’s favourite language. However, with all the flexibility python allows, it is very easy to program spaghetti code. While this is true for every language, the lack of strong typing acts as a lack of boundaries. Boundaries enforce structure, and if you have no time to think of your own structure, this can be something good.\nRead on to increase your understanding of the three fundamental ways objects can be related: aggregation, composition, and dependency.\nBy the end of this article, you’ll not only grasp these concepts but also know how to implement them effectively in Python, leveraging type hints for clarity and precision."
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#why-data-science-code-bases-often-lack-structure",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#why-data-science-code-bases-often-lack-structure",
    "title": "Object oriented programming for AI Projects",
    "section": "",
    "text": "The way we structure our code can make or break a project. But how do you decide when one object should own another, simply use it, or have a more flexible association? Traditionally, software engineering also places a chief focus on code architecture. However, in AI projects there is usually so much to take care o and so much new third party software that the SW architecture often comes last. Even more, many AI engineers have little education in traditional software engineering. Instead, there come from data driven fields in engineering or science.\nThings are getting worse by the choice of the language. Python is AI’s favourite language. However, with all the flexibility python allows, it is very easy to program spaghetti code. While this is true for every language, the lack of strong typing acts as a lack of boundaries. Boundaries enforce structure, and if you have no time to think of your own structure, this can be something good.\nRead on to increase your understanding of the three fundamental ways objects can be related: aggregation, composition, and dependency.\nBy the end of this article, you’ll not only grasp these concepts but also know how to implement them effectively in Python, leveraging type hints for clarity and precision."
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#the-importance-of-object-relationships",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#the-importance-of-object-relationships",
    "title": "Object oriented programming for AI Projects",
    "section": "2 The Importance of Object Relationships",
    "text": "2 The Importance of Object Relationships\nImagine building a car simulation. You have classes for Car, Engine, and Driver. How these classes interact is crucial:\n\nShould a Car own an Engine, or just reference one?\nDoes a Driver temporarily use a Car, or is there a deeper connection?\nHow can these relationships affect the maintenance and scalability of your code?\n\nImplementation should follow the SOLID principles.\nWe want\n\nSingle Responsible: only change the class based on one actor\nOpen/Close: classes should be closed for modification, but open for extension via new classes\nInterface Segregation: well-defined interfaces\nDependency Inversion: build on abstractions\n\nCorrectly implementing object relationships can lead to:\n\nCleaner code\nBetter maintainability\nEnhanced scalability"
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#aggregation-the-has-a-relationship",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#aggregation-the-has-a-relationship",
    "title": "Object oriented programming for AI Projects",
    "section": "3 Aggregation: The “Has-a” Relationship",
    "text": "3 Aggregation: The “Has-a” Relationship\nAggregation is a weak association where one class “has-a” reference to another. The lifetimes of the objects are independent.\nThink of a smartphone and a SIM card. The phone “has-a” SIM card, but the SIM card isn’t created by the phone and can be inserted into different phones.\nWhen to Use Aggregation\n\nWhen objects can exist independently.\nWhen you want to reuse existing instances.\nWhen the container doesn’t solely own the contained object.\n\nExample\nfrom typing import Optional\n\nclass Engine:\n    def start(self) -&gt; None:\n        print(\"Engine starts.\")\n\nclass Car:\n    def __init__(self, engine: Engine) -&gt; None:\n        self.engine: Engine = engine  # Aggregation (Car has an Engine)\n\n    def drive(self) -&gt; None:\n        self.engine.start()\n\nOwnership: The same Engine instance can be shared among multiple Car instances.\nLifecycle Management: The Engine can outlive the Car, or vice versa.\nEncapsulation/Coupling: Swap engines without affecting the Car’s structure.\n\n\n\n\n\n\n\nTip\n\n\n\nWhy Type Hints Elevate Your Code Strongly typed Languages like Java and C++ use a lot of OOP. Until recently a big advantage of python was its weak-typing. However weak typing can make code more complex. Especially if types which were not intended for a function are used in that function. If a member is missing, than the code crashes. Type hints can help. They server for static type checking and as documentation embedded in your code. They:\n\nEnhance Readability\nAid in Debugging\nImprove IDE Support"
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#composition-the-owns-a-relationship",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#composition-the-owns-a-relationship",
    "title": "Object oriented programming for AI Projects",
    "section": "4 Composition: The “Owns-a” Relationship",
    "text": "4 Composition: The “Owns-a” Relationship\nComposition is a strong association where one class “owns” another. The lifetime of the owned object is tightly coupled to the owner.\nConsider the human body and its heart. The body “owns” the heart, and the heart doesn’t exist independently outside the body (at least not for very long).\nWhen to Use Composition\n\nWhen the contained object shouldn’t exist without the container.\nWhen the container is solely responsible for the creation and destruction of the contained object.\nWhen you want to enforce a strict lifecycle.\n\nExample\nclass Engine:\n    def start(self) -&gt; None:\n        print(\"Engine starts.\")\n\nclass Car:\n    def __init__(self) -&gt; None:\n        self.engine: Engine = Engine()  # Composition (Car owns an Engine)\n\n    def drive(self) -&gt; None:\n        self.engine.start()\n\nOwnership: Car creates and owns the Engine.\nLifecycle Management: When Car is destroyed, so is its Engine.\nEncapsulation/Coupling: Engine is hidden within Car, emphasizing a strong bond."
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#dependency-the-uses-a-relationship",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#dependency-the-uses-a-relationship",
    "title": "Object oriented programming for AI Projects",
    "section": "5 Dependency: The “Uses-a” Relationship",
    "text": "5 Dependency: The “Uses-a” Relationship\nDependency is a temporary relationship where one class “uses” another to perform a function. It’s the loosest form of coupling.\nImagine renting a car. You “use” the car temporarily, but you don’t own it, and your interaction is limited to the rental period.\nWhen to Use Dependency\n\nWhen a class needs to perform an action using another class temporarily.\nWhen you want to minimize coupling between classes.\nWhen the interaction is brief and method-specific.\n\nExample\nclass Engine:\n    def start(self) -&gt; None:\n        print(\"Engine starts.\")\n\nclass Driver:\n    def operate(self, engine: Engine) -&gt; None:  # Dependency (Driver uses Engine)\n        engine.start()\n\nOwnership: Driver doesn’t own or hold a reference to Engine beyond the method.\nLifecycle Management: Driver uses Engine within the scope of the operate method.\nEncapsulation/Coupling: Changes to Engine have minimal impact on Driver."
  },
  {
    "objectID": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#conclusion",
    "href": "posts/clean-architecture/object-oriented-programming-for-ai-projects.html#conclusion",
    "title": "Object oriented programming for AI Projects",
    "section": "6 Conclusion",
    "text": "6 Conclusion\nUnderstanding the correct relationships between classes is a cornerstone of effective object-oriented programming. Keep those concepts in mind. By just wondering what relations your objects have, you write better code.\nTakeaways:\n\nAggregation is for flexible, independent associations.\nComposition is for strong, dependent ownership.\nDependency is for temporary, minimal coupling.\n\nReady to elevate your Python code? Start applying these principles today and experience the difference in your software development journey."
  },
  {
    "objectID": "posts/clean-architecture/topdown-thinking-is-holding-back-software-innovation.html",
    "href": "posts/clean-architecture/topdown-thinking-is-holding-back-software-innovation.html",
    "title": "Top-Down Thinking is Holding Back Software Innovation",
    "section": "",
    "text": "Dependency inversion requires well-designed interfaces. If interfaces are abstract, they can act as a contract. With this contract, different software teams can develop the same software.\nCould it be that much of today’s software failures result from an effective formulation of those contracts? This results in a strong coupling of software.\nOf course, defining those contracts hands over the control to the fulfiller of the contract. If an internal software team is responible, this means less central planning and more local competition to fulfill contracts. Defining contracts and ecosystems would ease contract fulfillment for external suppliers."
  },
  {
    "objectID": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html",
    "href": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html",
    "title": "How Poor Architectural Understanding is Impacting the German Software Industry",
    "section": "",
    "text": "Slow and steady wins the race. That also applies for software architecture."
  },
  {
    "objectID": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#the-hidden-cost-of-weak-architecture",
    "href": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#the-hidden-cost-of-weak-architecture",
    "title": "How Poor Architectural Understanding is Impacting the German Software Industry",
    "section": "1 The Hidden Cost of Weak Architecture",
    "text": "1 The Hidden Cost of Weak Architecture\nGermany’s industrial landscape—long renowned for engineering excellence—now faces a less visible threat: fragile or non-existent software architecture. This is more than a technical gap: it inflates costs, undermines strategic goals, and leaves CFOs and project teams equally frustrated.\nI came into contact with this at one of my projects. The project had an innovative product, a motivated and skilled team, and innovative technology. Yet, teams spent much of their time battling messy code and poorly integrated systems, turning an exciting initiative into a never-ending fix-it job. These technical failures often stemmed from a lack of—or an immature—software architecture.\nPoor architecture doesn’t stay confined to development; it soon becomes a C-level concern. CFOs see skyrocketing budgets, extended timelines, and uncertain ROI. Projects billed as game-changers collapse under the weight of their own technical debt, revealing just how critical a robust architecture really is.\nTo better understand why rapid development can backfire, consider a familiar fable that illustrates how slow and steady can prevail over quick but careless efforts."
  },
  {
    "objectID": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#the-tortoise-and-the-hare",
    "href": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#the-tortoise-and-the-hare",
    "title": "How Poor Architectural Understanding is Impacting the German Software Industry",
    "section": "2 The Tortoise and the Hare",
    "text": "2 The Tortoise and the Hare\nA common refrain—“We’ll clean it up later”—creates an illusion of speed. Software craftsman Robert C. Martin (Uncle Bob) warns that these quick hacks build up technical debt, eventually slowing development to a near-standstill.\nRacing to production without strong architecture echoes the hare’s fast-but-foolish dash. Deliberate architectural planning—like the tortoise’s slow-but-steady approach—ultimately wins by avoiding crippling rework and spiraling complexity.\nDespite knowing these pitfalls, organizations often resort to drastic measures when problems surface, overlooking the root cause of architectural shortfalls."
  },
  {
    "objectID": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#common-missteps-and-misconceptions",
    "href": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#common-missteps-and-misconceptions",
    "title": "How Poor Architectural Understanding is Impacting the German Software Industry",
    "section": "3 Common Missteps and Misconceptions",
    "text": "3 Common Missteps and Misconceptions\nWhen quality slips, some companies try “quick fixes,” such as firing staff or enforcing strict office attendance. These moves tackle surface-level symptoms rather than the underlying architectural deficits that sparked the crisis.\nOther organizations try scrapping entire systems and rebuilding from scratch. but, if the root problem—lack of architectural discipline—remains unaddressed, these greenfield efforts inevitably repeat the same mistakes, leading to another expensive mess.\nInstead of reactive decisions and costly overhauls, a proactive and structured approach to architecture offers a clear, sustainable way forward."
  },
  {
    "objectID": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#charting-a-better-path",
    "href": "posts/clean-architecture/how-poor-architectural-understanding-is-impacting-the-german-software-industry.html#charting-a-better-path",
    "title": "How Poor Architectural Understanding is Impacting the German Software Industry",
    "section": "4 Charting a Better Path",
    "text": "4 Charting a Better Path\nHow can we fix this? Offer continuous training and mentorship so teams can design robust, future-ready systems. Fostering a culture of craftsmanship ensures that quality and maintainability are not mere afterthoughts.\nBreak down internal silos to create a unified vision of design. Use proven methodologies like Clean Architecture and focus on maintainable, testable code rather than racing to meet unrealistic deadlines. Look beyond quick wins by tracking metrics that say long-term health—code complexity, defect rates, and developer productivity.\nBy embracing the principles of clean code, disciplined design, and sustainable development, organizations can secure both immediate results and lasting innovation."
  },
  {
    "objectID": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html",
    "href": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html",
    "title": "Writing, Doing, and Building an ML Productivity Pipeline",
    "section": "",
    "text": "I tend to learn in two modes. Sometimes I rush in: open the editor, copy a snippet, patch things together until it runs. Other times I slow down: write as I go, explain decisions, leave a trail I can follow later. The first approach builds momentum while the second builds understanding. The hard skill is knowing when to switch.\nWorking with modern machine learning tools like Kaggle notebooks, Hugging Face Spaces, Gradio, I wanted a workflow that remains flexible. While writing can feel slower in the moment it clarifies thinking and prevents rework. In contrast, the speedy approach is energizing; yet without notes I quickly get lost.\nThe solution, for me, is a simple pipeline where exploration, implementation, and communication are part of the same loop.\nThis post outlines that loop.\nI drafted much of it while building a small computer-vision project: the cheese classifier."
  },
  {
    "objectID": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#two-ways-to-learn-new-software-technologies",
    "href": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#two-ways-to-learn-new-software-technologies",
    "title": "Writing, Doing, and Building an ML Productivity Pipeline",
    "section": "",
    "text": "I tend to learn in two modes. Sometimes I rush in: open the editor, copy a snippet, patch things together until it runs. Other times I slow down: write as I go, explain decisions, leave a trail I can follow later. The first approach builds momentum while the second builds understanding. The hard skill is knowing when to switch.\nWorking with modern machine learning tools like Kaggle notebooks, Hugging Face Spaces, Gradio, I wanted a workflow that remains flexible. While writing can feel slower in the moment it clarifies thinking and prevents rework. In contrast, the speedy approach is energizing; yet without notes I quickly get lost.\nThe solution, for me, is a simple pipeline where exploration, implementation, and communication are part of the same loop.\nThis post outlines that loop.\nI drafted much of it while building a small computer-vision project: the cheese classifier."
  },
  {
    "objectID": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#the-pipeline-at-a-glance",
    "href": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#the-pipeline-at-a-glance",
    "title": "Writing, Doing, and Building an ML Productivity Pipeline",
    "section": "2 The pipeline at a glance",
    "text": "2 The pipeline at a glance\n\nProblem definition and model training\nApp for inference of the model\nWriting and publishing\n\nIn practice, this linear process is done in cycles. Training informs the demo, the demo shapes the story, the story clarifies what to train next.\n\n2.1 Stage 1: problem definition and model training\nMost projects begin with a problem statement and end with a model. I often do the reverse when I’m learning. I try a new tool or method first which I find interesting. Then I look for a problem it can help to solve. A word of warning: that approach is definitely not how you should build a successfully commercial product\nMachine learning splits cleanly into training and inference. Inference behaves like ordinary software, which consists of functions with inputs and outputs. Training is exploratory: choices about data, features, and objectives evolve as you learn. Without a record, it’s easy to lose your course.\nThis is where notebooks earn their place. Jupyter notebooks let code, results, and reasoning sit together. If kept in a lab style with comments, you can see what changed and why, when refering back to them.\nHowever, raw notebooks don’t play well with Git. Tools like nbdev help by turning notebooks into maintainable modules. When you work on Kaggle data, sometimes it can be better to run your code locally, or another remote environment. I use a small environment-check snippets to let notebooks run outside or in Kaggle; full code for kaggle auth and data import.\n\n\n2.2 Stage 2: building the app\nWhat better badge for your portfolio than making a small demo into a public one. I use Gradio hosted on Hugging Face to wrap inference in a minimal interface.\nThe app shifts the mindset from internal exploration to external communication.\nA public demo also sets a direction for the write-up. If a reader can click and see the behavior, the post can focus on choices and trade-offs rather than screenshots. The reverse is also true: no demo, then I use screenshots in the post.\n\n\n2.3 Stage 3: writing and publishing\nWriting closes the loop. It converts a set of experiments into a sequence of decisions. As in all good research writing the order might not be the same. I publish with Quarto because it treats Markdown, Jupyter, and Git automatically. The pipeline feels coherent rather than stitched together. See also my other article.\nThere are two workable ways to organize files:\n\nSingle repository: everything, experiments, app, and post, lives together: simple to navigate, slightly messier over time.\nSeparate repositories with selective syncing: experiments and app live in their own project directories. Curated notebooks, flow into the blog: cleaner long term, but requires a small amount of helper scripts.\n\nI use the second approach. In my blog all imported files live under projects/ sometimes with subdirectories. When a notebook is worth sharing, I redact it in the original repo and sync it into the blog repository. While this means I loose some linking ability in my notes app Obsidian, It keeps the writing close to the work."
  },
  {
    "objectID": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#summary-snippets",
    "href": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#summary-snippets",
    "title": "Writing, Doing, and Building an ML Productivity Pipeline",
    "section": "3 Summary snippets",
    "text": "3 Summary snippets\n\nDecide the mode before you start: sprint when you need momentum; write when choices are piling up and you can’t see the path.\nDocument decisions in Jupyter notebooks, not everything: note what changed, why it changed, and what you learned.\nTreat the demo as a learning tool: if the interface feels confused, the model probably is; fixing the demo often clarifies the model.\nKeep writing near the code: whether you use one repo or two, reduce the distance between experiments and narrative.\nPublish smaller; publish sooner: a short post attached to a working demo beats everything."
  },
  {
    "objectID": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#conclusion",
    "href": "posts/writing-doing-and-building-an-ml-productivity-pipeline.html#conclusion",
    "title": "Writing, Doing, and Building an ML Productivity Pipeline",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nParaphrase from everyone’s favourite ChatBot: Productivity isn’t doing more; it’s designing loops that help you learn while you work."
  },
  {
    "objectID": "posts/under-construction-gut-ist-der-vorsatz.html",
    "href": "posts/under-construction-gut-ist-der-vorsatz.html",
    "title": "Under construction Gut ist der Vorsatz",
    "section": "",
    "text": "The resolution is good, but fulfilling it is difficult.\nGut ist der Vorsatz, aber die Erfüllung schwer. - Goethe"
  },
  {
    "objectID": "posts/under-construction-gut-ist-der-vorsatz.html#reflection",
    "href": "posts/under-construction-gut-ist-der-vorsatz.html#reflection",
    "title": "Under construction Gut ist der Vorsatz",
    "section": "Reflection",
    "text": "Reflection\nWhen I started writing a block, I mentioned that most blogs do not make it past the initial launch post.\nSaddly this blog seems to have been befallen by the same illness.\nSo is this the sunset post?"
  },
  {
    "objectID": "posts/under-construction-gut-ist-der-vorsatz.html#what-is-going-on",
    "href": "posts/under-construction-gut-ist-der-vorsatz.html#what-is-going-on",
    "title": "Under construction Gut ist der Vorsatz",
    "section": "What is going on",
    "text": "What is going on\nNO! I merely had some unexpected road blocks on the way. I moved to a new appartment and in the wake of the unfolding events the blogging schedule came under the wheels.\nThe purpose of this blog is storytelling and how to influence with storytelling. This requires me to go through the ## Outlook\n()"
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html",
    "title": "How LLMs help and don’t help developing software",
    "section": "",
    "text": "Everyone says large language models make developers faster.\nI used to believe that too until I spent a week rebuilding a simple image pipeline with ChatGPT.\nWhat I found wasn’t just slower progress. I found a new kind of slowness. The kind that exposes how shallow your understanding really is.\nThis is a story about how LLMs help and don’t help us develop software; where they speed up flow, and where they quietly erode focus, judgment, and attention.\n\n\n\n\nSome years ago I developed an Epaper-based picture frame.\nThe limited bit depth (3-bit) makes gray-scale images look flat. I used a dithering approach to get sharper images.\nThe core of that project was hardware embedded engineering, so I kept the software side light and relied on a GIMP batch processing pipeline.\nGIMP has an implementation of the Floyd-Steinberg dithering.\n\n\n\nGimp Version of Dithering with Floyd-Steinberg\n\n\nI tried before to automate the process and do a simple script for image conversion. In my previous attempts, I could not get the exact same result as GIMP.\n\n\n\nIn 2025, every software developer will have used AI-assisted programming. Some think it is useful; others are not entirely convinced.\nI currently develop an AI-powered Meal Planner. I use ChatGPT a lot in the development as it allows me to outsource manual coding of trivial tasks, so I can focus on architecture tasks or more complex algorithms.\nLately, the responses have become better. So much, that I thought I could just redo the entire pipeline in a browser window. - We are all vibe coding now, aren’t we?\nThe Truth: in the end, I managed it.\nSee the fully working Demo to play with.\n\n\n\nThat was my unequivocal belief before I sat out on this journey. Boy, was I wrong.\nUsing an LLM to do this side project led to many failed attempts and dead ends. With the change to GPT5, the LLM has become more confident in proposing false solutions.\nThis leads me to the core question I want to explore in this post: “Where do LLMs actually help us develop softwrae, and where do they mislead us?”\nRead on, for the seven lessons I am going to share with you."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#the-promised-land-of-vibe-coding",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#the-promised-land-of-vibe-coding",
    "title": "How LLMs help and don’t help developing software",
    "section": "",
    "text": "Everyone says large language models make developers faster.\nI used to believe that too until I spent a week rebuilding a simple image pipeline with ChatGPT.\nWhat I found wasn’t just slower progress. I found a new kind of slowness. The kind that exposes how shallow your understanding really is.\nThis is a story about how LLMs help and don’t help us develop software; where they speed up flow, and where they quietly erode focus, judgment, and attention.\n\n\n\n\nSome years ago I developed an Epaper-based picture frame.\nThe limited bit depth (3-bit) makes gray-scale images look flat. I used a dithering approach to get sharper images.\nThe core of that project was hardware embedded engineering, so I kept the software side light and relied on a GIMP batch processing pipeline.\nGIMP has an implementation of the Floyd-Steinberg dithering.\n\n\n\nGimp Version of Dithering with Floyd-Steinberg\n\n\nI tried before to automate the process and do a simple script for image conversion. In my previous attempts, I could not get the exact same result as GIMP.\n\n\n\nIn 2025, every software developer will have used AI-assisted programming. Some think it is useful; others are not entirely convinced.\nI currently develop an AI-powered Meal Planner. I use ChatGPT a lot in the development as it allows me to outsource manual coding of trivial tasks, so I can focus on architecture tasks or more complex algorithms.\nLately, the responses have become better. So much, that I thought I could just redo the entire pipeline in a browser window. - We are all vibe coding now, aren’t we?\nThe Truth: in the end, I managed it.\nSee the fully working Demo to play with.\n\n\n\nThat was my unequivocal belief before I sat out on this journey. Boy, was I wrong.\nUsing an LLM to do this side project led to many failed attempts and dead ends. With the change to GPT5, the LLM has become more confident in proposing false solutions.\nThis leads me to the core question I want to explore in this post: “Where do LLMs actually help us develop softwrae, and where do they mislead us?”\nRead on, for the seven lessons I am going to share with you."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-1-llms-make-hard-problems-look-easy",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-1-llms-make-hard-problems-look-easy",
    "title": "How LLMs help and don’t help developing software",
    "section": "2 Lesson #1: LLMs make hard problems look easy",
    "text": "2 Lesson #1: LLMs make hard problems look easy\nWhen I started recreating GIMPs Floyd-Steinberg dithering, I thought I’d be done in a breeze. After all, the algo is well documented and fairly simple. What could go wrong?\n\n\n\nPython implementation of Floyd-Steinberg, seems noisier than GIMP\n\n\nYet, my results looked noisier and flatter. A quick Google Search revealed others had reported similar mismatch, discussion here.\nNext comes what every curious engineer with the power of a mighty LLM at his fingertips would do: ask ChatGPT to reimplement GIMP’s code.\nAt first glance, the code seemed straightforward: C code, only heavily relying on raw pointers.\n  src_buf  = g_malloc (width * src_bpp);\n  dest_buf = g_malloc (width * dest_bpp);\n  next_row = g_new (gint, width + 2);\n  prev_row = g_new0 (gint, width + 2);\nChatGPT immediately produced a fully working version,\n…only the results were wrong.\nBecause the full code is too long for the context window, I tried to be clever: breaking it into smaller parts, adding missing functions.\nDigging deeper, I found the issue is that the code relies on far more functions for tone mapping, error diffusion limits, histogram caching. Which rely on even more function.\nNone of which were in the initial prompt.\nWhile I was adding more and more context, I was never getting the same result. What should have been the work of an afternoon already stretched over two days.\nThen I realized the problem was not the LLM or GIMPS pointer code. The issue is, as always, the person in front of the machine; me.\nOf course, I knew LLMs are good at pretending to be fluent, even when they are not. But the issue is that I could not recognize the illiteracy of ChatGPT with the dithering algo.\nBeginner Lesson\nLLMs can make hard problems look easy. Fluent coding isn’t the same as real understanding. LLMs expand the search space, not the understanding space.\nIntermediate Lesson\nExpand your own understanding space\n\nUnderstand an unknown solution and own it conceptually\nAsk the model to explain its reasoning; don’t accept logic that feels incomplete\nExplore boundaries with contrastive examples to see where it breaks.\nExternalize your learning: keep a logbook, sketch diagrams, and track conversation branches.\n\nMastery Lesson\nCultivate your intuition of when an LLM can be trusted, even in unfamiliar domains. That will make you truly faster."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-2-focus-on-the-value-add",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-2-focus-on-the-value-add",
    "title": "How LLMs help and don’t help developing software",
    "section": "3 Lesson #2: Focus on the value add",
    "text": "3 Lesson #2: Focus on the value add\nI probably should have been satisfied with my 1-bit Floyd Steinberg pipeline. Let’s recall, the real goal is to have my pictures on the wall in a dynamic picture frame.\nBut here’s the catch: going through my pictures and sorting them is actually far more effort than the conversion for the picture frame. The optimization of code paths, dithering algo testing and chasing marginal speedups did not add value to the actual problem.\nThat is the quiet but biggest danger of LLMs for mid-career developers: you can solve so many problems, that you forget which ones are worth solving.\nChatGPT & Co lower the barrier to a 50% solution; quick, plausible, traditionally used to get further funding. Those half-baked solutions create new problems: bugs, improvements to make, experiments to run.\nFrom a meta perspective, it’s not so different from how low-impact tasks survive inside large organizations: easy to start, hard to stop.\nBeginner Lesson\nLearn to spot when ChatGPT suggests optimizations that don’t matter.\nIntermediate Lesson\nAdopt a product mindset. Clearly formulate the goal and what you want to achieve. Define what “done” means. Hold that line when the LLM tempts you with shiny detours.\nMastery Lesson\nThe tool amplifies habits. Develop good habits, drop bad ones.\n\nCalibrate to value: Write down The value of this work is * because it improves * . Revisit this statement after each hour.\nCuriosity within boundaries: use constraints, time boxes, iteration caps\nMode awareness: define the mode: learning (speed, breadth, discovery) or production(depth, polish, delivery)\nReflection logbook: what helped, what kind of question was misleading? Reread your chats or transcripts.\nDebug your thinking: ask yourself if you are framing the problem wrong.\nCultivate Strategic Boredom: stop when it is enough"
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-3-correct-initial-framing-beats-repeated-prompting",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-3-correct-initial-framing-beats-repeated-prompting",
    "title": "How LLMs help and don’t help developing software",
    "section": "4 Lesson #3: Correct initial framing beats repeated prompting",
    "text": "4 Lesson #3: Correct initial framing beats repeated prompting\nFrustrated, I was about to give up. Then I stumbled across a new approach: the Teddy-Beau Algorithm.\nThe algorithm creates multiple differently exposed versions of the image, then applies patterned dithering to each, and finally fuses the most contrasting regions. As a result, details stand out while maintaining the textured dither effect.\n\n\n\nTeddy Beau 2D algorithm, has more contrast; the Bayer pattern leads to antialiasing effects when displayed smaller than actual size though.\n\n\nThe demo code is written in JavaScript. As the author points out, it is not optimized and takes quite long.\nSo naturally, I asked my LLM buddy for help: “How to optimize this for performance?”\nChatGPT responded like an eager intern:\n\nFlatten 2D arrays to 1D.\nAvoid expensive array methods like push.\nUse typed arrays for pre-allocation.\nTry Uint8ClampedArray for automatic clamping.\n\nOne more thing. Lately, I have been exploring how to push ML workloads to the client to reduce compute cost and preserve data privacy. This is made possible using a technique called WebGPU.\nI doubled down and added the usage of WebGPU to my requirements. The dream of every product manager focusing on buzzwords alone: GPU acceleration, client-side compute, data privacy.\nI asked for a straightaway optimization with fingers crossed.\nThe first result? A gray picture.\nThen came hours of debugging, chasing error messages like a true VibeCoder.\nEventually, I gave up.\nThe realization: I didn’t need faster code.\nI needed a clearer architecture: what to optimize, in what order, and why.\nBeginner Lesson\nDon’t ask: “Make this faster”! Define what faster means; or explore this with the help of the LLM.\nIntermediate lesson\nBe an architect. Specify technical constraints. Define performance goals, and make the trade-offs explicit.\nMastery Lesson\nUse the LLM to map the landscape, not to sprint through it. Explore what-ifs. Guard against LLM’s instinct to jump to code too quickly. Keep it in design mode."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-4-do-not-succumb-to-the-illusion-of-progress",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-4-do-not-succumb-to-the-illusion-of-progress",
    "title": "How LLMs help and don’t help developing software",
    "section": "5 Lesson #4: Do not succumb to the illusion of progress",
    "text": "5 Lesson #4: Do not succumb to the illusion of progress\nI started from scratch, with an architect’s mindset. First, I asked to include the existing code on a web page that allows modifying parameters with sliders. That worked nicely. Then I told ChatGPT that we are going step by step in the transformation towards a WebGPU version.\nThe Plan:\n\nremove splice\nflatten to 1D with typed arrays\n\npre-allocate arrays\n\nreplace Laplacian of Gaussian with Difference of Gaussian\n\nSIMD: no map, only for\n\nworker thread\n\nuse WebGL\n\nuse WebGPU\n\nThe incremental work went smoothly and then WebGPU delivered the final wow effect: from 500 ms down to 20 ms for a 1MP image. I was ecstatic. Maybe this algorithm could even handle video!\nBut when I looked closer, the pictures weren’t pleasing.\nThe contrast was wrong; the textures felt flat. The fast version looked worse than the slow one.\nIt turned out that Difference of Gaussian is not the same as Laplacian of Gaussian and that the whole histogram calculation had been changed.\nIn chasing performance without reflection, I had altered the architecture.\nIn hindsight, the obvious solution: go slow and use tests. But in that moment, momentum felt like mastery.\nBeginner Lesson\n“Working” code does not imply “correct” code. Pure vibe coding hides understanding behind motion.\nIntermediate Lesson\nResist the illusion of speed. Go slow and write tests. Verify that the tests are correctly written by the LLM. Validate progress with objective, measurable evidence.\nMastery Lesson\nLet the model amplify your rigor, not bypass it. Ask for test scaffolds, validation metrics. Let the LLM be your QA nightmare. True velocity comes from confidence in correctness."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-5-allow-failures.-do-not-suffer-from-the-sunken-cost-fallacy.",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-5-allow-failures.-do-not-suffer-from-the-sunken-cost-fallacy.",
    "title": "How LLMs help and don’t help developing software",
    "section": "6 Lesson #5: Allow failures. Do not suffer from the sunken cost fallacy.",
    "text": "6 Lesson #5: Allow failures. Do not suffer from the sunken cost fallacy.\nI probably should have stopped.\nBut after getting so close, it felt wrong to quit. “All I need are a few simple tests,” I told myself. I started working on 3x3 images and actually managed to progress quickly through the codebase.\nHowever, I underestimated the issues that arise in complex floating-point algorithms. The algorithm is doing several passes for the actual dithering and combines Bayer-based dithering with error diffusion (the original article explains this in more detail).\nThat means any rounding errors can propagate through the image.\nOn small samples, the errors make no change. On full-size images, the algorithm fell apart.\nIn fact, I never got 100% equality on a 1MP image with the highest settings for iterative processing, even after days chasing tiny differences caused by inequality signs, truncation, and clamping.\nAt some point, I realized I wasn’t debugging anymore — I was defending my investment.\nThe LLM kept offering “helpful” directions, and I kept following, the way I once followed overconfident colleagues early in my career.\nThey sounded sure. So did the model.\nBut confidence isn’t correctness.\nSometimes, the real progress is in allowing failure.\nBeginner Lesson\nWhen you keep solving the same issue, that is not progress, that is pure grind. Know when to stop.\nIntermediate Lesson\nLLMs remove friction in syntax and reference lookup. But they also remove the pauses that help us think. Deliberately reintroduce these pauses. Use time-boxing or amount of code change.\nMastery Lesson\nUse the LLM to structure your reflection. Ask for summaries, dead ends, and hypotheses that were made."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-6-technology-fixation-hides-the-real-problem",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-6-technology-fixation-hides-the-real-problem",
    "title": "How LLMs help and don’t help developing software",
    "section": "7 Lesson #6: Technology fixation hides the real problem",
    "text": "7 Lesson #6: Technology fixation hides the real problem\nEventually, I made the algorithm’s result identical.\n\n\n\n1D optimized version, same as 2D version\n\n\nBut the speedups I’d worked so hard for had almost vanished. In single-pass runs, performance improved from 380 ms to 350ms. Only in the multi-pass runs did it look better: 4.7s down to 2s.\nStill, I wasn’t done. I wanted to use WebGPU.\nSo, I turned to ChatGPT once again.\nIt happily produced WebGPU code. Due to the immature state of WebGPU and limited sources, the code was incomplete and buggy, but plausible. I fixed syntax errors, adjusted shader parameters, and eventually got something to run.\nThe result: an educational detour into shaders, pipelines, and GPU execution (Yes, I am a GPU engineer now :-)).\nPerformance improvements were good: using 2 passes, from 2s down to 1s. Using 6 passes: 25s down to 2.8s.\nAgain, visual result was worse than the CPU version.\n\n\n\nGPU Version is darker and more uniform\n\n\nThat’s when I finally stopped myself.\nSomewhere along the way, I had forgotten that looking better was the reason I had selected the algorithm.\nBeginner Lesson\nSpeed gains are meaningless if they don’t serve the goal. Always ask: What does this achieve? What impact does it have on the outcome?\nIntermediate Lesson\nAI tools make every technical path feel accessible. And in part that is true. But every new route has hidden costs. For every new route you take, define what success means. If the gain doesn’t improve the purpose, skip it.\nMastery Lesson\nAgain, focus on the landscape. Let curiosity drive exploration, but set limits with an intent. AI’s biggest cost isn’t in tokens; it’s your attention."
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-7-ai-mirrors-your-thinking-including-your-flaws",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#lesson-7-ai-mirrors-your-thinking-including-your-flaws",
    "title": "How LLMs help and don’t help developing software",
    "section": "8 Lesson #7: AI mirrors your thinking, including your flaws",
    "text": "8 Lesson #7: AI mirrors your thinking, including your flaws\nLesson 6 was about chasing performance. This lesson is quite similar but focuses on features.\nUsing an LLM chat, everything feels easy. You start with a clear goal, then you drift and start exploring aspects which feel productive but aren’t.\nIt’s a lot like browsing the internet: you end up finding things you never searched.\nThe issue with the LLM is that it reinforces you in the believe of wrong ideas. That’s why many say AI assistants only work well “in the hands of an expert.”\nI agree only partly. An expert would only need the AI for very mundane tasks, like code completion. It’s the non-expert, facing a new domain who gains the most. But only if he manages to stop the wandering mind and meandering that come with it.\nAI is an amplifier, not a guide. It doesn’t tell you when your reasoning is off; it makes your detour smoother. To quote I, Robot: you need to “ask the right questions”.\nIn traditional software teams, that role falls to senior engineers and technical managers. They define the what and the why of the product.\nWith LLMs, you need to play the roles yourself to be successful. You’re not just writing code; you’re managing a conversation that can spiral without direction.\nBack to our real problem: displaying images on Epaper. When I read through the Inkplate code and API, I noticed that it also supports a 3bit mode. Quick modification in my 1bit Python script: a simple 3-bit Floyd–Steinberg algorithm almost looks 8bit Grayscale.\nThen why not use the Teddy-Beau algorithm with 3bit?\n\n\n\n3bit Floyd Steinberg, looks almost like an 8bit grayscale picture\n\n\n\n\n\n3bit Teddy Beau, more contrast in the trees but too much in the sky in this picture.\n\n\nComparing the two 3bit versions, I actually like the 3bit Floyd-Steinberg more than the 3bit Teddy-Beau. What was wrong this time, you might wonder? Everything looks good?\nEpaper has a non-linear color curve. What looked perfect on a monitor looked wrong on the device.\nFinally, I chose the Teddy Beau algorithm with 1Bit, which from 2 meters away looks a lot better than on a computer screen.\nBeginner Lesson\nLLM rarely correct wrong assumptions unless prompted to do so.\nIntermediate Lesson\nDon’t expect the LLM to know your true goal. Define context, constraints, and success criteria yourself. The system prompt is your friend.\nMastery Lesson\nTreat the LLM as a mirror, not a mentor. Its responses reflect your framing, clarity, and discipline. You’re not its student. You’re its manager!"
  },
  {
    "objectID": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#conclusion-the-real-work-is-thinking",
    "href": "posts/projects/a-year-in-pictures/how-llms-help-and-dont-help-developing-software.html#conclusion-the-real-work-is-thinking",
    "title": "How LLMs help and don’t help developing software",
    "section": "9 Conclusion: The real work is thinking",
    "text": "9 Conclusion: The real work is thinking\nAfter a week of chasing algorithmic performance gains, I realized the project’s real contribution wasn’t in the image pipeline. Instead, it was in understanding how humans and machines can think together.\nRather than exposing the limits of its reasoning the LLM revealed the limits of mine. In this article every lesson mapped to a deeper skill.\n\nConceptual clarity to increase your understanding space\nPrioritization to focus on value, not optimization.\nProblem definition to frame correctly before prompting.\nDiscipline to follow a stable process\nSelf-awareness to allow failures.\nPurpose alignment to avoid focusing on technology alone.\nJudgment to intentionally direct human-machine interaction\n\nIn short, AI is not a shortcut to mastery. It’s a mirror, reflecting your strengths, weaknesses, and habits on steroids.\nThe promise of LLMs isn’t speed; it’s awareness.\nThey expose how we think, where we skip steps, and how easily we confuse momentum for mastery.\nWorking with an LLM is no longer about writing code faster.\nIt’s about developing a clearer mind.\nIn the end, building software, and yourself, means learning to manage not just a tool, but your own attention.\nThat’s the real craft of this new era: knowing when to move fast, and when to slow down on purpose.\n\nA hammer is only as precise as the hand (and mind) that wields it.\n\nThe algorithms can be compared here. Source Code can be found here."
  },
  {
    "objectID": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html",
    "href": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html",
    "title": "Do you know the hidden paths of your code?",
    "section": "",
    "text": "Try seeing the forest for the trees."
  },
  {
    "objectID": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#what-if-we-had-a-zoom-button-for-our-code",
    "href": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#what-if-we-had-a-zoom-button-for-our-code",
    "title": "Do you know the hidden paths of your code?",
    "section": "1 What if we had a zoom button for our code?",
    "text": "1 What if we had a zoom button for our code?\nThink about code as a Digital Map. From far away, you can see the continents. When you zoom in, rivers and mountains appear. Then cities. Highways and train lines become visible. Then smaller streets. At the second to lowest level, you can see the street layout of a neighborhood. Until finally you can see one house or a tree.\nEven better when you search for a route from A to B. You can usually see it on all zoom levels. Quickly grasping the entire journey, as well as local challenges.\nWhat if we had something equivalent for code? First the module architecture and finally the code lines? And then what if we could see data flow in this full picture on several levels?\nI have to express my thanks to a former colleague of mine, who coined the term zoom button for this. In the following, I describe my approach to get closer to this zoom button."
  },
  {
    "objectID": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-i-a-picture-says-more-than-a-thousand-words",
    "href": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-i-a-picture-says-more-than-a-thousand-words",
    "title": "Do you know the hidden paths of your code?",
    "section": "2 Part I: A picture says more than a thousand words",
    "text": "2 Part I: A picture says more than a thousand words\nAnd so does a diagram. This part is about my motivation for doing this work. If you are only interested in results, skip it and go to part II.\n\n2.1 Software engineering is about reading code\n\nThere are 10 types of people in this world, those who understand binary and those who don’t.\n\n\n2.1.1 What Beginners and Non software Developers do not get\nA novice expects that developing software is all about writing code. And I have to admit that just hacking away can initially feel good. Directly coding and doing everything from scratch feels so powerful. The raw power is just at your fingertips. You are the wizard of the computer - in then end you will pay dearly. You get stuck in the mud of your code. This is blind activism.\nLarge companies are not immune to this. In fact, sometimes the management structure incentivizes quick hacks and fast coding over constant architecture development.\n\n\n2.1.2 The role of non-software people\nThe rise of non-code application and then the onset of the hype of LLM in 2022 have led to the fear that programming and software developers have no future. In the future, anybody can code. Personally, I disagree with this. My argument is not purely based on self-preservation. Instead, I believe AI can replace that simple apps that were done before by a single developer. However, the software engineers concerned will move to bigger projects. Similar as we do not know every single assembler instruction or binary instruction, we might no longer know every single code line in our precious masterpiece.\nTeams will focus on higher value tasks or just be quicker in developing new features. Engineers will focus more on higher-level tasks: system engineering, architecture and customer interaction. There could be a conversion of specialized engineering roles. The same team might do requirements, design, Code, and testing. Concentrating multiple roles on fewer staff. The cost of friction in human interactions will do the rest. The excessive cost of inter-team communication outweighs specialized teams’ remaining advantages. But until we get there, it will be a few more years with a lot of unforeseen changes.\n\n\n2.1.3 We always face new code\nAs we learn more and more during our journey as software developers, we discover reading code is far more important than writing. Usually we read someone else’s code and try to understand it.\nFor consulting-work or a short-term project, this is obvious.\nIf you always work on the same enormous project, you need to switch assignments and will work on different components. In fact, a dynamic and growing software business will always need to pivot the existing engineering staff to other tasks. Just hiring new engineers is not cost efficient.\nEven when you work all by yourself. Remembering the details of your code becomes difficult after about six months.\nSo regardless of your works nature. If you are productive, you will frequently encounter new code which needs to put into your works context. We need to understand if the code is doing what it should do. Figuring out what it should is about as hard as ensuring that it is doing this.\nThat is why I believe software engineers can not be replaced. Problem discovery and formulation is currently engrained in the process of writing code. Removing or simplifying the process of writing, will not remove problem discovery and formulation.\n\n\n\n2.2 How we approach unknown code\n\n2.2.1 Missing documentation makes it harder\nSadly, not all codebases have perfect documentation. The more innovative the business is, the more it will rely on exploration. Often, the original creator quickly produced and then abandoned his software. Take open source source software. While there are many gems with an outstanding code standard, there are as many counterexamples. Even more, even a perfectly documented code, becomes difficult to use if relies on a framework and there are major shifts in the framework.\nOne such shift is the change from Python 2 to Python 3. Projects can go stale as it becomes more difficult to update them.\nThe lack of documentation and especially lack of documented software architecture profoundly hinders grasping the code from a top-down perspective. The only solution, dig through the code.\n\n\n2.2.2 Poorly designed software takes a long time to understand\nPoorly written software may have suboptimal abstraction and encapsulation.\nAn example: Because of performance issues, it can be necessary to use a data structure as an input/output parameter. However, while this is comfortable, it increases code complexity dramatically. This mechanism invites us to just pass on a massive data structure and change a bit about it. Take enough of these functions and complexity will blow up in your face. A similar code smell is the god object. In such a class, side effects are none-obvious.\nThe only way to uncover the hidden connections is to read the complete code and keep track of the connections and dependencies which are important to you. Even with a modern IDE (search, find usage), this remains a very time-consuming task.\n\n\n\n2.3 SOLID principles and model-based system engineering\n\n2.3.1 Towards a clean architecture\nWhile I read about the importance of SOLID principles and good architecture in Clean Architecture, I thought about the code I produced myself. Where did I not apply these principles?\nMy biggest programming sin is definitively the code that I wrote during my PhD. A non-linear finite element solver, with different material models and integration schemes.\nIt lacked so many things. While it had classes, it did not obey all SOLID principles. In particular, it violated dependency inversion. The most abstract classes depended usually on the most concrete classes. For example, instead of using a high level builder, an intermediate level featured flags to select the proper material model. This whole architecture made it quite difficult to test the code. Of course, it did not matter to me, as the thoughts of code coverage and TDD had never crossed my mind.\nNow, having done a in-depth study of ‘Clean Architecture’ and the details about dependency inversion, I wanted to make a clean architecture for my FEM solver.\nI did not even know where to start. Of course my code had an architecture. The architecture had, however, mostly grown organically.\n\n\n2.3.2 Model based engineering\nAs a software developer, I’ve grown fond of using simple Mermaid or PlantUML diagrams. These small diagrams are more formal than paper-based drawings, while still allowing enough freedom to detail the abstractions. UML is the go to tool to formalize your architecture.\nChoosing a pure paper based approach or digital paper in form of text files, one faces the issue to keep source and documentation always in sync.\nIt was when working on a large-scale project with a dedicated modelling team; I learned about model-based system engineering. Tools like Enterprise Architecture can generate code from UML diagrams. Some of those tools can even analyse your code and create UML diagrams.\nAs a result, you get two views on the same software. One abstract (UML/SysML) and one very concrete (Code). The computer takes care to keep both in sync.\nThe abstract system models are usually consistent over several abstraction levels. However, the connection to code only happens at the lowest level. If the connection were to happen on any level, these models could act as the zoom button for the software.\nThe major drawback? Usability. Nowadays, software engineers use an IDE. And once being accustomed to their favourite IDE, they do not want to leave it.\nTools like Enterprise Architect have a steep learning curve, while not having any of the features a modern IDE has. In practice this seems not important. Many safety-aware businesses using model-based system engineering create special roles dedicated to these tools. This introduces the drawback of splitting the model and the code over two people instead of bringing everything closer together.\nIn addition, these tools can be pricey. A no-go for small to medium-sized projects.\nAnother alternative I discovered is the C4 diagram https://c4model.com. There are some projects that aim to automate the creation https://structurizr.com/.\n\n\n\n2.4 The two-way problem of model-based engineering\n\n2.4.1 Forward: Code to diagrams\nGenerating diagrams from code is state-of-the art. In the following I will only dive into the tools for this usage. Most of the time, tools focus on the class at hand or automatic generation of class diagrams over several classes.\n\n\n2.4.2 Backward: Diagrams to code\nThe other way round generating code from diagrams can be much more difficult. Existing system engineering tools can do this. Correct application of MBSE, in fact, results in very detailed diagrams; the model has already gathered all the information. Therefore it is easy to afterwards generate template based modules. This was actually not my idea when I thought about abstraction and a zoom button. As a side node, doing so usually leads to a schism between software engineers and system engineers. In addition, the lack of connection between the two tools usually results in duplicated information.\nA better approach could be the use of multimodal large language models. In an ideal world, we would draw a diagram and describe what we want. The computer would adjust the diagram to the correct constraints and then implement the code. Currently, in 2025, that is not how code generation works, even though the field is moving fast. The part of the constraints is lacking.\nThere are disadvantages to this approach. First, such diagrams would need to be flexible enough to facilitate discussion with all stakeholders. Discussions often leave out important details. Potentially, by writing done these assumptions, a LLM could take care of adding the abstracted information in the diagram.\nSecond, Model-based engineering enforces formalism, leading to better performance through standardized solutions. However, for the highest performance, we usually need to cut corners. This requires the direct modification of the code by us. That again would be the other direction again. Depending on the domain, it could be faster to directly write the code yourself."
  },
  {
    "objectID": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-ii-capturing-all-dependencies-in-one-diagram",
    "href": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-ii-capturing-all-dependencies-in-one-diagram",
    "title": "Do you know the hidden paths of your code?",
    "section": "3 Part II: capturing all dependencies in one diagram",
    "text": "3 Part II: capturing all dependencies in one diagram\nWhen I looked into the subtopic of code to diagrams, I focused on Python. Static-typed languages like C++ are even better for code analysis because of the explicit typing in the code. Many C++ programmers use doxygen extensively. For Python, the code needs to have type hints, for everything beyond base types.\nI found a few open source tools: Pyreverse, Pynsource and Py2Puml. As I explain below, Py2Puml is the best one. However, it falls short in the documentation of class methods. Not really satisfied with the output, I wrote some modifications. Finally, I considered how to better caputure dependencies using graphs. That is why I wrote Py2Graph.\n\n3.1 Meet our guinea-pig package: Productworld\nTo evaluate the different programs, I came up with a simple package: Productworld.\nBelow, you find the package structure and the full code.\nImportant to me was the use of an abstract class and the occurrence of the other classes in signature, member list, and function bodies. I also wanted free functions to be documented. Regardless how important, free functions do not exist in a standard UML class diagram. So I expected the tools to fall short here.\n\n3.1.1 Packages and Components\n\nproductworld/\n├── base/\n│   ├── base.py\n│   └── customer.py\n└── products/\n    └── products.py\n\n\n\n3.1.2 The full code\n# base.py\nfrom abc import ABC, abstractmethod  \n  \nclass Product(ABC):  \n    def __init__(self, product_id, name):  \n        self.product_id = product_id  \n        self.name = name  \n  \n    @abstractmethod  \n    def get_price(self):  \n        pass  \n  \n  \nclass NewOrder:  \n    def __init__(self, order_id, product: Product, quantity):  \n        self.order_id = order_id  \n        self.product:Product = product  \n        self.quantity = quantity  \n  \n    def calculate_total(self, product:Product)-&gt;int:  \n        return self.product.price * self.quantity  \n  \nclass Order:  \n    def __init__(self, order_id, product:Product, quantity):  \n        self.order_id = order_id  \n        self.product = Product()  \n        self.quantity = quantity  \n  \n    def calculate_total(self)-&gt;int:  \n        return self.product.price * self.quantity  \n  \n          \ndef fancyFunc(order: Order):  \n  return 42  \n  def funkyFunc():  \n return 42\n\n\n# customer.py\nfrom typing import List  \n  \nfrom productworld.base.base import Order,fancyFunc, NewOrder  \n  \n  \nclass Customer:  \n    def __init__(self, customer_id, name):  \n        self.customer_id = customer_id  \n        self.name = name  \n        self.orders = []  \n        self.newestOrder :NewOrder = NewOrder()  \n  \n    def add_order(self, order: Order):  \n        self.orders.append(order)  \n        self.orders.append(NewOrder())  \n        fancyFunc(order)  \n  \n    def get_total_spent(self)-&gt; int:  \n        return sum(order.calculate_total() for order in self.orders)\n\n# products.py\nfrom productworld.base.base import Product  \n  \nfrom productworld.base.base import funkyFunc  \n       \nclass PhysicalProduct(Product):  \n    def __init__(self, product_id, name, price):  \n        super().__init__(product_id, name)  \n        self.price = price  \n  \n    def get_price(self):  \n        return self.price  \n  \nclass DigitalProduct(Product):  \n    def __init__(self, product_id, name, price, discount):  \n        super().__init__(product_id, name)  \n        self.price = price  \n        self.discount = discount  \n        funkyFunc()  \n  \n    def get_price(self)-&gt;int:  \n        return self.price * (1 - self.discount)   \n          \nclass Productfactory():  \n def create_product(self,pid:str)-&gt;PhysicalProduct|DigitalProduct:  \n   return PhysicalProduct()  \n     \ndef create_product(self,pid:str)-&gt;PhysicalProduct|DigitalProduct:  \n  return PhysicalProduct()\n\n\n\n3.2 Existing tools\n\n3.2.1 Pyreverse\nPyreverse is part of Pylint and allows you to create an UML diagram for your code.\nIf you have Pylint installed, you can easily run it with the following command:\npyreverse  -ALSmy  -o puml     --verbose . \nWhat works well:\n\nInheritance is correctly captured\nAggregation is correctly captured\nArgument and return types are identified\n\nWhat does not work:\n\nPackages and components are not shown\nArgument and return type dependencies are not resolved\nIt is a pure UML Class diagram, therefore free functions are not covered\nUsage of classes in function body is not covered\n\nThis is the picture I got:\n\n\n\nPyreverse is a good start, but lacks critical connections\n\n\n\n\n3.2.2 Pynsource\nNext I tried Pynsource, which offers a GUI. Adding new files is cumbersome. It’s impossible to update a complete model. Overall, I do not recommend this. The result is worse than Pyreverse.\nWhat works:\n\nInheritance is correctly captured\nAggregation is captured as a normal dependency\nUsage of classes in function body is covered as dependency\n\nWhat does not work:\n\nPackages and components are not shown\nArgument and return type dependencies are not resolved\nIt is a pure UML Class diagram, therefore free functions are not covered\nMember types are not identified\n\nIn the free version, no saving of the UML file is possible, only a screenshot.\n\n\n\nPynsource has even less information\n\n\n\n\n3.2.3 Py2puml\nFinally, I tested Py2puml.\nWhat works:\n\nInheritance is correctly captured\nAggregation is captured as a composition\nMember types are identified\nPackages and components are not shown\nAbstract class is correctly shown\n\nAs I am focused on a clean architecture with dependency inversion, the correct capture of the abstract class is strong plus.\nWhat does not work:\n\nClass methods are not shown and as such, no argument and return type dependencies are resolved\nIt is a pure UML Class diagram, therefore free functions are not covered\nUsage of classes in function body is not covered\n\nOverall, I like this the most. The packages reflect the driectories and the components the files. The notion of different levels can be found in this picture.\n\n\n\nPy2puml provides us with information on the module structure, but missing class methods.\n\n\n\n\n\n3.3 My Contribution\nAs highlighted above, none of the programs clearly delivered what I wanted to do.\nMy favourite was Py2Puml. First, I addressed its major drawback: missing functions.\n\n3.3.1 Py2puml with methods\nLuckily for me, there is a py2puml fork that tries to deal with the class method. Details can be found in the pull requests for the py2puml, here.\nUnfortunately, the structure of py2puml has changed since the fork date, and the merge is not that straightforward. The PR remains in limbo for 2 years.\nI performed a rudimentary merge of this fork, but this clearly ruined my secondary goal of finding something suitable for production, not just a hobby. I now have loaded myself with a vast pile of technical debt.\nMy code is often a mixture of classes and free functions. Therefore, I collect all free functions in Annotation called Methods. Such an annotation exists in every component, every file. Some other minor changes were done as well.\nThese changes addressed almost all the critical points of Py2Puml\nWhat does still not work:\n\nUsage of classes in function body is not covered\n\nThe picture is now much more detailed. There are several connections that did not exist before. The richness of this picture would allow us to add different zoom levels and options. We could clearly hide, for example, the usage of free functions within the same component. However, we should highlight usage across components.\n\n\n\nClass methods are back thanks to an old fork.\n\n\n\n\n3.3.2 The next level: Py2Graph\n\n3.3.2.0.1 Problem description\nThere remains the missing linkage of functions that are used within the body of another function. For an inspection, that is quite bad. By changing a class A that is used within the body of another class’ B function, we influence behavior of class B. This is exactly the sort of connection we are interested in and which should be visible. The question is Which classes does class A influence.\nThe second drawback is performance. Even on this tiny example, the Py2Puml requires almost 20 milliseconds. For something which should work in not much more than a few milliseconds, that is too long.\n\n\n3.3.2.0.2 Digging deeper\nThe reason is in the architecture of Py2puml. It basically collects lists and then merges them together. To correctly cover all dependencies, we need two passes on the entire codebase. First, we identify existing functions, and then we identify their usage within other classes.\nThe same issue applies for the function body. In theory that could also be made to work for the original approach using list.\n\n\n3.3.2.0.3 My Approach: Graphs\nI avoided these issues by using another data structure. Instead of using lists, I moved to a graph-based analysis.\nMy analysis first analysis all entities (files, modules, classes, functions, members) in hierarchical order. I create a graph node for every parsed entity.\nEdges link contained entities or types with their parent. So a module contains classes, which contain functions and members. This approach ensures coverage of connections within functions. Naturally, this analysis might not include the class used, thus preventing a link. This problem is the two pass issue, again.\nWe resolved the two-pass issue by using a placeholder node for expressions the parser had not yet visited. Once the parser analyzes the true entity, it replaces the placeholder node, but keeps its connections.\nIf placeholder nodes remain, that is usually a sign that the expression is not from the package in analysis. The system suppresses placeholders in the output.\n\n\n3.3.2.1 Analysis of solution\nMy approach only took 3ms. The speedup actually surprised me. I attribute it to the more efficient implementation of networkx digraph, compared to manual parsing of list and dicts.\nThere can now be multiple relationships between two elements, as we distinguish usage in the class and usage in the class methods. The diagram is becoming more complex. This is exactly what I had in mind when I started my tjourney. It is far easier to reduce the full picture to something less than making sense of an incomplete picture.\nThe new connection is visible in the connection to base.base.fancyFunc and base.base.funkyFunc. Order is used byfancyFunc. But in the previous version both functions were not used by anybody. In the new version you can see that funkyFunc is used by DigitalProduct. Whereas fancyFunc is used by Customer.\nIn the final version of the code I changed to straight lines.\n\n\n\nUsage of a graph structure helps us to get the all connections.\n\n\n\n\n3.3.2.2 A bigger example\nAs initially mentioned, my interest in reverse diagram generation stemmed from my FEM solver. I rewrote parts of it in Python to test how to implement dependency inversion. And how this would look like in the project class diagram. Just for the record, I provide the full view here.\n\n\n\nFull view of a python port of my FEM solver classes"
  },
  {
    "objectID": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-iii-whats-next---productization",
    "href": "posts/projects/uml-analyser/do-you-know-the-hidden-paths-of-your-code.html#part-iii-whats-next---productization",
    "title": "Do you know the hidden paths of your code?",
    "section": "4 Part III: what’s next - Productization",
    "text": "4 Part III: what’s next - Productization\nSo far, this has been a nice study to learn more about UML class relations and the usage of graphs.\nBut how could this actually add value in a real project? Remember my colleague who came up with the name zoom button? Clearly we need to run this in a more integrated fashion. It should be a zoom button on a current version of the software. That is why runtime is critical.\n\n4.1 Live preview\nIn Pycharm the PlantUML plugin can provide a live view of the UML text file.\nI implemented something similar: A live view that analysis the entire project.\nSaving triggers a new generation of the diagram.\nHere we have two screenshots: in the second I introduced self.newPrice = 100 to PhysicalProduct. Because of the slow render time, the change was instant. Type is correctly inferred as int from using 100.\n\n\n\nScreenshot before the manipulation\n\n\n\n\n\nScreenshot after adding a member variable\n\n\nThe implementation works by watching for file changes and running a docker image with PlantUML. Upon detecting a change, analyzis is triggered. The UML code from Py2Graph is sent to the PlantUML server. The Server returns the image to the frontend for Display.\n\n\n\nDeployment view of the live mode\n\n\n\n\n4.2 The complete zoom button\nI set out to develop the zoom button. Clearly, by showing a more complete picture with all modules, component, and dependencies, we have done the first step. What is missing now is too selectively show information.\nThis would require to drop certain information from the graph and then send it to the render server. Highlighting a class’s influence zones would be acccomplished the same way. Thanks to the graph-based structure, we only need to carry out these steps on a graph, not on lists or text files.\n\n\n4.3 Going beyond the zoom button\nWhat else could be done.\nA call graph or a natural language model can auto-generate sequence diagrams, visualizing data flow as in LabVIEW/Simulink.\nIf any of these applications are interesting to you, just drop me a message and let’s discuss.\nSources for the Py2Puml mod\nSources for Py2Graph"
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "",
    "text": "C++ is often treated as a legacy programming language. Or something you only need when you are worried about low level system performance. With WebAssembly, that boundary is shifting.\nThe benefit of WebAssembly: free client side compute. You wrap you costly backend logic and ship it to the client.\nWhile I have been familiar with the idea, I wanted to see how this turns out in practice.\nSpoiler. Yes compute is free, development time isn’t. You can see the solution here"
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#c-for-the-masses",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#c-for-the-masses",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "",
    "text": "C++ is often treated as a legacy programming language. Or something you only need when you are worried about low level system performance. With WebAssembly, that boundary is shifting.\nThe benefit of WebAssembly: free client side compute. You wrap you costly backend logic and ship it to the client.\nWhile I have been familiar with the idea, I wanted to see how this turns out in practice.\nSpoiler. Yes compute is free, development time isn’t. You can see the solution here"
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#the-color-contrast-grid",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#the-color-contrast-grid",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "2 The color contrast grid",
    "text": "2 The color contrast grid\nI built a small program that arrangers colors in a grid to maximize contrast between neighbors. While simple, the search space is fast and optimization algorithms are difficult to implement.\n\n\n\ncolors.jpeg\n\n\nBesides brute force, I tried hill climbing and simulated annealing. But the problem is actually a little bit more complex than I thought and would need more time.\nTherefore, I focused on straightforward C++ improvement: inlining of functions, avoiding to reallocate memory inside loops and lookup tables. The speedups are between 15% to 30%."
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#getting-c-data-into-the-browser-window",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#getting-c-data-into-the-browser-window",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "3 Getting C++ Data into the Browser Window",
    "text": "3 Getting C++ Data into the Browser Window\nWebAssembly offers a way to run high-performance code safely in the browser. Using Emscripten, I compiled the solver into a module and connected it to a small TypeScript UI.\nBiggest lesson learned: complex objects cannot cross the boundary by value.\nSimply evoking call by value functions of complex objects lead to memory leaks. We can use shared memory buffers to avoid these leaks.\nWe need\n\na fixed buffer in Typescript\na C++ function to fill the buffer\nanother Typescript function to read from it\n\nI implemented this using an additional webworker, as I run several grids at the same time\nBuffer declaration in the main.ts\n// We first declare the buffer and allocate memory\nconst canvasRGBBuffers: SharedArrayBuffer[] = [];  \nconst canvasRGBViews: Uint8Array[] = [];\n\ncanvasRGBBuffers[canvasIndex] = new SharedArrayBuffer(dim * dim * 3); \ncanvasRGBViews[canvasIndex] = new Uint8Array(rgbSAB);\nC++ Function\n// In my example I have a global object storing pointers to the algorithms\nstd::unordered_map&lt;int, std::unique_ptr&lt;Algorithm&gt; &gt; algos;\n\n// This is the actual function that reads the grid\nvoid export_grid_rgb(int id, std::uint8_t *out, int max_len) {\n// get grid from the algorithm\n    auto &algo = *algos.at(id);  \n    auto *grid = algo.getBestGrid();\n...\n}\n\n// Emscripten Binding to export to typescript\nfunction(\"export_grid_rgb\",  \n         optional_override([](int id, uintptr_t ptr, int len) {  \n             auto *buf = reinterpret_cast&lt;std::uint8_t *&gt;(ptr);  \n             export_grid_rgb(id, buf, len);  \n         })  \n);\nTypescript Invocation in the worker\n// Receive callback in worker, receives the memory and then forwards the pointer\nself.onmessage = async (ev) =&gt; {  \n    const {  \n        sab,   \n    } = ev.data;\nconst createModule = (await import(scriptUrl)).default;  \nwasmModule = await createModule();\n\n\nconst sharedRGB = new Uint8Array(sab);\nconst rgbLen = sharedRGB.length;  \nconst wasmRGBPtr = wasmModule._malloc(rgbLen);\nwasmModule.export_grid_rgb(canvasIndex, wasmRGBPtr, rgbLen);\n}\nTypescript main\n// Send command in main\nworker.postMessage({  \n    sab: canvasRGBBuffers[canvasIndex],  \n});\n\n// Receive callback in main only uses the view on the buffer\nworker.onmessage = (ev) =&gt; {  \n...\n  \n    const rgbView = canvasRGBViews;  \n    drawGridFromRGB(canvas, rgbView, dim);\n    ...\n}"
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#webassembly-limitations",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#webassembly-limitations",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "4 Webassembly Limitations",
    "text": "4 Webassembly Limitations\n\n4.1 Resources\nI discovered there are resource limitations.\n\n16GB of memory\nMain thread wasm must yield back every 30 odd seconds to avoid dialogs\nWorker threads may be put to sleep if window not in focus\n\nHowever, that is the size of a small cloud virtual PC. Another aligned technology that allows the usage of gpu is WebGPU. For an intro to both, see this.\nCurrently GPU access in Webassembly is only possible via the JS-apis. But once direct access is possible, there could be even better performance gains.\n\n\n4.2 Webhosting\nTo use the webworkers, we require threads. And to use those we need special CORS headers. These headers are not available on Github Pages, why I needed to host the project on Cloudflare. For hobbiest, that just one extra layer."
  },
  {
    "objectID": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#summary",
    "href": "posts/projects/webassembly/c-in-your-browser-is-webassembly-worth-the-effort.html#summary",
    "title": "C++ in your Browser. Is WebAssembly worth the effort?",
    "section": "5 Summary",
    "text": "5 Summary\nAs you can see getting something to work in WebAssembly is requires quite a lot of boilerplate code. As the technology is less used LLMs are less of a help. While I used LLMs to create this examples a lot of manual effort was necessary.\nFor many prototypes, this effort would be better directed into the value adding activities.\nThis leads to a dilemma: say you have a business idea that would work well if the cloud compute would not be ruining the business case. WebAssembly could make it fly, but to get to working prototype you would be better off developing a FastApi Backend with Python and some pybind bindings for the C++ part.\nSome Example Ideas\n\nScientific compute with free tier computations\nClient Side ML of SLMs or voice transcription\n\nBut I guess that is always the case with infrastructure technology. There is always an upfront cost that needs to be paid.\n\nSource Code is available here\nProject is live here"
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "",
    "text": "For software developers who have been around for some time, the ever-evolving landscape of tools sometimes becomes frustrating.\nToday I want to write about one aspect of the development cycle: deployment.\nUntil a few years ago, deployment was not so much in the development team’s focus. We had separate teams for operations, then slowly DevOps came into our world. From packages, the more advanced teams moved to Docker. Then came the orchestration with carefully crafted scripts or docker compose and docker swarm for the lazy. And then there is Kubernetes.\nIn 2017, if you were not deeply working on cloud solutions back then , you had little connection to it. Nowadays, that is different.\nThe software world gets more and more connected. Even the epitome of non cloud software, embedded software, gets connected. Great, if your team can have a separate cloud engineer. But what if not? What if responsibility for your cloud backend needs to be shared? This requires not only theoretical knowledge of cloud containerization but some hard-working skills.\nSame for many AI startups search for engineers that know this kind of orchestration. In part because it is essential for the business to operate, in part because the existing engineers are not able to deliver this. The engineers skills are heavily focused on AI, so that a extra engineer is required to take care of the cloud orchestration.\nYou can easily understand the standard mechanics of Kubernetes: a container goes in a pod, which has restricted hardware resources. When the pod reaches repeatedly its limits, a new pod is created.\nThat is the theory, I create a small demo to visualize how this works in practice.\nSo if you work on any solution that uses a cloud backend and the number of users is dynamic, have a look at this article.\n\n\nWhen the number of users grows, the servers of your backend have an increased load. At some point one CPU is not enough; you need more. But how much more? And when to scale up?\nThat is the topic of vertical and horizontal scaling. With Kubernetes resources are constrained.\nVertical scaling just increases the resources assigned to your application\nHorizontal scaling adds clones of your application and uses a load balancer.\nSome examples may help.\nVertical scaling is best if the user number stays constant, but the process requires more and more resources: ML training, or complex simulation with unforeseen resource demand are such examples.\nHorizontal scaling works best if the requests can be treated in parallel. This is the standard for web apps, where more and more users send requests. In this demo, we look into horizontal scaling.\n\n\n\nBefore we explain the application, let’s look into some Kubernetes Theory. If you have already read this somewhere else skip to the next section.\nThe following diagram shows the architecture of the Kubernetes cluster.\n\n\n\n\n\nflowchart TD\n\n  \n\n%% External client\n\nClient[Client]\n\n  \n\n%% Service block\n\nSVC[Service ]\n\n  \n\n%% Node-proxy block\n\nNode[Kube-Proxy ]\n\n  \n\n%% Pod group block\n\nsubgraph PodsGroup [Pod replicas ]\n\nPodA[Pod A]\n\nPodB[Pod B]\n\nPodC[Pod C]\n\nend\n\n  \n\n%% Control plane\n\nsubgraph ControlPlane [Kubernetes Control Plane]\n\nHPA[Horizontal Pod Autoscaler]\n\nMetrics[Metrics Server]\n\nAPI[Kubernetes API Server]\n\nend\n\n  \n\nclass ControlPlane ctrlPlane;\n\nclass PodsGroup, dataPlane;\n\n  \n\n%% Connections\n\nClient --&gt;|request| SVC\n\nSVC --&gt;|forward| Node\n\nNode --&gt; PodA\n\nNode --&gt; PodB\n\nNode --&gt; PodC\n\n  \n\nPodA -.-&gt;|metrics| Metrics\n\nPodB -.-&gt;|metrics| Metrics\n\nPodC -.-&gt;|metrics| Metrics\n\n  \n\nMetrics --&gt; HPA\n\nHPA --&gt;|scale up/down| API\n\nAPI --&gt;|create/delete pods| PodsGroup\n\n\n\n\n\n\nWe start with the user, that is our Client.\nThe Client sends his ‘Request’ to a Service. This services acts as load balancer and calls Kube-Proxy on each node to distribute requests. On the node, there are uses several clones of the same Container. The application container in Kubernetes is wrapped inside a resource constrained Pod Therefore there a multiple replicas of the same Pod (A,B, C).\nThe Kubernetes Control Plane contains the orchestration to handle the scaling. We have the Metrics Server which collects CPU and memory usage from each Pod. The Horizontal Pod Autoscaler (HPA) acts on these metrics and scales the pod number up and down. These actions are executed using Kubernetes API Server.\nKey to scaling is the logic inside the HPA, see the deep-dive at the end of the post."
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#kubernetes-for-the-seasoned-non-cloud-software-developer",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#kubernetes-for-the-seasoned-non-cloud-software-developer",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "",
    "text": "For software developers who have been around for some time, the ever-evolving landscape of tools sometimes becomes frustrating.\nToday I want to write about one aspect of the development cycle: deployment.\nUntil a few years ago, deployment was not so much in the development team’s focus. We had separate teams for operations, then slowly DevOps came into our world. From packages, the more advanced teams moved to Docker. Then came the orchestration with carefully crafted scripts or docker compose and docker swarm for the lazy. And then there is Kubernetes.\nIn 2017, if you were not deeply working on cloud solutions back then , you had little connection to it. Nowadays, that is different.\nThe software world gets more and more connected. Even the epitome of non cloud software, embedded software, gets connected. Great, if your team can have a separate cloud engineer. But what if not? What if responsibility for your cloud backend needs to be shared? This requires not only theoretical knowledge of cloud containerization but some hard-working skills.\nSame for many AI startups search for engineers that know this kind of orchestration. In part because it is essential for the business to operate, in part because the existing engineers are not able to deliver this. The engineers skills are heavily focused on AI, so that a extra engineer is required to take care of the cloud orchestration.\nYou can easily understand the standard mechanics of Kubernetes: a container goes in a pod, which has restricted hardware resources. When the pod reaches repeatedly its limits, a new pod is created.\nThat is the theory, I create a small demo to visualize how this works in practice.\nSo if you work on any solution that uses a cloud backend and the number of users is dynamic, have a look at this article.\n\n\nWhen the number of users grows, the servers of your backend have an increased load. At some point one CPU is not enough; you need more. But how much more? And when to scale up?\nThat is the topic of vertical and horizontal scaling. With Kubernetes resources are constrained.\nVertical scaling just increases the resources assigned to your application\nHorizontal scaling adds clones of your application and uses a load balancer.\nSome examples may help.\nVertical scaling is best if the user number stays constant, but the process requires more and more resources: ML training, or complex simulation with unforeseen resource demand are such examples.\nHorizontal scaling works best if the requests can be treated in parallel. This is the standard for web apps, where more and more users send requests. In this demo, we look into horizontal scaling.\n\n\n\nBefore we explain the application, let’s look into some Kubernetes Theory. If you have already read this somewhere else skip to the next section.\nThe following diagram shows the architecture of the Kubernetes cluster.\n\n\n\n\n\nflowchart TD\n\n  \n\n%% External client\n\nClient[Client]\n\n  \n\n%% Service block\n\nSVC[Service ]\n\n  \n\n%% Node-proxy block\n\nNode[Kube-Proxy ]\n\n  \n\n%% Pod group block\n\nsubgraph PodsGroup [Pod replicas ]\n\nPodA[Pod A]\n\nPodB[Pod B]\n\nPodC[Pod C]\n\nend\n\n  \n\n%% Control plane\n\nsubgraph ControlPlane [Kubernetes Control Plane]\n\nHPA[Horizontal Pod Autoscaler]\n\nMetrics[Metrics Server]\n\nAPI[Kubernetes API Server]\n\nend\n\n  \n\nclass ControlPlane ctrlPlane;\n\nclass PodsGroup, dataPlane;\n\n  \n\n%% Connections\n\nClient --&gt;|request| SVC\n\nSVC --&gt;|forward| Node\n\nNode --&gt; PodA\n\nNode --&gt; PodB\n\nNode --&gt; PodC\n\n  \n\nPodA -.-&gt;|metrics| Metrics\n\nPodB -.-&gt;|metrics| Metrics\n\nPodC -.-&gt;|metrics| Metrics\n\n  \n\nMetrics --&gt; HPA\n\nHPA --&gt;|scale up/down| API\n\nAPI --&gt;|create/delete pods| PodsGroup\n\n\n\n\n\n\nWe start with the user, that is our Client.\nThe Client sends his ‘Request’ to a Service. This services acts as load balancer and calls Kube-Proxy on each node to distribute requests. On the node, there are uses several clones of the same Container. The application container in Kubernetes is wrapped inside a resource constrained Pod Therefore there a multiple replicas of the same Pod (A,B, C).\nThe Kubernetes Control Plane contains the orchestration to handle the scaling. We have the Metrics Server which collects CPU and memory usage from each Pod. The Horizontal Pod Autoscaler (HPA) acts on these metrics and scales the pod number up and down. These actions are executed using Kubernetes API Server.\nKey to scaling is the logic inside the HPA, see the deep-dive at the end of the post."
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#the-demo-project-architecture",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#the-demo-project-architecture",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "2 The demo project architecture",
    "text": "2 The demo project architecture\n\n2.1 A simple core process\nMany real applications are too complicated to play around with the Kubernetes settings. Instead, we just want something stable. It is not our interest to see when the system brakes.\nHowever, for a demo that is exactly what we want.\nTo achieve this, we use a simple CPU burn process. This comes with some flaws, as we will later see, but it allows us to focus more on Kubernetes mechanics.\nThis burn process is inside a small backend. The method is put in a small C++ backend using httplib for the webserver.\nvoid burn_cpu(int ms) {  \n    auto end = high_resolution_clock::now() + milliseconds(ms);  \n    volatile double x = 0.0001;  \n    while (high_resolution_clock::now() &lt; end) {  \n        x = std::sin(x) * std::cos(x) * std::tan(x + 1e-6);  \n    }  \n}\n\n\n2.2 The users\nOf course the most important part in the drama of autoscaling is played by the user.\nOur users are the hyperactive. They can not wait long for the news to appear on the screen. They constantly press F5 and hope for new content.\nWhen I first implemented the behavior I did naive implementation. However, without network lag, that leads to many many requests per second already for the first two users. That is one of reasons many servers have rate limits. It is not only the cost by request, but also the scaling cost.\nThat is actually not what we want. The users should show a defined behavior, and not act too quickly. If we spawn a new pod, that pod is automatically consumed by the users as they can get even quicker results.\nOne thing we could do is to prescribe the refresh rate in the frontend:\nsetInterval(() =&gt; {  \n    while (inflight &lt; targetUsers) {  \n        inflight++;  \n        fireUser();  \n    }  \n    inflightEl.textContent = String(inflight);  \n}, REFRESH_RATE);\nUsing REFRESH_RATE changes what we are actually simulating, we switch from a CPU based simulation to a request per second based simulation. The CPU becomes the side effect. Using the CPU load as metric for the HPA does not work in this case. Any improvement of the backend processing time does not lead to quicker cycles as these are bounded.\nInstead, we simulate real user behavior. We add a variable think time at the end of fireUser and let FireUser call itself. The same way a user would need to absorb the new content on the screen before pressing F5 again.\nfetch(`/compute?ms=${workMs}`)  \n    ...\n    .finally(() =&gt; {  \n      ...\n        // Realistic user: wait before next action  \n        const thinkTime = 200 + Math.random() * 300;  // 200–500ms  \n        fireUser();  \n        }, thinkTime);  \n    });\n\n\n2.3 Distributed architecture\nA Typescript frontend allows us to control the app.\n\n\n\nFrontend to drive scaling of the pods\n\n\nAs in a normal backend, the number of users drives the numbers of requests. We use a 1:1 mapping for simplicity. Different webservices have different tasks. We assume that the tasks are identically sized for each user. Therefore, we only allow the size of the task to change, that is how long the CPU is busy. The first plot shows the response time for each request.\nIn addition, we read metrics from the backend. We will explore the details further below. From this metrics we get the CPU usage per pod, and the average load relative to the resource constraint.\nThe frontend and the backend are both wrapped inside Docker containers. This is the architecture:\n\n\n\n\n\nflowchart TD\n\n\nUser[User Browser]\n  \n\nsubgraph FRONTEND_CONTAINER[Container Frontend]\n\nFE_APP[Typescript Frontend]\n\nend\n\n  \n\nsubgraph BACKEND_CONTAINER[Container Backend]\n\nBE_APP[C++ Webserver]\n\nend\n\n  \n\nUser --&gt;|HTTP request| FE_APP\n\nFE_APP --&gt;|Compute| BE_APP\n\n  \n\nFE_APP --&gt;|Metrics| BE_APP\n\n\n\n\n\n\n\n\n2.4 Single Node Kubernetes setup\nKubernetes is designed for large scale cloud architectures with many machines. In the cluster world these computers are called nodes. For simplicity I will stick to one node, my pc. If you want to trial multi-node usage you can use KillerCoda. However, each node only has only 1 CPU in the free version. You will need to deal with node synchronization and fetching metrics from several nodes. At scale this is solved using tools like Prometheus. Complex orchestration becomes easier using a package manager for Kubernetes like Helm.\nYou can run Kubernetes on your own PC with Minikube.\n\n2.4.1 Setting up the demo Kubernetes server\nSome important commands before you start building your Docker images.\n# Start Minikube\nminikube start\n\n# We need metrics, therefore we use the metrics server\nminikube addons enable metrics-server\n\n# We need to use the minikube docker daemon\neval \"$(minikube docker-env)\"\nDefault Kubernetes settings are conservative to avoid oscillations. Metric intervals are long to avoid acting on spikes. In contrast, for our demo that is exactly what we want. The metrics interval is usually 60s. We can lower it to 15s.\n# Optional: change metrics server delay:\nkubectl -n kube-system patch deployment metrics-server \\\n  --type='json' \\\n  -p='[\n    {\n      \"op\": \"replace\",\n      \"path\": \"/spec/template/spec/containers/0/args\",\n      \"value\": [\"--metric-resolution=15s\"]\n    }\n  ]'\n\nkubectl rollout restart deployment metrics-server -n kube-system"
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#starting-the-demo",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#starting-the-demo",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "3 Starting the demo",
    "text": "3 Starting the demo\nFirst, you need to clone the repo\ngit clone https://github.com/dolind/color_contrast_k8s\nand run it\nrun_demo.sh\nIf you prefer more direct control you can invoke kubectl, to control Kubernetes. Once Docker images are build and pushed to the k8s registry, a single command is enough to start the cluster.\nkubectl apply -f k8s.yaml\n\n3.1 Useful commands\nVerify the running pods with:\nkubectl top pods -n demo-autoscale\nAccess the frontend:\nminikube service frontend -n demo-autoscale\nSee the HPA status:\nkubectl get hpa -n demo-autoscale\nStop everything:\nkubectl delete all --all -n demo-autoscale"
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#the-demo",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#the-demo",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "4 The demo",
    "text": "4 The demo\n\n4.1 Try it yourself\nThe best experience is to try it yourself. I could not find any good free hosting to do this. However the installation instructions for minikube are quite straightforward. Give it a try.\n\n4.1.1 What you can do\nAdjust the user slider: As more users request the workload, the request time starts to increase. Increase of users is showed with a yellow line and numbers.\nAdjust the work time slider: this hits even harder.\nKubernetes is configured in such a way, that it will increase the number of pods if CPU usage repeatedly exceeds 80%. For scaling up, a green line is plotted in the requests plot. A red line for downscaling.\n\n\n\n4.2 Commented recording\nSometimes a good demo is a powerpoint or a video. If you can not use the demo yourself, watch the video at the end of the post. In the following I comment what you can see. If you tried the demo yourself and are more interested in technical details, skip to the deep dive.\n\n4.2.1 Warming up\nWe start by slowly adding users up to 11 (each increase is marked by yellow lines, with small numbers).\n\nThe response time stays almost constant. The initial spikes can be attributed to background process on my machine. After 5 users, the load is increasing. Even after it passed the threshold of 80% with 8 users, it remains quite long at elevated value of 120% for 11 users. Only then does the HPA spawn a new pod (green line).\nAfter a short startup period, the new pod becomes effective and average load drops below the threshold. This traffic would be identical to a new server in the very early morning.\n\n\n4.2.2 User Growth\nLet’s see how the system reacts when we add more and more users, up to the maximum of 100.\nThis is equivalent to the morning rush at 9 am, when a lot of people might use our service. \nThe first wave only goes up to 28 users. After the usual delay, the HPA adds a new pod and manages to bring the load close to 100%.\nAs you will later see in the settings, scaling is always conservative as we allow load spikes. In addition, only one pod can be created at a time.\nNext stage, we quickly go up to 57 users. This is equivalent to a faster rush to the servers. \nWe can again see the delay, but then the HPA quickly spawns three pods, bringing the load down to 102%.\n\n\n4.2.3 Maximum load\nIn a final increase, we very quickly up the user number to 100 users (almost doubling it). The delay is a little smaller now, and three pods are created. However, the load is not going fully down and the HPA waits for stabilization until craeting three more pods. This brings the load back to 86%. \n\n\n4.2.4 Load reduction\nOur website features flash sales at 9 am. At 9h30, the promotion rate drops. As a result our user numbers reduce by 50%.\nOur pods are underutilized, the load is far below the target line.\nThe HPA reacts to this with quick downscaling (red lines). I allowed scaling down several pods at once. As a result, we overscale. Ultimately the HPA needs to bring back up two pods, but lands at 85%.\n\n\n\n4.2.5 System update\nOne of our engineers made the mistake and introduced a system update right before lunch. The update made the workload go up from 10ms to 90ms per user.\nAs a result, the response time is now almost 10 times higher 207 ms vs 24 ms. And the average CPU load has gone up to 250%.\nThe HPA reacts after his normal delay, but than scales only with the allowed 1 pod and stabilization periods. This results in a long recovery.\nThe message: never do an update to all users at midday."
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#deep-dive-explanations",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#deep-dive-explanations",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "5 Deep dive explanations",
    "text": "5 Deep dive explanations\n\n5.1 Why Scaling is lagging behind\nThe metrics on the dashboard use a process called kubelet. There is little delay in this metric and we often see a nice match between request increase and load. However, the Scaling relies on two other services: Horizontal Pod Autoscaler (HPA), Metrics Server. The Metrics Server collects from kubelet, with the configured interval (standard 60s, we reduced to 15s), HPA controller runs every 15s. That means we could have a delay of up to 30s.\n\n\n5.2 Demo Scaling vs Production use\nAs a workaround to this metrics delay, I restricted scaling frequency to 10s and only 1 Pod.\nI also tweaked the resource settings to make the whole scaling experience more reactive to the sliders.\nThat is not what we want in production.\nUsers numbers do not increase that rapidly. Increases are usually more related to time of the day and are predicable. It is very rare for many people hitting a server at the same time, but when it happens the system usually goes down.\n\n\n5.3 The k8s.yaml explained\nThe whole Kubernetes cluster is configured in a yaml file. We will go through each section in this file.\n\n\n5.4 Namespaces\nFirst of all we can define namespaces. For microservices architecture with many containers, namespaces have the benefit that we can limit the inspection of running pods to a certain namespace.\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: demo-autoscale\n\n5.4.1 Services\nIn this demo, we expose a single external endpoint via a Service.\nWe can see that both backend and frontend are structured similarly:\n# Frontend\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  namespace: demo-autoscale\nspec:\n  type: NodePort\n  selector:\n    app: frontend\n  ports:\n    - port: 80\n      targetPort: 80\n      nodePort: 30080\n# Backend\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend\n  namespace: demo-autoscale\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 8080\n      targetPort: 8080\nOne specific detail here for demo workflows: we use nodePort. This allows us to connect directly to the node port. Otherwise, we would need an ingress controller, something I do not treat in this demo.\n\n\n5.4.2 Deployments\nDeployments connect a container to pods and nodes and can detail resource constraints.\nThe Frontend is defined to only exist once. As for our app we do not expect much load to the frontend server.\nwe define\napiVersion: apps/v1  \nkind: Deployment  \nmetadata:  \n  name: frontend  \n  namespace: demo-autoscale  \nspec:  \n  replicas: 1  \n  selector:  \n    matchLabels:  \n      app: frontend  \n  template:  \n    metadata:  \n      labels:  \n        app: frontend  \n    spec:  \n      nodeSelector:  \n        kubernetes.io/hostname: minikube  \n      containers:  \n      - name: frontend  \n        image: frontend:latest  \n        imagePullPolicy: Never  \n        ports:  \n        - containerPort: 80\nThe option nodeSelector means we pinpoint it to a specific node. This be becomes useful in multi-node environments. As we build our containers right before starting the cluster, we disable pulling. Policies to pull from a specific repository are also possible.\nThe backend deployment is more interesting\napiVersion: apps/v1  \nkind: Deployment  \nmetadata:  \n  name: backend  \n  namespace: demo-autoscale  \nspec:  \n  replicas: 1  \n  selector:  \n    matchLabels:  \n      app: backend  \n  template:  \n    metadata:  \n      labels:  \n        app: backend  \n    spec:  \n      containers:  \n      - name: backend  \n        image: backend:latest  \n        imagePullPolicy: Never  \n        env:  \n          - name: NODE_NAME   # needed for metrics\n            valueFrom:  \n              fieldRef:  \n                fieldPath: spec.nodeName  \n        ports:  \n        - containerPort: 8080  \n        resources:  \n          requests:  \n            cpu: \"250m\"  \n            memory: \"64Mi\"  \n          limits:  \n            cpu: \"700m\"  \n            memory: \"128Mi\"  \n        livenessProbe:  \n          httpGet:  \n            path: /healthz  \n            port: 8080  \n          initialDelaySeconds: 3  \n          periodSeconds: 10  \n        readinessProbe:  \n          httpGet:  \n            path: /healthz  \n            port: 8080  \n          initialDelaySeconds: 2  \n          periodSeconds: 5\nNote the resources block. We define requests to detail how much of a CPU one pod can request, defined in millicores. In our case, we use a quarter of a core, 250m. In limits we allow spikes. The pod can not use more than 0.7 cores. Same concept for memory.\n\n\n5.4.3 Horizontal Pod Autoscaling\nHorizontal Pod Autoscaling (HPA) is the brain behind the scaling\napiVersion: autoscaling/v2  \nkind: HorizontalPodAutoscaler  \nmetadata:  \n  name: backend  \n  namespace: demo-autoscale  \nspec:  \n  scaleTargetRef:  \n    apiVersion: apps/v1  \n    kind: Deployment  \n    name: backend  \n  minReplicas: 1  \n  maxReplicas: 20  \n  behavior:  \n    scaleDown:  \n      stabilizationWindowSeconds: 0  \n      policies:  \n        - type: Percent  \n          value: 200  \n          periodSeconds: 5  \n  \n    scaleUp:  \n      stabilizationWindowSeconds: 10  \n      policies:  \n        - type: Pods  \n          value: 1  \n          periodSeconds: 10  \n  metrics:  \n    - type: Resource  \n      resource:  \n        name: cpu  \n        target:  \n          type: Utilization  \n          averageUtilization: 80\nscaleTargetRef defines for which deployment the scaling is valid. We start with one pod, or replica, but can use up to maxReplicas=20.\nThe whole scaling logic is in behavior and metrics.\nIn metrics, we define the 80% limit, which has been mentioned before. This limit is calcculated with respect to the requests constraint of the deployment.\nIn behavior, we define to check every 10s. Keep in mind, that the metrics server only updates only every 15s. Scaling up is limited to 1 pod.\nFor downscaling i wanted, immediate downscaling. I removed the stabilization window, and allowed downscaling every 5s. 200% means we can remove up to the minimum of replicas. To my dissatisfaction that did not work in practice.\n\n\n5.4.4 Access rights\nThere are some additional settings in this project’s k8s.yaml. These are related to security and Role-Based Access Control. Even for a small local demo they are necessary for the HPA and the kubelet metrics to work properly."
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#summary",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#summary",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "6 Summary",
    "text": "6 Summary\nGreat, you made it to the end! I hope you this post helpful. While it is possible to define resource constraints in Docker, those values are final: a container cannot consume more resources than you assign. Kubernetes makes this more flexible by creating additional pod replicas, each with its own resource limits. In addition, the whole deployment can span multiple nodes.\nThe dynamic nature of this scaling becomes visual when we add spikes to the requests. The conservative scaling laws that provide stability in normal operation mean that scaling takes longer in peak situations.\n\n6.1 Why does this matter for non-cloud software engineers.\nIn today’s rapidly changing technical landscape, you should keep up-to-date. Many companies now search a Full-Stack-Engineer. And Full-Stack increasingly means someone who can handle algorithms, architecture, CI-pipelines, deployments, and observability. The last two items are traditionally “ops, but in modern DevOps they have become part of everyday working. Kubernetes is a central tool here.\nBut what about all us who happily work on our embedded devices, large and small? There, is Firmware-Over-The-Air and cloud supervision require connectivity. Once Kubernetes is set up, you may not need to touch it often. But under stress, having an idea of the mechanics pays way more than just knowing the concepts.\nThere’s also the trend toward edge devices, AI workloads are a major driver here, and traffic often ends up hitting backend systems. In many cases, Kubernetes tooling provides benefits over simple Docker Compose setups:\n\nSelf Healing: Pods restart automatically if they crash.\nRolling updates: New version comes up before the old one goes down; automatic rollbacks are easy to implement.\nService Discovery & Networking: Built-in DNS and load balancing; scaling requires no manual wiring.\nResource Scaling: Core concept completely missing in plain Docker and Docker Compose"
  },
  {
    "objectID": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#add-on-the-full-video",
    "href": "posts/projects/kubernetes/kubernetes-for-the-seasoned-noncloud-software-developer.html#add-on-the-full-video",
    "title": "Kubernetes for the seasoned non-cloud software developer",
    "section": "7 Add-on: The full video",
    "text": "7 Add-on: The full video\nThis is the full video of the scaling"
  },
  {
    "objectID": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html",
    "href": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html",
    "title": "How to fight computer eye strain",
    "section": "",
    "text": "Computer work strains your eyes and body.\nA lot of computer programmers have eye issues. The problems range from glasses to alignment problems in binocular vision.\n\nThere are many exercises one can do. For example, look out of the window and back at a pencil.\nMagic Eye books up to full fledge 3D glasses with medical apps.\n\n\n\nhttps://en.wikipedia.org/wiki/Magic_Eye\n\n\n\n\n\nhttps://avalonweb.com.au/demo/\n\n\nDuring my studies, I spent so many hours glued to a screen that I developed a light form of misalignment. When I was tired, my eyes ached and focusing on distant objects became difficult. A friend of mine reports issues much worse. He said he would always see two cars and would decide to drive through one when overtaking a car. He got it fixed with surgery.\nThose with mild symptoms may help from looking out the window.\nOr change the focus between your fingertip and a distant object.\n\n\n\nEye exercises can help: https://asmy.org.au/yoga/eye-exercises/\n\n\nI used to have a paper to train the convergence of the eyes. I could carry this with me for a quick relaxing of the eyes.\n.\nThis small paper works like the magic eye book. When eyes are relaxed, a third circle appears. With time, the picture got old and torn. As I could not find an offer for these papers, my first version was a handcrafted python script.\nI found more examples for those figures."
  },
  {
    "objectID": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#computer-work-is-heavy-weightlifting",
    "href": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#computer-work-is-heavy-weightlifting",
    "title": "How to fight computer eye strain",
    "section": "",
    "text": "Computer work strains your eyes and body.\nA lot of computer programmers have eye issues. The problems range from glasses to alignment problems in binocular vision.\n\nThere are many exercises one can do. For example, look out of the window and back at a pencil.\nMagic Eye books up to full fledge 3D glasses with medical apps.\n\n\n\nhttps://en.wikipedia.org/wiki/Magic_Eye\n\n\n\n\n\nhttps://avalonweb.com.au/demo/\n\n\nDuring my studies, I spent so many hours glued to a screen that I developed a light form of misalignment. When I was tired, my eyes ached and focusing on distant objects became difficult. A friend of mine reports issues much worse. He said he would always see two cars and would decide to drive through one when overtaking a car. He got it fixed with surgery.\nThose with mild symptoms may help from looking out the window.\nOr change the focus between your fingertip and a distant object.\n\n\n\nEye exercises can help: https://asmy.org.au/yoga/eye-exercises/\n\n\nI used to have a paper to train the convergence of the eyes. I could carry this with me for a quick relaxing of the eyes.\n.\nThis small paper works like the magic eye book. When eyes are relaxed, a third circle appears. With time, the picture got old and torn. As I could not find an offer for these papers, my first version was a handcrafted python script.\nI found more examples for those figures."
  },
  {
    "objectID": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#turning-the-circles-into-an-app.",
    "href": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#turning-the-circles-into-an-app.",
    "title": "How to fight computer eye strain",
    "section": "Turning the circles into an app.",
    "text": "Turning the circles into an app.\nBased on the python prototype, I thought about packaging the work as an app. To me, the most convenient way is a dynamic form where one can play around to motivate oneself to take out the “paper”.\nI first tried to realize this with kivy. I had a desktop kivy app running in no time on my pc. In contrast, compiling and packaging for Android turned out to be a nightmare. Kivy requires buildozer which comes with a million other settings and you end up in framework hell."
  },
  {
    "objectID": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#chatgpt-and-flutter-to-the-rescue",
    "href": "posts/projects/eyetrainer/how-to-fight-computer-eye-strain.html#chatgpt-and-flutter-to-the-rescue",
    "title": "How to fight computer eye strain",
    "section": "ChatGPT and Flutter to the rescue",
    "text": "ChatGPT and Flutter to the rescue\nAfter a while, I abandoned the project. Then came ChatGPT. For me, ChatGPT flattens the learning curve in many technologies. If ChatGPT has access to the app’s entire context, it works like a charm. For Android apps, a Flutter app comprises fewer files than a Java based app. As of writing, ChatGPT handles several files well. In 2023 and 2024, the quickest way for best results is the copy&paste approach.\nMy Flutter app saw the light of the day and works both on desktop and mobile.\nSee the following screenshots.\n\n\nAll code can be found in https://github.com/dolind/eyetrainer.\n\nWhat to different next time\nNowadays, I would write a web app and package it inside an app."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html",
    "href": "posts/projects/recipescanner/page_segmentation.html",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "",
    "text": "When I first started working on recipescanner, the biggest issue was scanning multi column pages and multi recipe pages. How to group the output from the OCR scan in such a way that recipes are not mixed with each other?\nThe following table shows different options of workflows, from image to fully parsed recipe.\n\n\n\n\n\n\n\n\n\n\n\nOption\nHow it Works\nSpeed (per page)\nNeeds\nBest When\nCost\n\n\n\n\n1. OCR → LLM Parsing\nExtract with OCR, LLM for classification\n3–5 s (small LLM)15–30 s (vision-LLM)\nGPU or strong CPU, few GB RAM\nLayouts are messy\nMedium\n\n\n2. Vision → Text (Donut / Pix2Struct)\nEnd-to-end vision does classification\n0.8–2 s on GPU\nGPU / NNAPI required\nHandwriting, warped images\nHigh\n\n\n3. OCR → Segmentation → Rules / Small Model\nExtract with OCR, Rules or DecisionTree for classification\n0.3 s on CPU\nCPU only, ~400 MB RAM\nScans are clean and structured\nLow\n\n\n\nFor pages with multiple recipes, the approach can be separated into two stages.\n\nImage to Text Blocks and recipe sections\nClassification of each recipe into ingredients, description, …\n\nThe division of the task into smaller tasks allows us to use less complex methods. In this notebook we focus on the task #1.\n\n\nNowadays, one straightforward solution is to run an LLM on the OCR output and ask it to cluster the text. You can even set up a complete workflow: cluster the text, check it, extract ingredients and instructions and the check again to ensure all content is used recipes are not mixed up.\nThe downside about all this? It is expensive to run. Especially if we introduce correctness checks. How much more expensive?\nFor reference, Google currently charges $1.5 per 1000 pages, whereas as Mistral asks for $3 per 1000 pages for annotated output. Google’s new interface, which (like Mistral) relies on Vision Transformers also charges asks for $1.5 per 1000 pages. Layout parsing costs extra at $10 per 1000 pages.\nLet’s say each of your users has about 2000 books he wants to convert. That results to $23 per user; and that is without classification. A custom extractor sets you back another $20. So the full workflow is about $50 per user. Again only for recipe extraction. Interaction with the recipe database will probably cost around $3 per month.\n\n\n\nI recently tested Docling, a transformer-based architecture. It has created quite a buzz recently.\nHere is my short evaluation. On the document which we are going to use throughout this notebook, it failed. The deterministic demo (temperature=0) got stuck in an inference loop. I tried increasing temperature and add other tweaks to help the model escape local optima. This came at the cost of accuracy.\nThe model repeated titles as ingredients for other recipes and failed to stop properly.\n\n\n\nDocling Result: one recipe title is not detected as such\n\n\nThe model has issue with line breaks: “Die Pilze damit bin-den” became “Pilze damit ben den” including line breaks.\nOn top of that, the speed was poor on a legacy GPU (GTX 1080), despite running at full load for the full time of 22 seconds! Memory consumption was steadily increasing as more tokens were decoded, just barely fitting on the 8GB GPU with 6.5GB max usage.\nReflecting on the architecture, I suspect it must work better on obscure edge cases. Complex Formats with overlaying figures or strongly nested tables could perform better.\nStrangely, even the demo mostly showcases simple formats.\n\n\n\nLayout Parsing is not new. In fact, it became popular about three years ago.\nOne such layout parser is the actual LayoutParser. It combines an automatic analysis of OCR output and segmentation. Unfortunately, the segmentation is done with detecron2. The active development seems to have stopped and it no longer works on my python installation (Python 3.12). My research revealed Python 3.9 as the last working version.\nA more recent model is DocLayout-YOLO. Based on the already massive YOLO dataset, it uses a very large document dataset to identify bounding boxes and classification in a combined loss function.\nWhat it lacks, however, is an automatic connection to OCR. One can either crop and ocr the text boxes or align with the OCR output.\nHere is an example:\n\n\nCode\n# Standard library\nimport glob\nimport json\nimport os\nimport random\nimport warnings\nfrom difflib import SequenceMatcher\nfrom pathlib import Path\n\n# Third-party\nimport cv2\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageDraw\n# Local / custom\nfrom doclayout_yolo import YOLOv10\nfrom sklearn.metrics import accuracy_score\n\n# Jupyter magic\n%matplotlib inline\n\n# Suppress all warnings (optional)\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\nCode\nmodel = YOLOv10(\"data/models/doclayout_yolo.pt\")\ndet_res = model.predict(\n    \"data/raw/20250922_135514.jpg\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\n\n\n\n\nCode\nannotated_frame = det_res[0].plot(pil=True, line_width=10, font_size=30)\nimg_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(10, 14))\nplt.imshow(img_rgb)\nplt.axis(\"off\")\nplt.title(\"Segmentation using Doclayout YOLO\")\nplt.show()\n\n\n\n\n\n\n\n\n\nDespite knowing nothing about the text, the CNN could still discover the layout. Which is clear, you don’t need to understand a language to break a book into paragraphs.\nThere are some errors in how the titles are handled. Bright red boxes highlight detected titles, and we can see that there are too many.\nWhen we run the CUDA-enabled version, the total runtime is 164ms, 650ms for cold start, whereas on CPU it can take up to 1.6s.\n\n\n\nAnd then there’s the domain knowledge approach. That is how I started. If we know all the text on a page, its location, and assume it’s a recipe: can we identify where recipes end, and which text belongs to which recipe?\nIn this notebook, I will examine this way and how it compares to DocLayout-YOLO."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#many-ways-lead-to-digitized-documents",
    "href": "posts/projects/recipescanner/page_segmentation.html#many-ways-lead-to-digitized-documents",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "",
    "text": "When I first started working on recipescanner, the biggest issue was scanning multi column pages and multi recipe pages. How to group the output from the OCR scan in such a way that recipes are not mixed with each other?\nThe following table shows different options of workflows, from image to fully parsed recipe.\n\n\n\n\n\n\n\n\n\n\n\nOption\nHow it Works\nSpeed (per page)\nNeeds\nBest When\nCost\n\n\n\n\n1. OCR → LLM Parsing\nExtract with OCR, LLM for classification\n3–5 s (small LLM)15–30 s (vision-LLM)\nGPU or strong CPU, few GB RAM\nLayouts are messy\nMedium\n\n\n2. Vision → Text (Donut / Pix2Struct)\nEnd-to-end vision does classification\n0.8–2 s on GPU\nGPU / NNAPI required\nHandwriting, warped images\nHigh\n\n\n3. OCR → Segmentation → Rules / Small Model\nExtract with OCR, Rules or DecisionTree for classification\n0.3 s on CPU\nCPU only, ~400 MB RAM\nScans are clean and structured\nLow\n\n\n\nFor pages with multiple recipes, the approach can be separated into two stages.\n\nImage to Text Blocks and recipe sections\nClassification of each recipe into ingredients, description, …\n\nThe division of the task into smaller tasks allows us to use less complex methods. In this notebook we focus on the task #1.\n\n\nNowadays, one straightforward solution is to run an LLM on the OCR output and ask it to cluster the text. You can even set up a complete workflow: cluster the text, check it, extract ingredients and instructions and the check again to ensure all content is used recipes are not mixed up.\nThe downside about all this? It is expensive to run. Especially if we introduce correctness checks. How much more expensive?\nFor reference, Google currently charges $1.5 per 1000 pages, whereas as Mistral asks for $3 per 1000 pages for annotated output. Google’s new interface, which (like Mistral) relies on Vision Transformers also charges asks for $1.5 per 1000 pages. Layout parsing costs extra at $10 per 1000 pages.\nLet’s say each of your users has about 2000 books he wants to convert. That results to $23 per user; and that is without classification. A custom extractor sets you back another $20. So the full workflow is about $50 per user. Again only for recipe extraction. Interaction with the recipe database will probably cost around $3 per month.\n\n\n\nI recently tested Docling, a transformer-based architecture. It has created quite a buzz recently.\nHere is my short evaluation. On the document which we are going to use throughout this notebook, it failed. The deterministic demo (temperature=0) got stuck in an inference loop. I tried increasing temperature and add other tweaks to help the model escape local optima. This came at the cost of accuracy.\nThe model repeated titles as ingredients for other recipes and failed to stop properly.\n\n\n\nDocling Result: one recipe title is not detected as such\n\n\nThe model has issue with line breaks: “Die Pilze damit bin-den” became “Pilze damit ben den” including line breaks.\nOn top of that, the speed was poor on a legacy GPU (GTX 1080), despite running at full load for the full time of 22 seconds! Memory consumption was steadily increasing as more tokens were decoded, just barely fitting on the 8GB GPU with 6.5GB max usage.\nReflecting on the architecture, I suspect it must work better on obscure edge cases. Complex Formats with overlaying figures or strongly nested tables could perform better.\nStrangely, even the demo mostly showcases simple formats.\n\n\n\nLayout Parsing is not new. In fact, it became popular about three years ago.\nOne such layout parser is the actual LayoutParser. It combines an automatic analysis of OCR output and segmentation. Unfortunately, the segmentation is done with detecron2. The active development seems to have stopped and it no longer works on my python installation (Python 3.12). My research revealed Python 3.9 as the last working version.\nA more recent model is DocLayout-YOLO. Based on the already massive YOLO dataset, it uses a very large document dataset to identify bounding boxes and classification in a combined loss function.\nWhat it lacks, however, is an automatic connection to OCR. One can either crop and ocr the text boxes or align with the OCR output.\nHere is an example:\n\n\nCode\n# Standard library\nimport glob\nimport json\nimport os\nimport random\nimport warnings\nfrom difflib import SequenceMatcher\nfrom pathlib import Path\n\n# Third-party\nimport cv2\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageDraw\n# Local / custom\nfrom doclayout_yolo import YOLOv10\nfrom sklearn.metrics import accuracy_score\n\n# Jupyter magic\n%matplotlib inline\n\n# Suppress all warnings (optional)\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\nCode\nmodel = YOLOv10(\"data/models/doclayout_yolo.pt\")\ndet_res = model.predict(\n    \"data/raw/20250922_135514.jpg\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\n\n\n\n\nCode\nannotated_frame = det_res[0].plot(pil=True, line_width=10, font_size=30)\nimg_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(10, 14))\nplt.imshow(img_rgb)\nplt.axis(\"off\")\nplt.title(\"Segmentation using Doclayout YOLO\")\nplt.show()\n\n\n\n\n\n\n\n\n\nDespite knowing nothing about the text, the CNN could still discover the layout. Which is clear, you don’t need to understand a language to break a book into paragraphs.\nThere are some errors in how the titles are handled. Bright red boxes highlight detected titles, and we can see that there are too many.\nWhen we run the CUDA-enabled version, the total runtime is 164ms, 650ms for cold start, whereas on CPU it can take up to 1.6s.\n\n\n\nAnd then there’s the domain knowledge approach. That is how I started. If we know all the text on a page, its location, and assume it’s a recipe: can we identify where recipes end, and which text belongs to which recipe?\nIn this notebook, I will examine this way and how it compares to DocLayout-YOLO."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#converting-data-to-dataframes",
    "href": "posts/projects/recipescanner/page_segmentation.html#converting-data-to-dataframes",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "2 Converting Data to Dataframes",
    "text": "2 Converting Data to Dataframes\nWe will perform a statistical analysis and therefore convert the data to pandas dataframes.\n\n2.1 OCR\nIn my project, I currently rely on Google cloud OCR. Therefore, we need to convert the API response to a dataframe. While doing so, we also add information on font_size and word count.\n\ndef ocr_json_to_df(ocr_json):\n    rows = []\n\n    for block in ocr_json:\n        block_type = block[\"blockType\"]\n        verts = block[\"boundingBox\"][\"vertices\"]\n        x1, y1 = verts[0].get(\"x\", 0), verts[0].get(\"y\", 0)\n        x2, y2 = verts[2].get(\"x\", 0), verts[2].get(\"y\", 0)\n\n        # Reconstruct text from words and establish size\n        block_words = []\n        average_word_height_sum = 0\n        word_counter = 0\n        for para_idx, para in enumerate(block.get(\"paragraphs\", [])):\n            paragraph_words = []\n            paragraph_average_word_height_sum = 0\n            paragraph_word_counter = 0\n            para_verts = para[\"boundingBox\"][\"vertices\"]\n            px1, py1 = para_verts[0].get(\"x\", 0), para_verts[0].get(\"y\", 0)\n            px2, py2 = para_verts[2].get(\"x\", 0), para_verts[2].get(\"y\", 0)\n            for word_idx, word in enumerate(para.get(\"words\", [])):\n                symbols = [s[\"text\"] for s in word.get(\"symbols\", [])]\n                word_text = \"\".join(symbols)\n                block_words.append(word_text)\n                paragraph_words.append(word_text)\n\n                # store word-level rows (optional)\n                word_verts = word[\"boundingBox\"][\"vertices\"]\n                wx1, wy1 = word_verts[0].get(\"x\", 0), word_verts[0].get(\"y\", 0)\n                wx3, wy3 = word_verts[3].get(\"x\", 0), word_verts[3].get(\"y\", 0)\n                average_word_height_sum += (wy3 - wy1)\n                word_counter += 1\n                paragraph_average_word_height_sum += (wy3 - wy1)\n                paragraph_word_counter += 1\n\n            rows.append({\n                \"level\": \"paragraph\",\n                \"x1\": px1, \"y1\": py1, \"x2\": px2, \"y2\": py2,\n                \"font_size\": paragraph_average_word_height_sum / paragraph_word_counter,\n                \"text\": \" \".join(paragraph_words),\n                \"block_type\": block_type\n            })\n\n        rows.append({\n            \"level\": \"block\",\n            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n            \"font_size\": average_word_height_sum / word_counter,\n            \"text\": \" \".join(block_words),\n            \"block_type\": block_type\n        })\n\n    df = pd.DataFrame(rows)\n\n    df[\"word_count\"] = df[\"text\"].str.split().str.len()\n\n    return df\n\n\n\nCode\ndef read_json(image_id):\n    json_path = Path(\"data/ocr/\")\n\n    with open(json_path / f\"{image_id}.json\", \"r\") as f:\n        return json.load(f)\n\n\n\nfilename = \"20250922_135514\"\npage = read_json(filename)\ndf_ocr = ocr_json_to_df(page)\n\nLet’s split block and paragraph rows for further processing.\n\ndf_block = df_ocr[df_ocr[\"level\"] == \"block\"]\ndf_para = df_ocr[df_ocr[\"level\"] == \"paragraph\"]\ndf_block.head()\n\n\n\n\n\n\n\n\nlevel\nx1\ny1\nx2\ny2\nfont_size\ntext\nblock_type\nword_count\n\n\n\n\n1\nblock\n874\n2331\n911\n2355\n24.000000\n64\nTEXT\n1\n\n\n7\nblock\n853\n484\n1510\n1389\n31.902913\nDie Butter zerlassen , das Weißbrot von beiden...\nTEXT\n103\n\n\n10\nblock\n878\n1501\n1404\n1737\n52.375000\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\nTEXT\n8\n\n\n16\nblock\n875\n1815\n1291\n2081\n32.761905\n2 Stangen Porree ( Lauch ) 250 g enthäutete To...\nTEXT\n21\n\n\n19\nblock\n877\n2101\n989\n2176\n26.500000\nSalz Pfeffer\nTEXT\n2\n\n\n\n\n\n\n\n\n\n2.2 Doclayout YOLO\nDocLayout-YOLO returns boxes, labels, and confidence levels.\n\ndef yolo_to_df(result):\n    boxes = result.boxes.xyxy.cpu().numpy()\n    labels = result.boxes.cls.cpu().numpy().astype(int)\n    scores = result.boxes.conf.cpu().numpy()\n    names = result.names\n\n    records = []\n    for box, lbl, score in zip(boxes, labels, scores):\n        x1, y1, x2, y2 = box.tolist()\n        label = names[lbl]\n        records.append({\n            \"x1\": x1,\n            \"y1\": y1,\n            \"x2\": x2,\n            \"y2\": y2,\n            \"label\": label,\n            \"confidence\": score,\n            \"is_title\": (label.lower() == \"title\")\n        })\n\n    return pd.DataFrame(records)\n\n\ndet_res = model.predict(\n    \"data/raw/20250922_135514.jpg\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\ndf_yolo = yolo_to_df(det_res[0]);df_yolo\n\n\n\n\n\n\n\n\nx1\ny1\nx2\ny2\nlabel\nconfidence\nis_title\n\n\n\n\n0\n879.157227\n1498.183594\n1404.824463\n1631.679443\ntitle\n0.922120\nTrue\n\n\n1\n879.624573\n1643.227661\n1357.394409\n1753.128174\nplain text\n0.903516\nFalse\n\n\n2\n3569.065430\n2246.001465\n3609.026123\n2281.185547\nabandon\n0.831622\nFalse\n\n\n3\n2968.354492\n450.490784\n3297.232910\n592.068970\ntitle\n0.809443\nTrue\n\n\n4\n870.937500\n2327.354248\n912.915344\n2362.086182\nabandon\n0.795582\nFalse\n\n\n5\n874.531006\n1780.801758\n1492.744629\n2286.900391\ntable\n0.727726\nFalse\n\n\n6\n1527.393433\n598.798950\n2144.085449\n1672.833618\nplain text\n0.705026\nFalse\n\n\n7\n2974.093750\n598.492249\n3467.499023\n654.774719\nplain text\n0.638011\nFalse\n\n\n8\n877.592163\n465.383392\n1481.144409\n1402.559326\nplain text\n0.626123\nFalse\n\n\n9\n2980.972656\n682.661133\n3532.022705\n1200.553101\ntable\n0.596943\nFalse\n\n\n10\n1526.767578\n597.575073\n2054.986328\n686.416992\nplain text\n0.583433\nFalse\n\n\n11\n2316.687988\n450.310455\n2927.670898\n824.062439\nplain text\n0.513546\nFalse\n\n\n12\n3022.026855\n1725.583984\n3593.486572\n2192.724609\nplain text\n0.488287\nFalse\n\n\n13\n2325.665283\n856.174072\n2937.416748\n1041.672241\nplain text\n0.481687\nFalse\n\n\n14\n2330.425537\n1042.294434\n2914.214844\n1225.915161\nplain text\n0.477337\nFalse\n\n\n15\n1532.011597\n1245.381348\n2047.088745\n1337.381592\nplain text\n0.455887\nFalse\n\n\n16\n2350.650879\n1689.926758\n2967.089355\n1876.195068\nplain text\n0.453441\nFalse\n\n\n17\n2337.659668\n1229.601807\n2960.235352\n1686.113770\nplain text\n0.445066\nFalse\n\n\n18\n1522.936157\n457.546967\n1769.362915\n547.661194\ntitle\n0.433465\nTrue\n\n\n19\n1525.181885\n461.238281\n1770.478882\n548.516296\ntitle\n0.419111\nTrue\n\n\n20\n1537.929932\n1843.337891\n2071.566162\n1914.832031\ntitle\n0.392423\nTrue\n\n\n21\n882.206665\n469.045898\n1474.692993\n848.210815\nplain text\n0.391044\nFalse\n\n\n22\n2355.457520\n1878.174194\n2988.262939\n2259.762207\nplain text\n0.389824\nFalse\n\n\n23\n882.791809\n845.683289\n1476.399170\n982.723877\nplain text\n0.378071\nFalse\n\n\n24\n3001.068604\n1266.987061\n3527.293213\n1354.325928\nplain text\n0.370774\nFalse\n\n\n25\n3006.092529\n1268.646606\n3583.754639\n2200.445557\nplain text\n0.360401\nFalse\n\n\n26\n1535.614624\n1842.507202\n2077.353516\n1984.601807\ntitle\n0.337300\nTrue\n\n\n27\n880.934509\n1258.313110\n1462.825928\n1400.205078\nplain text\n0.305315\nFalse\n\n\n28\n881.682800\n1118.672363\n1455.794189\n1258.220947\nplain text\n0.294823\nFalse\n\n\n29\n882.505371\n982.659119\n1479.449707\n1116.903931\nplain text\n0.263816\nFalse\n\n\n30\n1534.299072\n1620.801636\n2126.622803\n1667.255005\nplain text\n0.257625\nFalse\n\n\n31\n1533.716064\n1338.074707\n2135.751709\n1658.443481\nplain text\n0.245955\nFalse\n\n\n32\n1533.999634\n2035.315918\n2170.545654\n2285.304443\nplain text\n0.232413\nFalse\n\n\n33\n1537.556274\n1929.555420\n1743.389038\n1981.646973\nplain text\n0.227065\nFalse\n\n\n\n\n\n\n\nIn both cases, we can see that the title detection is not optimal. In the case of the block-based detection it will be difficult to separate “Soupe à l’ail bonne femme Knoblauchsuppe nach”.\nFor DocLayout-YOLO, there are too many titles. Ingredients were detected as title as they are on top of a column and in bold."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#title-detection",
    "href": "posts/projects/recipescanner/page_segmentation.html#title-detection",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "3 Title detection",
    "text": "3 Title detection\n\n3.1 Title detection using OCR\nLet’s try to improve the title detection. We start with the OCR blocks.\n\ndf_block[[\"text\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nfont_size\n\n\n\n\n1\n64\n24.000000\n\n\n7\nDie Butter zerlassen , das Weißbrot von beiden...\n31.902913\n\n\n10\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\n52.375000\n\n\n16\n2 Stangen Porree ( Lauch ) 250 g enthäutete To...\n32.761905\n\n\n19\nSalz Pfeffer\n26.500000\n\n\n21\neinige runde , ausgestochene Toast- brotscheiben\n34.000000\n\n\n24\nSpeiseöl Parmesankäse\n29.500000\n\n\n27\nDen Porree putzen , waschen , in Ringe schneid...\n35.600000\n\n\n29\nzerdrücken .\n25.500000\n\n\n34\nDas Öl erhitzen , das Gemüse mit den Knoblauch...\n33.516854\n\n\n36\nGigot de chevreuil\n62.000000\n\n\n38\nRehblatt\n37.000000\n\n\n41\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50 ...\n34.187500\n\n\n43\n2 Schalotten\n26.500000\n\n\n49\n2 zerdrückte Wacholderbeeren 2 zerdrückte Knob...\n32.347826\n\n\n51\n2 Teel . Weizenmehl 125 ml ( 1 ) Schlagsahne\n33.600000\n\n\n56\nDas Rehblatt unter fließendem kal- tem Wasser ...\n33.964072\n\n\n58\nCroûtes aux champignons Champignons in Pasteten\n45.666667\n\n\n60\n500 g Champignons 50 g Butter\n33.500000\n\n\n62\nSalz Pfeffer\n25.500000\n\n\n69\nCayennepfeffer 125 ml ( 1 ) Wasser 2 gestriche...\n32.321429\n\n\n73\nDie Champignons putzen , waschen , vierteln . ...\n32.377193\n\n\n75\n55\n-1.000000\n\n\n77\n65\n26.000000\n\n\n\n\n\n\n\nTitles are in index 10, 36, and 58. For index 10 and 58, the title is together with the subtitles. Both have a bigger average line height (fontsize) than the rest. Almost by factor 1.5. With this in mind we create our title detector. Just to be sure we limit the amount of words, too.\nLuckily we extracted this information earlier in our dataframe.\n\ndef detect_titles(df, font_factor=1.2, max_words=15):\n    df = df[df[\"word_count\"] &gt; 0].copy()\n\n    if len(df) == 1:\n        return df\n    # compute mean font size ignoring NaNs\n    mean_font_size = df[\"font_size\"].mean()\n\n    df[\"is_title\"] = (\n            (df[\"font_size\"] &gt; font_factor * mean_font_size) &\n            (df[\"word_count\"] &lt;= max_words) &\n             (df[\"text\"].str.len() &gt;= 3)\n    )\n    return df[df[\"is_title\"]]\n\n\ndf_titles_blocks = detect_titles(df_block)\ndf_titles_blocks[[\"text\",\"is_title\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n10\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\nTrue\n52.375000\n\n\n36\nGigot de chevreuil\nTrue\n62.000000\n\n\n58\nCroûtes aux champignons Champignons in Pasteten\nTrue\n45.666667\n\n\n\n\n\n\n\n\ndf_titles_para = detect_titles(df_para)\ndf_titles_para[[\"text\",\"is_title\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n8\nSoupe à l'ail bonne femme\nTrue\n56.600000\n\n\n9\nKnoblauchsuppe nach Hausfrauenart\nTrue\n45.333333\n\n\n35\nGigot de chevreuil\nTrue\n62.000000\n\n\n57\nCroûtes aux champignons Champignons in Pasteten\nTrue\n45.666667\n\n\n\n\n\n\n\nIn the case of blocks, the subtitle is detected with the title in a block. And in the case of the paragraphs, it has an almost equal font size. For the third title, separation is not possible on paragraph level.\nNow it would be great to include this information back into the dataframe.\n\ndef add_titles_to_df(original, titles):\n    original[\"is_title\"] = False\n    original.loc[titles.index, \"is_title\"] = titles[\"is_title\"]\n\n\nadd_titles_to_df(df_block, df_titles_blocks)\ndf_block[[\"text\",\"is_title\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n1\n64\nFalse\n24.000000\n\n\n7\nDie Butter zerlassen , das Weißbrot von beiden...\nFalse\n31.902913\n\n\n10\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\nTrue\n52.375000\n\n\n16\n2 Stangen Porree ( Lauch ) 250 g enthäutete To...\nFalse\n32.761905\n\n\n19\nSalz Pfeffer\nFalse\n26.500000\n\n\n21\neinige runde , ausgestochene Toast- brotscheiben\nFalse\n34.000000\n\n\n24\nSpeiseöl Parmesankäse\nFalse\n29.500000\n\n\n27\nDen Porree putzen , waschen , in Ringe schneid...\nFalse\n35.600000\n\n\n29\nzerdrücken .\nFalse\n25.500000\n\n\n34\nDas Öl erhitzen , das Gemüse mit den Knoblauch...\nFalse\n33.516854\n\n\n36\nGigot de chevreuil\nTrue\n62.000000\n\n\n38\nRehblatt\nFalse\n37.000000\n\n\n41\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50 ...\nFalse\n34.187500\n\n\n43\n2 Schalotten\nFalse\n26.500000\n\n\n49\n2 zerdrückte Wacholderbeeren 2 zerdrückte Knob...\nFalse\n32.347826\n\n\n51\n2 Teel . Weizenmehl 125 ml ( 1 ) Schlagsahne\nFalse\n33.600000\n\n\n56\nDas Rehblatt unter fließendem kal- tem Wasser ...\nFalse\n33.964072\n\n\n58\nCroûtes aux champignons Champignons in Pasteten\nTrue\n45.666667\n\n\n60\n500 g Champignons 50 g Butter\nFalse\n33.500000\n\n\n62\nSalz Pfeffer\nFalse\n25.500000\n\n\n69\nCayennepfeffer 125 ml ( 1 ) Wasser 2 gestriche...\nFalse\n32.321429\n\n\n73\nDie Champignons putzen , waschen , vierteln . ...\nFalse\n32.377193\n\n\n75\n55\nFalse\n-1.000000\n\n\n77\n65\nFalse\n26.000000\n\n\n\n\n\n\n\nLet’s do the same for the paragraphs.\n\nadd_titles_to_df(df_para, df_titles_para)\n\n\n\n3.2 Title detection using DocLayout-YOLO and OCR\nLuckily, the layout detector already flags which blocks are title. The issue: there is no text in any of those blocks. Most of the blocks span multiple lines, which means our font-size approach does not work. We do not know how many lines or words exist.\nThis is where DocLayout-YOLO falls short. We could run every single block through OCR. On a local OCR program that could be as effective as full page detection, maybe even better. But since we rely on Google OCR, that approach would lead to very high cost, as billing is per request.\nInstead, we align the two boxes and copy every OCR word which falls in a Doclayout boxes to the related dataframe row.\n\ndf_titles_yolo = df_yolo[df_yolo[\"is_title\"]].copy()\ndf_titles_yolo[\"text\"] = \"\"\ndf_titles_yolo[\"average_word_height_sum\"] = 0\ndf_titles_yolo[\"word_count\"] = 0\n\n\nfor block in page:\n    for para_idx, para in enumerate(block.get(\"paragraphs\", [])):\n\n        for word_idx, word in enumerate(para.get(\"words\", [])):\n            symbols = [s[\"text\"] for s in word.get(\"symbols\", [])]\n            word_text = \"\".join(symbols)\n            word_verts = word[\"boundingBox\"][\"vertices\"]\n            wx1, wy1 = word_verts[0].get(\"x\", 0), word_verts[0].get(\"y\", 0)\n            wx2, wy2 = word_verts[3].get(\"x\", 0), word_verts[3].get(\"y\", 0)\n            wcx = (wx1 + wx2) / 2\n            wcy = (wy1 + wy2) / 2\n            word_height = abs(wy2 - wy1)\n\n            # assign to title box if inside\n            for idx, row in df_titles_yolo.iterrows():\n                if (row[\"x1\"] &lt;= wcx &lt;= row[\"x2\"]) and (row[\"y1\"] &lt;= wcy &lt;= row[\"y2\"]):\n                    # append word text\n                    df_titles_yolo.at[idx, \"text\"] += \" \" + word_text\n                    # accumulate height + count\n                    df_titles_yolo.at[idx, \"average_word_height_sum\"] += word_height\n                    df_titles_yolo.at[idx, \"word_count\"] += 1\n                    # can only be in one title\n                    break\n\n\ndf_titles_yolo[\"font_size\"] = df_titles_yolo.average_word_height_sum / df_titles_yolo.word_count\ndf_titles_yolo[[\"text\",\"is_title\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n0\nSoupe à l'ail bonne femme\nTrue\n56.600000\n\n\n3\nCroûtes aux champignons\nTrue\n47.333333\n\n\n18\nSpeiseöl Parmesankäse\nTrue\n29.500000\n\n\n19\n\nTrue\nNaN\n\n\n20\nGigot de chevreuil\nTrue\n62.000000\n\n\n26\nRehblatt\nTrue\n37.000000\n\n\n\n\n\n\n\nAs indicated earlier, we have different kind of false positives. Only the “Rehblatt” is similar to the previous case, of subtitles in the paragraph based detection. Luckily for us, this time font size should work well.\n\ndf_titles_yolo = detect_titles(df_titles_yolo, font_factor=1)\ndf_titles_yolo[[\"text\",\"is_title\",\"font_size\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n0\nSoupe à l'ail bonne femme\nTrue\n56.600000\n\n\n3\nCroûtes aux champignons\nTrue\n47.333333\n\n\n20\nGigot de chevreuil\nTrue\n62.000000\n\n\n\n\n\n\n\nAs expected it worked even without a safety factor. We wrap this in a function.\n\ndef add_text_and_font_size_to_layout_df(df, ocr_page):\n    df[\"text\"] = \"\"\n    df[\"average_word_height_sum\"] = 0\n    df[\"word_count\"] = 0\n    unassigned_words = []\n    for block in ocr_page:\n        for para_idx, para in enumerate(block.get(\"paragraphs\", [])):\n\n            for word_idx, word in enumerate(para.get(\"words\", [])):\n                symbols = [s[\"text\"] for s in word.get(\"symbols\", [])]\n                word_text = \"\".join(symbols)\n                verts = word[\"boundingBox\"][\"vertices\"]\n                wx1, wy1 = verts[0].get(\"x\", 0), verts[0].get(\"y\", 0)\n                wx2, wy2 = verts[3].get(\"x\", 0), verts[3].get(\"y\", 0)\n                wcx = (wx1 + wx2) / 2\n                wcy = (wy1 + wy2) / 2\n                word_height = abs(wy2 - wy1)\n\n                assigned = False\n                for idx, row in df.iterrows():\n                    if (row[\"x1\"] &lt;= wcx &lt;= row[\"x2\"]) and (row[\"y1\"] &lt;= wcy &lt;= row[\"y2\"]):\n                        # append word text\n                        df.at[idx, \"text\"] += \" \" + word_text\n                        # accumulate height + count\n                        df.at[idx, \"average_word_height_sum\"] += word_height\n                        df.at[idx, \"word_count\"] += 1\n                        assigned = True\n                        break\n\n                if not assigned:\n                    unassigned_words.append({\n                        \"text\": word_text,\n                        \"x\": wcx,\n                        \"y\": wcy,\n                        \"height\": word_height\n                    })\n    if len(unassigned_words) &gt; 0:\n        print(\"unassigned words:\")\n    df[\"font_size\"] = df.average_word_height_sum / df.word_count\n    return df\n\nNote, I included a small debug hint, which should trigger if there are any unassigned words.\nNext, it would be great to include this information back into the dataframe.\nThe complete code for DocLayout-YOLO.\n\ndf_yolo_font_size = add_text_and_font_size_to_layout_df(df_yolo.copy(), page)\ndf_titles_yolo = detect_titles(df_yolo_font_size[df_yolo_font_size.is_title], font_factor=1)\nadd_titles_to_df(df_yolo_font_size, df_titles_yolo)\ndf_yolo_font_size[[\"text\", \"is_title\",\"font_size\"]]\n\nunassigned words:\n\n\n\n\n\n\n\n\n\ntext\nis_title\nfont_size\n\n\n\n\n0\nSoupe à l'ail bonne femme\nTrue\n56.600000\n\n\n1\nKnoblauchsuppe nach Hausfrauenart\nFalse\n45.333333\n\n\n2\n65\nFalse\n26.000000\n\n\n3\nCroûtes aux champignons\nTrue\n47.333333\n\n\n4\n64\nFalse\n24.000000\n\n\n5\n2 Stangen Porree ( Lauch ) 250 g enthäutete T...\nFalse\n32.586207\n\n\n6\nDen Porree putzen , waschen , in Ringe schnei...\nFalse\n33.900826\n\n\n7\nChampignons in Pasteten\nFalse\n44.000000\n\n\n8\nDie Butter zerlassen , das Weißbrot von beide...\nFalse\n31.902913\n\n\n9\n500 g Champignons g Butter Salz Pfeffer Cayen...\nFalse\n32.142857\n\n\n10\n\nFalse\nNaN\n\n\n11\nzerdrückte Wacholderbeeren zerdrückte Knoblau...\nFalse\n32.419355\n\n\n12\nSahne und Petersilie unterrühren . Die Champi...\nFalse\n32.016667\n\n\n13\nDas Rehblatt unter fließendem kal- tem Wasser...\nFalse\n35.842105\n\n\n14\nDen Speck in Streifen schneiden . Die Butter ...\nFalse\n34.090909\n\n\n15\n\nFalse\nNaN\n\n\n16\nFleisch von den Knochen Das gare lösen , in P...\nFalse\n30.380952\n\n\n17\nSchalotten abziehen , vierteln , mit den Wach...\nFalse\n32.963636\n\n\n18\nSpeiseöl Parmesankäse\nFalse\n29.500000\n\n\n19\n\nFalse\nNaN\n\n\n20\nGigot de chevreuil\nTrue\n62.000000\n\n\n21\n\nFalse\nNaN\n\n\n22\nDen Bratensatz mit etwas Wasser los- kochen u...\nFalse\n35.877551\n\n\n23\n\nFalse\nNaN\n\n\n24\nDie Champignons putzen , waschen , vierteln .\nFalse\n31.250000\n\n\n25\nDie Butter zerlassen , die Champi- gnons dari...\nFalse\n33.043478\n\n\n26\nRehblatt\nFalse\n37.000000\n\n\n27\n\nFalse\nNaN\n\n\n28\n\nFalse\nNaN\n\n\n29\n\nFalse\nNaN\n\n\n30\n\nFalse\nNaN\n\n\n31\n\nFalse\nNaN\n\n\n32\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50...\nFalse\n33.333333\n\n\n33\n\nFalse\nNaN"
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#recipe-detection-using-only-ocr",
    "href": "posts/projects/recipescanner/page_segmentation.html#recipe-detection-using-only-ocr",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "4 Recipe detection using only OCR",
    "text": "4 Recipe detection using only OCR\nNow with the titles cleaned, we know the number of titles. Next step is the distribution of the rows of each dataframe to the recipes.\nAn important domain knowledge, or prior knowledge, is that almost all recipe formats are organized in columns. Titles are usually placed somewhere in these columns, and a title marks the beginning of a recipe.\nThe main drawback: any other layout format cannot be processed.\nWe will do this approach in two steps:\n\nSplit the text into columns based on the row’s bounding box\nSplit columns into recipes based on title position.\n\n\n4.1 Working on OCR Block level\nThis was actually the hardest part. For the sake of brevity I only provide the final result and not the full way.\n\n4.1.1 Column detection\nThe OCR pipeline has already discovered fragments of text that belong together, and organized them into paragraphs and blocks.\nOur algorithm works with two approaches.\n\nWe assume there are no more than five columns, and they are evenly distributed. When column size is unequal, that is usually the case if ingredients are in a column.\n\nWe search for the best fit. Fit is defined by a score, which is the absolute distance of left beginning of the box and column centers.\n\nWe try to establish the number of columns with a normalized, area-weighted histogram. A valid column is defined by having 50% of the text amount of the maximum column. That of course assumes equal length of recipes. Because this assumption is shaky, the first approach is preferred.\n\n\ndef detect_columns(df, max_cols=5, error_threshold=20):\n    page_width = df[\"x2\"].max()\n    best_n, best_score, best_assignments = 1, float(\"inf\"), None\n\n    for n_cols in range(1, max_cols + 1):\n        col_width = page_width / n_cols\n        col_centers = [(i + 0.5) * col_width for i in range(n_cols)]\n\n        # Assign each block to nearest center\n        assignments = []\n        errors = []\n        for x in df[\"x1\"]:\n            dists = [abs(x - c) for c in col_centers]\n            col_idx = int(np.argmin(dists))\n            assignments.append(col_idx)\n            errors.append(min(dists))\n\n        score = np.mean(errors)  # lower = better alignment\n        if score &lt; best_score:\n            best_score = score\n            best_n = n_cols\n            best_assignments = assignments\n\n    if best_score &lt; error_threshold:\n        df[\"col_id\"] = best_assignments\n\n        col_boxes = []\n        for col_id, group in df.groupby(\"col_id\"):\n            col_boxes.append({\n                \"col_id\": col_id,\n                \"col_x1\": group[\"x1\"].min(),\n                \"col_y1\": group[\"y1\"].min(),\n                \"col_x2\": group[\"x2\"].max(),\n                \"col_y2\": group[\"y2\"].max()\n            })\n\n        col_boxes = pd.DataFrame(col_boxes).sort_values(\"col_x1\").reset_index(drop=True)\n        col_boxes[\"col_id\"] = range(len(col_boxes))\n        df[\"col_id\"] = df[\"col_id\"].map({old: new for new, old in enumerate(col_boxes[\"col_id\"])})\n        return col_boxes, df\n    else:\n        # Fallback to histogram based method\n        df[\"area\"] = (df[\"x2\"] - df[\"x1\"]) * (df[\"y2\"] - df[\"y1\"])\n        hist, bin_edges = np.histogram(\n            df[\"x1\"],\n            bins=10,\n            weights=df[\"area\"]\n        )\n        hist_norm = hist / np.max(hist)\n        valid_bins = np.where(hist_norm &gt; 0.5)[0]\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n        col_centers = bin_centers[valid_bins]\n\n        df[\"col_id\"] = df[\"x1\"].apply(lambda x: np.argmin(np.abs(col_centers - x)))\n\n        col_boxes = []\n        for col_id, group in df.groupby(\"col_id\"):\n            col_boxes.append({\n                \"col_id\": col_id,\n                \"col_x1\": group[\"x1\"].min(),\n                \"col_y1\": group[\"y1\"].min(),\n                \"col_x2\": group[\"x2\"].max(),\n                \"col_y2\": group[\"y2\"].max()\n            })\n\n        col_boxes = pd.DataFrame(col_boxes).sort_values(\"col_x1\").reset_index(drop=True)\n        col_boxes[\"col_id\"] = range(len(col_boxes))\n        df[\"col_id\"] = df[\"col_id\"].map({old: new for new, old in enumerate(col_boxes[\"col_id\"])})\n\n        return col_boxes, df\n\n\ncols, df = detect_columns(df_block.copy())\ncols\n\n\n\n\n\n\n\n\ncol_id\ncol_x1\ncol_y1\ncol_x2\ncol_y2\n\n\n\n\n0\n0\n853\n484\n1510\n2355\n\n\n1\n1\n1526\n467\n2138\n2271\n\n\n2\n2\n2306\n474\n2993\n2249\n\n\n3\n3\n2973\n455\n3608\n2274\n\n\n\n\n\n\n\n\ndf[[\"text\",\"col_id\"]]\n\n\n\n\n\n\n\n\ntext\ncol_id\n\n\n\n\n1\n64\n0\n\n\n7\nDie Butter zerlassen , das Weißbrot von beiden...\n0\n\n\n10\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\n0\n\n\n16\n2 Stangen Porree ( Lauch ) 250 g enthäutete To...\n0\n\n\n19\nSalz Pfeffer\n0\n\n\n21\neinige runde , ausgestochene Toast- brotscheiben\n0\n\n\n24\nSpeiseöl Parmesankäse\n1\n\n\n27\nDen Porree putzen , waschen , in Ringe schneid...\n1\n\n\n29\nzerdrücken .\n1\n\n\n34\nDas Öl erhitzen , das Gemüse mit den Knoblauch...\n1\n\n\n36\nGigot de chevreuil\n1\n\n\n38\nRehblatt\n1\n\n\n41\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50 ...\n1\n\n\n43\n2 Schalotten\n1\n\n\n49\n2 zerdrückte Wacholderbeeren 2 zerdrückte Knob...\n2\n\n\n51\n2 Teel . Weizenmehl 125 ml ( 1 ) Schlagsahne\n2\n\n\n56\nDas Rehblatt unter fließendem kal- tem Wasser ...\n2\n\n\n58\nCroûtes aux champignons Champignons in Pasteten\n3\n\n\n60\n500 g Champignons 50 g Butter\n3\n\n\n62\nSalz Pfeffer\n3\n\n\n69\nCayennepfeffer 125 ml ( 1 ) Wasser 2 gestriche...\n3\n\n\n73\nDie Champignons putzen , waschen , vierteln . ...\n3\n\n\n75\n55\n3\n\n\n77\n65\n3\n\n\n\n\n\n\n\nThe number of columns is correct.\n\n\n4.1.2 Recipe detection\nWe now proceed by grouping the blocks into recipes. This function is the work of many failed iterations.\nSince we have established columns, we treat all text as if it were in one big column. Whenever a title appears, we start a new recipe.\nI solved the subtitle issue by checking that the gap to the previous title is similar to the title font size. If so, it is a subtitle, not a new recipe.\n\ndef group_recipes(df, subtitle_factor=1.2):\n    df = df.copy()\n    recipe_id = -1\n    all_recipes = []\n    recipe_map = {}\n\n    # Sort by column, then y\n    cols = sorted(df[\"col_id\"].unique())\n    last_recipe_id = None\n    current_recipe = {\"title\": None, \"blocks\": []}\n\n    last_title_font = None\n\n    for col in cols:\n        col_blocks = df[df[\"col_id\"] == col].sort_values(\"y1\")\n        last_title_bottom = -1\n        for idx, row in col_blocks.iterrows():\n\n            if row.is_title:\n                # check if this title is actually a subtitle\n                subtitle_gap = (last_title_font or row.font_size) * subtitle_factor\n\n                is_subtitle = (\n                        current_recipe[\"title\"] is not None\n                        and (row[\"y1\"] - last_title_bottom) &lt; subtitle_gap\n                )\n\n                if is_subtitle:\n                    # merge into current recipe title\n                    current_recipe[\"title\"] += \" \" + row.text\n                    current_recipe[\"blocks\"].append(row.text)\n                    recipe_map[idx] = last_recipe_id\n                else:\n\n                    if current_recipe[\"title\"] is not None:\n                        all_recipes.append(current_recipe)\n\n                    # start new recipe\n                    recipe_id += 1\n                    current_recipe = {\"title\": row.text, \"blocks\": [row.text]}\n                    recipe_map[idx] = recipe_id\n                    last_recipe_id = recipe_id\n\n                last_title_bottom = row[\"y2\"]\n                last_title_font = row.font_size\n\n            else:\n\n                if last_recipe_id is None:\n                    recipe_map[idx] = -1  # orphan\n                else:\n                    recipe_map[idx] = last_recipe_id\n                    current_recipe[\"blocks\"].append(row.text)\n\n    if current_recipe[\"title\"] is not None:\n        all_recipes.append(current_recipe)\n\n    df[\"recipe_id\"] = df.index.map(recipe_map).fillna(-1).astype(int)\n    return df, all_recipes\n\n\ndf, recipes = group_recipes(df)\n\n\ndf[[\"text\", \"recipe_id\"]]\n\n\n\n\n\n\n\n\ntext\nrecipe_id\n\n\n\n\n1\n64\n0\n\n\n7\nDie Butter zerlassen , das Weißbrot von beiden...\n-1\n\n\n10\nSoupe à l'ail bonne femme Knoblauchsuppe nach ...\n0\n\n\n16\n2 Stangen Porree ( Lauch ) 250 g enthäutete To...\n0\n\n\n19\nSalz Pfeffer\n0\n\n\n21\neinige runde , ausgestochene Toast- brotscheiben\n0\n\n\n24\nSpeiseöl Parmesankäse\n0\n\n\n27\nDen Porree putzen , waschen , in Ringe schneid...\n0\n\n\n29\nzerdrücken .\n0\n\n\n34\nDas Öl erhitzen , das Gemüse mit den Knoblauch...\n0\n\n\n36\nGigot de chevreuil\n1\n\n\n38\nRehblatt\n1\n\n\n41\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50 ...\n1\n\n\n43\n2 Schalotten\n1\n\n\n49\n2 zerdrückte Wacholderbeeren 2 zerdrückte Knob...\n1\n\n\n51\n2 Teel . Weizenmehl 125 ml ( 1 ) Schlagsahne\n1\n\n\n56\nDas Rehblatt unter fließendem kal- tem Wasser ...\n1\n\n\n58\nCroûtes aux champignons Champignons in Pasteten\n2\n\n\n60\n500 g Champignons 50 g Butter\n2\n\n\n62\nSalz Pfeffer\n2\n\n\n69\nCayennepfeffer 125 ml ( 1 ) Wasser 2 gestriche...\n2\n\n\n73\nDie Champignons putzen , waschen , vierteln . ...\n2\n\n\n75\n55\n2\n\n\n77\n65\n2\n\n\n\n\n\n\n\nNice, even the fragment of the previous recipe in the first column was treated correctly. Only the page number was wrongly attributed to the first recipe.\nA picture says more than a thousand words.\n\ndef plot_recipes(df, image, save=False):\n    colors = {}\n    fig = plt.figure(figsize=(12, 16))\n    plt.imshow(image)\n\n    for _, row in df.iterrows():\n        rid = row[\"recipe_id\"]\n        if rid not in colors:\n            colors[rid] = [random.random(), random.random(), random.random()]\n        color = colors[rid]\n\n        rect = patches.Rectangle(\n            (row[\"x1\"], row[\"y1\"]),\n            row[\"x2\"] - row[\"x1\"],\n            row[\"y2\"] - row[\"y1\"],\n            linewidth=2,\n            edgecolor=color,\n            facecolor=\"none\"\n        )\n        plt.gca().add_patch(rect)\n\n        if row[\"is_title\"]:\n            plt.text(row[\"x1\"], row[\"y1\"] - 5, row[\"text\"][:30],\n                     color=color, fontsize=10, weight=\"bold\")\n\n    plt.axis(\"off\")\n    if save:\n        fig.savefig(\"result.jpg\")\n    plt.show()\n\n\n\ndef read_image(image_id,):\n    image_path = Path(\"data/raw\")\n    filename = image_path / f\"{image_id}.jpg\"\n    image = Image.open(filename)\n\n    return image\nimage = read_image(filename)\nplot_recipes(df, image, True)\n\n\n\n\n\n\n\n\nAs we can see this approach also works quite well.\n\n\n\n4.2 Working on OCR paragraph level\nWe will try OCR Paragraphs. Thanks to the subtitle workaround it also works for this recipe. However, doing so introduce another variable in the whole process and making it more brittle.\nWe can see that the first sub-title is printed in fat as the table still thinks it is a title.\n\ncols, df = detect_columns(df_para.copy())\ndf, recipes = group_recipes(df)\nplot_recipes(df, image)\n\n\n\n\n\n\n\n\n\n\n4.3 Generalization of OCR based splitting\nLet’s extend the algorithm to two other formats and see if it succeeds\n\n\nCode\nfilename = \"IMG_2077\"\npage = read_json(filename)\ndf = ocr_json_to_df(page)\ndf_block = df[df[\"level\"] == \"block\"]\ntitles = detect_titles(df_block.copy())\nadd_titles_to_df(df_block, titles)\nimage = read_image(filename)\ncols, df = detect_columns(df_block.copy())\ndf, recipes = group_recipes(df, 300)\nplot_recipes(df, image)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfilename = \"IMG_2074\"\npage = read_json(filename)\ndf = ocr_json_to_df(page)\ndf_block = df[df[\"level\"] == \"block\"]\ntitles = detect_titles(df_block.copy())\nadd_titles_to_df(df_block, titles)\nimage = read_image(filename)\ncols, df = detect_columns(df_block.copy())\ndf, recipes = group_recipes(df, 300)\nplot_recipes(df, image)\n\n\n\n\n\n\n\n\n\n\nrecipes\n\n[{'title': 'Ein würziger Schweinebraten aus der Normandie RÔTI DE PORC AUX POMMES CARAMÉLISÉES',\n  'blocks': ['Ein würziger Schweinebraten aus der Normandie RÔTI DE PORC',\n   'AUX POMMES CARAMÉLISÉES',\n   'SCHWEINEBRATEN MIT KARAMELLISIERTEN ÄPFELN',\n   'Wenig Rosmarinnadeln , die Salbeiblätter , Arbeitsaufwand : 30 Minuten die Knoblauchzehen und die Fenchelsamen im Mörser zerstoßen . Salz und Pfeffer zuge- ben . - Die Äpfel schälen , entkernen und in Schnitze schneiden . - Den Zucker mit dem Zitronensaft in einer Bratpfanne erhitzen . Sobald er hellbraun wird , die Äpfel zuge- ben , gut wenden , die Butter in Flocken zu- geben , mit 3 bis 5 EL Wasser ablöschen und ca. 5 Minuten garen . Salzen und pfeffern.- 3 bis 4 Einschnitte im Fleisch anbringen . Die Öffnungen mit der Gewürzmischung fül- len . Das Fleisch zu einem Rollbraten schnü- 2 dl Apfelwein ren , salzen und pfeffern . - Die Rosmarin-',\n   'Bratzeit : 2 Stunden Für 4 Personen 5 Zweige Rosmarin 2-3 Salbeiblätter 2 Knoblauchzehen 1 Prise Fenchelsamen Salz , Pfeffer',\n   '500 g säuerliche Äpfel 50g Rohzucker 1 EL Zitronensaft 2 EL frische Butter 1 kg magerer Schweinehals 2 EL zimmerwarme Bratbutter',\n   'zweige verteilt unter der Schnur anbringen . Das Fleisch mit der weichen Bratbutter bestreichen . In einer Bratkasserolle rundum an- braten . - Den Apfelwein zufügen und zugedeckt bei kleiner Hitze 2 Stunden garen . - Den Bratenfond mit 1 bis 2 EL Wasser aufkochen . 1/3 der Äpfel pürieren und mit dem Bratenjus gut mischen , abschme- cken . - Die restlichen Apfelschnitze rasch erwärmen und als Garni- tur zum tranchierten Braten servieren . Getränk : Rustikaler Rotwein , zum Beispiel aus der Provence Anmerkung : Diese ausgeprägten Zutaten passen auch gut zu Kalb- fleisch . Deshalb lässt sich nach demselben Rezept ebenso gut ein',\n   'Kalbsbratenzubereiten .']}]\n\n\nThis last layout is one of my favourites in terms of complexity. Triple title and a deeply nested format. The heuristic title detection with all the domain knowledge captures all the three titles together in the final extract. I’m looking forward, how this performs on completely unseen layouts."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#recipe-detection-using-doc-layout-yolo",
    "href": "posts/projects/recipescanner/page_segmentation.html#recipe-detection-using-doc-layout-yolo",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "5 Recipe detection using doc-layout YOLO",
    "text": "5 Recipe detection using doc-layout YOLO\nWe already know title detection works better with the YOLO detector, but what about the columns and recipes?\nOnce again, we proceed in a two-step approach. First columns, then recipes.\n\n5.1 Detecting columns\nWe use the previously defined function to find columns based on bounding box positions. At this stage, no text is required.\n\ncol_df, df_yolo_font_size = detect_columns(df_yolo_font_size)\n\n\ndf_yolo_font_size[[\"text\",\"is_title\",\"col_id\"]]\n\n\n\n\n\n\n\n\ntext\nis_title\ncol_id\n\n\n\n\n0\nSoupe à l'ail bonne femme\nTrue\n0\n\n\n1\nKnoblauchsuppe nach Hausfrauenart\nFalse\n0\n\n\n2\n65\nFalse\n3\n\n\n3\nCroûtes aux champignons\nTrue\n3\n\n\n4\n64\nFalse\n0\n\n\n5\n2 Stangen Porree ( Lauch ) 250 g enthäutete T...\nFalse\n0\n\n\n6\nDen Porree putzen , waschen , in Ringe schnei...\nFalse\n1\n\n\n7\nChampignons in Pasteten\nFalse\n3\n\n\n8\nDie Butter zerlassen , das Weißbrot von beide...\nFalse\n0\n\n\n9\n500 g Champignons g Butter Salz Pfeffer Cayen...\nFalse\n3\n\n\n10\n\nFalse\n1\n\n\n11\nzerdrückte Wacholderbeeren zerdrückte Knoblau...\nFalse\n2\n\n\n12\nSahne und Petersilie unterrühren . Die Champi...\nFalse\n3\n\n\n13\nDas Rehblatt unter fließendem kal- tem Wasser...\nFalse\n2\n\n\n14\nDen Speck in Streifen schneiden . Die Butter ...\nFalse\n2\n\n\n15\n\nFalse\n1\n\n\n16\nFleisch von den Knochen Das gare lösen , in P...\nFalse\n2\n\n\n17\nSchalotten abziehen , vierteln , mit den Wach...\nFalse\n2\n\n\n18\nSpeiseöl Parmesankäse\nFalse\n1\n\n\n19\n\nFalse\n1\n\n\n20\nGigot de chevreuil\nTrue\n1\n\n\n21\n\nFalse\n0\n\n\n22\nDen Bratensatz mit etwas Wasser los- kochen u...\nFalse\n2\n\n\n23\n\nFalse\n0\n\n\n24\nDie Champignons putzen , waschen , vierteln .\nFalse\n3\n\n\n25\nDie Butter zerlassen , die Champi- gnons dari...\nFalse\n3\n\n\n26\nRehblatt\nFalse\n1\n\n\n27\n\nFalse\n0\n\n\n28\n\nFalse\n0\n\n\n29\n\nFalse\n0\n\n\n30\n\nFalse\n1\n\n\n31\n\nFalse\n1\n\n\n32\n800 g Rehblatt ( Schulter ) Salz , Pfeffer 50...\nFalse\n1\n\n\n33\n\nFalse\n1\n\n\n\n\n\n\n\nAgain we have four columns. As the DocLayout-YOLO detector counts different, it is not obvious if col_id is correct. We therefore plot the result.\n\nimage = read_image(\"20250922_135514\")\n\nfig, ax = plt.subplots(1, figsize=(12, 12))\nax.imshow(image)\n\n# YOLO boxes\nfor _, row in df_yolo_font_size.iterrows():\n    color = \"red\" if row[\"is_title\"] else \"blue\"\n    rect = patches.Rectangle(\n        (row[\"x1\"], row[\"y1\"]),\n        row[\"x2\"] - row[\"x1\"],\n        row[\"y2\"] - row[\"y1\"],\n        linewidth=2,\n        edgecolor=color,\n        facecolor=\"none\"\n    )\n    ax.add_patch(rect)\n    if row[\"is_title\"]:\n        ax.text(row[\"x1\"], row[\"y1\"] - 5, \"TITLE\", color=\"red\", fontsize=10, weight=\"bold\")\n\n# Column boxes\nif col_df is not None:\n    for _, row in col_df.iterrows():\n        rect = patches.Rectangle(\n            (row[\"col_x1\"], row[\"col_y1\"]),\n            row[\"col_x2\"] - row[\"col_x1\"],\n            row[\"col_y2\"] - row[\"col_y1\"],\n            linewidth=3,\n            edgecolor=\"green\",\n            facecolor=\"none\",\n            linestyle=\"--\"\n        )\n        ax.add_patch(rect)\n        ax.text(row[\"col_x1\"], row[\"col_y1\"] - 5, \"COLUMN\", color=\"green\", fontsize=10)\n\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\nFirst, columns are correct.\nThere are also empty cells which we need to filter for the grouping.\nThen we can call our grouping function.\n\nsections_df, recipes = group_recipes(df_yolo_font_size[df_yolo_font_size.text != \"\"]); recipes\n\n[{'title': \" Soupe à l'ail bonne femme\",\n  'blocks': [\" Soupe à l'ail bonne femme\",\n   ' Knoblauchsuppe nach Hausfrauenart',\n   ' 2 Stangen Porree ( Lauch ) 250 g enthäutete Tomaten 3-5 Knoblauchzehen 3 EBI . Speiseöl 2 große Kartoffeln 141 Fleischbrühe Salz Pfeffer einige runde , ausgestochene Toast- brotscheiben',\n   ' 64',\n   ' Speiseöl Parmesankäse',\n   ' Den Porree putzen , waschen , in Ringe schneiden . Die Tomaten halbieren , die Stenge- lansätze herausschneiden , das Toma- tenfleisch in Würfel schneiden . Die Knoblauchzehen abziehen und zerdrücken . Das Öl erhitzen , das Gemüse mit den Knoblauchzehen darin andünsten . Die Kartoffeln schälen , waschen , in Scheiben schneiden , mit der Fleisch- brühe zu dem Gemüse geben , zum Kochen bringen , etwa 30 Minuten kochen lassen . Die Suppe mit Salz und Pfeffer abschmecken . Die Toastbrotscheiben mit dem Spei- seöl bestreichen , mit Parmesankäse bestreuen , in den auf 200-225 Grad ( Gas : Stufe 4-5 ) vorgeheizten Back- ofen schieben und 8-10 Minuten überbacken . Das Brot heiß zu der Suppe reichen .',\n   ' Rehblatt']},\n {'title': ' Gigot de chevreuil',\n  'blocks': [' Gigot de chevreuil',\n   ' 800 g Rehblatt ( Schulter ) Salz , Pfeffer 50 g durchwachsener Speck 25 g Butter 2 Schalotten',\n   ' zerdrückte Wacholderbeeren zerdrückte Knoblauchzehen 2-3 Thymianzweige 125 ml ( 1 ) Rotwein 250 ml ( 1 ) Wasser 10 g Butter 2 Teel . Weizenmehl 125 ml ( 1 ) Schlagsahne',\n   ' Das Rehblatt unter fließendem kal- tem Wasser abspülen , trockentupfen , enthäuten und mit Salz und Pfeffer einreiben .',\n   ' Den Speck in Streifen schneiden . Die Butter ( 25 g ) zerlassen , die Speckstreifen und das Fleisch darin anbraten .',\n   ' Schalotten abziehen , vierteln , mit den Wacholderbeeren und den gewaschenen Thymianzweigen zu dem Fleisch geben . Den Rotwein und etwas von dem Wasser hinzugießen . Das Fleisch etwa 1 Stunde schmoren lassen , ab und zu wenden und mit dem Bratensatz begießen . Die ver- dampfte Flüssigkeit nach und nach durch Wasser ersetzen .',\n   ' Fleisch von den Knochen Das gare lösen , in Portionsstücke schneiden , auf einer vorgewärmten Platte anrichten und warm stellen .',\n   ' Den Bratensatz mit etwas Wasser los- kochen und durch ein Sieb gießen . Die Butter ( 10 g ) mit dem Weizen- mehl verrühren , zum Bratensatz geben , mit einem Schneebesen durchschlagen und aufkochen lassen . Die Sahne unterrühren . Die Sauce mit Salz und Pfeffer abschmecken .']},\n {'title': ' Croûtes aux champignons',\n  'blocks': [' Croûtes aux champignons',\n   ' Champignons in Pasteten',\n   ' 500 g Champignons g Butter Salz Pfeffer Cayennepfeffer 125 ml ( 1 ) Wasser 2 gestrichene EBI . Speisestärke 3 EBI . Schlagsahne 2 EBI . gehackte Petersilie Zitronensaft 4 Blätterteigpasteten ( fertig gekauft )',\n   ' Die Champignons putzen , waschen , vierteln .',\n   ' Die Butter zerlassen , die Champi- gnons darin andünsten , mit Salz , Pfeffer und Cayennepfeffer würzen . Das Wasser hinzugießen , in etwa 10 Minuten gar dünsten lassen . Die Speisestärke mit 3 EBI . kaltem Wasser anrühren , die Pilze damit bin- den .',\n   ' Sahne und Petersilie unterrühren . Die Champignons mit den Gewürzen und dem Zitronensaft abschmecken . Von den Pasteten Hülsen und Deckel auf ein Backblech legen und in den auf 200-225 Grad ( Gas : Stufe 4-5 ) vorgeheizten Backofen schieben und in etwa 5 Minuten erwärmen . Die Champignons in die Pasteten fül- len , die Deckel darauf setzen .',\n   ' 65']}]\n\n\nThere is an issue with nested blocks: title “gigot de chevreuil” and “Rehblatt”. Somehow Rehblatt ended up in recipe 0.\n\n\n5.2 Generalization of YOLO-doclayout+OCR\nAgain we check, how other recipes perform. This time we look at the dataframe.\n\n\nCode\nfilename = \"IMG_2077\"\npage = read_json(filename)\n\ndet_res = model.predict(\n    \"data/raw/IMG_2077.jpg\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\ndf_yolo = yolo_to_df(det_res[0])\n\ndf_yolo_font_size = add_text_and_font_size_to_layout_df(df_yolo.copy(), page)\n\ndf_titles_yolo = detect_titles(df_yolo_font_size[df_yolo_font_size.is_title].copy(), font_factor=1)\nadd_titles_to_df(df_yolo_font_size, df_titles_yolo)\n\ncol_df, df_yolo_font_size = detect_columns(df_yolo_font_size.copy())\nsections_df, recipes = group_recipes(df_yolo_font_size[df_yolo_font_size.text != \"\"])\nsections_df[[\"text\",\"is_title\",\"recipe_id\"]]\n\n\n\n\n\n\n\n\n\ntext\nis_title\nrecipe_id\n\n\n\n\n0\nPréchauffez le four à 220 ° C . Faites cuire ...\nFalse\n0\n\n\n1\nMélangez les fèves dans un saladier avec le f...\nFalse\n0\n\n\n2\nToastez les tranches de pain . Répartissez le...\nFalse\n0\n\n\n3\nSalade de poulet , fèves , fenouil et concomb...\nTrue\n0\n\n\n4\nL'estragon est utilisé en phytothérapie pour ...\nFalse\n0\n\n\n5\nPour 4 personnes Préparation : 10 min Cuisson...\nFalse\n0\n\n\n6\nPelez le concombre ( s'il n'est pas bio ) et ...\nFalse\n0\n\n\n7\nParfait pour le soir !\nFalse\n0\n\n\n8\n✓ 1 cuil . à café de zestes de citron\nFalse\n0\n\n\n9\n126 PLATS DETOX\nFalse\n0\n\n\n10\n✓2 cuil . à soupe d'estragon frais haché\nFalse\n0\n\n\n11\n✓ 8 tranches de pain de campagne aux graines ...\nFalse\n0\n\n\n12\n✓ 1 cuil . à soupe de vinaigre de vin rouge\nFalse\n0\n\n\n13\n✓ 2 gros blancs de poulet ( ou 4 petits )\nFalse\n0\n\n\n14\n✓2 cuil . à café de jus de citron frais\nFalse\n0\n\n\n15\n✓ 150 g de fèves ( surgelées ) 1 petit concom...\nFalse\n0\n\n\n16\n✓ Huile d'olive ✓ Sel , poivre\nFalse\n0\n\n\n\n\n\n\n\n\n\nCode\nfilename = \"IMG_2074\"\npage = read_json(filename)\n\ndet_res = model.predict(\n    \"data/raw/IMG_2074.jpg\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\ndf_yolo = yolo_to_df(det_res[0])\n\ndf_yolo_font_size = add_text_and_font_size_to_layout_df(df_yolo.copy(), page)\n\ndf_titles_yolo = detect_titles(df_yolo_font_size[df_yolo_font_size.is_title].copy(), font_factor=1)\nadd_titles_to_df(df_yolo_font_size, df_titles_yolo)\n\ncol_df, df_yolo_font_size = detect_columns(df_yolo_font_size.copy())\nsections_df, recipes = group_recipes(df_yolo_font_size[df_yolo_font_size.text != \"\"])\nsections_df[[\"text\",\"is_title\",\"recipe_id\"]]\n\n\nunassigned words:\n\n\n\n\n\n\n\n\n\ntext\nis_title\nrecipe_id\n\n\n\n\n0\nFür 4 Personen Zweige Rosmarin 2-3 Salbeiblät...\nFalse\n0\n\n\n1\nzweige verteilt unter der Schnur anbringen . ...\nFalse\n0\n\n\n2\nRÔTI DE PORC POMMES CARAMÉLISÉES\nTrue\n0\n\n\n3\nBratzeit : 2 Stunden : 30 Minuten\nFalse\n0\n\n\n4\nSCHWEINEBRATEN MIT KARAMELLISIERTEN ÄPFELN\nFalse\n0\n\n\n5\nRosmarinnadeln , die Salbeiblätter , die Knob...\nFalse\n0\n\n\n6\nEin würziger Schweinebraten aus der Normandie\nFalse\n-1\n\n\n7\nGetränk : Rustikaler Rotwein , zum Beispiel a...\nFalse\n0\n\n\n\n\n\n\n\nHere we run into the first issue: the triple subtile leads to missing text in the final segmentation, shown as “-1” in the recipe_id column.\nSomething actually worse than the wrong identified title in the pure OCR case."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#comparison-of-pure-ocr-pipeline-vs-ocryolo-doclayout",
    "href": "posts/projects/recipescanner/page_segmentation.html#comparison-of-pure-ocr-pipeline-vs-ocryolo-doclayout",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "6 Comparison of pure OCR pipeline vs OCR+YOLO-doclayout",
    "text": "6 Comparison of pure OCR pipeline vs OCR+YOLO-doclayout\nWe will compare the two approaches by wrapping them in functions To make the comparison clearer, we’ll also use a different recipe this time.\n\ndef get_recipes_ocr_only_block(filename, type='block'):\n    page = read_json(filename)\n    df = ocr_json_to_df(page)\n    df_block = df[df[\"level\"] == type]\n\n    titles = detect_titles(df_block.copy())\n    add_titles_to_df(df_block, titles)\n\n    cols, df = detect_columns(df_block.copy())\n    df, recipes = group_recipes(df)\n    return df, recipes\n\n\ndef get_recipes_yolo(filename):\n    page = read_json(filename)\n\n    det_res = model.predict(\n        \"data/raw/\"+ filename +\".jpg\",\n        imgsz=1024,\n        conf=0.2,\n        device=\"cuda:0\",\n        verbose=False\n    )\n    df_yolo = yolo_to_df(det_res[0])\n\n    df_yolo_font_size = add_text_and_font_size_to_layout_df(df_yolo.copy(), page)\n\n    df_titles_yolo = detect_titles(df_yolo_font_size[df_yolo_font_size.is_title].copy(), font_factor=1)\n    add_titles_to_df(df_yolo_font_size, df_titles_yolo)\n\n    col_df, df_yolo_font_size = detect_columns(df_yolo_font_size.copy())\n    sections_df, recipes = group_recipes(df_yolo_font_size[df_yolo_font_size.text != \"\"])\n    return sections_df, recipes\n\n\n6.1 Runtime comparison\n\n%%time\ndf_ocr, r_ocr = get_recipes_ocr_only_block(\"IMG_2073\")\n\nCPU times: user 22.5 ms, sys: 162 μs, total: 22.7 ms\nWall time: 22.1 ms\n\n\n\n%%time\n\ndf_yolo, r_yolo = get_recipes_yolo(\"IMG_2073\")\n\nunassigned words:\nCPU times: user 354 ms, sys: 31.9 ms, total: 386 ms\nWall time: 386 ms\n\n\nThe OCR only approach is 20x faster, as we do not need to access the GPU. Without GPU it would take even more time.\n\n\n6.2 Recipe output comparison\nLet’s check if we discovered the same recipes. For that we try to realign the different rows and put the recipe ids of each approach on the ocr dataframe.\n\ndef attach_yolo_recipe_ids(df_ocr, df_yolo, pad=2, min_iou=0.1):\n    df_ocr = df_ocr.copy()\n    recipe_ids = []\n\n    for _, block in df_ocr.iterrows():\n        bx1, by1, bx2, by2 = block[\"x1\"], block[\"y1\"], block[\"x2\"], block[\"y2\"]\n\n        assigned_id = -1\n        best_iou = 0\n        candidate_boxes = []\n\n        for _, yrow in df_yolo.iterrows():\n            yx1, yy1 = yrow[\"x1\"] - pad, yrow[\"y1\"] - pad\n            yx2, yy2 = yrow[\"x2\"] + pad, yrow[\"y2\"] + pad\n\n            # Check containment first\n            if (bx1 &gt;= yx1) and (by1 &gt;= yy1) and (bx2 &lt;= yx2) and (by2 &lt;= yy2):\n                candidate_boxes.append((yrow[\"recipe_id\"], (yx2 - yx1) * (yy2 - yy1)))\n\n            # IoU calculation\n            inter_x1 = max(bx1, yx1)\n            inter_y1 = max(by1, yy1)\n            inter_x2 = min(bx2, yx2)\n            inter_y2 = min(by2, yy2)\n            inter_w = max(0, inter_x2 - inter_x1)\n            inter_h = max(0, inter_y2 - inter_y1)\n            inter_area = inter_w * inter_h\n\n            block_area = (bx2 - bx1) * (by2 - by1)\n            yolo_area = (yx2 - yx1) * (yy2 - yy1)\n            union_area = block_area + yolo_area - inter_area\n\n            iou = inter_area / union_area if union_area &gt; 0 else 0\n\n            if iou &gt; best_iou:\n                best_iou = iou\n                assigned_id = yrow[\"recipe_id\"]\n\n        # Prefer containment rule\n        if candidate_boxes:\n            # pick smallest enclosing box (most specific title/region)\n            assigned_id = min(candidate_boxes, key=lambda x: x[1])[0]\n        elif best_iou &lt; min_iou:\n            # fallback centroid if IoU too small\n            bcx, bcy = (bx1 + bx2) / 2, (by1 + by2) / 2\n            for _, yrow in df_yolo.iterrows():\n                if (yrow[\"x1\"] &lt;= bcx &lt;= yrow[\"x2\"]) and (yrow[\"y1\"] &lt;= bcy &lt;= yrow[\"y2\"]):\n                    assigned_id = yrow[\"recipe_id\"]\n                    break\n\n        recipe_ids.append(assigned_id)\n\n    df_ocr[\"recipe_id_yolo\"] = recipe_ids\n    return df_ocr\n\n\ncombined = attach_yolo_recipe_ids(df_ocr, df_yolo); combined[[\"recipe_id\",\"recipe_id_yolo\"]]\n\n\n\n\n\n\n\n\nrecipe_id\nrecipe_id_yolo\n\n\n\n\n1\n0\n0\n\n\n4\n0\n0\n\n\n11\n0\n0\n\n\n14\n0\n0\n\n\n16\n0\n0\n\n\n20\n0\n0\n\n\n23\n0\n0\n\n\n28\n0\n-1\n\n\n32\n0\n-1\n\n\n34\n0\n-1\n\n\n39\n0\n-1\n\n\n41\n0\n-1\n\n\n\n\n\n\n\nSomething has gone wrong.\nLet’s look at the recipes\n\nr_ocr\n\n[{'title': 'Merlu Koskera',\n  'blocks': ['Merlu Koskera',\n   'Pour 6 personnes : Temps de préparation : 30 minutes Temps de cuisson : 20 minutes',\n   \"Ingrédients : • 6 médaillons de merlu • 300 g d'asperges blanches en conserve • 500 g de petits pois en conserve • 1 poignée de palourdes • 1 poignée de moules ⚫ 3 œufs durs\",\n   \"• 10 cl de vin blanc sec type Irouléguy • 1 cuillère à café de purée de piment d'Espelette • 4 gousses d'ail\",\n   '• Persil',\n   \"• 3 cuillères à soupe de farine • Sel de Guérande • Poudre de piment d'Espelette\",\n   \"• Huile d'olive • 20 cl de fumet de poisson\",\n   \"Faites un hachis d'ail et de persil . Réservez . Salez et farinez les médaillons de merlu . Réservez . Dans une cocotte , faites ouvrir les moules et les palourdes , conservez leur jus . Dans une sauteuse , faites revenir les médaillons de merlu dans l'huile d'olive mélangée à la purée\",\n   \"de piment durant 2 minutes de chaque côté . Dans un plat en terre , déposez les médaillons de merlu . Réservez . Faites revenir pendant quelques minutes le hachis de persil et d'ail dans l'huile d'olive . Saupoudrez de farine , arrosez du jus des coquillages , du vin blanc et du fumet de poisson .\",\n   'Versez sur les médaillons .',\n   'Ajoutez les moules , les palourdes , les asperges et les petits pois . Laissez mijoter à feu doux pendant 10 minutes . Ajoutez les œufs durs en quartier avant la fin de la cuisson . Saupoudrez de persil et de poudre de piment .',\n   'Servez sans attendre .']}]\n\n\n\nr_yolo\n\n[{'title': ' Merlu Koskera',\n  'blocks': [' Merlu Koskera',\n   ' Pour 6 personnes : Temps de préparation : 30 minutes Temps de cuisson : 20 minutes',\n   ' Ingrédients :',\n   \" 6 médaillons de merlu 300 g d'asperges blanches en conserve • 500 g de petits pois en conserve • 1 poignée de palourdes • 1 poignée de moules ⚫ 3 œufs durs • 10 cl de vin blanc sec type Irouléguy • 1 cuillère à café de purée de piment d'Espelette • 4 gousses d'ail • Persil • 3 cuillères à soupe de farine • Sel de Guérande • Poudre de piment d'Espelette • Huile d'olive • 20 cl de fumet de poisson\"]}]\n\n\nWe are missing text in the DocLayout-YOLO recipe. When we look at the input dataframe, we see there are two columns.\n\ndf_yolo[[\"text\",\"col_id\",\"recipe_id\"]]\n\n\n\n\n\n\n\n\ntext\ncol_id\nrecipe_id\n\n\n\n\n0\nFaites un hachis d'ail et de persil . Réserve...\n0\n-1\n\n\n1\n6 médaillons de merlu 300 g d'asperges blanch...\n1\n0\n\n\n2\nPour 6 personnes : Temps de préparation : 30 ...\n1\n0\n\n\n3\nMerlu Koskera\n1\n0\n\n\n4\nIngrédients :\n1\n0\n\n\n\n\n\n\n\nBut when we look at the image there is only one.\n\n\n\nskew image\n\n\nA grain of salt: the shortcomings could be related to my optimization towards the heuristic approach."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#quantitative-analysis",
    "href": "posts/projects/recipescanner/page_segmentation.html#quantitative-analysis",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "7 Quantitative analysis",
    "text": "7 Quantitative analysis\nTo evaluate the performance, I did define some reference data, with recipe title and the correct OCR block to recipe mapping.\n\nwith open(\"data/ground-truth/ground-truth.json\", \"r\", encoding=\"utf-8\") as f:\n    reference = json.load(f)\n\nreference_map = {page[\"page_id\"]: page for page in reference[\"data\"]}\n\n\ndef evaluate_page(page_id, df_ocr, reference_map):\n    ref = reference_map[page_id]\n\n    df_ocr = df_ocr.sort_values([\"col_id\", \"y1\"]).reset_index(drop=True)\n    df_ocr[\"recipe_id_ref\"] = ref[\"reference_sections\"]\n\n    return df_ocr, ref\n\n\ndef compute_metrics(df):\n    y_ref = df[\"recipe_id_ref\"]\n    y_ocr = df[\"recipe_id\"]\n\n    results = {}\n\n    results[\"ocr_acc\"] = accuracy_score(y_ref, y_ocr) if \"recipe_id\" in df else None\n\n    return results\n\n\ndef title_accuracy_from_recipes(recipes, ref_titles, threshold=0.7):\n    pred_titles = [r[\"title\"].strip() for r in recipes if r.get(\"title\")]\n    print(pred_titles)\n    ref_titles = [rt.strip() for rt in ref_titles]\n\n    matches = []\n    matched = 0\n\n    for rt in ref_titles:\n        scores = [(pt, SequenceMatcher(None, pt.lower(), rt.lower()).ratio()) for pt in pred_titles]\n        if scores:\n            best_pred, best_score = max(scores, key=lambda x: x[1])\n            matches.append((rt, best_pred, best_score))\n            if best_score &gt;= threshold:\n                matched += 1\n        else:\n            matches.append((rt, None, 0.0))\n\n    accuracy = matched / len(ref_titles) if ref_titles else 0.0\n    return accuracy, matches\n\n\n\nall_metrics = []\n\nfor json_path in glob.glob(\"data/raw/*.jpg\"):\n    page_id = os.path.splitext(os.path.basename(json_path))[0]\n    if page_id not in reference_map:\n        continue\n\n    df_ocr, recipes_ocr = get_recipes_ocr_only_block(page_id)\n\n    df_eval, ref = evaluate_page(page_id, df_ocr,  reference_map)\n    metrics = compute_metrics(df_eval)\n\n    ref_titles = [r[\"title\"] for r in ref[\"recipes\"]]\n\n    ocr_acc, ocr_matches = title_accuracy_from_recipes(recipes_ocr, ref_titles, threshold=0.7)\n\n    metrics.update({\n        # OCR metrics\n        \"ocr_title_accuracy\": ocr_acc,\n        \"ocr_title_matches\": ocr_matches,\n        \"ocr_num_pred_recipes\": len(recipes_ocr),\n\n        # Reference info\n        \"num_ref_recipes\": len(ref_titles),\n    })\n\n    all_metrics.append((page_id, metrics))\n\n['Merlu Koskera']\n['Artichauts à la sauce vinaigrette Artischocken mit Vinaigrette ( Foto S. 63 )', 'Asperges ,, sauce mousseline❝ Spargel mit abgeschlagener Sauce', '2 EBI . steifgeschlagene Schlagsahne']\n[\"Soupe à l'ail bonne femme Knoblauchsuppe nach Hausfrauenart\", 'Gigot de chevreuil']\n[\"Dinde pochée au lait d'amande , mange - tout et haricots\", 'Info nutrition']\n['Croquetas', 'Boudin noir sur Canapé']\n['Lapin aux pruneaux']\n[\"Soupe à l'ail bonne femme Knoblauchsuppe nach Hausfrauenart\", 'Gigot de chevreuil', 'Croûtes aux champignons Champignons in Pasteten']\n['Variantes', '92 PLATS FEEL GOOD']\n['Salade de poulet , fèves , fenouil et concombre sur toasts']\n['Ein würziger Schweinebraten aus der Normandie RÔTI DE PORC AUX POMMES CARAMÉLISÉES']\n['Mulligatawny']\n['Croûtes aux champignons Champignons in Pasteten']\n\n\n\ndf_metrics = pd.DataFrame(\n    [{**{\"page_id\": pid}, **m} for pid, m in all_metrics]\n)\ndf_metrics\n\n\n\n\n\n\n\n\npage_id\nocr_acc\nocr_title_accuracy\nocr_title_matches\nocr_num_pred_recipes\nnum_ref_recipes\n\n\n\n\n0\nIMG_2073\n1.000000\n1.000000\n[(Merlu Koskera, Merlu Koskera, 1.0)]\n1\n1\n\n\n1\n20250922_135453\n0.750000\n0.000000\n[(Artichauts à la sauce vinaigrette, Artichaut...\n3\n2\n\n\n2\n20250922_135507\n1.000000\n0.500000\n[(Soupe à l'ail bonne femme, Soupe à l'ail bon...\n2\n2\n\n\n3\nIMG_2079\n0.692308\n1.000000\n[(Dinde pochée au lait d'amande, mange - tout ...\n2\n1\n\n\n4\n20250922_213505\n1.000000\n1.000000\n[(Croquetas, Croquetas, 1.0), (Boudin noir sur...\n2\n2\n\n\n5\nIMG_2078\n1.000000\n1.000000\n[(Lapin aux pruneaux, Lapin aux pruneaux, 1.0)]\n1\n1\n\n\n6\n20250922_135514\n0.916667\n0.333333\n[(Soupe à l'ail bonne femme, Soupe à l'ail bon...\n3\n3\n\n\n7\nIMG_2080\n0.125000\n0.000000\n[(Gnocchi sans gluten à la patate douce et pes...\n2\n1\n\n\n8\nIMG_2077\n1.000000\n1.000000\n[(Salade de poulet, fèves, fenouil et concombr...\n1\n1\n\n\n9\nIMG_2074\n1.000000\n0.000000\n[(RÔTI DE PORC POMMES CARAMÉLISÉES, Ein würzig...\n1\n1\n\n\n10\nIMG_2076\n1.000000\n1.000000\n[(Mulligatawny, Mulligatawny, 1.0)]\n1\n1\n\n\n11\n20250922_135510\n1.000000\n0.000000\n[(Croûtes aux champignons, Croûtes aux champig...\n1\n1\n\n\n\n\n\n\n\nIn short, the algorithm is far from perfect.\nMost errors result from incorrect titles. When the titles are wrong, to too many recipes are created."
  },
  {
    "objectID": "posts/projects/recipescanner/page_segmentation.html#outlook",
    "href": "posts/projects/recipescanner/page_segmentation.html#outlook",
    "title": "Page Segmentation: The easy and the hard way",
    "section": "8 Outlook",
    "text": "8 Outlook\nA few possible improvements include:\n\nstabilizing titles with DocLayout-YOLO\nusing book-dependent settings adjusted based on user feedback\nallowing manual user overrides\ntraining a classifier solely on OCR data, but with much larger datasets\n\nWe’ll see how this evolves once it’s integrated into the main app."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_doclayout.html",
    "href": "posts/projects/recipescanner/text_or_image_doclayout.html",
    "title": "Is training your own classifier really worth it?",
    "section": "",
    "text": "I recently trained a text or page classifier, which helped me dramatically speed up the sorting of scans for further processing in an OCR pipeline.\nRecently I have been using Doclayout-YOLO for further processing of the text pages and especially the pages with mixed layout.\nDoclayout-YOLO has proofed quite reliable in detecting existing text with bounding boxes. In addition it is optimized for speed.\nWhen I finished the first part of this classifier I had the idea, why not just count the number or size of text boxes on a page?"
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_doclayout.html#what-happened-so-far",
    "href": "posts/projects/recipescanner/text_or_image_doclayout.html#what-happened-so-far",
    "title": "Is training your own classifier really worth it?",
    "section": "",
    "text": "I recently trained a text or page classifier, which helped me dramatically speed up the sorting of scans for further processing in an OCR pipeline.\nRecently I have been using Doclayout-YOLO for further processing of the text pages and especially the pages with mixed layout.\nDoclayout-YOLO has proofed quite reliable in detecting existing text with bounding boxes. In addition it is optimized for speed.\nWhen I finished the first part of this classifier I had the idea, why not just count the number or size of text boxes on a page?"
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_doclayout.html#doclayout-yolo",
    "href": "posts/projects/recipescanner/text_or_image_doclayout.html#doclayout-yolo",
    "title": "Is training your own classifier really worth it?",
    "section": "2 Doclayout-YOLO",
    "text": "2 Doclayout-YOLO\nDoclayout-YOLO was trained on top of YOLO10 with 300k synthetic documents. YOLO is a End-to-end object detection network, whereas Resnet is first a classification network. While object detection can be done with a resnet by outputting 4 numbers for each pixel. It requires further processing. This makes it slower than YOLO. YOLO splits the image into boxes and then detects classes within those boxes.\n\n\nCode\nimport cv2\nimport matplotlib.pyplot as plt\nfrom doclayout_yolo import YOLOv10\n\n\n\n2.1 First impression\nWe first load the model to the GPU.\n\nmodel = YOLOv10(\"data/models/doclayout_yolo.pt\")\nmodel.to(\"cuda:0\");\n\nand then examine one page\n\ndet_res = model.predict(\n    \"data/raw/text_page/IMG_0751.JPG\",\n    imgsz=1024,\n    conf=0.2,\n    device=\"cuda:0\",\n    verbose=False\n)\n\nannotated_frame = det_res[0].plot(pil=True, line_width=10, font_size=30)\nimg_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(10, 14))\nplt.imshow(img_rgb)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\nWe can clearly see title, text and image boxes. The model ignores areas of white space. That the part outside of the book is recognized as image seems understandable, as the model has no concept of the entity book."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_doclayout.html#text-or-not",
    "href": "posts/projects/recipescanner/text_or_image_doclayout.html#text-or-not",
    "title": "Is training your own classifier really worth it?",
    "section": "3 Text or not",
    "text": "3 Text or not\nThe model returns the type of box. A text box is of the class 1.\nLet’s first count text boxes\n\n\ndef count_text_boxes(model, filename, conf_threshold=0.2):\n    det_res = model.predict(\n        filename,\n        imgsz=1024,\n        conf=conf_threshold,\n        verbose=False\n    )\n    detections = det_res[0].boxes\n\n    text_boxes = [\n        box for box in detections\n        if int(box.cls) == 1 and float(box.conf) &gt;= conf_threshold\n    ]\n    return len(text_boxes)\n\n\n%%time\ncount_text_boxes(model, \"data/raw/text_page/IMG_0751.JPG\")\n\nCPU times: user 144 ms, sys: 31 ms, total: 175 ms\nWall time: 172 ms\n\n\n11\n\n\nThere are 11 text boxes. The result was obtained in 179ms. My self trained CNN needs 160ms.\nWe allow one text box for image pages\n\ndef is_text_page(model, filename, conf_threshold=0.2, box_threshold=1):\n    text_box_count = count_text_boxes(model, filename, conf_threshold)\n    if text_box_count &gt; box_threshold:\n        return True\n    return False\n\n\nis_text_page(model, \"data/raw/text_page/IMG_0751.JPG\")\n\nTrue\n\n\n\n3.1 Evaluation\nWe will evaluate this on image pages and on text pages.\n\nimport glob\n\ntotal = 0\nincorrect = 0\nincorrect_files = []\nfor file in glob.glob(\"data/raw/image_page/*.JPG\"):\n    total += 1\n    if is_text_page(model, file):\n        incorrect += 1\n        incorrect_files.append(file)\n\nincorrect\n\n1\n\n\n\ncount_text_boxes(model, incorrect_files[0])\n\n5\n\n\n\n1-incorrect/total\n\n0.9969604863221885\n\n\n99.6% is far higher than any score, I obtained during training. On the other hand 5 boxes is clearly an outlier which needs to be accepted with this simple approach.\nLet’s check the text pages\n\nimport glob\n\ntotal = 0\nincorrect = 0\nincorrect_files = []\nfor file in glob.glob(\"data/raw/text_page/*.JPG\"):\n    total += 1\n    if not is_text_page(model, file):\n        incorrect += 1\n        incorrect_files.append(file)\n\n\nincorrect\n\n0\n\n\nWe have 100% correct identification.\n\n\n3.2 Performance on CPU\nOne place where the OCR based model was a bottleneck was automated testing. The slow performance dramatically slowed down the tests.\nIn the actual usage, the slow performance was is not that important as we proceed with api calls later on, which are slow too.\n\nmodel2 = YOLOv10(\"data/models/doclayout_yolo.pt\")\nmodel2.to(\"cpu\");\n\n\n%%time\nis_text_page(model2, \"data/raw/text_page/IMG_0751.JPG\")\n\nCPU times: user 5.06 s, sys: 368 ms, total: 5.43 s\nWall time: 1.02 s\n\n\nTrue\n\n\nOn CPU the model is slower by factor 6."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_doclayout.html#foundation-models-with-some-logic-often-win",
    "href": "posts/projects/recipescanner/text_or_image_doclayout.html#foundation-models-with-some-logic-often-win",
    "title": "Is training your own classifier really worth it?",
    "section": "4 Foundation models with some logic often win",
    "text": "4 Foundation models with some logic often win\nIn the way we are using Doclayout-YOLO it can be called a foundation model.\nInstead of spending time an resources on training of our own model, it can be quicker to run some post-processing on the output of a foundational model.\nMost counterintuitive we are using a regression-classification model to perform pure classification."
  },
  {
    "objectID": "posts/projects/recipescanner/smart_shopping_list.html",
    "href": "posts/projects/recipescanner/smart_shopping_list.html",
    "title": "Can AI fix your shopping list?",
    "section": "",
    "text": "A dumb shopping list, albeit an easy one\n\n\nMost shopping or recipe apps can make a list — but few can aggregate it correctly. Ask them to combine “1 l milk”, “1 l lait”, and “1 l Milch”, and they’ll happily buy you one liter of each.\nCan multilingual AI models understand that milk, lait, and Milch are the same thing? We’ll explore a full pipeline — from regex parsing to multilingual embeddings, fuzzy matching, and translation —\n(Spoiler: not as far as you’d hope.)\n\n\nLet’s have a look at some test cases, to make things clearer:\n\ntest_cases= [\n    # === Milk family ===\n    {\n        \"input\": [\"1l milk\", \"1l lait\", \"1l Milch\"],\n        \"expected\": [\"3l milk\"]\n    },\n    {\n        \"input\": [\"1l whole milk\", \"1l lait entier\", \"1l Vollmilch\"],\n        \"expected\": [\"3l milk\"]\n    },\n    {\n        \"input\": [\"1l hot milk\", \"1l warme Milch\", \"1l lait chaud\"],\n        \"expected\": [\"3l milk\"]\n    },\n\n    # === Sugar ===\n    {\n        \"input\": [\"1000g sugar\", \"1kg Zucker\", \"1kg sucre\", \"1 EL Zucker\"],\n        \"expected\": [\"3kg sugar\"]\n    },\n    {\n        \"input\": [\"1kg brown sugar\", \"1kg sucre blanc\", \"1kg weißer Zucker\"],\n        \"expected\": [\"1kg brown sugar\", \"1kg white sugar\"]\n    },\n\n    # === Eggs ===\n    {\n        \"input\": [\"2 eggs\", \"1 œuf\", \"1 Ei\"],\n        \"expected\": [\"4 eggs\"]\n    },\n\n    # === Bread ===\n    {\n        \"input\": [\"1 baguette\", \"1 bread\", \"1 Brot\"],\n        \"expected\": [\"3 bread\"]\n    },\n\n    # === Water & wine distinction ===\n    {\n        \"input\": [\"1 bottle of water\", \"1 bouteille de vin\", \"1 Flasche Wasser\"],\n        \"expected\": [\"2 bottles of water\", \"1 bottle of wine\"]\n    },\n\n    # === Branded/variant milk ===\n    {\n        \"input\": [\"1l Oatly milk\", \"1l lait Oatly\", \"1l Oatly Milch\"],\n        \"expected\": [\"3l Oatly Milk\"]\n    },\n\n    # === Rice ===\n    {\n        \"input\": [\"½kg rice\", \"500g Reis\", \"500g riz\"],\n        \"expected\": [\"1.5kg rice\"]\n    },\n\n    # === Onion ===\n    {\n        \"input\": [\"1 onion\", \"1 oignon\", \"1 Zwiebel\"],\n        \"expected\": [\"3 onions\"]\n    },\n\n    # === Bell pepper ===\n    {\n        \"input\": [\"1 bell pepper\", \"1 capsicum\", \"1 poivron\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n\n    # === Red pepper flakes ===\n    {\n        \"input\": [\"1 red pepper flakes\", \"1 chili flakes\", \"1 piment concassé\"],\n        \"expected\": [\"3 red pepper flakes\"]\n    },\n\n    # === Butter ===\n    {\n        \"input\": [\"1 tbsp butter\", \"1 cuillère de beurre\", \"1 EL Butter\"],\n        \"expected\": [\"3 tbsp butter\"]\n    },\n\n    # === Salt ===\n    {\n        \"input\": [\"1 tsp salt\", \"1 TL Salz\", \"1 cuillère à café de sel\"],\n        \"expected\": [\"3 tsp salt\"]\n    },\n\n    # === Tomato cans ===\n    {\n        \"input\": [\"1 can crushed tomatoes\", \"1 boîte de tomates concassées\", \"1 Dose Tomatenstücke\"],\n        \"expected\": [\"3 cans crushed tomatoes\"]\n    },\n\n    # === Yogurt ===\n    {\n        \"input\": [\"1 cup yogurt\", \"1 tasse de yaourt\", \"1 Becher Joghurt\"],\n        \"expected\": [\"3 cups yogurt\"]\n    },\n\n    # === Oil ===\n    {\n        \"input\": [\"1 tbsp olive oil\", \"1 EL Olivenöl\", \"1 cuillère à soupe d'huile d'olive\"],\n        \"expected\": [\"3 tbsp olive oil\"]\n    },\n\n    # === Bread variants shouldn’t merge with pastry ===\n    {\n        \"input\": [\"1 croissant\", \"1 pain\", \"1 bread\"],\n        \"expected\": [\"2 bread\", \"1 croissant\"]\n    },\n\n    # === Cheese ===\n    {\n        \"input\": [\"100g cheese\", \"100g fromage\", \"100g Käse\"],\n        \"expected\": [\"300g cheese\"]\n    },\n\n    # === Flour ===\n    {\n        \"input\": [\"1kg flour\", \"1000g Mehl\", \"1kg farine\"],\n        \"expected\": [\"3kg flour\"]\n    },\n]\n\n\n\n\n\nIn addition, we will also examine what will happen on longer phrases:\n\ntest_cases_long_sentences = [\n    # === Quantities with comments ===\n    {\n        \"input\": [\"1 large yellow onion, coarsely chopped\", \"1 oignon jaune haché\", \"1 große gelbe Zwiebel, gehackt\"],\n        \"expected\": [\"3 onions\"]\n    },\n    {\n        \"input\": [\"2 cups mango chunks, (2 large mangoes) (fresh or frozen)\"],\n        \"expected\": [\"2 cups mango chunks\"]\n    },\n    {\n        \"input\": [\"½ cup butter (softened)\", \"100g beurre (ramolli)\", \"100g Butter (weich)\"],\n        \"expected\": [\"1.5 sticks butter\"] \n    },\n    {\n        \"input\": [\"1 tbsp minced cilantro, leaves and stems\", \"1 EL gehackter Koriander\", \"1 cuillère à soupe de coriandre hachée\"],\n        \"expected\": [\"3 tbsp cilantro\"]\n    },\n\n    # === Multi-part phrases ===\n    {\n        \"input\": [\"1 bell pepper, cut in pieces\", \"1 poivron coupé en morceaux\", \"1 Paprika in Stücke geschnitten\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n    {\n        \"input\": [\"2 cloves garlic, finely chopped\", \"2 gousses d’ail hachées\", \"2 Knoblauchzehen, fein gehackt\"],\n        \"expected\": [\"6 cloves garlic\"]\n    },\n    {\n        \"input\": [\"1 stalk bell peppers, cut in pieces\", \"1 Stiel Paprika, geschnitten\", \"1 tige de poivron, coupée\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n\n    # === Fractional & descriptive ===\n    {\n        \"input\": [\"1½ tsp garam masala\", \"1 cuillère à café de garam masala\", \"1 TL Garam Masala\"],\n        \"expected\": [\"3 tsp garam masala\"]\n    },\n    {\n        \"input\": [\"a pinch of salt\", \"une pincée de sel\", \"eine Prise Salz\"],\n        \"expected\": [\"3 pinches salt\"]\n    },\n    {\n        \"input\": [\"a handful of nuts\", \"une poignée de noix\", \"eine Handvoll Nüsse\"],\n        \"expected\": [\"3 handfuls nuts\"]\n    },\n\n    # === Compounds / alternatives ===\n    {\n        \"input\": [\"2 cups milk or cream\", \"2 tasses de lait ou de crème\", \"2 Tassen Milch oder Sahne\"],\n        \"expected\": [\"6 cups milk or cream\"]\n    },\n    {\n        \"input\": [\"1 tbsp olive oil, plus extra for frying\", \"1 EL Olivenöl, zusätzlich zum Braten\", \"1 cuillère à soupe d’huile d’olive, plus pour la cuisson\"],\n        \"expected\": [\"3 tbsp olive oil\"]\n    },\n    {\n        \"input\": [\"1 cup chopped tomatoes (canned)\", \"1 boîte de tomates concassées\", \"1 Dose gehackte Tomaten\"],\n        \"expected\": [\"3 cups chopped tomatoes\"]\n    },\n\n    # === Units expressed as nouns ===\n    {\n        \"input\": [\"1 bottle of water\", \"1 bouteille d’eau\", \"1 Flasche Wasser\"],\n        \"expected\": [\"3 bottles of water\"]\n    },\n    {\n        \"input\": [\"1 can coconut milk\", \"1 boîte de lait de coco\", \"1 Dose Kokosmilch\"],\n        \"expected\": [\"3 cans coconut milk\"]\n    },\n\n    # === Descriptive words shouldn’t break grouping ===\n    {\n        \"input\": [\"1 large potato\", \"1 grosse pomme de terre\", \"1 große Kartoffel\"],\n        \"expected\": [\"3 potatoes\"]\n    },\n    {\n        \"input\": [\"2 small onions\", \"2 petits oignons\", \"2 kleine Zwiebeln\"],\n        \"expected\": [\"6 onions\"]\n    },\n]"
  },
  {
    "objectID": "posts/projects/recipescanner/smart_shopping_list.html#meet-the-data",
    "href": "posts/projects/recipescanner/smart_shopping_list.html#meet-the-data",
    "title": "Can AI fix your shopping list?",
    "section": "",
    "text": "A dumb shopping list, albeit an easy one\n\n\nMost shopping or recipe apps can make a list — but few can aggregate it correctly. Ask them to combine “1 l milk”, “1 l lait”, and “1 l Milch”, and they’ll happily buy you one liter of each.\nCan multilingual AI models understand that milk, lait, and Milch are the same thing? We’ll explore a full pipeline — from regex parsing to multilingual embeddings, fuzzy matching, and translation —\n(Spoiler: not as far as you’d hope.)\n\n\nLet’s have a look at some test cases, to make things clearer:\n\ntest_cases= [\n    # === Milk family ===\n    {\n        \"input\": [\"1l milk\", \"1l lait\", \"1l Milch\"],\n        \"expected\": [\"3l milk\"]\n    },\n    {\n        \"input\": [\"1l whole milk\", \"1l lait entier\", \"1l Vollmilch\"],\n        \"expected\": [\"3l milk\"]\n    },\n    {\n        \"input\": [\"1l hot milk\", \"1l warme Milch\", \"1l lait chaud\"],\n        \"expected\": [\"3l milk\"]\n    },\n\n    # === Sugar ===\n    {\n        \"input\": [\"1000g sugar\", \"1kg Zucker\", \"1kg sucre\", \"1 EL Zucker\"],\n        \"expected\": [\"3kg sugar\"]\n    },\n    {\n        \"input\": [\"1kg brown sugar\", \"1kg sucre blanc\", \"1kg weißer Zucker\"],\n        \"expected\": [\"1kg brown sugar\", \"1kg white sugar\"]\n    },\n\n    # === Eggs ===\n    {\n        \"input\": [\"2 eggs\", \"1 œuf\", \"1 Ei\"],\n        \"expected\": [\"4 eggs\"]\n    },\n\n    # === Bread ===\n    {\n        \"input\": [\"1 baguette\", \"1 bread\", \"1 Brot\"],\n        \"expected\": [\"3 bread\"]\n    },\n\n    # === Water & wine distinction ===\n    {\n        \"input\": [\"1 bottle of water\", \"1 bouteille de vin\", \"1 Flasche Wasser\"],\n        \"expected\": [\"2 bottles of water\", \"1 bottle of wine\"]\n    },\n\n    # === Branded/variant milk ===\n    {\n        \"input\": [\"1l Oatly milk\", \"1l lait Oatly\", \"1l Oatly Milch\"],\n        \"expected\": [\"3l Oatly Milk\"]\n    },\n\n    # === Rice ===\n    {\n        \"input\": [\"½kg rice\", \"500g Reis\", \"500g riz\"],\n        \"expected\": [\"1.5kg rice\"]\n    },\n\n    # === Onion ===\n    {\n        \"input\": [\"1 onion\", \"1 oignon\", \"1 Zwiebel\"],\n        \"expected\": [\"3 onions\"]\n    },\n\n    # === Bell pepper ===\n    {\n        \"input\": [\"1 bell pepper\", \"1 capsicum\", \"1 poivron\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n\n    # === Red pepper flakes ===\n    {\n        \"input\": [\"1 red pepper flakes\", \"1 chili flakes\", \"1 piment concassé\"],\n        \"expected\": [\"3 red pepper flakes\"]\n    },\n\n    # === Butter ===\n    {\n        \"input\": [\"1 tbsp butter\", \"1 cuillère de beurre\", \"1 EL Butter\"],\n        \"expected\": [\"3 tbsp butter\"]\n    },\n\n    # === Salt ===\n    {\n        \"input\": [\"1 tsp salt\", \"1 TL Salz\", \"1 cuillère à café de sel\"],\n        \"expected\": [\"3 tsp salt\"]\n    },\n\n    # === Tomato cans ===\n    {\n        \"input\": [\"1 can crushed tomatoes\", \"1 boîte de tomates concassées\", \"1 Dose Tomatenstücke\"],\n        \"expected\": [\"3 cans crushed tomatoes\"]\n    },\n\n    # === Yogurt ===\n    {\n        \"input\": [\"1 cup yogurt\", \"1 tasse de yaourt\", \"1 Becher Joghurt\"],\n        \"expected\": [\"3 cups yogurt\"]\n    },\n\n    # === Oil ===\n    {\n        \"input\": [\"1 tbsp olive oil\", \"1 EL Olivenöl\", \"1 cuillère à soupe d'huile d'olive\"],\n        \"expected\": [\"3 tbsp olive oil\"]\n    },\n\n    # === Bread variants shouldn’t merge with pastry ===\n    {\n        \"input\": [\"1 croissant\", \"1 pain\", \"1 bread\"],\n        \"expected\": [\"2 bread\", \"1 croissant\"]\n    },\n\n    # === Cheese ===\n    {\n        \"input\": [\"100g cheese\", \"100g fromage\", \"100g Käse\"],\n        \"expected\": [\"300g cheese\"]\n    },\n\n    # === Flour ===\n    {\n        \"input\": [\"1kg flour\", \"1000g Mehl\", \"1kg farine\"],\n        \"expected\": [\"3kg flour\"]\n    },\n]\n\n\n\n\n\nIn addition, we will also examine what will happen on longer phrases:\n\ntest_cases_long_sentences = [\n    # === Quantities with comments ===\n    {\n        \"input\": [\"1 large yellow onion, coarsely chopped\", \"1 oignon jaune haché\", \"1 große gelbe Zwiebel, gehackt\"],\n        \"expected\": [\"3 onions\"]\n    },\n    {\n        \"input\": [\"2 cups mango chunks, (2 large mangoes) (fresh or frozen)\"],\n        \"expected\": [\"2 cups mango chunks\"]\n    },\n    {\n        \"input\": [\"½ cup butter (softened)\", \"100g beurre (ramolli)\", \"100g Butter (weich)\"],\n        \"expected\": [\"1.5 sticks butter\"] \n    },\n    {\n        \"input\": [\"1 tbsp minced cilantro, leaves and stems\", \"1 EL gehackter Koriander\", \"1 cuillère à soupe de coriandre hachée\"],\n        \"expected\": [\"3 tbsp cilantro\"]\n    },\n\n    # === Multi-part phrases ===\n    {\n        \"input\": [\"1 bell pepper, cut in pieces\", \"1 poivron coupé en morceaux\", \"1 Paprika in Stücke geschnitten\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n    {\n        \"input\": [\"2 cloves garlic, finely chopped\", \"2 gousses d’ail hachées\", \"2 Knoblauchzehen, fein gehackt\"],\n        \"expected\": [\"6 cloves garlic\"]\n    },\n    {\n        \"input\": [\"1 stalk bell peppers, cut in pieces\", \"1 Stiel Paprika, geschnitten\", \"1 tige de poivron, coupée\"],\n        \"expected\": [\"3 bell peppers\"]\n    },\n\n    # === Fractional & descriptive ===\n    {\n        \"input\": [\"1½ tsp garam masala\", \"1 cuillère à café de garam masala\", \"1 TL Garam Masala\"],\n        \"expected\": [\"3 tsp garam masala\"]\n    },\n    {\n        \"input\": [\"a pinch of salt\", \"une pincée de sel\", \"eine Prise Salz\"],\n        \"expected\": [\"3 pinches salt\"]\n    },\n    {\n        \"input\": [\"a handful of nuts\", \"une poignée de noix\", \"eine Handvoll Nüsse\"],\n        \"expected\": [\"3 handfuls nuts\"]\n    },\n\n    # === Compounds / alternatives ===\n    {\n        \"input\": [\"2 cups milk or cream\", \"2 tasses de lait ou de crème\", \"2 Tassen Milch oder Sahne\"],\n        \"expected\": [\"6 cups milk or cream\"]\n    },\n    {\n        \"input\": [\"1 tbsp olive oil, plus extra for frying\", \"1 EL Olivenöl, zusätzlich zum Braten\", \"1 cuillère à soupe d’huile d’olive, plus pour la cuisson\"],\n        \"expected\": [\"3 tbsp olive oil\"]\n    },\n    {\n        \"input\": [\"1 cup chopped tomatoes (canned)\", \"1 boîte de tomates concassées\", \"1 Dose gehackte Tomaten\"],\n        \"expected\": [\"3 cups chopped tomatoes\"]\n    },\n\n    # === Units expressed as nouns ===\n    {\n        \"input\": [\"1 bottle of water\", \"1 bouteille d’eau\", \"1 Flasche Wasser\"],\n        \"expected\": [\"3 bottles of water\"]\n    },\n    {\n        \"input\": [\"1 can coconut milk\", \"1 boîte de lait de coco\", \"1 Dose Kokosmilch\"],\n        \"expected\": [\"3 cans coconut milk\"]\n    },\n\n    # === Descriptive words shouldn’t break grouping ===\n    {\n        \"input\": [\"1 large potato\", \"1 grosse pomme de terre\", \"1 große Kartoffel\"],\n        \"expected\": [\"3 potatoes\"]\n    },\n    {\n        \"input\": [\"2 small onions\", \"2 petits oignons\", \"2 kleine Zwiebeln\"],\n        \"expected\": [\"6 onions\"]\n    },\n]"
  },
  {
    "objectID": "posts/projects/recipescanner/smart_shopping_list.html#simple-approach",
    "href": "posts/projects/recipescanner/smart_shopping_list.html#simple-approach",
    "title": "Can AI fix your shopping list?",
    "section": "2 Simple Approach",
    "text": "2 Simple Approach\nFor a human aggregating the items on the list is fairly easy. What similar items exist? And how many?\nFor a computer, this is not so easy.\nI came up with a simple pipeline\n\nWe start by separating numbers from pure text. This should allow us to identify quantity and units, we’ll use regex for this.\nAs there will be multiple languages with similar words, we need to detect similar concepts. This will be done via multi language embeddings.\nOnce we have grouped items via embeddings, we aggregate the quantity. We need to normalize quantities to do this.\n\n\n2.1 Using Regex: What is the unit of 4 Apples?\nWhile developing a solution, I discovered that embedding models have issues with numeric content. The reason is that we are looking at very short sequences. Numeric content leds to identical tokens for different items. If the numeric token is more than a certain threshold, things purely become similar due to the numeric component\nWe ’ll use a simple regex approach. Quantities are most of the time at the front of the ingredients.\nUnits are predefined as there only exists a limited set of units in each language. We will limit ourselves to english, french and german here. Let’s build unit map:\n\n# === Multilingual normalization map ===\nUNIT_MAP = {\n    # === volume ===\n    \"l\": \"l\", \"lt\": \"l\",\n    \"liter\": \"l\", \"liters\": \"l\",          # EN\n    \"litre\": \"l\", \"litres\": \"l\",          # FR\n    \"literen\": \"l\", \"liter\": \"l\", \"literes\": \"l\", \"litern\": \"l\",  # DE plural inflections\n    \"ml\": \"ml\", \"millilitre\": \"ml\", \"millilitres\": \"ml\",\n    \"milliliter\": \"ml\", \"milliliters\": \"ml\",\n    # === weight ===\n    \"g\": \"g\", \"gram\": \"g\", \"grams\": \"g\",\n    \"gramme\": \"g\", \"grammes\": \"g\",        # FR\n    \"gramm\": \"g\", \"gramme\": \"g\", \"grammen\": \"g\",  # DE\n    \"kg\": \"kg\", \"kilogram\": \"kg\", \"kilograms\": \"kg\",\n    \"kilogramme\": \"kg\", \"kilogrammes\": \"kg\",      # FR\n    \"kilogramm\": \"kg\", \"kilogramme\": \"kg\", \"kilogrammen\": \"kg\",  # DE\n    # === spoons & cups ===\n    \"cup\": \"cup\", \"cups\": \"cup\",\n    \"tasse\": \"cup\", \"tasses\": \"cup\",      # FR\n    \"becher\": \"cup\", \"tasse\": \"cup\",      # DE\n    \"tbsp\": \"tbsp\", \"tablespoon\": \"tbsp\", \"tablespoons\": \"tbsp\",\n    \"cuillère\": \"tbsp\", \"cuillerée\": \"tbsp\", \"cuillères\": \"tbsp\",  # FR\n    \"esslöffel\": \"tbsp\", \"el\": \"tbsp\",    # DE\n    \"tsp\": \"tsp\", \"teaspoon\": \"tsp\", \"teaspoons\": \"tsp\",\n    \"tl\": \"tsp\", \"teelöffel\": \"tsp\",      # DE\n    \"cuillère à café\": \"tsp\", \"cc\": \"tsp\", # FR\n    # === qualitative small measures ===\n    \"pinch\": \"pinch\", \"pinches\": \"pinch\",\n    \"pincée\": \"pinch\", \"pincées\": \"pinch\",\n    \"prise\": \"pinch\", \"prisen\": \"pinch\",\n    \"dash\": \"dash\", \"dashes\": \"dash\",\n    \"goutte\": \"drop\", \"gouttes\": \"drop\",\n    \"tropfen\": \"drop\", \"tropf\": \"drop\",\n}\n\nFor simplicity we assume that volumes can be converted to grams, regardless of food type. In most cases this leads to an upper bound, as water often has the highest density of all food types. As a result, we would just buy too much food.\n\nVOLUME_EQUIVALENTS = {\"cup\": 240, \"tbsp\": 15, \"tsp\": 5, \"ml\": 1, \"l\": 1000}\nWEIGHT_EQUIVALENTS = {\"g\": 1, \"kg\": 1000}\n\ndef normalize_unit(raw_unit: str) -&gt; str:\n    raw_unit = raw_unit.lower().strip()\n    return UNIT_MAP.get(raw_unit, raw_unit)\n\ndef convert_to_base(qty: float, unit: str):\n    if unit in VOLUME_EQUIVALENTS:\n        return qty * VOLUME_EQUIVALENTS[unit], \"ml\"\n    if unit in WEIGHT_EQUIVALENTS:\n        return qty * WEIGHT_EQUIVALENTS[unit], \"g\"\n    return qty, unit\n\nNext comes the actual regex function. It searches for number and units. The remainder is assumed to be the ingredient. An Edge case is unitless quantities like 4 apples. We catch this with a comparison to the units in the UNIT_MAP.\n\nimport re\nfrom rapidfuzz.distance import JaroWinkler\ndef parse_item(text: str):\n    text = text.strip()\n    # Match multiple number + unit combos, e.g. \"1l 200g\", \"2 Tassen Zucker\"\n    matches = re.findall(r'(\\d+(?:[.,]\\d+)?|\\½|\\¼|\\¾)\\s*([a-zA-ZÀ-ÿ]+)', text)\n    remainder = re.sub(r'^((\\d+(?:[.,]\\d+)?|\\½|\\¼|\\¾)\\s*[a-zA-ZÀ-ÿ]+\\s*)+', '', text).strip().lower()\n\n    if not matches:\n        return [(1.0, None, remainder)]\n    result = []\n    for qty_str, unit_str in matches:\n        qty = (\n            0.5 if qty_str == \"½\"\n            else 0.25 if qty_str == \"¼\"\n            else 0.75 if qty_str == \"¾\"\n            else float(qty_str.replace(',', '.'))\n        )\n        raw = unit_str.lower().strip()\n        norm_unit = normalize_unit(raw)\n        if norm_unit in UNIT_MAP.values():\n            result.append((qty, norm_unit, remainder))\n        else:\n            result.append((qty, None, f\"{unit_str.lower()} {remainder}\".strip()))\n    return result\n\n\nparse_item('4 apples')\n\n[(4.0, None, 'apples')]\n\n\n\nparse_item(\"100g chocolate\")\n\n[(100.0, 'g', 'chocolate')]\n\n\nLet’s do it for one test case:\n\ntest_cases[3][\"input\"]\n\n['1000g sugar', '1kg Zucker', '1kg sucre', '1 EL Zucker']\n\n\n\ndef parse_items_list(texts):\n    results = []\n    for text in texts:\n        parsed = parse_item(text)\n        results.extend(parsed)\n    return results\n\n\nconverted= parse_items_list(test_cases[3][\"input\"]);converted\n\n[(1000.0, 'g', 'sugar'),\n (1.0, 'kg', 'zucker'),\n (1.0, 'kg', 'sucre'),\n (1.0, 'tbsp', 'zucker')]\n\n\nSoo sweet, it works!\n\n\n2.2 Embeddings for clustering: putting together, what belongs together\nThe next phase is the identification of similar concepts. For this we use an embedding model.\nThe hardest part consists in finding an embedding model that works well with our data. Ingredients can be multilingual and their length can range from one short word to several words.\nA simple one word model would be a simple dictionary. As we have longer phrases, we need a sentence model.\nOne such model is paraphrase-multilingual-MiniLM-L12-v2.\n\nfrom sentence_transformers import SentenceTransformer, util\nmodel_emb = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n\nSimilar embeddings are frequently identified using cosine similarity.\n\ndef is_same_concept(a: str, b: str, model, threshold=0.8) -&gt; bool:\n    emb_a = model.encode(a, normalize_embeddings=True)\n    emb_b = model.encode(b, normalize_embeddings=True)\n    sim = util.cos_sim(emb_a, emb_b).item()\n    return sim &gt;= threshold\n\nThis is pairwise comparison and we need to transform our list.\n\nfrom itertools import combinations\n\nnames = [t[2] for t in converted]\n\npairs = list({tuple(sorted(p)) for p in combinations(names, 2)})\npairs\n\n[('sucre', 'sugar'),\n ('zucker', 'zucker'),\n ('sucre', 'zucker'),\n ('sugar', 'zucker')]\n\n\n\nfor a, b in pairs:\n    print(is_same_concept(a,b, model_emb))\n\nTrue\nTrue\nTrue\nTrue\n\n\nVoila.\nBut what we are actually interested in is the number of similar concepts and which item belongs to which concept.\nTo do this we use a similarity matrix. And then search for clusters in the matrix.\n\ndef cluster_same_concept(names, model, threshold=0.8):\n    # Encode all names\n    embeddings = model.encode(names, normalize_embeddings=True)\n    n = len(names)\n    sim_matrix = util.cos_sim(embeddings, embeddings).numpy()\n\n    cluster_id = [-1] * n\n    current_id = 0\n\n    for i in range(n):\n        if cluster_id[i] != -1:\n            continue  # already assigned\n        cluster_id[i] = current_id\n        for j in range(i + 1, n):\n            if sim_matrix[i, j] &gt;= threshold:\n                cluster_id[j] = current_id\n        current_id += 1\n\n    # map each name to its assigned cluster id\n    return {names[i]: cluster_id[i] for i in range(n)}\n\nLet’s look at a longer list.\n\nnames = [\"sugar\", \"zucker\", \"sucre\", \"milk\", \"Milch\", \"lait\", \"bread\"]\nfor n, cid in cluster_same_concept(names, model_emb, threshold=0.8).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  1\nMilch →  2\nlait →  1\nbread →  3\n\n\nNot too bad. But Milch was identified as its own category, instead of adding it to milk.\nThe issue is that single words provide little information for cosine similarity of tokens.\nThere are four things we could do. First, lower the threshold and risk grouping unrelated concepts, second, we could use a better clustering algo, third contextualize, and fourth use fuzzy matching for small words.\n\n2.2.1 Approach 1: lowering the threshold\nLet’s start with approach 1.\n\nfor n, cid in cluster_same_concept(names, model_emb, threshold=0.65).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  1\nMilch →  1\nlait →  1\nbread →  2\n\n\nThat one worked, but I had to lower the threshold to 0.65, which makes the algo brittle.\n\n\n2.2.2 Approach 2: transitive clustering\nInside our similarity matrix we only do pair wise clustering. If milk is only partly similar to Milch and Milch and lait are more similar, the current algo does not cluster everything if lait and milk are similar.\nWhat we need is transitive clustering. One way to do this is via a connected component clustering.\n\ndef cluster_same_concept_transitive(names, model, threshold=0.8):\n    embeddings = model.encode(names, normalize_embeddings=True)\n    sim_matrix = util.cos_sim(embeddings, embeddings).numpy()\n    n = len(names)\n\n    adjacency = sim_matrix &gt;= threshold\n\n    visited = [False] * n\n    clusters = [-1] * n\n    cluster_id = 0\n\n    def dfs(i, cid):\n        visited[i] = True\n        clusters[i] = cid\n        for j in range(n):\n            if adjacency[i, j] and not visited[j]:\n                dfs(j, cid)\n\n    for i in range(n):\n        if not visited[i]:\n            dfs(i, cluster_id)\n            cluster_id += 1\n\n    return {names[i]: clusters[i] for i in range(n)}\n\n\nfor n, cid in cluster_same_concept_transitive(names, model_emb, threshold=0.71).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  1\nMilch →  1\nlait →  1\nbread →  2\n\n\nNow, the threshold only needs to be lowered to 0.71.\n\n\n2.2.3 Approach 3: contextualization\nThe third approach, contextualise, is rooted in the ways the embeddings were created. Multilingual embeddings are most often trained from sentences; not dictionary expressions like humans learn them for translation tasks. We can add a static expression to put all expressions in the same corner of the embedding space. By forcing a static expression of the input, we make the similarity expression less sensitive to milk vs. Milch.\n\ndef contextualize(name):\n    return f\" this is a food ingredient called {name}\"\n\n\ndef cluster_same_concept_transitive_context(names, model, threshold=0.8):\n    embeddings = model.encode([contextualize(n) for n in names], normalize_embeddings=True)\n\n    sim_matrix = util.cos_sim(embeddings, embeddings).numpy()\n    n = len(names)\n\n    adjacency = sim_matrix &gt;= threshold\n\n    visited = [False] * n\n    clusters = [-1] * n\n    cluster_id = 0\n\n    def dfs(i, cid):\n        visited[i] = True\n        clusters[i] = cid\n        for j in range(n):\n            if adjacency[i, j] and not visited[j]:\n                dfs(j, cid)\n\n    for i in range(n):\n        if not visited[i]:\n            dfs(i, cluster_id)\n            cluster_id += 1\n\n    return {names[i]: clusters[i] for i in range(n)}\n\n\nfor n, cid in cluster_same_concept_transitive_context(names, model_emb, threshold=0.74).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  1\nMilch →  2\nlait →  2\nbread →  0\n\n\n\nfor n, cid in cluster_same_concept_transitive_context(names, model_emb, threshold=0.73).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  0\nMilch →  0\nlait →  0\nbread →  0\n\n\nOops. That did not work as expected. We go from bad to worse. #### Second Example: don’t spoil the milk Let’s try another datapoint.\n\nconverted= parse_items_list(test_cases[2][\"input\"])\nnames = [t[2] for t in converted]\nnames\n\n['hot milk', 'warme milch', 'lait chaud']\n\n\n\nfor n, cid in cluster_same_concept(names, model_emb, threshold=0.96).items():\n    print(f\"{n} → {cid:2d}\")\n\nhot milk →  0\nwarme milch →  0\nlait chaud →  0\n\n\n\nfor n, cid in cluster_same_concept_transitive(names, model_emb, threshold=0.98).items():\n    print(f\"{n} → {cid:2d}\")\n\nhot milk →  0\nwarme milch →  0\nlait chaud →  0\n\n\n\nfor n, cid in cluster_same_concept_transitive_context(names, model_emb, threshold=0.70).items():\n    print(f\"{n} → {cid:2d}\")\n\nhot milk →  0\nwarme milch →  0\nlait chaud →  0\n\n\n\n\n2.2.4 Approach 4: dealing with one word ingredients via fuzzy matching\nOne-word ingredients are a bit tricky. They can lead to only one token in the sentence. Embeddings are not able to capture the meaning of a single word and are not robust against spelling mistakes\nFuzzy matching might work better. We compare strings directly and count distances or number of permutations to turn one in the other.Levenshtein distance and Jaro Winkler are two such metrics. Without diving too deep: on small words with a similar prefix (milk & Milch), jaro winkler can lead to better results.\n\nimport numpy as np\n\ndef cluster_same_concept_transitive_winkler(names, model, threshold=0.8, jaro_thresh=0.8):\n    embeddings = model.encode(names, normalize_embeddings=True)\n    sim_matrix = util.cos_sim(embeddings, embeddings).numpy()\n    n = len(names)\n\n    adjacency = np.zeros((n, n), dtype=bool)\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                adjacency[i, j] = True\n                continue\n            # Embedding similarity\n            if sim_matrix[i, j] &gt;= threshold:\n                adjacency[i, j] = True\n                continue\n            # Jaro–Winkler fallback\n            jw = JaroWinkler.similarity(names[i].lower(), names[j].lower())\n            if jw &gt;= jaro_thresh:\n                adjacency[i, j] = True\n\n    visited = [False] * n\n    clusters = [-1] * n\n    cluster_id = 0\n\n    def dfs(i, cid):\n        visited[i] = True\n        clusters[i] = cid\n        for j in range(n):\n            if adjacency[i, j] and not visited[j]:\n                dfs(j, cid)\n\n    for i in range(n):\n        if not visited[i]:\n            dfs(i, cluster_id)\n            cluster_id += 1\n\n    return {names[i]: clusters[i] for i in range(n)}\n\n\nnames = [\"sugar\", \"zucker\", \"sucre\", \"milk\", \"Milch\", \"lait\", \"bread\"]\nfor n, cid in cluster_same_concept_transitive_winkler(names, model_emb, threshold=0.90, jaro_thresh=0.84).items():\n    print(f\"{n} → {cid:2d}\")\n\nsugar →  0\nzucker →  0\nsucre →  0\nmilk →  1\nMilch →  1\nlait →  1\nbread →  2\n\n\nThat helped quite a lot. Before we only had 0.71.\n\n\n\n2.3 Normalization of quantities and merging\nNow we have quantities, units and now which items belong together. We need two helpers to combine all this. One to get the Labels of each cluster. And the second to aggregate across units. In this second function we use the convert_to_base function we define earlier and which allows us adding g to ml.\n\nfrom collections import defaultdict\n\ndef get_cluster_labels(clusters):\n    \"\"\"Invert {name -&gt; cid} into {cid -&gt; representative name}.\"\"\"\n    groups = defaultdict(list)\n    for name, cid in clusters.items():\n        groups[cid].append(name)\n    return {cid: names[0] for cid, names in groups.items()}\n\nVOLUME_UNITS = {\"l\", \"ml\", \"cup\", \"tbsp\", \"tsp\"}\nWEIGHT_UNITS = {\"kg\", \"g\"}\n\ndef unify_units_1to1(qty, unit):\n    \"\"\"Normalize all weight units to grams and volume units to milliliters.\"\"\"\n    if isinstance(unit, str):\n        unit_str = unit.strip().lower()\n    else:\n        unit_str = getattr(unit, \"name\", None) or getattr(unit, \"unit\", None) or str(unit)\n        unit_str = unit_str.strip().lower()\n\n    unit_str = UNIT_MAP.get(unit_str, unit_str)\n\n    # Handle weights\n    if unit_str in WEIGHT_UNITS:\n        qty, base = convert_to_base(qty, unit_str)\n        return qty, \"g\"\n\n    # Handle volumes\n    elif unit_str in VOLUME_UNITS:\n        qty, base = convert_to_base(qty, unit_str)\n        return qty, \"ml\"\n\n    # Unknown or nonstandard unit\n    else:\n        return qty, unit_str or \"\"\n\nNow comes the final aggregation logic. I added the final version here, which has an if block as we will later reuse this function, with a different input.\n\n\ndef aggregate_by_concept(items, clusters):\n    totals = defaultdict(float)\n    labels = get_cluster_labels(clusters)\n\n    for item in items:\n        if isinstance(item, dict):\n            qty = item.get(\"quantity\", 1.0)\n            unit = item.get(\"unit\", \"\")\n            name = item.get(\"name\", \"\").lower()\n        else:\n            qty, unit, name = item\n            name = name.lower()\n        cid = clusters.get(name)\n        q, base = unify_units_1to1(qty, unit)\n        totals[(cid, base)] += q\n\n    return  [(round(q, 3), u, labels.get(cid, str(cid))) for (cid, u), q in totals.items()]\n\n\nconverted= parse_items_list(test_cases[3][\"input\"])\nnames = [t[2] for t in converted]\nclusters = cluster_same_concept_transitive(names, model_emb)\nmerged = aggregate_by_concept(converted, clusters); merged\n\n[(3015.0, 'g', 'sugar')]\n\n\nThat is the result we want. Let’s polish it a little.\n\ndef format_aggregate(aggregated):\n    formatted = []\n    for qty, unit, cid in aggregated:\n        if unit == \"ml\" and qty &gt;= 1000:\n            qty /= 1000\n            unit = \"l\"\n        elif unit == \"g\" and qty &gt;= 1000:\n            qty /= 1000\n            unit = \"kg\"\n        elif unit == \"none\":\n            unit = \"\"\n        formatted.append(f\"{qty:g} {unit} {cid}\")\n    return formatted\nformat_aggregate(merged)\n\n['3.015 kg sugar']\n\n\n\n\n2.4 Test case evaluation\nNow comes the moment of truth. We define our test function.\n\ndef convert(ing_list, model):\n    converted= parse_items_list(ing_list)\n    names = [t[2] for t in converted]\n    clusters = cluster_same_concept_transitive_winkler(names, model, jaro_thresh=0.65, threshold=0.60)\n    merged = aggregate_by_concept(converted, clusters)\n    out = format_aggregate(merged)\n    return out\n\n\nfor case in test_cases:\n    print(case[\"expected\"],convert(case[\"input\"], model_emb))\n\n['3l milk'] ['3kg milk']\n['3l milk'] ['3kg whole milk']\n['3l milk'] ['3kg hot milk']\n['3kg sugar'] ['3.015kg sugar']\n['1kg brown sugar', '1kg white sugar'] ['3kg brown sugar']\n['4 eggs'] ['3 eggs', '1 ei']\n['3 bread'] ['2 baguette', '1 brot']\n['2 bottles of water', '1 bottle of wine'] ['3 bottle of water']\n['3l Oatly Milk'] ['3kg oatly milk']\n['1.5kg rice'] ['1.5kg rice']\n['3 onions'] ['2 onion', '1 zwiebel']\n['3 bell peppers'] ['1 bell pepper', '1 capsicum', '1 poivron']\n['3 red pepper flakes'] ['2 red pepper flakes', '1 piment concassé']\n['3 tbsp butter'] ['45g butter']\n['3 tsp salt'] ['25g salt']\n['3 cans crushed tomatoes'] ['3 can crushed tomatoes']\n['3 cups yogurt'] ['720g yogurt']\n['3 tbsp olive oil'] ['45g olive oil']\n['2 bread', '1 croissant'] ['1 croissant', '1 pain', '1 bread']\n['300g cheese'] ['200g cheese', '100g käse']\n['3kg flour'] ['2kg flour', '1kg mehl']\n\n\nAgain, I had to lower the thresholds quite dramatically to get some sensible outputs.\nAs we can see, this process is far from perfect. Luckily for us, we are not the first computer scientists who are going food shopping."
  },
  {
    "objectID": "posts/projects/recipescanner/smart_shopping_list.html#using-third-party-libraries",
    "href": "posts/projects/recipescanner/smart_shopping_list.html#using-third-party-libraries",
    "title": "Can AI fix your shopping list?",
    "section": "3 Using third party libraries",
    "text": "3 Using third party libraries\n\n3.1 Intro\nThere are many other projects which deal with shopping lists and ingredients. Ingredient Parser sticks out as it already uses a data-driven approach trained on ingredient data.\nI was thinking about this myself, but then discovered this project. Assembling a dataset is a lot of work cudos to the author. We will use this parser.\nAnother approach, which I discovered in Meallie is the use of an LLM with a Prompt. In my opinion, that becomes quite costly. For a self-hosted version with a few recipes, this might be ok, for a hosted version that will turn out to be expensive. Mealie uses a confidence logic similar to the threshold approach we used with embeddings and the Jaro Winkler.\n\n\n3.2 Need for translations\n\n3.2.1 Architecture\nIf we are going to rely on ingredient parser, there is one further issue. The model was trained using English words. Any non-English word will lead to less good results.\nAs now everything is in English, we need to back-translate to the target language. That has the advantage that we can have different input languages.\nwe will have the following pipeline:\n\n\n\n\n\nflowchart TD\n    A[Raw input] --&gt; B[Translate to English]\n    B --&gt; C[Ingredient Parser]\n    C --&gt; D[Embedding Model]\n    D --&gt; E[Aggregation]\n    E --&gt; F[Translate Output Back for UI]\n\n\n\n\n\n\n\n\n3.2.2 Finding a good model\nWe need a multilanguage model. My intention is to use client side translation to reduce the server load. One such model is MarianMT based Helsinki-NLP models. They are small (300MB) and fast. The downside is that they require knowing the source language. We need to use langdetect to detect the language. Side note: that is actually how the recipe on device android app started back in 2020.\n\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom langdetect import detect\n\nMODELS = {\n    'fr': 'Helsinki-NLP/opus-mt-fr-en',\n    'de': 'Helsinki-NLP/opus-mt-de-en'\n}\n\ncache = {}\n\ndef translate_to_english_helsinki_with_langdetect(text):\n    lang = detect(text)\n    if lang not in MODELS:\n        return text, lang\n    if lang not in cache:\n        name = MODELS[lang]\n        cache[lang] = (\n            MarianTokenizer.from_pretrained(name),\n            MarianMTModel.from_pretrained(name)\n        )\n    tok, mod = cache[lang]\n    inputs = tok(text, return_tensors=\"pt\")\n    outputs = mod.generate(**inputs)\n    return tok.decode(outputs[0], skip_special_tokens=True), lang\n\n\ntranslated_all = []\nfor i, case in enumerate(test_cases, start=1):\n    print(f\"\\n=== Test case {i} ===\")\n\n    translated, lang = zip(*(translate_to_english_helsinki_with_langdetect(x) for x in case[\"input\"]))\n    translated_all.append({\"input\":translated})\n    for orig, trans, la in zip(case[\"input\"], translated, lang):\n        print(f\"{orig:&lt;30} → {trans}; lang: {la}\")\n\n\n=== Test case 1 ===\n1l milk                        → 1l milk; lang: et\n1l lait                        → 1L milk; lang: fr\n1l Milch                       → 1l Milch; lang: it\n\n=== Test case 2 ===\n1l whole milk                  → 1l whole milk; lang: en\n1l lait entier                 → 1l whole milk; lang: fr\n1l Vollmilch                   → 1l Vollmilch; lang: it\n\n=== Test case 3 ===\n1l hot milk                    → 1l hot milk; lang: et\n1l warme Milch                 → 1l warme Milch; lang: en\n1l lait chaud                  → 1l hot milk; lang: fr\n\n=== Test case 4 ===\n1000g sugar                    → 1000g sugar; lang: tl\n1kg Zucker                     → 1kg of sugar; lang: de\n1kg sucre                      → 1kg sucre; lang: en\n1 EL Zucker                    → 1 tbsp sugar; lang: de\n\n=== Test case 5 ===\n1kg brown sugar                → 1kg brown sugar; lang: en\n1kg sucre blanc                → 1kg sucre blanc; lang: en\n1kg weißer Zucker              → 1 kg of white sugar; lang: de\n\n=== Test case 6 ===\n2 eggs                         → 2 eggs; lang: no\n1 œuf                          → 1 egg; lang: fr\n1 Ei                           → 1 egg; lang: de\n\n=== Test case 7 ===\n1 baguette                     → 1 baguette; lang: no\n1 bread                        → 1 bread; lang: pt\n1 Brot                         → 1 Brot; lang: en\n\n=== Test case 8 ===\n1 bottle of water              → 1 bottle of water; lang: en\n1 bouteille de vin             → 1 bottle of wine; lang: fr\n1 Flasche Wasser               → 1 bottle of water; lang: de\n\n=== Test case 9 ===\n1l Oatly milk                  → 1l Oatly milk; lang: hu\n1l lait Oatly                  → 1l Oatly milk; lang: fr\n1l Oatly Milch                 → 1l Oatly Milch; lang: en\n\n=== Test case 10 ===\n½kg rice                       → ½kg rice; lang: en\n500g Reis                      → 500g rice; lang: de\n500g riz                       → 500g riz; lang: hr\n\n=== Test case 11 ===\n1 onion                        → 1 onion; lang: en\n1 oignon                       → 1 oignon; lang: it\n1 Zwiebel                      → 1 onion; lang: de\n\n=== Test case 12 ===\n1 bell pepper                  → 1 bell pepper; lang: sv\n1 capsicum                     → 1 capsicum; lang: ro\n1 poivron                      → 1 poivron; lang: sl\n\n=== Test case 13 ===\n1 red pepper flakes            → 1 red pepper flakes; lang: no\n1 chili flakes                 → 1 chili flakes; lang: sw\n1 piment concassé              → 1 piment concassé; lang: ca\n\n=== Test case 14 ===\n1 tbsp butter                  → 1 tbsp butter; lang: no\n1 cuillère de beurre           → 1 spoon of butter; lang: fr\n1 EL Butter                    → 1 tbsp butter; lang: de\n\n=== Test case 15 ===\n1 tsp salt                     → 1 tsp salt; lang: fi\n1 TL Salz                      → 1 TL salt; lang: de\n1 cuillère à café de sel       → 1 teaspoon of salt; lang: fr\n\n=== Test case 16 ===\n1 can crushed tomatoes         → 1 can crushed tomatoes; lang: en\n1 boîte de tomates concassées  → 1 can of crushed tomatoes; lang: fr\n1 Dose Tomatenstücke           → 1 can of tomato pieces; lang: de\n\n=== Test case 17 ===\n1 cup yogurt                   → 1 cup yogurt; lang: ro\n1 tasse de yaourt              → 1 cup of yogurt; lang: fr\n1 Becher Joghurt               → 1 cup of yoghurt; lang: de\n\n=== Test case 18 ===\n1 tbsp olive oil               → 1 tbsp olive oil; lang: fi\n1 EL Olivenöl                  → 1 EL Olivenöl; lang: sv\n1 cuillère à soupe d'huile d'olive → 1 tablespoon of olive oil; lang: fr\n\n=== Test case 19 ===\n1 croissant                    → 1 increasing; lang: fr\n1 pain                         → 1 pain; lang: fi\n1 bread                        → 1 bread; lang: es\n\n=== Test case 20 ===\n100g cheese                    → 100g cheese; lang: nl\n100g fromage                   → 100g fromage; lang: da\n100g Käse                      → 100g Käse; lang: sv\n\n=== Test case 21 ===\n1kg flour                      → 1kg flour; lang: da\n1000g Mehl                     → 1000g flour; lang: de\n1kg farine                     → 1kg farine; lang: no\n\n\nLangdetect fails to detect the language quite frequently, and we cannot translate. We should definitely normalize the numeric parts by splitting them from the letters.\n\ndef normalize_qty(text):\n    # add space between digits and letters (1l → 1 l)\n    text = re.sub(r\"(\\d)([a-zA-Z])\", r\"\\1 \\2\", text)\n    return text.strip()\n\n\ntranslated_all = []\nfor i, case in enumerate(test_cases, start=1):\n    print(f\"\\n=== Test case {i} ===\")\n\n    translated, lang = zip(*(translate_to_english_helsinki_with_langdetect(normalize_qty(x)) for x in case[\"input\"]))\n    translated_all.append({\"input\":translated})\n    for orig, trans, la in zip(case[\"input\"], translated, lang):\n        print(f\"{orig:&lt;30} → {trans}; lang: {la}\")\n\n\n=== Test case 1 ===\n1l milk                        → 1 l milk; lang: et\n1l lait                        → 1 l milk; lang: fr\n1l Milch                       → 1 l Milch; lang: it\n\n=== Test case 2 ===\n1l whole milk                  → 1 l whole milk; lang: en\n1l lait entier                 → 1 l whole milk; lang: fr\n1l Vollmilch                   → 1 l Vollmilch; lang: it\n\n=== Test case 3 ===\n1l hot milk                    → 1 l hot milk; lang: et\n1l warme Milch                 → 1 l warme Milch; lang: en\n1l lait chaud                  → 1 l hot milk; lang: fr\n\n=== Test case 4 ===\n1000g sugar                    → 1000 g sugar; lang: tl\n1kg Zucker                     → 1 kg sugar; lang: de\n1kg sucre                      → 1 kg sucre; lang: en\n1 EL Zucker                    → 1 tbsp sugar; lang: de\n\n=== Test case 5 ===\n1kg brown sugar                → 1 kg brown sugar; lang: en\n1kg sucre blanc                → 1 kg sucre blanc; lang: en\n1kg weißer Zucker              → 1 kg of white sugar; lang: de\n\n=== Test case 6 ===\n2 eggs                         → 2 eggs; lang: no\n1 œuf                          → 1 egg; lang: fr\n1 Ei                           → 1 egg; lang: de\n\n=== Test case 7 ===\n1 baguette                     → 1 baguette; lang: no\n1 bread                        → 1 bread; lang: es\n1 Brot                         → 1 Brot; lang: en\n\n=== Test case 8 ===\n1 bottle of water              → 1 bottle of water; lang: en\n1 bouteille de vin             → 1 bottle of wine; lang: fr\n1 Flasche Wasser               → 1 bottle of water; lang: de\n\n=== Test case 9 ===\n1l Oatly milk                  → 1 l Oatly milk; lang: hu\n1l lait Oatly                  → 1 l Oatly milk; lang: fr\n1l Oatly Milch                 → 1 l Oatly Milch; lang: en\n\n=== Test case 10 ===\n½kg rice                       → ½kg rice; lang: en\n500g Reis                      → 500 g rice; lang: de\n500g riz                       → 500 g riz; lang: hr\n\n=== Test case 11 ===\n1 onion                        → 1 onion; lang: en\n1 oignon                       → 1 oignon; lang: it\n1 Zwiebel                      → 1 onion; lang: de\n\n=== Test case 12 ===\n1 bell pepper                  → 1 bell pepper; lang: sv\n1 capsicum                     → 1 capsicum; lang: ro\n1 poivron                      → 1 poivron; lang: sl\n\n=== Test case 13 ===\n1 red pepper flakes            → 1 red pepper flakes; lang: no\n1 chili flakes                 → 1 chili flakes; lang: sw\n1 piment concassé              → 1 piment concassé; lang: ca\n\n=== Test case 14 ===\n1 tbsp butter                  → 1 tbsp butter; lang: en\n1 cuillère de beurre           → 1 spoon of butter; lang: fr\n1 EL Butter                    → 1 EL Butter; lang: no\n\n=== Test case 15 ===\n1 tsp salt                     → 1 tsp salt; lang: lv\n1 TL Salz                      → 1 TL salt; lang: de\n1 cuillère à café de sel       → 1 teaspoon of salt; lang: fr\n\n=== Test case 16 ===\n1 can crushed tomatoes         → 1 can crushed tomatoes; lang: en\n1 boîte de tomates concassées  → 1 can of crushed tomatoes; lang: fr\n1 Dose Tomatenstücke           → 1 can of tomato pieces; lang: de\n\n=== Test case 17 ===\n1 cup yogurt                   → 1 cup yogurt; lang: ro\n1 tasse de yaourt              → 1 cup of yogurt; lang: fr\n1 Becher Joghurt               → 1 cup of yoghurt; lang: de\n\n=== Test case 18 ===\n1 tbsp olive oil               → 1 tbsp olive oil; lang: fi\n1 EL Olivenöl                  → 1 EL Olivenöl; lang: sv\n1 cuillère à soupe d'huile d'olive → 1 tablespoon of olive oil; lang: fr\n\n=== Test case 19 ===\n1 croissant                    → 1 increasing; lang: fr\n1 pain                         → 1 pain; lang: fi\n1 bread                        → 1 bread; lang: pt\n\n=== Test case 20 ===\n100g cheese                    → 100 g cheese; lang: nl\n100g fromage                   → 100 g fromage; lang: da\n100g Käse                      → 100 g Käse; lang: sv\n\n=== Test case 21 ===\n1kg flour                      → 1 kg flour; lang: da\n1000g Mehl                     → 1000 g flour; lang: de\n1kg farine                     → 1 kg farine; lang: no\n\n\nNot much better.\nThen, there is a Helsinki-NLP allrounder model, which knows many languages at the expense of accuracy.\n\nimport functools\n\nMODEL_NAME = \"Helsinki-NLP/opus-mt-mul-en\"\n\n# Lazy-load for reuse\n@functools.lru_cache(maxsize=1)\ndef get_multilingual_translator():\n    tokenizer = MarianTokenizer.from_pretrained(MODEL_NAME)\n    model = MarianMTModel.from_pretrained(MODEL_NAME)\n    return tokenizer, model\n\n\ndef translate_to_english_helsinki(text: str) -&gt; str:\n    text = text.strip()\n    if not text:\n        return text\n\n    tok, mod = get_multilingual_translator()\n\n    batch = tok([text], return_tensors=\"pt\", truncation=True)\n    gen = mod.generate(**batch, max_new_tokens=64)\n    result = tok.decode(gen[0], skip_special_tokens=True)\n\n    return result.strip()\n\n\ntranslated_all = []\nfor i, case in enumerate(test_cases, start=1):\n    print(f\"\\n=== Test case {i} ===\")\n\n    translated = [translate_to_english_helsinki(x) for x in case[\"input\"]]\n    translated_all.append({\"input\":translated})\n    for orig, trans in zip(case[\"input\"], translated):\n        print(f\"{orig:&lt;30} → {trans}\")\n\n\n=== Test case 1 ===\n1l milk                        → 1l milk\n1l lait                        → 1 l\n1l Milch                       → 1l Milk\n\n=== Test case 2 ===\n1l whole milk                  → 1l whole milk\n1l lait entier                 → 1l leaves all\n1l Vollmilch                   → 1l Full milk\n\n=== Test case 3 ===\n1l hot milk                    → 1l hot milk\n1l warme Milch                 → 1l hot milk\n1l lait chaud                  → 1 L to the left\n\n=== Test case 4 ===\n1000g sugar                    → 1000g sugar\n1kg Zucker                     → 1kg Sugar\n1kg sucre                      → 1kg sugar\n1 EL Zucker                    → 1 EL Sugar\n\n=== Test case 5 ===\n1kg brown sugar                → 1kg brown sugar\n1kg sucre blanc                → 1kg white sugar\n1kg weißer Zucker              → 1kg white sugar\n\n=== Test case 6 ===\n2 eggs                         → 2 eggs\n1 œuf                          → 1 egg\n1 Ei                           → 1 Yes\n\n=== Test case 7 ===\n1 baguette                     → 1 baguette\n1 bread                        → 1 board\n1 Brot                         → 1 Brot\n\n=== Test case 8 ===\n1 bottle of water              → 1 bottle of water\n1 bouteille de vin             → 1 bottle of wine\n1 Flasche Wasser               → 1 bottle of water\n\n=== Test case 9 ===\n1l Oatly milk                  → 1l Oatly milk\n1l lait Oatly                  → 1l Leave Oatly\n1l Oatly Milch                 → 1l Oatly Milk\n\n=== Test case 10 ===\n½kg rice                       → 1⁄2kg of rice\n500g Reis                      → 500g Reis\n500g riz                       → 500g rice\n\n=== Test case 11 ===\n1 onion                        → 1 onion\n1 oignon                       → 1 firenon\n1 Zwiebel                      → 1 Double\n\n=== Test case 12 ===\n1 bell pepper                  → 1 bell pepper\n1 capsicum                     → 1 capsicum\n1 poivron                      → 1 piovirone\n\n=== Test case 13 ===\n1 red pepper flakes            → 1 red pepper flakes\n1 chili flakes                 → 1 Chilean flakes\n1 piment concassé              → 1 Pim Concazed\n\n=== Test case 14 ===\n1 tbsp butter                  → 1 tbsp Butter\n1 cuillère de beurre           → 1 glass of beer\n1 EL Butter                    → 1 EL Butter\n\n=== Test case 15 ===\n1 tsp salt                     → 1 tsp salt\n1 TL Salz                      → 1 TL Salz\n1 cuillère à café de sel       → 1 silver coffee cooker\n\n=== Test case 16 ===\n1 can crushed tomatoes         → 1 can cross-sectional tomatoes\n1 boîte de tomates concassées  → 1 box of sliced tomatoes\n1 Dose Tomatenstücke           → 1 Dose of Tomatoes\n\n=== Test case 17 ===\n1 cup yogurt                   → 1 cup yogurt\n1 tasse de yaourt              → 1 yourt rate\n1 Becher Joghurt               → 1 Becher Joghurt\n\n=== Test case 18 ===\n1 tbsp olive oil               → 1 tbsp of olive oil\n1 EL Olivenöl                  → 1 EU Olive oil\n1 cuillère à soupe d'huile d'olive → 1 olive oil soup cooler\n\n=== Test case 19 ===\n1 croissant                    → 1 significant place\n1 pain                         → 1 pen\n1 bread                        → 1 board\n\n=== Test case 20 ===\n100g cheese                    → 100g cheese\n100g fromage                   → 100g of cheese\n100g Käse                      → 100g Käse\n\n=== Test case 21 ===\n1kg flour                      → 1kg flower\n1000g Mehl                     → 1000g Mehl\n1kg farine                     → 1kg far\n\n\nMixed results.Sometimes it is better, but then it completely fails.\nThere would be bigger models to try Facebook’s m2m100 or NLLB. Besides being too big for a browser-based application, the common flaw in all those models, they require a source language. Facebook’s NLLB (No Language Left Behind). However, even the smallest distilled model is 2.4g.\nHowever, there is one thing we can do. There is Facebook’s Fasttext library, which works on subword embeddings (character n-grams). That could mean it works well on single words. We first need to get the weights of the model.\nSadly, the model relies on an old numpy version. I saw no other version than to patch the file directly.\n\nfrom os import path\nif not path.exists(\"lid.176.bin\"):\n    !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n\n\nimport os, fasttext, inspect\n\n# Locate FastText.py in your environment\nft_path = os.path.join(os.path.dirname(inspect.getfile(fasttext)), \"FastText.py\")\n\n# Read the file\nwith open(ft_path, \"r\", encoding=\"utf-8\") as f:\n    content = f.read()\n\n# Check if it's already patched\nif \"np.asarray(probs)\" not in content:\n    patched = content.replace(\"np.array(probs, copy=False)\", \"np.asarray(probs)\")\n    with open(ft_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(patched)\n    print(\"✅ Patched FastText.py — replaced np.array(..., copy=False) with np.asarray(...).\")\nelse:\n    print(\"✅ Already patched — no action needed.\")\n\n\nimport sys, gc, importlib\nmods = [m for m in sys.modules if m.startswith(\"fasttext\")]\nfor m in mods:\n    del sys.modules[m]\ngc.collect()\n\nimport fasttext\nimportlib.reload(fasttext)\nprint(\"fasttext reloaded with patched FastText.py\")\n\n✅ Already patched — no action needed.\nfasttext reloaded with patched FastText.py\n\n\n\nimport fasttext\n\n# Load pretrained language identification model\nmodel = fasttext.load_model(\"lid.176.bin\")\n\ndef detect_lang(text: str):\n    labels, probs = model.predict(text)\n    return labels[0].replace(\"__label__\", \"\"), float(probs[0])\n\nprint(detect_lang(\"lait\"))     # ('fr', 0.99)\nprint(detect_lang(\"Milch\"))    # ('de', 0.98)\nprint(detect_lang(\"egg\"))      # ('en', 0.99)\nprint(detect_lang(\"Zucker\"))   # ('de', 0.97)\n\n('fr', 0.9928548336029053)\n('de', 0.8860894441604614)\n('en', 0.5928217768669128)\n('de', 0.486892431974411)\n\n\nThat worked quite nicely. We can use it to replace langdetect.\n\ndef translate_to_english_helsinki_with_fastdetect(text, fastdetect_model=model):\n    labels, probs = fastdetect_model.predict(text)\n    lang = labels[0].replace(\"__label__\", \"\")\n    if lang not in MODELS or lang == 'en':\n        return text, lang\n    if lang not in cache:\n        name = MODELS[lang]\n        cache[lang] = (\n            MarianTokenizer.from_pretrained(name),\n            MarianMTModel.from_pretrained(name)\n        )\n    tok, mod = cache[lang]\n    inputs = tok(text, return_tensors=\"pt\")\n    outputs = mod.generate(**inputs)\n    return tok.decode(outputs[0], skip_special_tokens=True), lang\n\n\ntranslated_all = []\nfor i, case in enumerate(test_cases, start=1):\n    print(f\"\\n=== Test case {i} ===\")\n\n    translated, lang = zip(*(translate_to_english_helsinki_with_fastdetect(normalize_qty(x)) for x in case[\"input\"]))\n    translated_all.append({\"input\":translated})\n    for orig, trans, la in zip(case[\"input\"], translated, lang):\n        print(f\"{orig:&lt;30} → {trans}; lang: {la}\")\n\n\n=== Test case 1 ===\n1l milk                        → 1 l milk; lang: en\n1l lait                        → 1 l milk; lang: fr\n1l Milch                       → 1 l milk; lang: de\n\n=== Test case 2 ===\n1l whole milk                  → 1 l whole milk; lang: en\n1l lait entier                 → 1 l whole milk; lang: fr\n1l Vollmilch                   → 1 l whole milk; lang: de\n\n=== Test case 3 ===\n1l hot milk                    → 1 l hot milk; lang: en\n1l warme Milch                 → 1 l warm milk; lang: de\n1l lait chaud                  → 1 l hot milk; lang: fr\n\n=== Test case 4 ===\n1000g sugar                    → 1000 g sugar; lang: en\n1kg Zucker                     → 1 kg sugar; lang: de\n1kg sucre                      → 1 kg sugar; lang: fr\n1 EL Zucker                    → 1 tbsp sugar; lang: de\n\n=== Test case 5 ===\n1kg brown sugar                → 1 kg brown sugar; lang: en\n1kg sucre blanc                → 1 kg white sugar; lang: fr\n1kg weißer Zucker              → 1 kg of white sugar; lang: de\n\n=== Test case 6 ===\n2 eggs                         → 2 eggs; lang: en\n1 œuf                          → 1 egg; lang: fr\n1 Ei                           → 1 Ei; lang: pt\n\n=== Test case 7 ===\n1 baguette                     → 1 wand; lang: fr\n1 bread                        → 1 bread; lang: en\n1 Brot                         → 1 bread; lang: de\n\n=== Test case 8 ===\n1 bottle of water              → 1 bottle of water; lang: en\n1 bouteille de vin             → 1 bottle of wine; lang: fr\n1 Flasche Wasser               → 1 bottle of water; lang: de\n\n=== Test case 9 ===\n1l Oatly milk                  → 1 l Oatly milk; lang: en\n1l lait Oatly                  → 1 l Oatly milk; lang: fr\n1l Oatly Milch                 → 1 l Oatly Milch; lang: en\n\n=== Test case 10 ===\n½kg rice                       → ½kg rice; lang: en\n500g Reis                      → 500 g Reis; lang: en\n500g riz                       → 500 g riz; lang: es\n\n=== Test case 11 ===\n1 onion                        → 1 onion; lang: pl\n1 oignon                       → 1 oignon; lang: id\n1 Zwiebel                      → 1 onion; lang: de\n\n=== Test case 12 ===\n1 bell pepper                  → 1 bell pepper; lang: en\n1 capsicum                     → 1 capsicum; lang: la\n1 poivron                      → 1 poivron; lang: pt\n\n=== Test case 13 ===\n1 red pepper flakes            → 1 red pepper flakes; lang: en\n1 chili flakes                 → 1 chili flakes; lang: en\n1 piment concassé              → 1 crushed chilli; lang: fr\n\n=== Test case 14 ===\n1 tbsp butter                  → 1 tbsp butter; lang: en\n1 cuillère de beurre           → 1 spoon of butter; lang: fr\n1 EL Butter                    → 1 EL Butter; lang: en\n\n=== Test case 15 ===\n1 tsp salt                     → 1 tsp salt; lang: en\n1 TL Salz                      → 1 TL salt; lang: de\n1 cuillère à café de sel       → 1 teaspoon of salt; lang: fr\n\n=== Test case 16 ===\n1 can crushed tomatoes         → 1 can crushed tomatoes; lang: en\n1 boîte de tomates concassées  → 1 can of crushed tomatoes; lang: fr\n1 Dose Tomatenstücke           → 1 can of tomato pieces; lang: de\n\n=== Test case 17 ===\n1 cup yogurt                   → 1 cup yogurt; lang: en\n1 tasse de yaourt              → 1 cup of yogurt; lang: fr\n1 Becher Joghurt               → 1 Becher Joghurt; lang: en\n\n=== Test case 18 ===\n1 tbsp olive oil               → 1 tbsp olive oil; lang: en\n1 EL Olivenöl                  → 1 EL Olivenöl; lang: eo\n1 cuillère à soupe d'huile d'olive → 1 tablespoon of olive oil; lang: fr\n\n=== Test case 19 ===\n1 croissant                    → 1 increasing; lang: fr\n1 pain                         → 1 pain; lang: en\n1 bread                        → 1 bread; lang: en\n\n=== Test case 20 ===\n100g cheese                    → 100 g cheese; lang: en\n100g fromage                   → 100 g fromage; lang: en\n100g Käse                      → 100 g cheese; lang: de\n\n=== Test case 21 ===\n1kg flour                      → 1 kg flour; lang: en\n1000g Mehl                     → 1000 g flour; lang: de\n1kg farine                     → 1 kg farine; lang: en\n\n\nThat is a lot better, but we get misclassifications. If we know what language we expect we can map to the closest language.\n\n\ndef translate_to_english_helsinki_with_fastdetect_v2(text, fastdetect_model=model):\n    labels, probs = fastdetect_model.predict(text)\n    lang = labels[0].replace(\"__label__\", \"\")\n    if lang in ['pt', 'es','id']:\n        lang = 'fr'\n    if lang not in MODELS or lang == 'en':\n        return text, lang\n\n    if lang not in cache:\n        name = MODELS[lang]\n        cache[lang] = (\n            MarianTokenizer.from_pretrained(name),\n            MarianMTModel.from_pretrained(name)\n        )\n    tok, mod = cache[lang]\n    inputs = tok(text, return_tensors=\"pt\")\n    outputs = mod.generate(**inputs)\n    return tok.decode(outputs[0], skip_special_tokens=True), lang\n\n\ntranslated_all = []\n\n\nfor i, case in enumerate(test_cases, start=1):\n    print(f\"\\n=== Test case {i} ===\")\n\n\n    translated, lang = zip(*(translate_to_english_helsinki_with_fastdetect_v2(normalize_qty(x)) for x in case[\"input\"]))\n    translated_all.append({\"input\":translated})\n    for orig, trans, la in zip(case[\"input\"], translated, lang):\n        print(f\"{orig:&lt;30} → {trans}; lang: {la}\")\n\n\n=== Test case 1 ===\n1l milk                        → 1 l milk; lang: en\n1l lait                        → 1 l milk; lang: fr\n1l Milch                       → 1 l milk; lang: de\n\n=== Test case 2 ===\n1l whole milk                  → 1 l whole milk; lang: en\n1l lait entier                 → 1 l whole milk; lang: fr\n1l Vollmilch                   → 1 l whole milk; lang: de\n\n=== Test case 3 ===\n1l hot milk                    → 1 l hot milk; lang: en\n1l warme Milch                 → 1 l warm milk; lang: de\n1l lait chaud                  → 1 l hot milk; lang: fr\n\n=== Test case 4 ===\n1000g sugar                    → 1000 g sugar; lang: en\n1kg Zucker                     → 1 kg sugar; lang: de\n1kg sucre                      → 1 kg sugar; lang: fr\n1 EL Zucker                    → 1 tbsp sugar; lang: de\n\n=== Test case 5 ===\n1kg brown sugar                → 1 kg brown sugar; lang: en\n1kg sucre blanc                → 1 kg white sugar; lang: fr\n1kg weißer Zucker              → 1 kg of white sugar; lang: de\n\n=== Test case 6 ===\n2 eggs                         → 2 eggs; lang: en\n1 œuf                          → 1 egg; lang: fr\n1 Ei                           → 1 Ei; lang: fr\n\n=== Test case 7 ===\n1 baguette                     → 1 wand; lang: fr\n1 bread                        → 1 bread; lang: en\n1 Brot                         → 1 bread; lang: de\n\n=== Test case 8 ===\n1 bottle of water              → 1 bottle of water; lang: en\n1 bouteille de vin             → 1 bottle of wine; lang: fr\n1 Flasche Wasser               → 1 bottle of water; lang: de\n\n=== Test case 9 ===\n1l Oatly milk                  → 1 l Oatly milk; lang: en\n1l lait Oatly                  → 1 l Oatly milk; lang: fr\n1l Oatly Milch                 → 1 l Oatly Milch; lang: en\n\n=== Test case 10 ===\n½kg rice                       → ½kg rice; lang: en\n500g Reis                      → 500 g Reis; lang: en\n500g riz                       → 500 g rice; lang: fr\n\n=== Test case 11 ===\n1 onion                        → 1 onion; lang: pl\n1 oignon                       → 1 onion; lang: fr\n1 Zwiebel                      → 1 onion; lang: de\n\n=== Test case 12 ===\n1 bell pepper                  → 1 bell pepper; lang: en\n1 capsicum                     → 1 capsicum; lang: la\n1 poivron                      → 1 pepper; lang: fr\n\n=== Test case 13 ===\n1 red pepper flakes            → 1 red pepper flakes; lang: en\n1 chili flakes                 → 1 chili flakes; lang: en\n1 piment concassé              → 1 crushed chilli; lang: fr\n\n=== Test case 14 ===\n1 tbsp butter                  → 1 tbsp butter; lang: en\n1 cuillère de beurre           → 1 spoon of butter; lang: fr\n1 EL Butter                    → 1 EL Butter; lang: en\n\n=== Test case 15 ===\n1 tsp salt                     → 1 tsp salt; lang: en\n1 TL Salz                      → 1 TL salt; lang: de\n1 cuillère à café de sel       → 1 teaspoon of salt; lang: fr\n\n=== Test case 16 ===\n1 can crushed tomatoes         → 1 can crushed tomatoes; lang: en\n1 boîte de tomates concassées  → 1 can of crushed tomatoes; lang: fr\n1 Dose Tomatenstücke           → 1 can of tomato pieces; lang: de\n\n=== Test case 17 ===\n1 cup yogurt                   → 1 cup yogurt; lang: en\n1 tasse de yaourt              → 1 cup of yogurt; lang: fr\n1 Becher Joghurt               → 1 Becher Joghurt; lang: en\n\n=== Test case 18 ===\n1 tbsp olive oil               → 1 tbsp olive oil; lang: en\n1 EL Olivenöl                  → 1 EL Olivenöl; lang: eo\n1 cuillère à soupe d'huile d'olive → 1 tablespoon of olive oil; lang: fr\n\n=== Test case 19 ===\n1 croissant                    → 1 increasing; lang: fr\n1 pain                         → 1 pain; lang: en\n1 bread                        → 1 bread; lang: en\n\n=== Test case 20 ===\n100g cheese                    → 100 g cheese; lang: en\n100g fromage                   → 100 g fromage; lang: en\n100g Käse                      → 100 g cheese; lang: de\n\n=== Test case 21 ===\n1kg flour                      → 1 kg flour; lang: en\n1000g Mehl                     → 1000 g flour; lang: de\n1kg farine                     → 1 kg farine; lang: en\n\n\nThat looks quite good, though not 100% perfect.\n\n\n\n3.3 Ingredient parsing\nNow that everything is sort of in english, we can use the ingredient parser\n\nfrom ingredient_parser import parse_ingredient\n\ndef parse_ingredient_line(text: str):\n    \"\"\"\n    Parse an English ingredient line into structured (quantity, unit, name, note)\n    using the `ingredient-parser` package.\n    \"\"\"\n    parsed = parse_ingredient(text)\n\n    # Extract quantity\n    if parsed.amount and parsed.amount[0].quantity !=\"\":\n        # Supports ranges, fractions, etc.\n        qty = float(parsed.amount[0].quantity)\n        unit = parsed.amount[0].unit or \"\"\n    else:\n        qty, unit = 1.0, \"\"\n\n    # Extract main food name\n    name = parsed.name[0].text if parsed.name else \"\"\n\n    # Optional note (preparation, comment, etc.)\n    note = \"\"\n    if parsed.comment:\n        note = parsed.comment.text\n    elif parsed.preparation:\n        note = parsed.preparation.text\n    elif parsed.size:\n        note = parsed.size.text\n\n    return {\n        \"quantity\": qty,\n        \"unit\": unit,\n        \"name\": name,\n        \"note\": note\n    }\n\n\ntranslated_all[3][\"input\"]\n\n('1000 g sugar', '1 kg sugar', '1 kg sugar', '1 tbsp sugar')\n\n\n\n\nconverted = [parse_ingredient_line(item) for item in translated_all[3][\"input\"]]; converted\n\n[{'quantity': 1000.0, 'unit': &lt;Unit('gram')&gt;, 'name': 'sugar', 'note': ''},\n {'quantity': 1.0, 'unit': &lt;Unit('kilogram')&gt;, 'name': 'sugar', 'note': ''},\n {'quantity': 1.0, 'unit': &lt;Unit('kilogram')&gt;, 'name': 'sugar', 'note': ''},\n {'quantity': 1.0, 'unit': &lt;Unit('tablespoon')&gt;, 'name': 'sugar', 'note': ''}]\n\n\n\nnames = [t[\"name\"] for t in converted]; names\n\n['sugar', 'sugar', 'sugar', 'sugar']\n\n\n\n\n3.4 Clustering, aggregation & output\nThe next steps work the same way as before\n\nclusters = cluster_same_concept_transitive_winkler(names, model_emb);clusters\n\n{'sugar': 0}\n\n\n\nmerged = aggregate_by_concept(converted, clusters);merged\n\n[(3015.0, 'g', 'sugar')]\n\n\n\nout = format_aggregate(merged);out\n\n['3.015kg sugar']\n\n\n\n\n3.5 Backtranslation\nThe user will have his own native language; therefore, we need to translate back from English to that language. However, this time we know the languages, so we do not need fastdetect.\n\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Add the reverse models\nBACK_MODELS = {\n    'fr': 'Helsinki-NLP/opus-mt-en-fr',\n    'de': 'Helsinki-NLP/opus-mt-en-de'\n}\n\nback_cache = {}\n\ndef back_translate_from_english(text, target_lang):\n    \"\"\"\n    Translate English text back into the target language ('fr' or 'de')\n    using OPUS-MT.  Falls back to English if no model is defined.\n    \"\"\"\n    if target_lang not in BACK_MODELS or target_lang == \"en\":\n        return text\n\n    if target_lang not in back_cache:\n        model_name = BACK_MODELS[target_lang]\n        back_cache[target_lang] = (\n            MarianTokenizer.from_pretrained(model_name),\n            MarianMTModel.from_pretrained(model_name)\n        )\n\n    tok, mod = back_cache[target_lang]\n    inputs = tok(text, return_tensors=\"pt\", truncation=True)\n    outputs = mod.generate(**inputs)\n    return tok.decode(outputs[0], skip_special_tokens=True)\n\n\nback_translate_from_english(out, 'de')\n\n'3,015 kg Zucker'\n\n\nThe models even translated the floating point seperator from ‘.’ to ‘,’ . However, we now need four models for three languages. Maybe a bigger model is not too bad.\n\n\n3.6 Evaluation\n\ndef convert_ingredient_parser(ing_list, model):\n    translated_all=[]\n\n    translated = [a for a, _ in (translate_to_english_helsinki_with_fastdetect_v2(normalize_qty(x)) for x in ing_list)]\n    translated_all.append({\"input\":translated})\n    for row in translated_all:\n        converted = [parse_ingredient_line(item) for item in row[\"input\"]]\n\n    names = [t[\"name\"] for t in converted]\n    clusters = cluster_same_concept_transitive_winkler(names, model)\n    merged = aggregate_by_concept(converted, clusters)\n    out = format_aggregate(merged)\n    return out\n\n\nfor case in test_cases:\n    print(case[\"expected\"],convert_ingredient_parser(case[\"input\"], model_emb))\n\n['3l milk'] ['3 l milk']\n['3l milk'] ['3 l whole milk']\n['3l milk'] ['3 l hot milk']\n['3kg sugar'] ['3 kg sugar', '15 ml sugar']\n['1kg brown sugar', '1kg white sugar'] ['3 kg brown sugar']\n['4 eggs'] ['3  eggs', '1  None']\n['3 bread'] ['1  wand', '2  bread']\n['2 bottles of water', '1 bottle of wine'] ['2 bottle water', '1 bottle wine']\n['3l Oatly Milk'] ['3 l None']\n['1.5kg rice'] ['1 kg rice', '500 g None']\n['3 onions'] ['3  onion']\n['3 bell peppers'] ['2  bell pepper', '1  capsicum']\n['3 red pepper flakes'] ['1  red pepper flakes', '2  chili flakes']\n['3 tbsp butter'] ['15 ml butter', '1  butter', '1  None']\n['3 tsp salt'] ['10 ml salt', '1  None']\n['3 cans crushed tomatoes'] ['3 can crushed tomatoes']\n['3 cups yogurt'] ['480 ml yogurt', '1  None']\n['3 tbsp olive oil'] ['30 ml olive oil', '1  None']\n['2 bread', '1 croissant'] ['1  increasing', '1  pain', '1  bread']\n['300g cheese'] ['300 g cheese']\n['3kg flour'] ['3 kg flour']\n\n\n\nfor case in test_cases_long_sentences:\n    print(case[\"expected\"],convert_ingredient_parser(case[\"input\"], model_emb))\n\n['3 onions'] ['3  yellow onion']\n['2 cups mango chunks'] ['480 ml mango chunks']\n['1.5 sticks butter'] ['120 ml butter', '200 g butter']\n['3 tbsp cilantro'] ['15 ml cilantro', '1  None', '15 ml coriander']\n['3 bell peppers'] ['3  bell pepper']\n['6 cloves garlic'] ['6 cloves garlic']\n['3 bell peppers'] ['2 stalk bell peppers', '1  tige de poivron']\n['3 tsp garam masala'] ['12.5 ml garam masala', '1  None']\n['3 pinches salt'] ['3  salt']\n['3 handfuls nuts'] ['3  nuts']\n['6 cups milk or cream'] ['1.44 l milk']\n['3 tbsp olive oil'] ['45 ml olive oil']\n['3 cups chopped tomatoes'] ['240 ml tomatoes', '2 can tomatoes']\n['3 bottles of water'] ['3 bottle water']\n['3 cans coconut milk'] ['2 can coconut milk', '1 box coconut milk']\n['3 potatoes'] ['3  potato']\n['6 onions'] ['4  onions', '2  petits oignons']"
  },
  {
    "objectID": "posts/projects/recipescanner/smart_shopping_list.html#lesssons-learned",
    "href": "posts/projects/recipescanner/smart_shopping_list.html#lesssons-learned",
    "title": "Can AI fix your shopping list?",
    "section": "4 Lesssons learned",
    "text": "4 Lesssons learned\nAfter all this, the verdict is still “not convinced.”\nThe translation models sometimes work impressively well. For short, multilingual phrases like ingredients (riz), the context is sometime too thin to provide meaningful embeddings.\nThe experiments reveal a big flaw in the use of NLP. Much of our daily communication is implicit. Humans excel at resolving short information flow in the current context. LLM would need to be told the same context, exploding token cost and making the approach economically unrealistic.\nFor production use, hybrid approaches will win: structured ontology with model-based matching and maybe some translation. However, that is exactly what I wanted to avoid. The user needs to input data. For a new user it is not evident that he could speed up the process by teaching the computer instead of doing the work himself. If users are to benefit from shared data, strict processes for privacy protection become necessary."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html",
    "title": "Beauty is in the eye of the beholder",
    "section": "",
    "text": "The recipescanner allows scanning books and creating recipes with thumbnails. These Thumbnails should look nice and provide a good first impression of the meal.\nThere are three categories of recipes:\n\nThe picture that belongs to the recipe is identified.\nThe recipe does not have a picture.\nWe have a picture and several recipes, but we don’t know which recipe the picture belongs to.\n\nIn this notebook we will examine case 1 and case 2. Case 3 is part of the page segmentation task, which I’ll cover in another notebook."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#why-we-need-thumbnails",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#why-we-need-thumbnails",
    "title": "Beauty is in the eye of the beholder",
    "section": "",
    "text": "The recipescanner allows scanning books and creating recipes with thumbnails. These Thumbnails should look nice and provide a good first impression of the meal.\nThere are three categories of recipes:\n\nThe picture that belongs to the recipe is identified.\nThe recipe does not have a picture.\nWe have a picture and several recipes, but we don’t know which recipe the picture belongs to.\n\nIn this notebook we will examine case 1 and case 2. Case 3 is part of the page segmentation task, which I’ll cover in another notebook."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#what-makes-a-good-thumbnail",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#what-makes-a-good-thumbnail",
    "title": "Beauty is in the eye of the beholder",
    "section": "2 What makes a good thumbnail",
    "text": "2 What makes a good thumbnail\nWe have a picture of a recipe and want to create a good thumbnail from it. Simply resizing the image often produces thumbnails that lack detail.\nA better, straightforward solution is to center-crop the picture to the size of the thumbnail.\nThe rationale: plates are usually centered in recipe photos.\nBut what if that’s not the case?\nDoes this method produce aesthetically pleasing thumbnails, and is there a way to improve in case of non-centered subjects?\nThe short answer: yes.\nSee the following picture\n\n\n\nImprovements in Thumbnail generation\n\n\nRead on to discover how we do this."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#straightforward-solution-center-crop-of-pictures",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#straightforward-solution-center-crop-of-pictures",
    "title": "Beauty is in the eye of the beholder",
    "section": "3 Straightforward solution: center crop of pictures",
    "text": "3 Straightforward solution: center crop of pictures\n\n\nCode\n# Standard library\nimport os\nimport tempfile\nfrom glob import glob\nfrom pathlib import Path\nfrom os.path import expanduser\nfrom urllib.request import urlretrieve\nimport warnings\n\n# Third-party\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport open_clip\nimport pandas as pd\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom PIL import Image, ImageOps\nfrom gradio_client import Client, file, handle_file\nfrom torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\nimport tqdm\n\n# Local modules\nfrom aesthetic_predictor_v2_5 import convert_v2_5_from_siglip\n\n# Jupyter magic\n%matplotlib inline\n\n# Suppress all warnings (optional)\nwarnings.filterwarnings(\"ignore\")\n\n\nDATA_DIR = Path(\"data/covers\")\nTHUMB_SIZE = 512\nNROW = 12\n\n\nthumb_transform = transforms.Compose([\n    transforms.Resize(THUMB_SIZE, interpolation=InterpolationMode.LANCZOS),\n    transforms.CenterCrop(THUMB_SIZE),\n    transforms.ToTensor()\n])\n\nto_pil = transforms.ToPILImage()\nto_tensor = transforms.ToTensor()\n\ndef show_image_grid(images, nrow=NROW, figsize=(14, 12)):\n    grid = torchvision.utils.make_grid(images, nrow=nrow)\n    plt.figure(figsize=figsize)\n    plt.imshow(grid.permute(1, 2, 0))\n    plt.axis(\"off\")\n    plt.show()\n\n\nLet’s first load our sample data and apply center-cropping.\n\nfiles = sorted(glob(str(DATA_DIR / \"*.JPG\")))\n\nimages = [thumb_transform(Image.open(f).convert(\"RGB\")) for f in files]\nshow_image_grid(images)\n\n\n\n\n\n\n\n\nAs we can see, many picture look quite good. However, in some images the dish gets cut off. We could certainly do better.\nFor a human it’s obvious that we should center the plate in the thumbnail. For a computer that is challenging as plates are coming in different shapes, and sometimes there are no plates at all. In our specific case, the images are also upside down.\nWe’ll see later that this is still solvable. Before we get there, though, let’s first define what makes a picture look good.\nFor that, we need a metric."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#how-to-measure-beauty",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#how-to-measure-beauty",
    "title": "Beauty is in the eye of the beholder",
    "section": "4 How to measure beauty",
    "text": "4 How to measure beauty\nWouldn’t it be great if we could define a metric that tells us how good a picture is? How beautiful it looks?\nIn fact, there is a way to do this. We can use Aesthetic Predictor models. Let’s look at two such Models LAION and Aesthetic Predictor V2.5.\n\n4.1 LAION\nLAION is the older of the two models.\nIt is “a linear estimator on top of CLIP to predict the aesthetic quality of pictures.”\n\nBut how does it work?\nContrastive Language-Image Pretraining (CLIP) is a multimodal model introduced in 2021. It’s based on\n\nA text encoder, usually GPT like\nA vision encoder, a vision transformer\n\nBoth encoders produce embeddings, and the model produces combined embeddings with a dimensionality of 768. CLIP was trained on image-caption pairs and used cosine similarity to align text and image embeddings as close as possible.\nThis allowed the model to identify the best caption for a given image, or vice-versa.\nLAION builds on top of CLIP, but scales it up to billions of images compared to clips 400 million.\nOn top of this embedding model, a linear regression model is trained using a much smaller dataset. The model is define by,\n\\[score= W * \\vec{emb} + b\\]\nWhere W and b are the weights and bias of the linear regression model.\n\n\n4.2 Aesthetic Predictor V2.5\nIn AI, four years is a long time.\nIn 2023 Google introduced SigLIP, Sigmoid Loss for Language–Image Pretraining.\nThe original CLIP model from OpenAI uses a contrastive loss function. Core to this function is a softmax over all image pairs. Even though all images can not be included at once, this is approximated using a very large batch size. This large batch size requires expensive compute hardware.\nAnother limitation of LAION was its the underperformance across diverse domains.\nSigLIP addresses both problems:\n\nFirst it uses a sigmoid loss function. Smaller batch sizes can be used.\nSecond it uses more data, being more robust to diverse domains.\n\nSo let’s check the aesthetic scores for our images.\n\n\n4.3 Calculating scores with Aesthetic Predictor 2.5\nWe will start with the newer model. Unfortunately, my GPU is too old and is no longer supported by PyTorch version required for this model.\nWe can use the Hugginface Api or CPU, though.\n\n4.3.1 Using the Hugging Face API for Aesthetic Predictor 2.5\n\n%%time\n\nclient = Client(\"discus0434/aesthetic-predictor-v2-5\")\n\ndef predict_with_ae25api(img_tensor, client):\n    img = to_pil(img_tensor.cpu())\n\n    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as t:\n        img.save(t.name, format=\"PNG\")\n        return client.predict(image=file(t.name), api_name=\"/inference\")\n\nscores_api = [predict_with_ae25api(img, client) for img in images]\nprint(scores_api)\n\nLoaded as API: https://discus0434-aesthetic-predictor-v2-5.hf.space ✔\n['4.712978', '4.985875', '5.3126655', '5.0395384', '4.75456', '4.390934', '5.410819', '5.163789', '5.7570896', '5.6178026', '5.0622964', '4.242473', '4.695843', '5.7283096', '5.394037', '5.970618', '5.013522', '5.021712', '5.727453', '4.788595', '5.810698', '5.6538353', '5.338957', '5.173321', '5.7376328', '5.856394', '4.9087625', '5.0130215', '5.60766', '4.9622364', '5.304905', '4.6225524', '4.5034065', '5.2350173', '5.9285026', '5.1088295', '5.6992407', '5.356913', '5.652878', '5.0367103', '4.662853', '4.8960724', '5.1651015', '5.030403', '4.730472', '5.0686293', '5.6805077', '5.1905656', '5.3466654', '5.454918', '5.108632', '5.384975', '5.2946644', '6.0702987', '5.935483', '5.140892', '4.4770913', '4.819613', '5.5843506', '5.7856994']\nCPU times: user 14.3 s, sys: 432 ms, total: 14.7 s\nWall time: 4min 38s\n\n\n4 Minutes for the execution is quite long. Let’s try CPU.\n\n\n4.3.2 Running Aesthetic Predictor 2.5 locally on CPU\nWe first define a function, so we can reuse it later.\n\ndef get_aesthetic_scores_v25(images, batch_size=16):\n\n    model, preproc = convert_v2_5_from_siglip(\n        low_cpu_mem_usage=True,\n        trust_remote_code=True,\n    )\n    model = model.eval()\n\n    scores = []\n\n    with torch.inference_mode():\n        for i in range(0, len(images), batch_size):\n            batch = images[i:i+batch_size]\n            batch_tensor = torch.stack(batch)\n            batch_tensor = F.interpolate(batch_tensor, size=(384,384), mode=\"bilinear\", align_corners=False)\n    \n            mean = torch.tensor(preproc.image_mean).view(1,3,1,1)\n            std  = torch.tensor(preproc.image_std).view(1,3,1,1)\n            batch_tensor = (batch_tensor - mean) / std\n            \n            logits = model(batch_tensor).logits.squeeze(-1)\n            batch_scores = logits.float().cpu().numpy()\n    \n            scores.extend(batch_scores)\n\n    return scores\n\n\n%%time\nscores_ap25 = get_aesthetic_scores_v25(images, batch_size=16)\n\nCPU times: user 7min 47s, sys: 47.3 s, total: 8min 34s\nWall time: 1min 27s\n\n\n\nnp.array(scores_ap25).mean()\n\nnp.float32(5.3517203)\n\n\nWith 1.5 minutes, this approach is faster than calling the api.\nOne possible use case is iterative improvement of the score through an algorithmic approach. In such a scenario, we should aim to process all 60 images within just a few seconds.\nLAION has lower requirements on the hardware, we’ll try it next.\n\n\n\n4.4 Calculating scores with LAION on GPU\nFrom the LAION github repository, we find the following function:\n\ndef get_aesthetic_model(clip_model=\"vit_l_14\"):\n    \"\"\"load the aethetic model\"\"\"\n    home = expanduser(\"~\")\n    cache_folder = home + \"/.cache/emb_reader\"\n    path_to_model = cache_folder + \"/sa_0_4_\"+clip_model+\"_linear.pth\"\n    if not os.path.exists(path_to_model):\n        os.makedirs(cache_folder, exist_ok=True)\n        url_model = (\n            \"https://github.com/LAION-AI/aesthetic-predictor/blob/main/sa_0_4_\"+clip_model+\"_linear.pth?raw=true\"\n        )\n        urlretrieve(url_model, path_to_model)\n    if clip_model == \"vit_l_14\":\n        m = nn.Linear(768, 1)\n    elif clip_model == \"vit_b_32\":\n        m = nn.Linear(512, 1)\n    else:\n        raise ValueError()\n    s = torch.load(path_to_model)\n    m.load_state_dict(s)\n    m.eval()\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    return m.to(device=device, dtype=torch.float32)\n\nThis is just the linear head of the whole estimator. We need to run the CLIP model for scoring as well.\n\ndef score_with_laion(torch_images):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    dtype  = torch.float32\n\n    clip_model_name = \"ViT-L-14\"\n    clip_ckpt = \"openai\"\n\n    # CLIP encoder + preprocess (must match the LAION head variant)\n    model, _, preprocess = open_clip.create_model_and_transforms(clip_model_name, pretrained=clip_ckpt)\n    model = model.to(device).eval()\n\n    # Linear estimator\n    head = get_aesthetic_model()\n\n    images_preprocessed = [preprocess(to_pil(img)) for img in torch_images]\n    batch = torch.stack(images_preprocessed).to(device=device, dtype=dtype)\n\n    with torch.inference_mode():\n        clip_embeddings = model.encode_image(batch)\n        clip_embeddings = clip_embeddings / clip_embeddings.norm(dim=-1, keepdim=True).clamp_min(1e-12)\n        clip_embeddings = clip_embeddings.to(dtype) \n        scores = head(clip_embeddings).squeeze(-1).float().cpu().numpy()\n\n    return scores\n\nRunning on our images.\n\n%%time\nscores_laion = score_with_laion(images)\n\nCPU times: user 10.4 s, sys: 559 ms, total: 11 s\nWall time: 7.89 s\n\n\nAs expected, the GPU calculation is a lot faster, and 8.5 seconds is less than what we would need.\nLet’s examine min and max result.\n\nscores_laion\n\narray([4.682658 , 5.5719824, 4.7548094, 5.6179185, 5.8664765, 5.2028084,\n       6.0401983, 6.153771 , 4.6438675, 5.7687664, 5.8421736, 5.352836 ,\n       5.795928 , 6.3411045, 5.2397337, 6.822626 , 5.9344873, 5.9164524,\n       5.7080965, 5.8545227, 6.7204437, 5.451813 , 6.035965 , 6.1448298,\n       6.310848 , 6.398098 , 6.13536  , 6.0679417, 5.075293 , 6.218848 ,\n       4.5623236, 5.423691 , 5.0390825, 6.200203 , 5.6596227, 4.7416925,\n       5.774774 , 6.2334433, 5.8048406, 5.828251 , 5.0799165, 4.574512 ,\n       5.1658216, 6.413603 , 5.409901 , 5.9421396, 6.02083  , 5.6725616,\n       5.6838965, 5.1442785, 4.757121 , 5.8007193, 6.006052 , 5.8004303,\n       6.1855965, 4.3213387, 5.9920015, 5.3351316, 6.3207726, 5.7225537],\n      dtype=float32)\n\n\n\nmin_idx = np.argmin(scores_laion)\nmin_score = scores_laion[min_idx]\n\nmax_idx = np.argmax(scores_laion)\nmax_score = scores_laion[max_idx]\nprint(f\"Minimum score is {min_score} and maximum score is {max_score}\")\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nimg_min = images[min_idx].permute(1, 2, 0)\nplt.imshow(img_min)\nplt.title(f\"min_score: {min_score:.4f}\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nimg_max = images[max_idx].permute(1, 2, 0)\nplt.imshow(img_max)\nplt.title(f\"max_score: {max_score:.4f}\")\nplt.axis(\"off\")\n\n\nplt.show()\n\nMinimum score is 4.321338653564453 and maximum score is 6.822626113891602\n\n\n\n\n\n\n\n\n\nWhile the plates are cut in both pictures, the higher rated picture somehow looks better.\n\n\n4.5 Comparing the two predictors\nLet’s see how the two scores of LAION and Aesthetic Predictor align.\n\nscores_ap25= np.array(scores_ap25)\ndf = pd.DataFrame({\n    \"LAION Score\": (scores_laion - scores_laion.mean()) /scores_laion.std(),\n    \"AE25 Score\": (scores_ap25 - scores_ap25.mean()) /scores_ap25.std()\n})\n\n# Create scatter plot\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=df, x=\"LAION Score\", y=\"AE25 Score\", alpha=0.6, edgecolor=None)\n\n# Improve visualization\nplt.title(\"Aesthetic Score Comparison: LAION vs SigLIP\")\nplt.xlabel(\"LAION Aesthetic Score\")\nplt.ylabel(\"SigLIP Aesthetic Score\")\n\nText(0, 0.5, 'SigLIP Aesthetic Score')\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import pearsonr, spearmanr\npearson_corr, _ = pearsonr(scores_laion, scores_ap25)\nspearman_corr, _ = spearmanr(scores_laion, scores_ap25)\n\n\nprint(f\"Pearson correlation is {pearson_corr}, Spearman correlation is {spearman_corr}\")\n\nPearson correlation is 0.268462598323822, Spearman correlation is 0.22606279522089476\n\n\nValues close to 0.2 indicate that there is little correlation between the CLIP-based and the SIGLIP-based evaluations. The picture confirms the numerical values, too.\nAt first, this might seem surprising. Should a good image not always look good?\nNot necessarily. Beauty lies in the eye of the beholder. And in fact, those two models are different. The difference in the loss functions is not the only factor that changed.\nThe two models were trained on very different datasets.\n\nLAION is primarily focused on Photography\nSIGLIP focuses on much broader range of web images.\n\nAs a result, images with bright, unrealistic colours may score higher using SIGLIP than with LAION."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#optimizing-thumbnails-with-global-methods",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#optimizing-thumbnails-with-global-methods",
    "title": "Beauty is in the eye of the beholder",
    "section": "5 Optimizing thumbnails with global methods",
    "text": "5 Optimizing thumbnails with global methods\nDue to the significant speed advantage on my machine, I will focus on LAION. Let’s create a baseline.\n\nbaseline_score = scores_laion.mean()\nbaseline_score\n\nnp.float32(5.671463)\n\n\nIn theory, several improvements are possible.\nNon-crop improvements, modifying the entire image - Correct orientation - Color correction - Glare and noise reduction\nCrop-based improvements try to locate a plate in the image and crop. - Use saliency maps to highlight the most important object in the image - Use segmentation models to find all contours - Use bounding box object detection models like YOLO to detect the dish - Perform optimizations on (x, y, zoom) by scoring multiple crops and treating the search for the perfect crop as an optimization problem\n\n5.1 Correct orientation\nThis is the most obvious one.\n\nimages_correct_orientation = [thumb_transform(ImageOps.exif_transpose(Image.open(f)).convert(\"RGB\")) for f in files]\n\n\nshow_image_grid(images_correct_orientation)\n\n\n\n\n\n\n\n\n\nscores_laion_correct_orientation = score_with_laion(images_correct_orientation)\n\n\nscores_laion_correct_orientation.mean()\n\nnp.float32(5.8733764)\n\n\nAs we can see correct orientation leads to a better score.\n\n\n5.2 Color correction and denoising\nI experiment with applying color correction and denoising on some samples. However, in most cases this actually lowers the score.\nOne possible explanation is that the model was trained on untreated sRGB pictures. By altering the images too much, we risk creating an out-of-domain.\nNevertheless, we will still apply a mild correction to to reduce glare, but only after cropping."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#optimizing-thumbnails-with-cropping-using-saliency-maps",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#optimizing-thumbnails-with-cropping-using-saliency-maps",
    "title": "Beauty is in the eye of the beholder",
    "section": "6 Optimizing Thumbnails with cropping using saliency maps",
    "text": "6 Optimizing Thumbnails with cropping using saliency maps\nSaliency detection attempts to identify which parts of an image are the most visually important.\nWe have two lightweight options for generating saliency maps:\n\nOpencv-based fine-grained saliency map\nU²-Net\n\nWe will not use the Opencv Method.\nOpencv algorithm compares pixel color variations with their neighbours. However, the approach is outdated and quite slow, making it not suitable for our purpose.\n\n6.1 U²-Net saliency map\nU²-Net is a deep learning model for salient object detection that uses a nested U-shaped architecture with Residual U-blocks (RSUs) for efficient multi-scale feature extraction. It delivers high-accuracy segmentation and is widely used for background removal.\nWe aim to identify the main dish as the foreground. Instead of removing the background, we’ll simply use the saliency map to crop the dish region.\nLet’s start by testing it on a sample picture.\n\n\nCode\ntest_image = Image.open(files[2])\nplt.axis(\"off\")\nplt.imshow(test_image)\n\n\n\n\n\n\n\n\n\nWhich we need to turn\n\n\nCode\ntransposed_image = ImageOps.exif_transpose(test_image).convert(\"RGB\")\ntransposed_image_np = np.array(transposed_image)\nplt.axis(\"off\")\nplt.imshow(transposed_image_np)\n\n\n\n\n\n\n\n\n\nWe need to scale down the picture to 320px, as the model was trained on this and convert to pytorch.\n\narr = transposed_image_np.astype(np.float32) / 255.0\nH, W = arr.shape[:2]\nscale = min(320 / max(H, W), 1.0)\nif scale &lt; 1.0:\n    newW, newH = int(round(W * scale)), int(round(H * scale))\n    arr = cv.resize(arr, (newW, newH), interpolation=cv.INTER_AREA)\n\nten = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0).to(\"cuda\")\n\nNext, let’s load the model, and examine if it correctly loaded. If so We should see definitions of RSUs. I copied definition and weights from https://github.com/xuebinqin/U-2-Net/.\n\nfrom u2net import U2NET\nmodel = U2NET(3, 1)\nstate = torch.load(\"data/u2net.pth\", map_location='cuda')\nmodel.load_state_dict(state, strict=True)\nmodel.to(\"cuda\")\n_ = model.eval()\n\nThis seems identical to what is specified in the sources.\nLet’s run the the model. U²-Net produces multiple maps; one at each level of the u-net. We are only interested in the upper layer.\n\nwith torch.inference_mode():\n    out = model(ten)\n    pred = out[0] if isinstance(out, (list, tuple)) else out\n    sal_small = torch.sigmoid(pred)\n\nFor futher processing we will convert back to uint8 and inspect the output.\n\nsal_u8 = (sal_small.detach().clamp(0, 1).cpu().numpy() * 255).astype(\"uint8\").squeeze()\nplt.axis(\"off\")\nplt.imshow(sal_u8)\n\n\n\n\n\n\n\n\nThe main plate is correctly identified.\n\n\n6.2 Optimized pipeline\nWe start by defining a function to run inference on a unscaled numpy/opencv image.\n\ndef run_u2_on_pil(model, image,resolution=320):\n    # preprocessing\n    H, W = image.shape[:2]\n    scale = min(resolution / max(H, W), 1.0)\n    if scale &lt; 1.0:\n        newW, newH = int(round(W * scale)), int(round(H * scale))\n        target_image = cv.resize(image, (newW, newH), interpolation=cv.INTER_AREA)\n    else:\n        target_image = image\n    ten = (torch.from_numpy(target_image).float().permute(2,0,1) / 255.0).unsqueeze(0).to(\"cuda\")\n\n    # getting saliency map\n    with torch.inference_mode():\n        out = model(ten)\n        pred = out[0] if isinstance(out, (list, tuple)) else out\n        sal_small = torch.sigmoid(pred)\n\n    # postprocessing back to original scale and cpu\n    sal_full = F.interpolate(sal_small, size=(H, W), mode=\"bilinear\", align_corners=False)\n    sal_full = sal_full.squeeze(0).squeeze(0).clamp(0,1).detach().cpu().numpy().astype(np.float32)\n    return sal_full\n\n\nsal_full = run_u2_on_pil(model, transposed_image_np)\n\nLet’s add an edge detector. The edge detector uses the Scharr operator on the luminance.\n\ndef rim_prior_from_L(image_uint8):\n    L = cv.cvtColor(image_uint8, cv.COLOR_RGB2LAB)[:,:,0]\n    gx = cv.Scharr(L, cv.CV_32F, 1, 0)\n    gy = cv.Scharr(L, cv.CV_32F, 0, 1)\n    mag = cv.magnitude(gx, gy)\n    mag = cv.GaussianBlur(mag, (9,9), 0)\n    mag -= mag.min()\n    mag /= (mag.max() + 1e-6)\n    return mag.astype(np.float32)\n\nR = rim_prior_from_L(transposed_image_np)\nplt.axis(\"off\")\nplt.imshow(R)\n\n\n\n\n\n\n\n\nWe fuse the two detections, doing so gives us a slightly nicer visualization.\n\n# Fuse\nS_fused = 0.85*sal_full + 0.15*R\n# Normalize\nS_fused -= S_fused.min()\nS_fused /= (S_fused.max() + 1e-6)\n\n\n\nCode\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(transposed_image_np)\nplt.title(\"Original\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 2)\nplt.imshow(S_fused , cmap=\"inferno\")\nplt.title(\"Fused Saliency\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNext, we are interested in generating a bounding box around the main dish.\n\nS8 = np.clip(S_fused * (255 if S_fused.max() &lt;= 1.0 else 1.0), 0, 255).astype(np.uint8)\n_, mask = cv.threshold(S8, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\nplt.axis(\"off\")\nplt.imshow(mask)\n\n\n\n\n\n\n\n\nWe remove small islands through close open transforms. Eventually we search the largest component.\n\nmask = cv.morphologyEx(mask, cv.MORPH_CLOSE, np.ones((7, 7), np.uint8))\nmask = cv.morphologyEx(mask, cv.MORPH_OPEN,  np.ones((5, 5),  np.uint8))\nplt.axis(\"off\")\nplt.imshow(mask)\n\n\n\n\n\n\n\n\n\nnum, labels, stats, _ = cv.connectedComponentsWithStats(mask, 8)\n\n\nimg_area = H * W\nbest_i, best_area = None, 0\nfor i in range(1, num):\n    x, y, w, h, area = stats[i]\n    if area &gt; best_area and area &gt;= 0.01 * img_area:\n        best_i, best_area = i, area\n\n\nx, y, w, h, _ = stats[best_i]\ncx, cy = x + w / 2.0, y + h / 2.0\n\n\nout = transposed_image_np.copy()\ncv.rectangle(out, (x, y), (x+w,y+h), (0, 255, 0), 10)\nplt.axis(\"off\")\nplt.imshow(out)\n\n\n\n\n\n\n\n\nThe green bounding box shows very nicely how we detected the plate. Let’s turn this into a function, which produces a resized square crop while respecting image boundaries.\n\ndef crop_on_saliency_map(saliency_map, image):\n    S8 = np.clip(saliency_map * (255 if saliency_map.max() &lt;= 1.0 else 1.0), 0, 255).astype(np.uint8)\n    _, mask = cv.threshold(S8, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, np.ones((7, 7), np.uint8))\n\n    mask = cv.morphologyEx(mask, cv.MORPH_OPEN,  np.ones((5, 5),  np.uint8))\n    num, labels, stats, _ = cv.connectedComponentsWithStats(mask, 8)\n    img_area = H * W\n    best_i, best_area = None, 0\n    for i in range(1, num):\n        x, y, w, h, area = stats[i]\n        if area &gt; best_area and area &gt;= 0.01 * img_area:\n            best_i, best_area = i, area\n    x, y, w, h, _ = stats[best_i]\n    cx, cy = x + w / 2.0, y + h / 2.0\n\n    # make image square and shift if we are too close to the border\n    pad = 0.0\n    w2, h2 = w * (1 + 2 * pad), h * (1 + 2 * pad)\n    side = max(w2, h2)\n    side_px = min(int(round(side)), W, H)\n    half = side_px / 2.0\n\n    cx = float(np.clip(cx, half, W - half))\n    cy = float(np.clip(cy, half, H - half))\n\n    x0 = int(round(cx - half))\n    y0 = int(round(cy - half))\n    \n    # guard against rounding pushing us out of bounds\n    x0 = max(0, min(x0, W - side_px))\n    y0 = max(0, min(y0, H - side_px))\n    x1 = x0 + side_px\n    y1 = y0 + side_px\n\n    # crop and resize    \n    crop = image[y0:y1, x0:x1]\n    interp = cv.INTER_AREA if 512 &lt; max(crop.shape[:2]) else cv.INTER_LINEAR\n    crop = cv.resize(crop, (512, 512), interpolation=interp)\n    return crop\n\n\nresult = crop_on_saliency_map(S_fused, transposed_image_np)\nplt.axis(\"off\")\nplt.imshow(result)\n\n\n\n\n\n\n\n\nThis is the correct crop of the plate in the picture. Next, we score the cropped image.\n\nscores_laion_cropped = score_with_laion([to_tensor(transposed_image)])\n\n\nscores_laion_cropped\n\narray([5.954031], dtype=float32)\n\n\nThis score is higher than our baseline score. That means correct cropping has a effect.\n\n\n6.3 Improving even more\nOn some images, there are too many fine details. The network will detect the whole page as salient object. We need to run the network with another input resolution. We can run several resolutions and decide which is best after scoring. A quicker approach is to examine the size of the main component in the picture, if it is too large we need to increase the resolution.\nTherefore, we define a function, which checks if we cover too much of the page with one component, where “too much” means 80%.\n\ndef _looks_like_full_page(sal, area_frac_thresh=0.80,require_border_touch=True):\n    \"\"\"Heuristic: is the biggest component huge and touching the image border?\"\"\"\n    S8 = (np.clip(sal * 255, 0, 255)).astype(np.uint8)\n    _, mask = cv.threshold(S8, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n    num, labels, stats, _ = cv.connectedComponentsWithStats(mask, 8)\n    if num &lt;= 1:\n        return False\n        \n    # largest component (skip background 0)\n    idx = 1 + np.argmax(stats[1:, cv.CC_STAT_AREA])\n    x, y, w, h, area = stats[idx]\n    H, W = sal.shape[:2]\n    area_frac = area / float(H * W)\n    touches = (x == 0) or (y == 0) or (x + w == W) or (y + h == H)\n    return (area_frac &gt;= area_frac_thresh) and (touches if require_border_touch else True)\n\nWith this function in place we can run a small optimization function. It will run over predefined scales and check if the result does not look like the full page. We start with smaller resolutions as these tend to produce the full page saliency map.\n\ndef run_u2_autoscale(model, image_np, sizes=(320, 480, 640, 896), device=\"cuda\"):\n\n    last_sal = None\n    for i, s in enumerate(sizes):\n        sal = run_u2_on_pil(model, image_np, s)\n        last_sal = sal\n        if not _looks_like_full_page(sal):\n            return sal\n            \n    # If even the largest still looks like a page, fall back to a small multi-scale fuse (max)\n    sal_big = last_sal\n    sal_small = run_u2_on_pil(model, image_np, sizes[0])\n    return np.maximum(sal_big, sal_small)\n\n\n\n6.4 The full pipeline\nNow with everything in place we can define a function that creates the fused saliency map, the bounding box, and finally crops.\n\ndef full_crop_pipeline(model, image):\n    transposed_image = np.array(ImageOps.exif_transpose(image).convert(\"RGB\"))\n    \n    sal_full = run_u2_autoscale(model, transposed_image)\n\n    # run edge detector\n    def rim_prior_from_L(image_uint8):\n        L = cv.cvtColor(image_uint8, cv.COLOR_RGB2LAB)[:,:,0]\n        gx = cv.Scharr(L, cv.CV_32F, 1, 0)\n        gy = cv.Scharr(L, cv.CV_32F, 0, 1)\n        mag = cv.magnitude(gx, gy)\n        mag = cv.GaussianBlur(mag, (9,9), 0)\n        mag -= mag.min()\n        mag /= (mag.max() + 1e-6)\n        return mag.astype(np.float32)\n\n    R = rim_prior_from_L(transposed_image)\n\n    # Fuse\n    S_fused = 0.85*sal_full + 0.15*R\n    \n    # Normalize\n    S_fused -= S_fused.min()\n    S_fused /= (S_fused.max() + 1e-6)\n\n    # Crop\n    cropped = crop_on_saliency_map(S_fused, transposed_image)\n    return cropped\n\n\ncropped_test_image = full_crop_pipeline(model, test_image)\nplt.axis(\"off\")\nplt.imshow(cropped_test_image)\n\n\n\n\n\n\n\n\nAs expected we get the same picture.\nLet’s calculate for all images and score.\n\ncropped_images= []\nfor file in tqdm.tqdm(files):\n    cropped_images.append(full_crop_pipeline(model, Image.open(file)))\n\n\nscores_laion_cropped = score_with_laion([to_tensor(img) for img in cropped_images])\n\n\nscores_laion_cropped.mean()\n\nnp.float32(5.951551)\n\n\nThis mean score is slightly better than the uncropped. let’s check the details.\n\nimprovement = (scores_laion_cropped-scores_laion_correct_orientation)\nimprovement.mean()\n\nnp.float32(0.07817339)\n\n\n\nimprovement.std()\n\nnp.float32(0.3198055)\n\n\nThe high standard deviation means some images improved a lot more, some got worse. Let’s identify the worst decline in the score.\n\nnp.argmin(scores_laion_cropped-scores_laion_correct_orientation)\n\nnp.int64(22)\n\n\n\nplt.axis(\"off\")\nplt.imshow(cropped_images[22])\nprint(improvement[22])\n\n-0.76167774\n\n\n\n\n\n\n\n\n\nThe image is a perfect crop. It is not obvious why the score decreased. In terms of results it is exactly what we want. The same is true for almost all other images, as we can see below.\n\nshow_image_grid([to_tensor(img) for img in cropped_images])\n\n\n\n\n\n\n\n\n\n\n6.5 Postprocessing\nThe pictures were done with a mobile phone camera. This is the quickest way to digitize a book without expensive equipment. There is some glare from glossy paper and non-perfect light condition. Let’s try to improve.\n\ndef reduce_glare(img):\n    # Ensure BGR → LAB (good for luminance adjustments)\n    lab = cv.cvtColor(img, cv.COLOR_RGB2LAB)\n    l, a, b = cv.split(lab)\n\n    # Apply CLAHE on L-channel, 2.0 and 8.8 produce moderately aggressive results\n    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    cl = clahe.apply(l)\n\n    # Merge and convert back\n    limg = cv.merge((cl, a, b))\n    final = cv.cvtColor(limg, cv.COLOR_LAB2RGB)\n    return final\n\ndef detect_glare_mask(img, thresh=230):\n    hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n    h, s, v = cv.split(hsv)\n    mask = (v &gt;= thresh).astype(np.uint8) * 255\n\n    # Optional: clean up mask\n    kernel = np.ones((5,5), np.uint8)\n    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)   # fill small holes\n    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel)    # remove tiny specks\n\n    return mask\n\ndef inpaint_glare(img, thresh):\n    mask = detect_glare_mask(img, thresh=thresh)\n    gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n    \n    # Detect glare: very bright areas\n    img_bgr = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n    inpainted_bgr = cv.inpaint(img_bgr, mask, inpaintRadius=5, flags=cv.INPAINT_TELEA)\n    inpainted_rgb = cv.cvtColor(inpainted_bgr, cv.COLOR_BGR2RGB)\n    return inpainted_rgb\n\n\ncrop_glare_reduced = [reduce_glare(img) for img in cropped_images]\ncrop_glare_reduced_and_inpainted = [inpaint_glare(img,240) for img in crop_glare_reduced]\n\n\nshow_image_grid([to_tensor(img) for img in crop_glare_reduced])\n\n\n\n\n\n\n\n\n\nshow_image_grid([to_tensor(img) for img in crop_glare_reduced_and_inpainted])\n\n\n\n\n\n\n\n\n\nscores_laion_cropped_fixed_glare = score_with_laion([to_tensor(img) for img in crop_glare_reduced])\nscores_laion_cropped_fixed_glare.mean()\n\nnp.float32(5.9497223)\n\n\n\nscores_laion_cropped_fixed_glare_inpaint = score_with_laion([to_tensor(img) for img in crop_glare_reduced_and_inpainted])\nscores_laion_cropped_fixed_glare_inpaint.mean()\n\nnp.float32(5.816769)\n\n\nSubjectively the pictures look better. The average score is a little lower for histogram equalization and gets bad for mask-based glare inpainting. Let’s check a single image.\n\nprint(scores_laion_cropped[0],scores_laion_cropped_fixed_glare[0],scores_laion_cropped_fixed_glare_inpaint[0])\n\n6.1202517 6.257745 6.3136473\n\n\nThis tells a completely other story. Here the images got better, the more processing was applied. We will do a visual inspection.\n\n\nCode\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(cropped_images[0])\nplt.title(\"No Glare Fix\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 2)\nplt.imshow(crop_glare_reduced[0] , cmap=\"inferno\")\nplt.title(\"Histogram Equalization\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 3)\nplt.imshow(crop_glare_reduced_and_inpainted[0] , cmap=\"inferno\")\nplt.title(\"Inpainting\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe strong glare is succesfully removed, without introducing artifacts or too high contrast.As we can see glare reduction can deliver improvements. Let’s combine the best of all.\n\nscores_list = [scores_laion_cropped, scores_laion_cropped_fixed_glare, scores_laion_cropped_fixed_glare_inpaint]\nimages_list = [cropped_images, crop_glare_reduced, crop_glare_reduced_and_inpainted]\n\nscores = np.stack(scores_list, axis=1)\nbest_indices = scores.argmax(axis=1)\nbest_scores = scores.max(axis=1)\n\nN = scores.shape[0]\nbest_images = [images_list[idx][i] for i, idx in enumerate(best_indices)]\nbest_scores.mean()\n\nnp.float32(6.1018143)\n\n\n\nshow_image_grid([to_tensor(img) for img in best_images])\n\n\n\n\n\n\n\n\nNow we have an average improvement. Let’s check a picture with a lot of glare\n\n\nCode\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(best_images[29])\nplt.title(\"Best Image\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 2)\nplt.imshow(crop_glare_reduced[29] , cmap=\"inferno\")\nplt.title(\"Histogram Equalization\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 3)\nplt.imshow(crop_glare_reduced_and_inpainted[29] , cmap=\"inferno\")\nplt.title(\"Inpainting\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe best picture is the one without post-processing. Personally I like the histogram equalization most. The inpainting has to strong artifacts in the non glare parts. There is too much contrast on the parts of the image which were not affected by the glare. With more work this could certainly be improved.\nFinally, my impression is that the LAION score is not good for our use case of food photography. The scores are too close together."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#other-methods",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#other-methods",
    "title": "Beauty is in the eye of the beholder",
    "section": "7 Other methods",
    "text": "7 Other methods\n\n7.1 Segmentation\nWhen I brainstormed ideas, I considered using segmentation models. On of the most advanced segmentation models is (Segment Anything)[https://segment-anything.com/demo].\nFor a problematic image, the segmentation model gives the following result: \nHowever, identifying the best crop would require significant post- processing. Assuming we always look for dishes, which is not necessarily the case, we could look for smooth large shapes.\n\n\n7.2 Object detection\nBounding box object detection algorithms can, in theory, locate the plates quite well. The main drawback is that I would need to train such a detector myself, which requires a lot of labeled data.\nWhile there are backbones such as YOLO, we would still require several hundreds of labeled images.\nThis could be a viable refinement once a significant number of images has been processed.\n\n\n7.3 Direct optimization\nAnother possible approach is a brute-force optimization method. We would run an optimization algorithm that uses LAION to score the images. Based on the gradients we would vary the crop zone.\nHowever, from my experiments with saliency-based images, the aesthetic score is somewhat subjective and not always intuitive. To make this approach effective, the scoring function would likely need to be reworked. While there is certainly room for experimentation here, this method would require more research and fine-tuning."
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#summary",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#summary",
    "title": "Beauty is in the eye of the beholder",
    "section": "8 Summary",
    "text": "8 Summary\nWhat did we learn?\nWe found that it is possible to generate better thumbnails using slightly more intelligent techniques. I used a multi-scale saliency algorithm to identify the dominant object in each image. This lead to a average score increase of 1.3%.\nAdditionally, glare reduction makes the pictures subjectively nicer, but it actually leads to a lower mean score.\nThis raises an interesting question: how should we score good-looking thumbnails? The LAION classifier can help slightly improve images, but in some cases, it actually prefers images with more glare.\n\n\nCode\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(to_pil(images_correct_orientation[29]))\nplt.title(\"Center Crop\")\nplt.axis(\"off\")\nplt.subplot(1, 3, 2)\nplt.imshow(crop_glare_reduced[29] , cmap=\"inferno\")\nplt.title(\"Saliency Map Crop with Glare Removal\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.savefig(\"best_thumbnail_method.jpg\", dpi=300, bbox_inches=\"tight\")\nplt.show()"
  },
  {
    "objectID": "posts/projects/recipescanner/thumbnail_optimization.html#bonus-section-case-2-recipes-without-images",
    "href": "posts/projects/recipescanner/thumbnail_optimization.html#bonus-section-case-2-recipes-without-images",
    "title": "Beauty is in the eye of the beholder",
    "section": "9 Bonus Section: case 2 recipes without images",
    "text": "9 Bonus Section: case 2 recipes without images\nWhat if we have no images at all. Then the only option is image generation.\nHowever, this is computationally far more costly as the previous processing. And it does not seem to work that well.\n\nReal photo\nWith this prompt : A bright, photorealistic cookbook-style photo of a freshly cooked Thai-style chicken stir-fry with cashews, beautifully plated on a white ceramic dish. The dish features tender, thinly sliced chicken thighs coated in a glossy, rich sauce made from oyster sauce, soy sauce, and fish sauce. Golden-brown roasted cashews scattered evenly, thin wedges of onion, vibrant green onion pieces, and delicate slices of red cayenne pepper for a pop of color. Served alongside a small bowl of perfectly steamed jasmine rice. The composition is clean and minimal, shot on a light wooden kitchen table with natural daylight. Soft, even lighting with gentle shadows, crisp textures, and realistic color tones. High-end food photography, cookbook aesthetic, ultra-HD.\nLeads to this quite unrealistic picture from Chatgpt and FluxSchnell\n\nChatGPT\n\nFluxschnell\nPersonally i find those less appealing than real photos, even though Flux Schnell comes at a much lower price tag.\nSlighly better is Stable diffusion\n\nStable Diffusion\nUntil one has cooked the recipe this is the only option to have a picture.\nIt would be interesting to see how the saliency map methods works on real pictures of the cooked food."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "",
    "text": "\\[   F = ma \\]\n\n\n\nPushing a shopping cart with groceries, the amount of force you need to apply to get the cart moving is directly proportional to its mass and acceleration. Visible Brush Strokes Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#newtons-second-law-of-motion",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#newtons-second-law-of-motion",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "",
    "text": "\\[   F = ma \\]\n\n\n\nPushing a shopping cart with groceries, the amount of force you need to apply to get the cart moving is directly proportional to its mass and acceleration. Visible Brush Strokes Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#work-energy-theorem",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#work-energy-theorem",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "2 Work-Energy theorem",
    "text": "2 Work-Energy theorem\n\\[   W = \\Delta K\\]\n\n\n\nA person is lifting a box and placing it on a shelf. Communist art."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#gravitational-force",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#gravitational-force",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "3 Gravitational force",
    "text": "3 Gravitational force\n\\[    F = G * \\frac{m_1 * m_2}{r^2}\\]\n\n\n\nNewtons apple, the apple falling from the tree to your hand."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#simple-harmonic-motion",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#simple-harmonic-motion",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "4 Simple harmonic motion",
    "text": "4 Simple harmonic motion\n\\[ x = Acos(\\omega t + \\Phi)\\]\n\n\n\nSwinging on a swing, the back and forth motion of the swing can be described by simple harmonic motion. Impressionism Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#kinetic-energy",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#kinetic-energy",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "5 Kinetic energy",
    "text": "5 Kinetic energy\n\\[ K = \\frac{1}{2} m  v^2\\]\n\n\n\nA foot has hit a soccer ball. Cubism art style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#potential-energy",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#potential-energy",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "6 Potential energy",
    "text": "6 Potential energy\n\\[U = mgh\\]\n\n\n\nClimbing a staircase, the higher you go, the more potential energy you have stored due to the force of gravity acting on your body. Style of Pieter Bruegel the Elder’s The Tower of Babel."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#elastic-force",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#elastic-force",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "7 Elastic force",
    "text": "7 Elastic force\n\\[ F = -kx\\]\n\n\n\nBouncing a basketball, the ball compresses and stores potential energy, which is then released and converted into kinetic energy as the ball bounces back. Surrealism style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#centripetal-force",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#centripetal-force",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "8 Centripetal force",
    "text": "8 Centripetal force\n\\[F = m  \\frac{v^2}{r}\\]\n\n\n\nRiding a roller coaster, the centripetal force is what keeps you in your seat as the coaster goes around sharp turns. Neoclassicism style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#moment-of-inertia",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#moment-of-inertia",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "9 Moment of inertia",
    "text": "9 Moment of inertia\n\\[ I = m  r^2\\]\n\n\n\nA ballet dancer uses the moment of inertia to speed up in turns by pulling the arms to the center. Style like Edgar Degas."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#momentum",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#momentum",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "10 Momentum",
    "text": "10 Momentum\n\\[p = m v\\]\n\n\n\nA car collision, the momentum of the cars before and after the collision can be calculated to determine the amount of force transferred between the cars. Pop Art Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#power",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#power",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "11 Power",
    "text": "11 Power\n\\[P = \\frac{W}{t}\\]\n\n\n\nUsing a power drill to screw in a nail, the power of the drill determines how quickly the nail is driven into the wood. Renaissance painting style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#friction",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#friction",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "12 Friction",
    "text": "12 Friction\n\\[ F_f = \\mu  N\\]\n\n\n\nA child slides down a slide and is keep in place by the friction."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#bernoullis-equation",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#bernoullis-equation",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "13 Bernoulli’s equation",
    "text": "13 Bernoulli’s equation\n\\[p + \\frac{1}{2}  \\rho  v^2 + \\rho g  h = constant\\]\n\n\n\nFeeling a decrease in air pressure as a moving car passes by, this is due to the Bernoulli’s equation as the speed of the air increases. Fauvism Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#projectile-motion",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#projectile-motion",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "14 Projectile motion",
    "text": "14 Projectile motion\n\\[ y = v_0  t - \\frac{1}{2}  g  t^2\\]\n\n\n\nThrowing a ball into the air, the path it takes can be described by the equations of projectile motion. Painterly Style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#torque",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#torque",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "15 Torque",
    "text": "15 Torque\n\\[ \\tau = r  F\\]\n\n\n\nturning a doorknob, the force applied at a certain distance from the pivot point creates a torque. Style like Paul Cezanne."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-conservation-of-energy",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-conservation-of-energy",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "16 Law of conservation of energy",
    "text": "16 Law of conservation of energy\n\\[\\Delta E = \\Delta K + \\Delta U\\]\n\n\n\nA rollercoaster ride demonstrates the conservation of energy, as the potential energy of the car at the top of a hill is converted into kinetic energy as it moves downwards and vice versa.Style like Allan Rohan Crite."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-conservation-of-momentum",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-conservation-of-momentum",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "17 Law of conservation of momentum",
    "text": "17 Law of conservation of momentum\n\\[\\frac{\\delta p}{\\delta t} = 0\\]\n\n\n\nIn a game of pool, when a cue ball strikes another ball, the cue ball loses some of its momentum, but the momentum of the two balls before and after the collision must remain the same."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#hookes-law",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#hookes-law",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "18 Hooke’s law",
    "text": "18 Hooke’s law\n\\[ F = -kx\\]\n\n\n\nA trampoline follows Hooke’s law as it stretches and compresses when a person jumps on it. The greater the force, the greater the stretch or compression and vice versa. Church window style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#center-of-mass",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#center-of-mass",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "19 Center of mass",
    "text": "19 Center of mass\n\\[ x_c = \\frac{\\Sigma m_ix_i}{  \\Sigma m_i}\\]\n\n\n\nA scale can be used to find the center of mass of an object. If an object is placed on a scale unevenly, the scale will tip to one side until the center of mass is directly over the center of the scale. Japanese Painting."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-universal-gravitation",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#law-of-universal-gravitation",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "20 Law of universal gravitation",
    "text": "20 Law of universal gravitation\n\\[ F = G \\frac{ m_1  m_2}{r^2}\\]\n\n\n\nThe force of attraction between the Earth and the Moon, causing the Moon to orbit the Earth, is determined by the law of universal gravitation. Neoclassicism style."
  },
  {
    "objectID": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#from-idea-to-result",
    "href": "posts/projects/science2art/scienceart-a-lesson-in-artful-prompt-engineering.html#from-idea-to-result",
    "title": "Science2Art, a lesson in artful prompt engineering",
    "section": "21 From idea to result",
    "text": "21 From idea to result\n\n21.1 Origins\nPhysical phenoma are complex and often beautiful. Think about the vortex created through a bridge pillar. We can observe many physical equations in daily life. This led to the original question: How can a painting express a physical equation?.\nIn the beginning, I only had a few ideas, and capturing all the ideas in photos or in paintings seemed quite effortful. The entire idea landed on the pile of fancy ideas with a low effort/reward ratio.\n\n\n21.2 ChatGPT & Dalle\nThen in 2023 I discovered ChatGPT & Dalle. Most of the above images reflect the ChatGPT results from early 2023 and 2024.\nOver the cause of time, the results of Dalle got better regarding image content. The shift from DALL-E 2 to DALL-E 3 accounts for this. See this comparison. . To me, the Dalle3 images seem sometimes less artistic. However, they are more accurate with regard to the prompt.\n\n\n21.3 The outdated art of prompt engineering\nIn 2023, the issue back then was to get the content correctly created regarding image content. I used prompt engineering to get ChatGPT to write correct prompts for Dalle.\nI first used ChatGPT to generate equations found in daily life, along with examples. Then I used it to create prompts for Dalle. I added an art style which I found fitting for the context.\nSome images required tweaking to be usable.\nNowadays, in 2025, the entire process works a lot more straightforward, but as already mentioned, all images look quite similar.\nThis leads to a . Is prompt engineering actually something someone should learn? Or is it quickly becoming outdated by the use of AI agents?\nI think it all starts with the creative process of noting your thoughts and expressing what is in your mind. If you do it on a computer or to another person, this could become very similar. For the people without the skills to craft the images themselves, it provides a better interface to the world.\n\n\n21.4 Comparison 2023 vs 2024 output\nI redid some images in 2024. As mentioned before, the images are smoother but have a very identical look for an identical post to the 2023 version.\n\n\n\n\n\n\n2024 Version of a bouncing basketball.\n\n\n\n\n\n\n\n2023 Version of a bouncing basketball.\n\n\n\n\n\n\n\n\n\n\n\n2024 Version of a child on a swing.\n\n\n\n\n\n\n\n2023 Version of a child on a swing.\n\n\n\n\n\n\n\n\n\n\n\n2024 Version of a man with a powerdrill.\n\n\n\n\n\n\n\n2023 Version of a man with a powerdrill.\n\n\n\n\n\n\n\n\n\n\n\n2024 Version of a rollercoaster.\n\n\n\n\n\n\n\n2023 Version of a rollercoaster."
  },
  {
    "objectID": "posts/blogging-with-quarto.html",
    "href": "posts/blogging-with-quarto.html",
    "title": "Blogging with quarto",
    "section": "",
    "text": "Using quarto for blogging"
  },
  {
    "objectID": "posts/blogging-with-quarto.html#blogging-platform-update.",
    "href": "posts/blogging-with-quarto.html#blogging-platform-update.",
    "title": "Blogging with quarto",
    "section": "1 Blogging platform update.",
    "text": "1 Blogging platform update.\nWordPress blogging works well. There’s one caveat to my personal portfolio website. My production pipeline is slow and cumbersome. I use Obsidians vault system with one zettelkasten for all my writing. This has the benefit of having all data in text form and does not suffer from non-accessible formats in the distant future. From Obsidian I copy the text to WordPress, where I need to format it properly and finally copy it back. This duplication means I need to keep track of two databases.\nIn addition, the WordPress site requires maintennace. Albeit low effort, it is a mental effort; one other thing to keep in mind.\nAs a software engineer, I found this redundant source of truth unsatisfactory."
  },
  {
    "objectID": "posts/blogging-with-quarto.html#enter-quarto",
    "href": "posts/blogging-with-quarto.html#enter-quarto",
    "title": "Blogging with quarto",
    "section": "2 Enter Quarto",
    "text": "2 Enter Quarto\nThen I discovered quarto. Quite relevant in the data science field, it has gained a following in recent years. Jekyll is quite similar, but somehow the whole quarto experience seems more feature-rich. It effortlessly transforms repositories into websites or books.\nAnother cool feature is live content. Add the raw code to the text, which will lead to creating figures. I did this during my PhD with tikz for my figures. With quarto, it is not just figures with new formatting, it can run whole scripts to generate the entire data.\nThis becomes really handy when running Jupyter notebooks or small python programs habits, which have a small runtime, but a high development effort.\n\n2.1 The ideal blogging pipeline\n\nDo some work\nWrite about it\nCreate pleasant images\nFormat it properly\nPublish\n\nQuarto can combine steps 2 to 4 in one. It can even integrate the publishing process.\nThe main issue is not with quarto, but integrating quarto in an existing working process.\nIf you have done something for a while, you have developed habits. In a professional setting, people usually formalize those habits as processes. Introducing something new is usually challenging. It is hard to change your habits, and it is also hard to change long running processes.\nFor me, the conflict arose from using Obsidian, a zettelkasten note taking system. In addition, I was used to a WordPress based workflow.\nBut let’s dive into the details."
  },
  {
    "objectID": "posts/blogging-with-quarto.html#setting-up-quarto",
    "href": "posts/blogging-with-quarto.html#setting-up-quarto",
    "title": "Blogging with quarto",
    "section": "3 Setting up Quarto",
    "text": "3 Setting up Quarto\nThere are some cool tutorials. As a software engineer, I found the Quarto documentation very well structured. Quarto gallery has a few inspirations on how to format the blog.\nImportantly, these sources address the following more complex topics:\n\nnewsletter\ncomments\nlegal notice\ngoogle analytics\n\nSo far, I have nothing to add to those fabulous resources."
  },
  {
    "objectID": "posts/blogging-with-quarto.html#switching-to-quarto",
    "href": "posts/blogging-with-quarto.html#switching-to-quarto",
    "title": "Blogging with quarto",
    "section": "4 Switching to Quarto",
    "text": "4 Switching to Quarto\n\n4.1 Content Structure\nI put the old content in the new blog as a new platform is usually best judged with some content in it.\nThere are two things needed: a better directory structure and yaml front matters.\nI have been using Obsidian so far with a flat file structure. However, Obsidian has no issue with all nested structure, as long as the blog remains in the Obsidian vault.\nAs the blog content should still be accessible from one Obsidian vault, I put the Blog in the Zettelkasten.\nZettelkasten/\n├── blog/\n│   ├── posts/\n│   │   ├── book reviews/\n│   │   └── projects/\n│   └── normal blog posts\n└── normal zettelkasten files\n\nDoing so enables me to link from Zettel outside of the blog to the blog. The otherway round is not intended as Readers would experience dead links.\nQuarto advises to use directories to structure the content. And for a good reason. In Quarto, it is easy to generate an auto-created overview, so-called listings, for a directory. I use listings on my book reviews and projects overview pages.\nAdding the front matters was easy. Filing them with consistent content was more difficult.\nThe yaml front matter is necessary as it contains all the metadata. This data was previously in WordPress. I prefer this design as I now can change everything from within Obsidian. This mainly comprised creating yaml front matters for all my files.\nFor new Files, I have a script that adds a template.\n\n\n4.2 Using drafts\nDraft versions of blog post can be quite stable. Sometimes there is no time to finish an article, then again you want some time for the thoughts to age. The article remains in draft state.\nIn my WordPress workflow, I had two release gates. The first check occurs when copying from Obsidian to WordPress. I perform the second check before clicking “publish” on the WordPress interface.\nQuarto supports this draft state via the yaml front matter draft: true. You can render or hide drafts. The Quarto YAML defines this via.\ndraft_mode: visible\nFor the production version of my blog, I wanted no drafts. However, I found no way to change the behaviour quickly. Therefore, I decided on a custom deployment process via python script.\nUsually quarto only informs you that a post is a draft. There is no option to see all your drafts in a rendered version. I added a category draft, which gets set once the draft tag is true.\nAgain everything is done via python script.\n\n\n4.3 Output name\nWord press automatically shortens the title to something easily readable in the browser address page.\nMy zettelkasten files usually have the form: 202304170008 Decision paralysis at a McDonalds. The date shows when I created the note, not when I published the post.\nThe publishing date and the title is in the yaml front matter. I only need a easily readable webpage without spaces.\nI wrote a converter which makes this to decision-paralysis-at-a-mcdonalds for the output file.\n\n\n4.4 Dynamic Content\nAs stated before, I mainly use Obsidian. There are many discussions to get Quarto and Obsidian to work with each other, . However, none of the presented ways worked for me.\nOne enormous challenge is one of the USP of Quarto is the executing of code from the text files. To make this work, files needed to be qmd files.\nThere is an Obsidian extension: qmd as md. This plugin can currently just show the content of the file and allows editing via Obsidian. Obsidian search or graph do not work.\nI resolved the issue by naming my qmd files qmd.md. My integration pipeline then changes this to qmd for the rendering to work, as Quarto can only execute code in qmd not md files.\n\n\n4.5 Wiki links\nOne of the biggest issues is the linking. Obsidian uses wikilinks, Quarto uses Markdown links.\nI tried a lot of things: prerender script, lua filter. These approach failed because it violated the designs of Quarto: a to be rendered file can not be changed and the list of to be rendered files can not be modified by the prerender script.\nI settled on the wikilink to markdown Obsidian extension. It only lets you change one link. Changing Back does not correctly work. However, the backlinks and graph view show the markdown links correctly. The only tiring aspect is that the markdown link has %20 for spaces.\nThere is also the plugin: better markdown links. It offers more features, but did not work with my version.\nThe community seems onto this one. So I expect better results next year."
  },
  {
    "objectID": "posts/blogging-with-quarto.html#publishing-with-quarto",
    "href": "posts/blogging-with-quarto.html#publishing-with-quarto",
    "title": "Blogging with quarto",
    "section": "5 Publishing with Quarto",
    "text": "5 Publishing with Quarto\n\n5.1 Draft & Publish Directories\nSo far I have been using Hostinger with a WordPress installation. Getting my work to the blog always required manual copies.\nThe main reason to switch to Quarto was that it streamlines this quite dump part of the entire writing process. In contrast, Quarto offers support for direct publishing from the repository to a GitHub Pages enabled repository.\nWhat sounds great at first sight, proofed to be rather difficult to get to work.\nFirst, I had the issues with the draft tag and the qmd files. I resolved this issue by introduction extra directories for draft and publishing. A script then runs through all the files and checks and syncs the files. To avoid any privacy leaks, theses directories are outside of my Zettelkasten. Drawback, rendering on render preview is not instant, but requires a manual copy. Future feature: a watchdog process could resolve this.\nI then review the publish directory and push it to git, where I have setup github actions.\nThe complete pipeline is:\n\nWrite in Obsidian\nUse a command to copy to draft or publish directory\nIn draft, do a render preview. Any subsequent copy just updates the file.\nDo it with the publishing repo\nExamine new content in git\nCommit and push\nGithub renders the repo\nGithub updates the blog\n\n\n\n5.2 Large Blogs\nI noticed that quarto takes some time to render large blogs. Sometimes, there are errors and I needed to delete the render. Which could mean rendering takes a lot of time. Luckily, quarto offers GitHub actions to render your blog on the GitHub server. This has two advantages:\n\nNot blocking your system with the final render\nEasier diff, as only md source needs review\n\n\n\n5.3 Privacy Concerns & Data Leaks\nGitHub only allows GitHub pages for public repositories. If you do not feel comfortable to push the raw data of the blog to a public repository, there is a solution.\nYou need two repositories. One to store the blog source files and the second to store the rendered files with static js.\nHere are the instructions to do this in a general case.\nTo sum up the benefits:\n\nSeparation of Concerns: Keep source files private while hosting the static site publicly.\nSecurity: Sensitive files in the source repo remain private.\nVersion Control: Build files are pushed only to the public repo without cluttering the source repo’s history.\n\nFor quarto a different GitHub actions file is required:\nname: Quarto Publish\n\non:\n  push:\n    branches:\n      - master\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout source repository\n        uses: actions/checkout@v3\n\n      - name: Setup Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Configure SSH for deploy\n        run: |\n          # the deploykey is the private key. The public key is in the github pages repo\n          mkdir -p ~/.ssh\n          echo \"${{ secrets.DEPLOY_KEY }}\" &gt; ~/.ssh/id_ed25519\n          chmod 600 ~/.ssh/id_ed25519\n          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts\n\n      - name: Render\n        run: |\n          quarto render\n\n\n    # Git task\n      - name: publish\n        run: |\n          # remove git history and settings - to avoid inheritance\n          rm -rf .git\n          # re-initialise git\n          git init\n          git config user.name \"name\"\n          git config user.email \"mail@mail.com\"\n          git branch -m main\n          git remote add origin git@github.com:$USERNAME/$USERNAME.github.io.git\n          # add and commit /docs/ folder\n          git add docs\n          git commit -m \"deploy the bundle\"\n          # push the commit to the public repository\n          git push -u origin main --force"
  },
  {
    "objectID": "posts/blogging-with-quarto.html#code",
    "href": "posts/blogging-with-quarto.html#code",
    "title": "Blogging with quarto",
    "section": "6 Code",
    "text": "6 Code\nAll code can be found in https://github.com/dolind/obsidian2quarto."
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html",
    "title": "Good managers are immune to survivorship bias",
    "section": "",
    "text": "Photo by Unsplash"
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#management-in-general",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#management-in-general",
    "title": "Good managers are immune to survivorship bias",
    "section": "1 Management in general",
    "text": "1 Management in general\nGood old-fashioned capitalism tells us that a good manager increases the absolute profit of a business. The essence of good management is deriving actions from measuring business performance.\nHow many numbers of screws were produced?\nHow many defects exist per batch?\nHow expensive do we sell each screw?\nThe actions that follow from such questions are straightforward."
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#software-management-is-complex",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#software-management-is-complex",
    "title": "Good managers are immune to survivorship bias",
    "section": "2 Software management is complex",
    "text": "2 Software management is complex\nA well-touted slogan is that the software industry is not traditional assembly line work.\nSoftware is not monolithic, and interactions of the many components are complex.\nIn addition, software creation requires highly skilled workers. These workers are often better educated than managers.\nManagers usually can derive little authority from education alone. They can not just prescribe a possible solution. The software workers want to be convinced, not ordered to perform a task.\nAll this boils down to Daniel Pink’s Mastery, Purpose, and Autonomy."
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#software-management-requires-discussions-on-eye-level",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#software-management-requires-discussions-on-eye-level",
    "title": "Good managers are immune to survivorship bias",
    "section": "3 Software management requires discussions on eye level",
    "text": "3 Software management requires discussions on eye level\nMany of today’s issues can be better fixed by self-organizing teams. The decision needs to be taken on the spot. Reducing communication waste in the chain of command can lead to higher outputs."
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#researching-ideas-how-to-improve-your-business",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#researching-ideas-how-to-improve-your-business",
    "title": "Good managers are immune to survivorship bias",
    "section": "4 Researching ideas how to improve your business",
    "text": "4 Researching ideas how to improve your business\nEvery business is different. And while every manager faces similar problems, there are slightly different.\nStill, as a manager, you rarely have the time to test all the possible solutions. And coming back to the previous point, you will lose the trust of your workers if you try many things aimlessly.\nManagement books are an endless source of inspiration and improvement ideas.\nEvery year there are at least a dozen of new books. At once every decade, there comes a new management method that promises better results. All these methods present successful companies that changed something in their organization and increased profits.\nTake the Spotify model. Spotify is successful; should not all companies organize themself as Spotify did?"
  },
  {
    "objectID": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#there-is-no-yearbook-of-company-bankruptcy",
    "href": "posts/think-fast-and-slow/good-managers-are-immune-to-survivorship-bias.html#there-is-no-yearbook-of-company-bankruptcy",
    "title": "Good managers are immune to survivorship bias",
    "section": "5 There is no yearbook of company bankruptcy",
    "text": "5 There is no yearbook of company bankruptcy\nThe number and reasons why projects fail or companies go bankrupt often remain in the dark. Many companies fail due to trivial issues, like lack of funding.\nBut what about the decline of old behemoths like Kodak?\nThe issue is that these business stories rarely have statistical relevance. Applying one of the remedies to your business could help, it could not matter, or it could harm.\nThe business success stories are marked by survivorship bias.\nAnd blindly ignoring this will lead to surprises while implementing your new shiny methodology."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html",
    "href": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html",
    "title": " The perfect way that projects will never be planned",
    "section": "",
    "text": "Photo by Unsplash"
  },
  {
    "objectID": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#selling-a-project",
    "href": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#selling-a-project",
    "title": " The perfect way that projects will never be planned",
    "section": "Selling a project",
    "text": "Selling a project\nA good presentation is critical when you want to sell a project or product. You want to pitch your solution to investors or internal managers. The presentation should be lively and memorable.\nThe best presentations present a simple and emotional story that has concrete details.\nThey must present something unexpected that invites the reader to continue the story in his head. “Jaws in space” was the memorable slogan that motivated Hollywood producers to fund the film, Alien."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#planning-a-project",
    "href": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#planning-a-project",
    "title": " The perfect way that projects will never be planned",
    "section": "Planning a project",
    "text": "Planning a project\nWhen you want to plan a project properly, you best think of all the eventualities.\nThink through every step as best as you can. Avoid planning every step in detail, but all the steps should be clear. Modern techniques to do so include the creation of a feature map.\nThink of it as ascending a mountain. You do not precisely know the path or how long it will take you. Yet, you would be foolish not to have a map with you. And like with a good map, you would know in advance if you face obstacles and challenging trails at some point.\nIn your project, you should know the places of uncertainty as best as possible."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#sold-projects-are-rarely-declared-a-failure.",
    "href": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#sold-projects-are-rarely-declared-a-failure.",
    "title": " The perfect way that projects will never be planned",
    "section": "Sold projects are rarely declared a failure.",
    "text": "Sold projects are rarely declared a failure.\nUsually, projects are first sold and then adequately planned. But now comes the surprise: it should be the other way around.\nA project should be first planned and then sold. Why?\nA sold project must be completed, no matter the potential risks.\nPeople that sold the project are usually 100 % convinced by its success. They evaluate the project with an inside view. They are no longer open to a new perspective."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#the-key-stakeholders-are-sold-on-their-own-perspective",
    "href": "posts/think-fast-and-slow/the-perfect-way-that-projects-will-never-be-planned.html#the-key-stakeholders-are-sold-on-their-own-perspective",
    "title": " The perfect way that projects will never be planned",
    "section": "The key stakeholders are sold on their own perspective",
    "text": "The key stakeholders are sold on their own perspective\nOnce the project starts, new people are hired and tasked with proper planning. They usually have experience with similar projects or tasks. Like engineers do in technical questions.\nThey can imagine what paths lead to a negative outcome by comparing specific milestones and tasks to their experience. Compared with the stakeholder’s perspective, this is called the outside view. Consultants perform a similar role.\nAs these people are tasked with planning the project, questioning basic assumptions is not part of the plan. Even if consultants were hired to do that, the outside view is rarely welcome. The\nThis psychological dilemma poses a challenge for companies and venture capital firms. They will fund winning entrepreneurs with unrealistic plans.\nThat is why projects would best be planned first and then sold. Unrealistic?"
  },
  {
    "objectID": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html",
    "href": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html",
    "title": "Any fool can criticize, condemn and complain - and most fools do",
    "section": "",
    "text": "In the post tips before lunch to get more followers, I provided information on being likable."
  },
  {
    "objectID": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#cognitive-ease",
    "href": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#cognitive-ease",
    "title": "Any fool can criticize, condemn and complain - and most fools do",
    "section": "1 Cognitive ease",
    "text": "1 Cognitive ease\nBut how are these methods successful? Whether we communicate with other people verbally or non-verbally, our brain processes any sensory input of our senses.\nWe perceive the singular input, like the smell of familiar food or the noise in our favorite bar, as a cue.\nIf this cue is familiar to us, then we have a feeling of cognitive ease. We are happy to recognize something familiar. The same applies to abstract things like events, speech, or thoughts. The more we can rely on existing cues, the less alien something feels."
  },
  {
    "objectID": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#what-influences-cognitive-ease-in-communication",
    "href": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#what-influences-cognitive-ease-in-communication",
    "title": "Any fool can criticize, condemn and complain - and most fools do",
    "section": "2 What influences cognitive ease in communication",
    "text": "2 What influences cognitive ease in communication\nMost people know that the clothes you wear must fit the occasion. Nobody comes in his holiday shorts to a job interview as a bank teller. Visual appearance, manners, and speaking style add to this equation. We perceive someone as likable if he dresses the same way as us and if he has the same values. And because he is likable, he seems more trustworthy. This halo effect relies on a feeling of cognitive ease.\nIn contrast, somebody unfamiliar to us will face the full force of our intellect. We analyze all his arguments with a lot more scrutiny. We observe and analyze more rationally.\nRemember the feeling you have when you enter a new group. You are first aware of the differences or do not perceive any familiar cues. As a result, you experience neural stress. As soon as you get acquainted with the new situation, you start to relax."
  },
  {
    "objectID": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#how-to-fit-in",
    "href": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#how-to-fit-in",
    "title": "Any fool can criticize, condemn and complain - and most fools do",
    "section": "3 How to fit in",
    "text": "3 How to fit in\nYou have undoubtedly encountered situations where some people seemed more equal than others. Be it at the selection for group contests or a work promotion. Rarely are people actively discriminated against. Instead, the choice was done because their message seemed easier to understand. And because it is easier, it looks better and more authentic.\nIf you do not fit in the system 100%, be it by gender, skin color, dress style, or attitude, then you must work extra hard to replace the missing cognitive ease with other factors that can smooth the way."
  },
  {
    "objectID": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#how-a-good-mood-helps-to-smoothen-things",
    "href": "posts/think-fast-and-slow/any-fool-can-criticize-condemn-and-complain-and-most-fools-do.html#how-a-good-mood-helps-to-smoothen-things",
    "title": "Any fool can criticize, condemn and complain - and most fools do",
    "section": "4 How a good mood helps to smoothen things",
    "text": "4 How a good mood helps to smoothen things\nThe other factor is mood. The mood is like the perceived safety of our surroundings. If an environment is not safe, we have a bad mood as we constantly need to watch our back. This is why office politics affects a workforce’s long-term happiness. Inversely, showing a good attitude can provide an image of safety to other people. This “artificial” good mood can act as a balance to the missing familiarity.\nTherefore it is always good to show your bright side towards strangers and only complain towards your friends.\n\n“Any fool can criticize, condemn and complain - and most fools do.”\n– Dale Carnegie"
  },
  {
    "objectID": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html",
    "href": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html",
    "title": "Everybody wants more money and thinks inflation is unfair",
    "section": "",
    "text": "Photo by Unsplash: https://unsplash.com/photos/yRLFOE7AbDk)"
  },
  {
    "objectID": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html#why-inflation-is-not-unfair-for-poor-people",
    "href": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html#why-inflation-is-not-unfair-for-poor-people",
    "title": "Everybody wants more money and thinks inflation is unfair",
    "section": "1 Why inflation is not unfair for poor people",
    "text": "1 Why inflation is not unfair for poor people\nInflation leads to a devaluation of the borrows’ debt. At the same time, it reduces the value of the credit or real money in your possession.\nThis shift means wealthy people get poorer. People living in a lot of debt get richer.\nPoor people usually live on their salary alone. In an ideal world, wages would be affected by inflation.\nEverybody wants more money, and people would stop working if exploited there.\nCurrently, this adaptation happens in many areas of the economy, like the healthcare and the restaurant industry. The salaries are too low for the work. There are more attractive jobs elsewhere.\nPeople working on sub-living wage is only possible in a feudalistic society relying on servitude and slavery. Many people will stop working, as basic social security is often a better option, even in the USA.\nThus, wages will catch up in the long run, or businesses will go out of business."
  },
  {
    "objectID": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html#when-price-increases-are-unfair",
    "href": "posts/think-fast-and-slow/everybody-wants-more-money-and-thinks-inflation-is-unfair.html#when-price-increases-are-unfair",
    "title": "Everybody wants more money and thinks inflation is unfair",
    "section": "2 When price increases are unfair",
    "text": "2 When price increases are unfair\nCatastrophic events like war, corona, or natural disasters can increase prices due to supply shortages.\nToday, many businesses have handed down these increases to their customers. For business to business, the cost increases are often handed further to the next customer.\nWorkers usually cannot increase their price, that is, their salary directly. Instead, collective negotiations or finding a new job takes place. Small businesses currently have the same issues. If they increased their prices, their customers would stop coming.\nThe ability to increase the price relies on its own market power, also known as pricing power. To determine if you have pricing power, ask yourself, “Can you increase the price of whatever you sell”?\nPeople without pricing power see the exploitation of market power as unfair. They lose in the inflation game. Somebody else is making a huge gain, which is their loss.\nIf this did not happen, everybody would be in the same position after a complete cycle of increases. Only the rich and unproductive people would lose."
  },
  {
    "objectID": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html",
    "href": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html",
    "title": "Regression to the mean reshapes our memories",
    "section": "",
    "text": "How was your day? Was it a good day? Or was it not so good?\nThe optimists will say it was not as good as tomorrow because tomorrow will always be better.\nBut here comes the tricky question:\nWas today better than yesterday?\nAnd if yesterday was not so good, how was your last month?\nFor those that had a bad day yesterday, the last month was quite ok. For the others, the previous month was also quite ok.\n?? Does it mean we are all feeling equal about our lives?"
  },
  {
    "objectID": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#experience-vs.-memory",
    "href": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#experience-vs.-memory",
    "title": "Regression to the mean reshapes our memories",
    "section": "1 Experience vs. Memory",
    "text": "1 Experience vs. Memory\nWe all experience daily ups and downs. The anger, the joy, and the bitterness. But our mind has a natural tendency to forget the negative emotions and, as such, the attached bad events.\nOur remembered emotional curve gets smoothed out as we try to remember farther back."
  },
  {
    "objectID": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#regression-to-the-mean",
    "href": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#regression-to-the-mean",
    "title": "Regression to the mean reshapes our memories",
    "section": "2 Regression to the mean",
    "text": "2 Regression to the mean\nGood days follow bad days. And the other way around. This pattern has an excellent explanation.\nRegression to the mean. The remembered emotions are the mean.\nThe daily ups and downs are the deviations from that mean. Bad days will always follow a long series of good days.\nRegression is challenging to understand, and our mind has another natural tendency:\nIt searches for causes everywhere.\nRemember your last mishap. We try to analyze and search for a cause. We would be far better to accept the reversal and think that tomorrow will always be better,\neven though today was not good."
  },
  {
    "objectID": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#shifting-the-mean",
    "href": "posts/think-fast-and-slow/regression-to-the-mean-reshapes-our-memories.html#shifting-the-mean",
    "title": "Regression to the mean reshapes our memories",
    "section": "3 Shifting the mean",
    "text": "3 Shifting the mean\nNow I wonder what we can do to shift the mean. Is it even possible?\nMy takeaways from a quick google search :\n\nImprove sleep and meals\nGet active in the fresh air\nCreativity and self-determined success\nMeditation and reflection using a journal"
  },
  {
    "objectID": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html",
    "href": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html",
    "title": "Sticking in a shitty job, deprives you of rich experiences",
    "section": "",
    "text": "Photo by Unsplash\nPeople stay in a job they actually dislike because of the low intensity of their work life.\nDay in and day out, they perform the same actions. There is nothing they really can point the finger on that is just not right.\nAnother year has passed, and you can not remember what was special about your work year. What were your top 5 highlights?\nNo day is that bad that you would generally say that you have a shit job."
  },
  {
    "objectID": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#your-last-holiday-was-memorable.",
    "href": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#your-last-holiday-was-memorable.",
    "title": "Sticking in a shitty job, deprives you of rich experiences",
    "section": "1 Your last holiday was memorable.",
    "text": "1 Your last holiday was memorable.\nWhen we are on a holiday trip, there is usually something special. I do not mean that holiday with auntie Willis. You have visited new places, tried exotic food, and met interesting people.\nMaybe something terrible happened. You got robbed, suffered food poisoning, or were bitten by an exotic animal. Despite the negativity of the events, you will remember them until the end of your life. There are stories that you can tell when you are old.\nWhat is the difference?\nHow is remembering a bad event better than not remembering an average job experience?"
  },
  {
    "objectID": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#the-intensity-matters",
    "href": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#the-intensity-matters",
    "title": "Sticking in a shitty job, deprives you of rich experiences",
    "section": "2 The intensity matters",
    "text": "2 The intensity matters\nImagine your lifeline is like a landscape. That means your job is like a flat desert. In contrast, your holiday is like a mountain range full of cliffs, valleys, and lakes.\nThe intensity of your experience is much greater. You could be blind and still get around much of your daily life.\nThe dire events do not matter in retrospect. The holiday feels longer and richer as the duration of the two periods is wholly neglected. Your brain lives on memorable events. If your job provides none, not even bad ones, there is nothing your remembering self can feast on."
  },
  {
    "objectID": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#a-strong-remembering-self-motivates-for-the-future",
    "href": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#a-strong-remembering-self-motivates-for-the-future",
    "title": "Sticking in a shitty job, deprives you of rich experiences",
    "section": "3 A strong remembering self motivates for the future",
    "text": "3 A strong remembering self motivates for the future\nRemembering significant events becomes addictive at some point. You are always on the search for something new. Before you engage in something new, your remembering self will assess the potential for remembering events to happen. Think camping vs. safari."
  },
  {
    "objectID": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#the-dangers-of-giving-in-to-the-remembering-self",
    "href": "posts/think-fast-and-slow/sticking-in-a-shitty-job-deprives-you-of-rich-experiences.html#the-dangers-of-giving-in-to-the-remembering-self",
    "title": "Sticking in a shitty job, deprives you of rich experiences",
    "section": "4 The dangers of giving in to the remembering self",
    "text": "4 The dangers of giving in to the remembering self\nYour mind is motivated by potential future happy moments and rich experiences, so you become influenced in your decisions.\nDid you ever buy an expensive object because you thought it would lead to a richer experience? Once the object was in your possession, you were disappointed that it was just an object and nothing special happened afterward. Many buyers of luxury cars fall into this trap.\nMany of those objects have something interesting for the first time we experience them. That is actually what is the motivation for the purchase. But then the intensity dwindles.\nNo long-term happiness is to be gained. Something that is called miswanting.\nWe are indeed terrible at knowing what we want and what will lead to long-term happiness."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "",
    "text": "Discussions about bias and discrimination in artificial intelligence (AI) are growing louder. Critics argue it is unethical for technology to display discrimination. However, this critique often overlooks a fundamental truth: technology reflects the humans who create it."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#the-intersection-of-ai-bias-and-human-nature",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#the-intersection-of-ai-bias-and-human-nature",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "",
    "text": "Discussions about bias and discrimination in artificial intelligence (AI) are growing louder. Critics argue it is unethical for technology to display discrimination. However, this critique often overlooks a fundamental truth: technology reflects the humans who create it."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#the-human-touch-in-technology-design",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#the-human-touch-in-technology-design",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "2 The Human Touch in Technology Design",
    "text": "2 The Human Touch in Technology Design\nSo far, no technology has surpassed the limitations of its creators. History provides countless examples for discriminatory technology, for example, tools for right-handed individuals, inadvertently disadvantaging the left-handed population. The better alternative would have been designing for omni-dexterity, but the biases and norms of the time limited such foresight.\nSimilarly, AI and machine learning (ML) systems are shaped by the data they are trained on. Since humans select this data and curate it, the data carries the biases—conscious or unconscious—of its creators. And even if no selection is done, all available sources of the world are just an expression of human prejudices. The expectation that AI is inherently unbiased ignores the deep biases of humans."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#how-human-bias-mirrors-ai",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#how-human-bias-mirrors-ai",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "3 How Human Bias Mirrors AI",
    "text": "3 How Human Bias Mirrors AI\nInstead of looking at the bias of AI, let’s instead focus on the human prejudices and biases.\nOur intuitive brains, much like clustering algorithms in ML, categorize entities and events based on repeated exposure. Over time, this leads to the formation of stereotypes, which serve as mental shortcuts to navigate a complex world.\nFor example, imagine data represented as clusters of points on a graph. A machine learning algorithm groups similar points together, forming clusters that define categories. If new data appears outside these clusters, the model struggles to make sense of it. Humans experience a similar cognitive disruption when encountering events or behaviors that don’t fit their existing worldview.\n\n3.1 Initial bias\nImagine two dense clusters of points on a graph. These represent established categories or stereotypes based on limited data.\n\n\nShow code\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Ellipse\n# Generate data for two large, irregular clusters\nnp.random.seed(42)\n\ncluster1_x = np.random.normal(2, 1, 100)\ncluster1_y = np.random.normal(2, 1, 100)\n\ncluster2_x = np.random.normal(8, 1, 100)\ncluster2_y = np.random.normal(8, 1, 100)\n\n# Plotting the clusters\nplt.figure(figsize=(8, 6))\nplt.scatter(cluster1_x, cluster1_y, label=\"Measurements 1\", alpha=0.6)\nplt.scatter(cluster2_x, cluster2_y, label=\"Measurements 2\", alpha=0.6)\n\n\n# Adding ellipses to highlight clusters\ncluster1_ellipse = Ellipse((2, 2), width=5, height=5, edgecolor='blue', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 1\") \ncluster2_ellipse = Ellipse((8, 8), width=5, height=5, edgecolor='orange', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 2\")\n\n# Add ellipses to the plot\nplt.gca().add_patch(cluster1_ellipse)\nplt.gca().add_patch(cluster2_ellipse)\n\n# Adding titles and labels\nplt.title(\"Two Large, Irregular Clusters\", fontsize=14)\nplt.xlabel(\"X-axis\", fontsize=12)\nplt.ylabel(\"Y-axis\", fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.2 Encountering the unfamiliar\nA few smaller, isolated measurements appear. These represent data points that challenge existing categories, much like unexpected experiences disrupt human assumptions.\n\n\nShow code\nimport numpy as np\nfrom matplotlib.patches import Ellipse\nimport matplotlib.pyplot as plt\n# Generate data for two large, irregular clusters\nnp.random.seed(42)\n\ncluster1_x = np.random.normal(2, 1, 100)\ncluster1_y = np.random.normal(2, 1, 100)\n\ncluster2_x = np.random.normal(8, 1, 100)\ncluster2_y = np.random.normal(8, 1, 100)\n\ncluster3_x = np.random.normal(8, 1, 20)\ncluster3_y = np.random.normal(2, 1, 20)\n\n\n# Plotting the clusters\nplt.figure(figsize=(8, 6))\nplt.scatter(cluster1_x, cluster1_y, label=\"Measurements 1\", alpha=0.6)\nplt.scatter(cluster2_x, cluster2_y, label=\"Measurements 2\", alpha=0.6)\nplt.scatter(cluster3_x, cluster3_y, label=\"Measurements 3\", alpha=0.6)\n\n\n# Adding ellipses to highlight clusters\ncluster1_ellipse = Ellipse((2, 2), width=5, height=5, edgecolor='blue', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 1\") \ncluster2_ellipse = Ellipse((8, 8), width=5, height=5, edgecolor='orange', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 2\")\n\n# Add ellipses to the plot\nplt.gca().add_patch(cluster1_ellipse)\nplt.gca().add_patch(cluster2_ellipse)\n\n# Adding titles and labels\nplt.title(\"Unknown measurements\", fontsize=14)\nplt.xlabel(\"X-axis\", fontsize=12)\nplt.ylabel(\"Y-axis\", fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.3 Broader perspective\nExpanding the dataset reveals larger, more inclusive measurement clusters. These reflect a refined understanding, showing how more diverse exposure can reshape biases and improve predictions.\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Ellipse\n# Generate data for two large, irregular clusters\nnp.random.seed(42)\n\ncluster1_x = np.random.normal(2, 1, 3000)\ncluster1_y = np.random.normal(2, 1, 3000)\n\ncluster2_x = np.random.normal(8, 1, 3000)\ncluster2_y = np.random.normal(8, 1, 3000)\n\ncluster3_x = np.random.normal(8, 1, 3000)\ncluster3_y = np.random.normal(2, 1, 3000)\n\n\n# Plotting the clusters\nplt.figure(figsize=(8, 6))\nplt.scatter(cluster1_x, cluster1_y, label=\"Measurements 1\", alpha=0.6)\nplt.scatter(cluster2_x, cluster2_y, label=\"Measurements 2\", alpha=0.6)\nplt.scatter(cluster3_x, cluster3_y, label=\"Measurements 3\", alpha=0.6)\n\n\n# Adding ellipses to highlight clusters\ncluster1_ellipse = Ellipse((2, 2), width=5, height=5, edgecolor='blue', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 1\") \ncluster2_ellipse = Ellipse((8, 8), width=5, height=5, edgecolor='orange', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 2\")\n\n\n\n# Add ellipses to the plot\nplt.gca().add_patch(cluster1_ellipse)\nplt.gca().add_patch(cluster2_ellipse)\n\n\n# Adding titles and labels\nplt.title(\"Much more data reveals new category\", fontsize=14)\nplt.xlabel(\"X-axis\", fontsize=12)\nplt.ylabel(\"Y-axis\", fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nA Human, trained about the 3 categories, would correctly classify the following data points.\n\n\nShow code\nimport numpy as np\nfrom matplotlib.patches import Ellipse\nimport matplotlib.pyplot as plt\n# Generate data for two large, irregular clusters\nnp.random.seed(42)\n\ncluster1_x = np.random.normal(2, 1, 20)\ncluster1_y = np.random.normal(2, 1, 20)\n\ncluster2_x = np.random.normal(8, 1, 20)\ncluster2_y = np.random.normal(8, 1, 20)\n\ncluster3_x = np.random.normal(8, 1, 20)\ncluster3_y = np.random.normal(2, 1, 20)\n\n\n# Plotting the clusters\nplt.figure(figsize=(8, 6))\nplt.scatter(cluster1_x, cluster1_y, label=\"Measurements 1\", alpha=0.6)\nplt.scatter(cluster2_x, cluster2_y, label=\"Measurements 2\", alpha=0.6)\nplt.scatter(cluster3_x, cluster3_y, label=\"Measurements 3\", alpha=0.6)\n\n\n# Adding ellipses to highlight clusters\ncluster1_ellipse = Ellipse((2, 2), width=5, height=5, edgecolor='blue', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 1\") \ncluster2_ellipse = Ellipse((8, 8), width=5, height=5, edgecolor='orange', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 2\")\ncluster3_ellipse = Ellipse((8, 2), width=5, height=5, edgecolor='orange', facecolor='none', linestyle='--', linewidth=1.5, label=\"Known Category 3\")\n\n\n# Add ellipses to the plot\nplt.gca().add_patch(cluster1_ellipse)\nplt.gca().add_patch(cluster2_ellipse)\nplt.gca().add_patch(cluster3_ellipse)\n\n# Adding titles and labels\nplt.title(\"An expert knows about small categories\", fontsize=14)\nplt.xlabel(\"X-axis\", fontsize=12)\nplt.ylabel(\"Y-axis\", fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nThis is called the base rate effect. It is easily understandable when talking about categories and groups. But this base rate is also at play when we evaluate a quantity and decide whether it is good or bad."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#bridging-bias-ai-and-human-learning",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#bridging-bias-ai-and-human-learning",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "4 Bridging Bias: AI and Human Learning",
    "text": "4 Bridging Bias: AI and Human Learning\nAI bias stems from incomplete data, just as human stereotypes arise from limited exposure. Traveling to unknown places or interacting with unfamiliar cultures challenges our mental models. Think about your last holiday in an exotic location, the surprising design of a toilet or the local customs around everyday activities. These experiences reveal the narrowness of our perspective and force us to recalibrate.\nFor AI, this recalibration occurs by diversifying training data and refining algorithms to account for underrepresented groups or scenarios. For humans, it requires intentional exposure to diverse perspectives."
  },
  {
    "objectID": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#how-better-ai-development-and-ethics-can-improve-society",
    "href": "posts/think-fast-and-slow/your-mind-and-machine-learning-the-base-rate-effect.html#how-better-ai-development-and-ethics-can-improve-society",
    "title": "Your mind and machine learning, the base rate effect",
    "section": "5 How better AI development and ethics can improve society",
    "text": "5 How better AI development and ethics can improve society\nRather than seeing AI bias as uniquely outrageous and fearing the effects of AI, we should view the opportunity as a chance to improve our own behavior.\nBy acknowledging and addressing biases in ourselves and in the systems (AI or traditional) we create, we can strive for a more fair and inclusive society."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html",
    "href": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html",
    "title": "You are most likely overinsured",
    "section": "",
    "text": "Insurances are a necessary evil of the middle-aged person’s lifestyle. You are old enough to know that you may need it and too young to skip over it."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#what-insurances-are-necessary",
    "href": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#what-insurances-are-necessary",
    "title": "You are most likely overinsured",
    "section": "1 What insurances are necessary",
    "text": "1 What insurances are necessary\nInsurance should protect us from a negative outcome, like losing our health or having an expensive lawsuit.\nBANG!\nYou just dropped your phone. While you scramble to the flow, you hope the screen is not broken.\nBetter buy the insurance and never care again!\nOn the other side, insurance comes with a cost. Money that you could have spent elsewhere. And unless you are filthy rich, you probably do care. And dirty rich people do not need insurance anyway.\nThere is no unique strategy to decide whether you need insurance."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#a-strategy-to-decide-on-insurance",
    "href": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#a-strategy-to-decide-on-insurance",
    "title": "You are most likely overinsured",
    "section": "2 A strategy to decide on insurance",
    "text": "2 A strategy to decide on insurance\nWhat can help is the fourfold pattern. An Eisenhower matrix-like pattern of gains/losses and high/low certainty. \n\n\n\n\n\nCertainty\n\n\nGain\n\n\nLoss\n\n\n\n\n\n\ncertain\n\n\nRisk-averse\n\n\nHope\n\n\n\n\nuncertain\n\n\nGamble\n\n\nInsurance\n\n\n\n\n\nThe fourfold pattern\n\n\n\nThe fourfold pattern\nSuppose you face a potential loss. Think about the probability of the event. How likely is it that you will drop your phone?\nVery high? Then factor in the insurance cost to your phone price.\nBut let’s make things more complicated. Some insurance contracts do not pay in all cases. How likely are these cases to occur? Likely, then hope for the best. You will waste your money on insurance.\nThis category also applies to cases where no insurance can be bought or is too expensive. Many businesses on the downward path hope to reverse the trend and rise again."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#not-all-insurance-cost-is-transparent",
    "href": "posts/think-fast-and-slow/you-are-most-likely-overinsured.html#not-all-insurance-cost-is-transparent",
    "title": "You are most likely overinsured",
    "section": "3 Not all insurance cost is transparent",
    "text": "3 Not all insurance cost is transparent\nWhen there is something to gain, we do not need insurance. Many situations in life are uncertain. Sometimes we lose, and sometimes we win. This is called a gamble.\nAnd sometimes we always win, in any case. There is usually the option to take a save small win and an unsafe big win. Deciding on the potential big win is a gamble.\nTake, for example, your latest work project. You probably settled for something less than the maximum solution for the next milestone. This safe decision could have been driven by fear of facing your boss with empty hands if you can not deliver the big solution.\nThe insurance premium you pay is the value difference between the small and big solutions. In this case, your company paid. But you also paid because the win did not deliver into your account.\nYou might be overinsured if you are risk-averse and always refuse the gamble.\nIf you want to know more about the fourfold pattern, check out this article."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html",
    "href": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html",
    "title": "The story of Covid and Plato’s cave allegory",
    "section": "",
    "text": "Photo by Unsplash"
  },
  {
    "objectID": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#scenes-from-the-past",
    "href": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#scenes-from-the-past",
    "title": "The story of Covid and Plato’s cave allegory",
    "section": "1 Scenes from the past",
    "text": "1 Scenes from the past\nSome city before the year 2020: People rush to the metro stations at 8 o’clock in the morning. Up the stairs, down the stairs. They squeeze themselves into the already-closing doors, avoiding stepping on other people’s toes.\n\nYou drink your hot coffee in your warm seat while listening to your favorite morning motivation music.\nThen you suddenly look left and see all the other drivers looking equally frustrated towards the red traffic light, down the avenue over the thousand other cars in front of you. Dread begins to rise in the back of your mind. The meeting hour is approaching, and you are still in the car.\n\nYou work in such a socially advanced company. Once a week, you can work from home. You get a haircut and do the weekly chores when the shops are less busy. The handyman is coming. Or you are just not feeling well, and everybody prefers you take care of your germ zoo at home. Bonus points if you are allowed to leave early to fetch your kids and then continue working."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#the-present",
    "href": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#the-present",
    "title": "The story of Covid and Plato’s cave allegory",
    "section": "2 The present",
    "text": "2 The present\nNobody wants to go back to the office. And if we do, we expect fun and a good time with our coworkers. Office time is for celebration, networking, and brainstorming. It is something special. But we only need it every second week."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#entitlement-to-work-from-home-is-rooted-in-human-nature",
    "href": "posts/think-fast-and-slow/the-story-of-covid-and-platos-cave-allegory.html#entitlement-to-work-from-home-is-rooted-in-human-nature",
    "title": "The story of Covid and Plato’s cave allegory",
    "section": "3 Entitlement to work from home is rooted in human nature",
    "text": "3 Entitlement to work from home is rooted in human nature\nWorking from home has become the norm for many in the hot covid phase. It was expected to remain at home and do your eight hours of work there. Everybody experienced it, even though the equipment and comfort differed.\nMany experienced advantages they had never heard of. This makes them similar to those who left the cave with the shadow play to see the sun for the first time. Plato’s story describes that we can never return once we have seen another better reality. This shifted the social norm.\nGoing back with the knowledge of the advantages is like going to the toilet without toilet paper. You are annoyed if it is not as expected.\nAs the social norm shifted, people now feel entitled to work from home. Even without the best setup now, they expect they will have better equipment.\nRemoving the entitlement to working from will come with the same conflicts as removing entitlements to healthcare or retirement pensions. It is the current norm; therefore, the population expects it in the future. Everything else is experienced as a decisive loss."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html",
    "href": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html",
    "title": "The good storyteller is a travel guide through the listener’s memories.",
    "section": "",
    "text": "Human brains work with stories. If you have read only a handful of articles about this topic, you know that a story is helpful in convincing people. Stories are the second best thing next to the experience. Stories act as a simulator, allowing the reader to live the story mentally.\nBut what makes a good story, and why are some stories better than others? Extensive literature exists on this topic, for example, the book storytelling animal.\nToday I want to write about what makes some stories more appealing than others and the role our mind plays."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#stories-are-the-real-metaverse.",
    "href": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#stories-are-the-real-metaverse.",
    "title": "The good storyteller is a travel guide through the listener’s memories.",
    "section": "",
    "text": "Human brains work with stories. If you have read only a handful of articles about this topic, you know that a story is helpful in convincing people. Stories are the second best thing next to the experience. Stories act as a simulator, allowing the reader to live the story mentally.\nBut what makes a good story, and why are some stories better than others? Extensive literature exists on this topic, for example, the book storytelling animal.\nToday I want to write about what makes some stories more appealing than others and the role our mind plays."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#be-consistent-with-the-reader",
    "href": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#be-consistent-with-the-reader",
    "title": "The good storyteller is a travel guide through the listener’s memories.",
    "section": "2 Be consistent with the reader",
    "text": "2 Be consistent with the reader\nWe commonly understand a story’s consistency to be within the story itself. But this is only one-half of the medal. Good stories arise if the consistency stretches from the past experiences of the listener over the entirety of the story.\nLong stories usually require a long time to achieve this consistency. Some books feel dull in the beginning. Slow. Nothing seems to happen. But suddenly, you find yourself sucked into it. Characters and actions become consistent.\n\n2.1 Bring the reader into the story\nOther stories, usually the better ones, directly relate to something in our daily life. Take, for example, Harry Potter. The first few pages of the first book describe the everyday life of many children. Every person can relate to these events. Fantasy elements only start appearing by and by, allowing us to catch up. Wands and flying brooms suddenly seem very consistent in this world."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#start-where-the-people-are",
    "href": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#start-where-the-people-are",
    "title": "The good storyteller is a travel guide through the listener’s memories.",
    "section": "3 Start where the people are",
    "text": "3 Start where the people are\nUse this gradual approach in your presentations. The audience needs to hear information consistent with their worldview. Any full-blown confrontation with controversial facts will lead to strong resistance.\n\n3.1 Usage of shared experiences as priming\nImagine that you talk to climate change deniers. If you would state the experimental data and then open a discussion, you will only face a wall. However, if you slowly evoke memories of cold winters and emotional elements of increasing weather catastrophes, even the most outspoken deniers will start to discuss these events.\nThis effect is related to priming. You have set the baseline for your data by recalling singular events that may never have been an objective baseline. Recall today’s weather disasters and profoundly affect the listener’s consciousness. The vivid images will replace any memory of his comfy warm armchair.\n\n\n3.2 Usage of priming in your meetings\nA good example is the typical meeting check-in. You can ask everybody on Monday how he is feeling today. Many people are ignorant of those meeting tricks.\nBut you can influence the response by talking about something good that happened during the last work week. It is essential to speak of shared memory and direct the focus on positive thoughts. There is nothing to gain if you talk about your fancy weekend.\nIn addition, most people feel happier during their personal life than their professional life. The workweek memory establishes a positive baseline.\nUsually, people want to share something equally lovely or more admirable. As a result, they will focus on what was even more positive on their weekend."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#relate-unknown-things-to-known-things",
    "href": "posts/think-fast-and-slow/the-good-storyteller-is-a-travel-guide-through-the-listeners-memories.html#relate-unknown-things-to-known-things",
    "title": "The good storyteller is a travel guide through the listener’s memories.",
    "section": "4 Relate unknown things to known things",
    "text": "4 Relate unknown things to known things\nSometimes it isn’t easy to describe the quality of a new thing. How would you describe the internet to someone from the 17th century?\nYou can use a long explanation of what it can do and where it is. Still, you may fail.\nBetter are phrases like,\n“the internet lets you have the world’s wisdom at your fingertip.”\nMake it concrete:\n“The internet lets you see the number of cows in your country as quickly as the content of your storage cupboard.”\nRelate information by matching across different dimensions, like speed and information retrieval:\n“You can speak to distant relatives as quickly as water flows from your tap.”\nThis last approach is the most difficult to come up with but bridges the widest gap of understanding.\nNext time you present something, think about the listener’s world."
  },
  {
    "objectID": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html",
    "href": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html",
    "title": "Trust me; I am an expert",
    "section": "",
    "text": "woman sitting on sofa holding eyeglasses Photo by Unsplash\nHave you ever been fooled by an expert? The car dealer sold you a bad car? Your doctor prescribed the wrong treatment?"
  },
  {
    "objectID": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#experts-do-the-work",
    "href": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#experts-do-the-work",
    "title": "Trust me; I am an expert",
    "section": "1 Experts do the work",
    "text": "1 Experts do the work\nDo you know the famous expert videos? Seeing these videos, almost nobody wants the role of the expert. Yet our society runs and is advanced mainly on expert knowledge.\nExperts are so valued that Ph.D. is a valuable sign of expertise that people use to promote their products. A slightly less impressive expert badge is the white doctor’s coat in the hospital. These badges are there to assure us that we can trust the experts."
  },
  {
    "objectID": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#faking-expertise",
    "href": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#faking-expertise",
    "title": "Trust me; I am an expert",
    "section": "2 Faking expertise",
    "text": "2 Faking expertise\nOften people want to appear more proficient than they are. They do so to acquire our trust and, with this, the potential for favors and better deals.\nI do not want to talk about these fake experts; I have done so in another article."
  },
  {
    "objectID": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#real-experts-that-can-be-trusted",
    "href": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#real-experts-that-can-be-trusted",
    "title": "Trust me; I am an expert",
    "section": "3 Real experts that can be trusted",
    "text": "3 Real experts that can be trusted\nInstead, let’s examine when we should trust real experts.\nAn expert can be trusted, if\n\nhe works in an environment that is sufficiently regular to be predictable,\nhe has an opportunity to learn these regularities through prolonged practice\n\nThese preconditions result in skilled intuitions, that is, mental shortcuts, which can be trusted.\nExperts in mechanical skills can observe immediate feedback. Many doctors that cure common illnesses receive quick feedback from their patients."
  },
  {
    "objectID": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#real-experts-that-can-not-be-trusted",
    "href": "posts/think-fast-and-slow/trust-me-i-am-an-expert.html#real-experts-that-can-not-be-trusted",
    "title": "Trust me; I am an expert",
    "section": "4 Real experts that can not be trusted",
    "text": "4 Real experts that can not be trusted\nIrregular environments and light exposure create untrustworthy intuitions.\nDoctors that treat rare cases do not have enough experience to make reliable and intuitive judgments.\nThe same applies to many creative experts, like software developers. Many situations are so new that the lack of feedback makes it difficult to make intuitive judgments.\nEven worse is the situation for business managers. Cases are rarely comparable, and there is always a new detail.\nThese experts often replace their lack of experience with confidence in their decisions. That, however, is a dangerous path.\nKahneman pointed out, “Judgments that answer the wrong question can also be made with high confidence.”\nConfidence in the own judgment is not a good diagnostic of accuracy. Next time your doctor tells you he is confident in your treatment, ask him how many patients with similar symptoms he had."
  },
  {
    "objectID": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html",
    "href": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html",
    "title": "Here is what I learned from thinking fast and slow.",
    "section": "",
    "text": "Almost everyone agrees that you should read good books. Few people do. And even less are able to recall important lessons of the book after some time.\nHow to remember the content from good books? The usual approach is to summarize a book and extract its key lessons. Blinkist and many other summary websites splendidly do this.\nIn my opinion, this approach hinders us from learning from a book. Learning from books is mainly enabled by the exercise of written ideas. We can directly transfer the prescribed methods to our reality, like recipes from a cookbook.\nThis approach is limited when applied to more abstract topics such as management or thinking. Insights about thinking are difficult to understand and even more cumbersome to use.\nIn my opinion, the book is only a teacher. It can show you the general rules. But to digest the book, you must apply the rules to your own life. And the quickest way to do that is to write about such occasions. Writing is much more condensed than waiting for the next experience when you can apply the rules. By writing, you tell your own stories and create your own simulator.\nThe topics that interest me are software development, storytelling, self-improvement, and money.\nSo let’s talk about Thinking, Fast and Slow. I read the book in 2021, and spend most of the year of 2022 to come up with article ideas. I think it is a fantastic book, which anybody ought to have read, as it deepens your understanding of the human mind. Kahneman, who died this year, got the Nobel prize for his work and this book contains much of his knowledge."
  },
  {
    "objectID": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#software-development",
    "href": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#software-development",
    "title": "Here is what I learned from thinking fast and slow.",
    "section": "1 Software development",
    "text": "1 Software development\n\n1.1 Programming\nAs a programmer, it is easy to be dragged into your code. You spent hours in front of it, only to resurface and see that you were solving the wrong issue. Why that is so can be learned in: Experienced engineers stay away from the flow zone\nAt some point in your career, you have to decide. Do you want to be an expert or remain a generalist? As a decision help, Look at your industrys state and then decide if you want to become an expert.\nMost engineers dislike PowerPoint and the management presentations that go along with it. There is a reason for it. As engineers, we are fond of small details. Later we wonder why our reporting is not well received. What you should do instead can be learned in Why engineers do not understand stories.\n\n\n1.2 Planning\nPlanning is everybody’s favorite activity in software development. Plannings are always off.\nWant to try something new? Try to establish your next planning predictions on well-defined reference points.\nStill, uncertainty is inherent to all software development. If too much complexity exists, tasks can not be well planned. Use risk policies and avoid common planning fallacies in software development\nAt one point in the planning cycle, we always refer to the experts to provide estimates. The issue is not whether you have good experts at hand, but if you should trust your real experts, Trust me; I am an expert.\nOnce a plan is done, we vote on it. High uniform confidence reveals a lack of trust. The SAFe confidence vote reveals the state of emotional security in your project.\nFailures settle the history of software engineers like skeletons on the trail through a desert.\nThorough planning should come before the pitching. It is never done so but would avoid failures. The perfect way that projects will never be planned.\nOne important aspect of planning is to control the success of the plan. Control with regard to efficiency of operation: are you doing all plan tasks. As well as control of effectivity: are the plan tasks doing the right thing. The last aspect is certainly the most challenging in planning and management. Many business books are successfully selling recipes how to deal with both challenges. Most of the time such recipes are biased by survivorship biased and overconfidence. Taylorism in complex environmentsdeals with the second aspect. Personal confidence does not replace a statistical analysis. Yet we often use KPIs to give our opinions a statistical backing.\n\n\n1.3 Management\nMany articles are trying to create a fissure between software developers and management. Some aspects might be accurate, but what also remains true? No software industry without leadership.\nI have three articles, one for the managers:\nGood managers are immune to survivorship bias. I wrote these articles in the post covid phase in 2022. At this time the back to office debate started.\nYou should go back to the office, to help your boss understand you\nMy last article is details why we will not all return to the office. The story of Covid and Platos cave allegory"
  },
  {
    "objectID": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#storytelling",
    "href": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#storytelling",
    "title": "Here is what I learned from thinking fast and slow.",
    "section": "2 Storytelling",
    "text": "2 Storytelling\nI started my journey to learn about storytelling and how understanding the mind helps us be better storytellers.\nFirst, start your story from the listener’s memory 202208041700 The good storyteller is a travel guide through the listeners memories.\nIf you need to give an engineering or science presentation and have bad news, learn Providing fake reliability with statistics.\nIn addition, do not focus on the 100 % correct picture: Why engineers do not understand stories This is certainly I, as an engineer struggle the most with.\nLast but not least, try to keep a happy face, because Any fool can criticize, condemn and complain - and most fools do."
  },
  {
    "objectID": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#self-improvement",
    "href": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#self-improvement",
    "title": "Here is what I learned from thinking fast and slow.",
    "section": "3 Self Improvement",
    "text": "3 Self Improvement\nThe topic of rhetoric and storytelling is a reoccurring theme in the big cluster of self-improvement.\nI read my fair share of articles.\nTo keep yourself energizedAvoid spending mental energy as if would be limitless. If you find yourself in a tricky situation, try to Use mental anchors to determine the start position of high-stakes discussions.\nDo you sometimes wonder why we remember certain things and others do not? That is because Regression to the mean reshapes our memories.\nAnd why is your holiday always more memorable than your breakfast. If there are no extremes, bad/good, we can not make lasting memories: Sticking in a shitty job, deprives you of rich experiences."
  },
  {
    "objectID": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#money",
    "href": "posts/think-fast-and-slow/here-is-what-i-learned-from-thinking-fast-and-slow.html#money",
    "title": "Here is what I learned from thinking fast and slow.",
    "section": "4 Money",
    "text": "4 Money\nMoney is undoubtedly the hottest topic out there in the blogosphere, web. 2.0, and web 3.0. We all want to be millionaires, but Investors are living from the greatest of all treasures, which is Hope. Inspired by an opening of Terry Pratchetts books.\nIf you are not raffling millions on the stock market, you might try to get into your own business and learn, There are no losses; just costs for profits.\nOn the other hand, it is always good to be frugal. And one aspect of being frugal is not buying everything special deal, including insurance.\nNot all insurance costs are transparent; if you are too careful, you forgo good opportunities, You are most likely overinsured.\nInflation was the topic of 2022, therefore last but not least, you maybe wonder why, ;Everybody wants more money and thinks inflation is unfair."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html",
    "title": "Why engineers do not understand stories",
    "section": "",
    "text": "Let’s consider the 0.001 % corner case and make it 80 % of our work.\nThe problem: this level of detail is hard to impossible to explain. To get to 0.1 %, you must present the big picture and add some details. From there, it is still a way to go to 0.001 %.\nIt is impossible to tell the accurate picture to a novice in the field.\nAnd most often, the novice in the field can be your customer or your boss."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#in-love-with-details",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#in-love-with-details",
    "title": "Why engineers do not understand stories",
    "section": "",
    "text": "Let’s consider the 0.001 % corner case and make it 80 % of our work.\nThe problem: this level of detail is hard to impossible to explain. To get to 0.1 %, you must present the big picture and add some details. From there, it is still a way to go to 0.001 %.\nIt is impossible to tell the accurate picture to a novice in the field.\nAnd most often, the novice in the field can be your customer or your boss."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#telling-a-story",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#telling-a-story",
    "title": "Why engineers do not understand stories",
    "section": "2 Telling a story",
    "text": "2 Telling a story\nThe point is that 100 % truth is unnecessary to achieve the goal. The goal is to convince your customer/superior to provide additional funding for an idea you have.\nIt would be best if you instilled confidence that your idea is the one that can solve the problem."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#details-add-credibility",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#details-add-credibility",
    "title": "Why engineers do not understand stories",
    "section": "3 Details add credibility",
    "text": "3 Details add credibility\nWell, then, let’s tell only a superficial account of our idea! What about this story: Man was born, angered the authorities, and was crucified?\nDoes it not sound too appealing? What about: Man was born, angered the authorities by declaring he was god’s son and delivering his message, for this, he was crucified.\nThe second one is much more interesting. It adds some intriguing detail to the story.\nNow comes twitch. The religious blasphemers were only a tiny part of all the men born and crucified.\nIn other words, a more detailed story is less likely to occur. Details reduce the probability. But credible elements increase persuasiveness."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#the-brain-does-not-understand-relativity.",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#the-brain-does-not-understand-relativity.",
    "title": "Why engineers do not understand stories",
    "section": "4 The brain does not understand relativity.",
    "text": "4 The brain does not understand relativity.\nThis logical fallacy comes from the fact that our brain is slow to process relative information. In many situations, we make quick guesses that rely on absolute numbers.\nIf you buy a drink for 5$ and get 0.5$ off during the happy hour, this sounds better than 5$ and 10% off.\n50¢ is a level of detail that is easier to grasp than 10 %. And 0.5$ sounds better than 50¢."
  },
  {
    "objectID": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#focus-on-the-big-picture",
    "href": "posts/think-fast-and-slow/why-engineers-do-not-understand-stories.html#focus-on-the-big-picture",
    "title": "Why engineers do not understand stories",
    "section": "5 Focus on the big picture",
    "text": "5 Focus on the big picture\nSo next time, focus on the big picture, sprinkle it with some small convincing details, and avoid relative numbers."
  },
  {
    "objectID": "Influences & Reading Notes.html",
    "href": "Influences & Reading Notes.html",
    "title": "Influences & Reading Notes",
    "section": "",
    "text": "These essays explore ideas from books that have shaped how I think about systems, learning, and communication.\nRather than one-page reviews, they distill insights that connect directly to my work in software engineering."
  },
  {
    "objectID": "Influences & Reading Notes.html#influence-by-r.-cialdini",
    "href": "Influences & Reading Notes.html#influence-by-r.-cialdini",
    "title": "Influences & Reading Notes",
    "section": "Influence by R. Cialdini",
    "text": "Influence by R. Cialdini\n\n\n\n\n\n\n\n\nThe world requires influential engineers with a passion for stories\n\n\n\n\n\n\n\n\n\n\nSuccessful cross-functional teams need the luxury of confidence and trust\n\n\n\n\n\n\n\n\n\n\nThree old but trusted ways to reveal your team’s common story\n\n\n\n\n\n\n\n\n\n\nGood presenters embrace these psycho tips in their life\n\n\n\n\n\n\n\n\n\n\nThe science of influence and storytelling\n\n\n\n\n\n\n\n\n\n\nTry these 9 tips to get more and stronger follower growth\n\n\n\n\n\n\n\n\n\n\nTry these priceless mental tricks to gain the upper hand in pointless conflicts\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Influences & Reading Notes.html#clean-architecture-by-r.-c.-martin",
    "href": "Influences & Reading Notes.html#clean-architecture-by-r.-c.-martin",
    "title": "Influences & Reading Notes",
    "section": "Clean Architecture by R. C. Martin",
    "text": "Clean Architecture by R. C. Martin\n\n\n\n\n\n\n\n\nSuccessful teams strike the right Balance between Immediate Needs with Long-Term Architecture\n\n\n\n\n\n\n\n\n\n\nObject oriented programming for AI Projects\n\n\n\n\n\n\n\n\n\n\nHow Poor Architectural Understanding is Impacting the German Software Industry\n\n\n\n\n\n\n\n\n\n\nTop-Down Thinking is Holding Back Software Innovation\n\n\n\n\n\n\n\n\n\n\nClean coders use lambda expressions\n\n\n\n\n\n\n\n\n\n\nPremature optimization and the importance of algorithms\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Influences & Reading Notes.html#made-to-stick-by-c-d.-heath",
    "href": "Influences & Reading Notes.html#made-to-stick-by-c-d.-heath",
    "title": "Influences & Reading Notes",
    "section": "Made to stick by C & D. Heath",
    "text": "Made to stick by C & D. Heath\n\n\n\n\n\n\n\n\nBreaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication\n\n\n\n\n\n\n\n\n\n\nHow to avoid burying the lead\n\n\n\n\n\n\n\n\n\n\nHow domain driven design makes software development concrete and abstract\n\n\n\n\n\n\n\n\n\n\nEngineering presentations that stick\n\n\n\n\n\n\n\n\n\n\nDecision paralysis at a McDonalds\n\n\n\n\n\n\n\n\n\n\nWhat is wrong about the pattern tell them what you are going to tell, tell and then tell what you told\n\n\n\n\n\n\n\n\n\n\nThe Stickiness Improvement Plan\n\n\n\n\n\n\n\n\n\n\nGet huge benefits for minimal costs after reading\n\n\n\n\n\n\n\n\n\n\nThe one thing missing in your perfect presentation\n\n\n\n\n\n\n\n\n\n\nThree basic plots - my take\n\n\n\n\n\n\n\n\n\n\nFrom Challenges to Champions: Unsticking Negative Workplace Stories\n\n\n\n\n\n\n\n\n\n\nUnlock the Power of Metaphors at Work to Captivate Your Listeners!\n\n\n\n\n\n\n\n\n\n\nWaterfall management is a strict recipe, while agility is improvisational cooking.\n\n\n\n\n\n\n\n\n\n\nEffective Story Spotting\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Influences & Reading Notes.html#thinking-fast-and-slow-by-d.-kahnemann",
    "href": "Influences & Reading Notes.html#thinking-fast-and-slow-by-d.-kahnemann",
    "title": "Influences & Reading Notes",
    "section": "Thinking, Fast and Slow by D. Kahnemann",
    "text": "Thinking, Fast and Slow by D. Kahnemann\n\n\n\n\n\n\n\n\nYour mind and machine learning, the base rate effect\n\n\n\n\n\n\n\n\n\n\nHere is what I learned from thinking fast and slow.\n\n\n\n\n\n\n\n\n\n\nTaylorism in complex environments\n\n\n\n\n\n\n\n\n\n\nUse risk policies and avoid common planning fallacies in software development\n\n\n\n\n\n\n\n\n\n\nInvestors are living from the greatest of all treasures, which is Hope\n\n\n\n\n\n\n\n\n\n\nThe story of Covid and Plato’s cave allegory\n\n\n\n\n\n\n\n\n\n\nSticking in a shitty job, deprives you of rich experiences\n\n\n\n\n\n\n\n\n\n\nEverybody wants more money and thinks inflation is unfair\n\n\n\n\n\n\n\n\n\n\nGood managers are immune to survivorship bias\n\n\n\n\n\n\n\n\n\n\nThe perfect way that projects will never be planned\n\n\n\n\n\n\n\n\n\n\nTrust me; I am an expert\n\n\n\n\n\n\n\n\n\n\nLook at your industry’s state and then decide if you want to become an expert\n\n\n\n\n\n\n\n\n\n\nThe SAFe confidence vote reveals the state of emotional security in your project\n\n\n\n\n\n\n\n\n\n\nYou should go back to the office, to help your boss understand you\n\n\n\n\n\n\n\n\n\n\nUse mental anchors to determine the start position of high-stakes discussions\n\n\n\n\n\n\n\n\n\n\nTry to establish your next planning predictions on well-defined reference points\n\n\n\n\n\n\n\n\n\n\nThe good storyteller is a travel guide through the listener’s memories.\n\n\n\n\n\n\n\n\n\n\nYou are most likely overinsured\n\n\n\n\n\n\n\n\n\n\nThere are no losses; just costs for profits\n\n\n\n\n\n\n\n\n\n\nRegression to the mean reshapes our memories\n\n\n\n\n\n\n\n\n\n\nWhy engineers do not understand stories\n\n\n\n\n\n\n\n\n\n\nExperienced engineers stay away from the flow zone\n\n\n\n\n\n\n\n\n\n\nAvoid spending mental energy as if would be limitless\n\n\n\n\n\n\n\n\n\n\nProviding fake reliability with statistics\n\n\n\n\n\n\n\n\n\n\nAny fool can criticize, condemn and complain - and most fools do\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Influences & Reading Notes.html#laws-of-leadership-by-j.-c.-maxwell",
    "href": "Influences & Reading Notes.html#laws-of-leadership-by-j.-c.-maxwell",
    "title": "Influences & Reading Notes",
    "section": "21 laws of leadership by J. C. Maxwell",
    "text": "21 laws of leadership by J. C. Maxwell\n\n\n\n\n\n\n\n\nWorld Sensation, Why remarkably nobody has built your leadership\n\n\n\n\n\n\n\n\n\n\nEffective leaders listen for stories that touch the heart and mind\n\n\n\n\n\n\n\n\n\n\n4 powerful secrets medium user need to know about leadership\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "all projects.html",
    "href": "all projects.html",
    "title": "All Projects",
    "section": "",
    "text": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers\n\n3 min\n\nA hands-on demo exploring how Kubernetes Horizontal Pod Autoscaling behaves under real, chaotic load, and why this matters even for ML and embedded engineers.\n\n\n\nNov 21, 2025\n\n\n\n\n\n\n\n\n\n\n\nC++ in your Browser. Is WebAssembly worth the effort?\n\n5 min\n\nMy experiment of getting C++ delivered to the browser. Find out the why and see why client-side compute is cheap and expensive at the same time.\n\n\n\nNov 19, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe Hidden Cost of “Magic” Schemas\n\n4 min\n\nWhen DRY turns to dust: what I learned after letting automation define my API contracts. A story about boundaries, intent, and why hand-written schemas age better than…\n\n\n\nNov 8, 2025\n\n\n\n\n\n\n\n\n\n\n\nCan AI fix your shopping list?\n\n9 min\n\nMany shopping apps can create shopping lists. But many apps fail to correctly aggregate similar items. Let’s discover if AI can help.\n\n\n\nNov 4, 2025\n\n\n\n\n\n\n\n\n\n\n\nWhen to use pydantic in your app?\n\n6 min\n\n“Should we wrap this in a BaseModel or just slap a @dataclass on it”? If that debate keeps popping up in code-reviews, this post is for you.\n\n\n\nOct 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nHow LLMs help and don’t help developing software\n\n14 min\n\nThere is a lot of debate if LLMs actually help software developers. Here’s what i learned rebuilding a simple image pipeline with regard to thinking, focus and failure in…\n\n\n\nOct 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPage Segmentation: The easy and the hard way\n\n13 min\n\nAn OCR scan of a whole page of a complex layout can be done two ways. The easy expensive one using an LLM or the more sophisticated one, which is harder to develop but…\n\n\n\nOct 24, 2025\n\n\n\n\n\n\n\n\n\n\n\nIs training your own classifier really worth it?\n\n3 min\n\nI small update to the longer update. We use a YOLO-doclayout to decide if it is a text or image.\n\n\n\nOct 2, 2025\n\n\n\n\n\n\n\n\n\n\n\nText or Image\n\n5 min\n\nRunning Document digitization pipelines can be expensive. Especially if you pay per API request. A good triage of pages is helping to reduce costs. In this notebook we…\n\n\n\nSep 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeauty is in the eye of the beholder\n\n12 min\n\nAutomatically generating thumbnails from pictures, can lead to bad crops or small details. Saliency Maps allow us to focus on the dominant object in a picture. I use…\n\n\n\nSep 5, 2025\n\n\n\n\n\n\n\n\n\n\n\nHow Neural Networks Hear Music\n\n19 min\n\nDid you ever wonder how Spotify, Tidal or YouTube work? Why are they suggesting a song to you?. Sometimes the suggestions are quite good. Come with we on a visual journey…\n\n\n\nJul 15, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner - part 2\n\n7 min\n\nBack from the Dead, driven by AI Agent\n\n\n\nJul 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner\n\n6 min\n\nPart I: What happened so far\n\n\n\nJul 3, 2025\n\n\n\n\n\n\n\n\n\n\n\nDo you know the hidden paths of your code?\n\n21 min\n\nMost software is complex. Especially with AI-assisted coding, complexity can quickly run out of hands and turn into a nightmare. To never get lost again, let’s create the…\n\n\n\nMay 14, 2025\n\n\n\n\n\n\n\n\n\n\n\nStreet view game - hit the road\n\n7 min\n\nHit the road allows you to sit back and enjoy the scenary when using Google street view. You can look around while you advance. Very much the same as you would in a car.\n\n\n\nApr 26, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe road less travelled - from the dijkstras shortest path to the least visited path\n\n5 min\n\nWhat if you are not interested in getting as fast as possible from A to B. But you always search a new path. A python adventure to discover new places.\n\n\n\nMar 25, 2025\n\n\n\n\n\n\n\n\n\n\n\nWhich cheese are we eating?\n\n11 min\n\nDid you ever wonder what kind of cheese you should buy? They all look the same. And then the embarrasement when you can just point and say: that one. Meet the cheese…\n\n\n\nMar 13, 2025\n\n\n\n\n\n\n\n\n\n\n\nScience2Art, a lesson in artful prompt engineering\n\n11 min\n\nHow can physical equations be expressed in a paintings? In the beginning I only had a few ideas and the whole process was very effortful. Then in 2023, I discovered ChatGPT.…\n\n\n\nJan 15, 2025\n\n\n\n\n\n\n\n\n\n\n\nHow to fight computer eye strain\n\n3 min\n\nAt least for your eyes and your back computer work puts a tremendous strain. This is what can help.\n\n\n\nDec 3, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers\n\n\n\nSoftware Engineering\n\nApplied Engineering\n\n\n\nA hands-on demo exploring how Kubernetes Horizontal Pod Autoscaling behaves under real, chaotic load, and why this matters even for ML and embedded engineers.\n\n\n\n\n\nNov 21, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nC++ in your Browser. Is WebAssembly worth the effort?\n\n\n\nC++\n\nApplied Engineering\n\nSoftware Engineering\n\n\n\nMy experiment of getting C++ delivered to the browser. Find out the why and see why client-side compute is cheap and expensive at the same time.\n\n\n\n\n\nNov 19, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nWriting, Doing, and Building an ML Productivity Pipeline\n\n\n\nMachine Learning\n\nKnowledge Work\n\nSoftware Engineering\n\n\n\nHow I balance writing and rapid prototyping to learn ML faster: using Jupyter, Kaggle, Hugging Face, and Quarto to turn experiments into publishable apps.\n\n\n\n\n\nNov 11, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nThe Hidden Cost of “Magic” Schemas\n\n\n\nSoftware Engineering\n\nPython\n\n\n\nWhen DRY turns to dust: what I learned after letting automation define my API contracts. A story about boundaries, intent, and why hand-written schemas age better than auto-generated ones.\n\n\n\n\n\nNov 8, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nCan AI fix your shopping list?\n\n\n\nMachine Learning\n\nApplied Engineering\n\n\n\nMany shopping apps can create shopping lists. But many apps fail to correctly aggregate similar items. Let’s discover if AI can help.\n\n\n\n\n\nNov 4, 2025\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\nWhen to use pydantic in your app?\n\n\n\nPython\n\nSoftware Engineering\n\n\n\n“Should we wrap this in a BaseModel or just slap a @dataclass on it”? If that debate keeps popping up in code-reviews, this post is for you.\n\n\n\n\n\nOct 28, 2025\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nHow LLMs help and don’t help developing software\n\n\n\nSoftware Engineering\n\nManagement\n\nGenerative AI\n\n\n\nThere is a lot of debate if LLMs actually help software developers. Here’s what i learned rebuilding a simple image pipeline with regard to thinking, focus and failure in the age of large language models.\n\n\n\n\n\nOct 25, 2025\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nPage Segmentation: The easy and the hard way\n\n\n\nPython\n\nComputer Vision\n\nMachine Learning\n\nGenerative AI\n\n\n\nAn OCR scan of a whole page of a complex layout can be done two ways. The easy expensive one using an LLM or the more sophisticated one, which is harder to develop but cheaper to run.\n\n\n\n\n\nOct 24, 2025\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\nIs training your own classifier really worth it?\n\n\n\nComputer Vision\n\nMachine Learning\n\nPython\n\n\n\nI small update to the longer update. We use a YOLO-doclayout to decide if it is a text or image.\n\n\n\n\n\nOct 2, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nText or Image\n\n\n\nComputer Vision\n\nMachine Learning\n\nPython\n\n\n\nRunning Document digitization pipelines can be expensive. Especially if you pay per API request. A good triage of pages is helping to reduce costs. In this notebook we separate pages full of text from pages with only images.\n\n\n\n\n\nSep 29, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nBeauty is in the eye of the beholder\n\n\n\nComputer Vision\n\nMachine Learning\n\nPython\n\n\n\nAutomatically generating thumbnails from pictures, can lead to bad crops or small details. Saliency Maps allow us to focus on the dominant object in a picture. I use multimodal aesthetic scoring models to evaluate the crops.\n\n\n\n\n\nSep 5, 2025\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\nWhat I have been reading: What is a ml compiler\n\n\n\nC++\n\nMachine Learning\n\nApplied Engineering\n\n\n\nLately, I’ve been digging into machine learning (ML) compilers and how they differ from traditional software compilers.\n\n\n\n\n\nAug 31, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nChoosing the Right Metric for Classification Models\n\n\n\nMachine Learning\n\nData Science\n\n\n\nIn this post, we explore various classification metrics: accuracy, precision, recall, F1-score, and AUC-ROC.\n\n\n\n\n\nAug 29, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nAvoiding Python version chaos in ML\n\n\n\nMachine Learning\n\nSoftware Engineering\n\nPython\n\n\n\nWorking with machine learning often means juggling multiple Python versions, CUDA drivers, TensorFlow/PyTorch builds, and environment conflicts. Let’s checkout how docker can help us to ease the version pain. Say goodbye to “works on my machine” and Python hell.\n\n\n\n\n\nAug 28, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nHow Neural Networks Hear Music\n\n\n\nComputer Vision\n\nGenerative AI\n\nPython\n\n\n\nDid you ever wonder how Spotify, Tidal or YouTube work? Why are they suggesting a song to you?. Sometimes the suggestions are quite good. Come with we on a visual journey through AI playlists.\n\n\n\n\n\nJul 15, 2025\n\n19 min\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner - part 2\n\n\n\nSoftware Engineering\n\nGenerative AI\n\nPython\n\n\n\nBack from the Dead, driven by AI Agent\n\n\n\n\n\nJul 7, 2025\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nFrom damping factor to learning rate\n\n\n\nMachine Learning\n\nApplied Engineering\n\n\n\nMachine learning is in the center of the AI hype. But what does “learning” actually mean? We look behind the jargon and compare to another popular field computational mechanics.\n\n\n\n\n\nJul 5, 2025\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nBlog Update July 2025\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\nTime for some fresh paint\n\n\n\n\n\nJul 4, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner\n\n\n\nSoftware Engineering\n\nMachine Learning\n\nPython\n\nC++\n\n\n\nPart I: What happened so far\n\n\n\n\n\nJul 3, 2025\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nDo you know the hidden paths of your code?\n\n\n\nSoftware Engineering\n\nPython\n\n\n\nMost software is complex. Especially with AI-assisted coding, complexity can quickly run out of hands and turn into a nightmare. To never get lost again, let’s create the zoom button for software that turns your code into a zommable map.\n\n\n\n\n\nMay 14, 2025\n\n21 min\n\n\n\n\n\n\n\n\n\n\n\nBreaking the Curse of Knowledge: Why Simplicity is the Ultimate Sophistication\n\n\n\nKnowledge Work\n\nStorytelling\n\nLeadership\n\n\n\nUnderstanding doesn’t always mean communicating effectively. You have a choice: become stupid or learn how to overcome the Curse of Knowledge, simplify ideas, and make them stick.\n\n\n\n\n\nApr 27, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nStreet view game - hit the road\n\n\n\nComputer Vision\n\nC++\n\nApplied Engineering\n\n\n\nHit the road allows you to sit back and enjoy the scenary when using Google street view. You can look around while you advance. Very much the same as you would in a car.\n\n\n\n\n\nApr 26, 2025\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nWhat I learned about risk management\n\n\n\nManagement\n\nLeadership\n\nKnowledge Work\n\n\n\nThis guide includes my experience and research around the often difficult question in project management, “What is a business risk, and what is just our daily work?”\n\n\n\n\n\nApr 24, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nThe triangle of trust reveals your projects issues.\n\n\n\nAgile\n\nStorytelling\n\n\n\nSomewhere out there, a remote project is teetering on the edge of failure. Let’s see how much of this can be attributed to the remote environment and how much is a classic leadership issue. The triangle of trust let’s you turn this situation around.\n\n\n\n\n\nApr 20, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nWhy the Fishbone Diagram Triumphs Over 5 Whys\n\n\n\nManagement\n\nAgile\n\n\n\nDiscover why the Fishbone Diagram outshines the 5 Whys in solving complex problems, fostering teamwork, and avoiding blame. Learn which method suits your team best for effective and collaborative problem-solving.\n\n\n\n\n\nApr 17, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nHow to avoid burying the lead\n\n\n\nKnowledge Work\n\nStorytelling\n\n\n\nA failed presentation on metal strength taught me a powerful lesson in communication. Learn to apply journalistic techniques — leading with key points, forced priorization, and using the inverted pyramid structure — you too can avoid burying the lead and nail your presentations\n\n\n\n\n\nApr 15, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThe road less travelled - from the dijkstras shortest path to the least visited path\n\n\n\nPython\n\nSoftware Engineering\n\n\n\nWhat if you are not interested in getting as fast as possible from A to B. But you always search a new path. A python adventure to discover new places.\n\n\n\n\n\nMar 25, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nHow domain driven design makes software development concrete and abstract\n\n\n\nSoftware Engineering\n\nKnowledge Work\n\nStorytelling\n\n\n\nIn the world of technology it’s worth examining whether abstraction truly helps us connect. If anything, abstraction often obscures, complicating both understanding and memory. Concreteness, on the other hand, breaks through barriers, simplifying communication and amplifying retention.\n\n\n\n\n\nMar 24, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nEngineering presentations that stick\n\n\n\nStorytelling\n\nApplied Engineering\n\nKnowledge Work\n\n\n\nMake your next presentation remarkable\n\n\n\n\n\nMar 23, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nWhich cheese are we eating?\n\n\n\nMachine Learning\n\nComputer Vision\n\nPython\n\n\n\nDid you ever wonder what kind of cheese you should buy? They all look the same. And then the embarrasement when you can just point and say: that one. Meet the cheese classifier.\n\n\n\n\n\nMar 13, 2025\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\nYour mind and machine learning, the base rate effect\n\n\n\nMachine Learning\n\nMental Models\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nSuccessful teams strike the right Balance between Immediate Needs with Long-Term Architecture\n\n\n\nManagement\n\nSoftware Engineering\n\n\n\nIn the world of software development, frustration often emerges when a product behaves in a way that users find counterintuitive or outright inconvenient. When questioned, the response might be disheartening: It’s in the requirements. This sheds light on a deeper issue—the conflict between immediate deliverables and long-term system health.\n\n\n\n\n\nMar 7, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nObject oriented programming for AI Projects\n\n\n\nPython\n\nData Science\n\nSoftware Engineering\n\n\n\nDiscover what can can transform your AI project into clean, efficient, and scalable software\n\n\n\n\n\nMar 6, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nHow Poor Architectural Understanding is Impacting the German Software Industry\n\n\n\nSoftware Engineering\n\nLeadership\n\n\n\nWeak software architecture can topple even the most promising projects, inflating costs and frustrating everyone from CFOs to developers. Explore the failure of quick fixes with me and what a tortoise has to do with it.\n\n\n\n\n\nFeb 25, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nTop-Down Thinking is Holding Back Software Innovation\n\n\n\nSoftware Engineering\n\nManagement\n\n\n\nA thought about dependency inversion.\n\n\n\n\n\nFeb 22, 2025\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nBe careful using python’s dataclass\n\n\n\nPython\n\nSoftware Engineering\n\n\n\nPython’s @dataclass is a powerful tool for creating data containers with minimal boilerplate code. However, it introduces a subtle pitfall when working with mutable defaults like lists or NumPy arrays. This article explores this common issue, its root cause, and how to fix it effectively.\n\n\n\n\n\nFeb 18, 2025\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nMilestone vs Activity Planning: Finding the Right Approach for Your Project Management\n\n\n\nManagement\n\nLeadership\n\nAgile\n\n\n\nI was at a pivotal point in my project management career with a high-stakes project on the line. I needed to find the key to keeping my team focused and motivated. As I explored milestone and activity planning, I discovered valuable insights about each approach. In this article, I’ll share my journey and how it led to a turning point in my career.\n\n\n\n\n\nFeb 15, 2025\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nDecision paralysis at a McDonalds\n\n\n\nKnowledge Work\n\nLeadership\n\n\n\nStuck staring at the McDonald’s menu, always ordering the same thing? You’re not alone—it’s called decision paralysis, and it’s sabotaging more than just your lunch. Discover how it’s creeping into your work life and learn how to stop it before it derails your next big project!\n\n\n\n\n\nFeb 12, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nPrecision/Recall vs FN/TN/FP/TP\n\n\n\nMachine Learning\n\nData Science\n\n\n\nPrecision, recall, and the confusion matrix help evaluate machine learning models. Learn to Understand their tradeoffs, especially in imbalanced datasets, and optimize your classifier for better results.\n\n\n\n\n\nFeb 10, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nWhat is wrong about the pattern tell them what you are going to tell, tell and then tell what you told\n\n\n\nStorytelling\n\nMental Models\n\n\n\nTired of dull, repetitive “tell them, tell them, then tell them again” messaging? Learn how to break the mold with surprising twists and curiosity-driven storytelling. Discover why planned unexpectedness, knowledge gaps, and challenging common sense can make your ideas stick and keep your audience hooked.\n\n\n\n\n\nFeb 6, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThe Stickiness Improvement Plan\n\n\n\nStorytelling\n\nLeadership\n\n\n\nBased on the book Made to Stick, I provide a plan of question to evaluate your idea’s stickiness. Comes with keywords for further improvements.\n\n\n\n\n\nFeb 3, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nGet huge benefits for minimal costs after reading\n\n\n\nStorytelling\n\nKnowledge Work\n\n\n\nThe ultimate goal of creating a sticky idea is to make people care. To achieve this, bridge the gap between what they already care about and what they don’t yet care about. Here I provide a checklist to evaluate the stickiness of your ideas.\n\n\n\n\n\nJan 28, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThe one thing missing in your perfect presentation\n\n\n\nStorytelling\n\nKnowledge Work\n\n\n\nSticky ideas are those that capture attention, linger in the mind, and inspire action. Learn the principles of creating messages that are not just understandable but also memorable and impactful enough to drive change.\n\n\n\n\n\nJan 27, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nThree basic plots - my take\n\n\n\nStorytelling\n\nLeadership\n\n\n\nLearn how the three basic plots are alternative to the hero’s journey\n\n\n\n\n\nJan 25, 2025\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nBlogging with quarto\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\nI recently switch from WordPress to quarto. Learn why and how to integrate it in an Obsidian based workflow.\n\n\n\n\n\nJan 17, 2025\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nScience2Art, a lesson in artful prompt engineering\n\n\n\nGenerative AI\n\nMachine Learning\n\nStorytelling\n\n\n\nHow can physical equations be expressed in a paintings? In the beginning I only had a few ideas and the whole process was very effortful. Then in 2023, I discovered ChatGPT. And it become a lesson in the art of prompt engineering.\n\n\n\n\n\nJan 15, 2025\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\nClean coders use lambda expressions\n\n\n\nPython\n\nC++\n\n\n\nIn modern programming, lambda expressions have become an indispensable tool for concise and efficient code. They have their origin in functional programming but have made it to many programming languages. But how, when, and why should you use them? Let’s dive in.\n\n\n\n\n\nJan 10, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nHow to fight computer eye strain\n\n\n\nSoftware Engineering\n\nPython\n\nApplied Engineering\n\n\n\nAt least for your eyes and your back computer work puts a tremendous strain. This is what can help.\n\n\n\n\n\nDec 3, 2024\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nPremature optimization and the importance of algorithms\n\n\n\nSoftware Engineering\n\nC++\n\n\n\nDSA is unknown to many developers. Learn why this is a big mistake.\n\n\n\n\n\nAug 10, 2024\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nHere is what I learned from thinking fast and slow.\n\n\n\nKnowledge Work\n\nStorytelling\n\nGrowth\n\n\n\nA summary with link to the previous posts\n\n\n\n\n\nApr 24, 2024\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nTaylorism in complex environments\n\n\n\nManagement\n\nAgile\n\nSoftware Engineering\n\n\n\nStudies show that over 70% of businesses rely heavily on KPIs for decision-making. Yet, there’s a story that illustrates how this reliance can sometimes lead to unexpected and counterintuitive outcomes.\n\n\n\n\n\nMar 9, 2024\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nFrom Challenges to Champions: Unsticking Negative Workplace Stories\n\n\n\nStorytelling\n\nLeadership\n\nKnowledge Work\n\n\n\nStories stick. But what can unstick a story?\n\n\n\n\n\nMay 15, 2023\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nUnlock the Power of Metaphors at Work to Captivate Your Listeners!\n\n\n\nStorytelling\n\nKnowledge Work\n\n\n\nI’ll be sharing a simple yet effective approach to finding and creating your very own metaphors. Learn to apply metaphors more frequently.\n\n\n\n\n\nMay 3, 2023\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nWaterfall management is a strict recipe, while agility is improvisational cooking.\n\n\n\nStorytelling\n\nManagement\n\n\n\nIn a world where information is fleeting, generative metaphors are the secret weapon. They don’t just simplify complex ideas; they reframe understanding, sparking fresh insights and lasting impressions. Think of a metaphor not as a mere comparison but as a doorway\n\n\n\n\n\nMay 3, 2023\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nEffective Story Spotting\n\n\n\nStorytelling\n\nLeadership\n\nKnowledge Work\n\n\n\nUnleashing the Power of Storytelling How Our Team Overcame Remote Work Challenges and You Can Too\n\n\n\n\n\nMay 1, 2023\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nHow Playing Zelda Teaches Us the Importance of Audience Engagement in Interactive Storytelling\n\n\n\nStorytelling\n\n\n\n\n\n\n\n\n\nApr 16, 2023\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nIntellectual Dishonesty: Recognizing and Combating Toxic meeting culture\n\n\n\nKnowledge Work\n\nLeadership\n\n\n\nLearn how to spot dishonest behavior in other people’s replies and your arguments.\n\n\n\n\n\nMar 4, 2023\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nUse risk policies and avoid common planning fallacies in software development\n\n\n\nSoftware Engineering\n\nAgile\n\n\n\nEven though most methods tell you otherwise, always use a rule of thumb in software planning.\n\n\n\n\n\nNov 10, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nInvestors are living from the greatest of all treasures, which is Hope\n\n\n\nGrowth\n\nKnowledge Work\n\n\n\nRising prices in the stock market show that the recession is coming.\n\n\n\n\n\nNov 10, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThe story of Covid and Plato’s cave allegory\n\n\n\nStorytelling\n\nKnowledge Work\n\nManagement\n\n\n\nRemember the time before Covid? We all went to work and were happy. Despite all the talk, we will never all go back to the office.\n\n\n\n\n\nNov 10, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nSticking in a shitty job, deprives you of rich experiences\n\n\n\nGrowth\n\nMental Models\n\n\n\nIf there are no extremes bad/good we can not make lasting memories.\n\n\n\n\n\nNov 10, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nEverybody wants more money and thinks inflation is unfair\n\n\n\nGrowth\n\nKnowledge Work\n\n\n\nToday inflation is rampant. The cost of living in many countries is close to or above 10 %. Many people perceive this as a bad sign.\n\n\n\n\n\nNov 10, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nGood managers are immune to survivorship bias\n\n\n\nManagement\n\nSoftware Engineering\n\nLeadership\n\n\n\nLearning the golden truth from the one successful projects is rarely possible. Always keep your starting position in mind\n\n\n\n\n\nNov 10, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nThe perfect way that projects will never be planned\n\n\n\nManagement\n\nSoftware Engineering\n\nStorytelling\n\n\n\nThere is a profound difference between selling and planning a project—the order of these two phases matters.\n\n\n\n\n\nNov 9, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nTrust me; I am an expert\n\n\n\nManagement\n\nKnowledge Work\n\nMental Models\n\n\n\nThe issue is not whether you are an excellent expert, but expert knowledge can not be trusted in an irregular environment.\n\n\n\n\n\nNov 7, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nLook at your industry’s state and then decide if you want to become an expert\n\n\n\nSoftware Engineering\n\nKnowledge Work\n\nGrowth\n\n\n\nThe t-shaped engineer is a human centipede. These modern software engineers are different than traditional experts. Which one is better? And what have foxes to do with it?\n\n\n\n\n\nNov 7, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThe SAFe confidence vote reveals the state of emotional security in your project\n\n\n\nAgile\n\nManagement\n\nLeadership\n\n\n\nIf you have confidence in a plan, there should be a uniform vote for this plan. The question is if your endeavour is predictable.\n\n\n\n\n\nNov 7, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nYou should go back to the office, to help your boss understand you\n\n\n\nManagement\n\nKnowledge Work\n\nSoftware Engineering\n\n\n\nShadows are lurking behind your working-from-home chair. There is one big one big disadvantage egoistic developers fail to see.\n\n\n\n\n\nNov 3, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nUse mental anchors to determine the start position of high-stakes discussions\n\n\n\nMental Models\n\nKnowledge Work\n\n\n\nThe next time you find yourself in a tricky situation, try to influence the discussion by anchoring at another reference point.\nTime-dependent algorithms usually have one major issue. The starting value heavily decides the outcome. The same applies to your mind’s thinking process.\nThis concept is also called anchoring\n\n\n\n\n\nNov 1, 2022\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nTry to establish your next planning predictions on well-defined reference points\n\n\n\nSoftware Engineering\n\nAgile\n\nMental Models\n\n\n\nHere is a new method to relate software estimations to a related base rate.\n\n\n\n\n\nOct 29, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nThe good storyteller is a travel guide through the listener’s memories.\n\n\n\nStorytelling\n\nGrowth\n\n\n\nStories act as a simulator, allowing the reader to live the story mentally.\n\n\n\n\n\nOct 28, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nYou are most likely overinsured\n\n\n\nMental Models\n\nKnowledge Work\n\n\n\nNot all insurance cost is transparent, if you are very careful, you forgo good opportunities.\n\n\n\n\n\nOct 26, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nThere are no losses; just costs for profits\n\n\n\nManagement\n\nStorytelling\n\n\n\nThe best guide to selling anything, or so they say.\n\n\n\n\n\nOct 26, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nRegression to the mean reshapes our memories\n\n\n\nMental Models\n\nStorytelling\n\n\n\nWhy to tomorrow will always be better (or worse).\n\n\n\n\n\nOct 25, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nWhy engineers do not understand stories\n\n\n\nStorytelling\n\nSoftware Engineering\n\n\n\nAs engineers, we love details. Nothing can be too complex. It is complexity itself that attracts us. What you should do instead.\n\n\n\n\n\nOct 19, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nExperienced engineers stay away from the flow zone\n\n\n\nSoftware Engineering\n\nMental Models\n\n\n\nFlow is the process that happens when no deliberate control of attention is necessary for a mental task.\n\n\n\n\n\nOct 17, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nAvoid spending mental energy as if would be limitless\n\n\n\nMental Models\n\nKnowledge Work\n\n\n\nKnow if you unwisely exhausted your mental energy supply for the day.\n\n\n\n\n\nOct 12, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nA new writer’s easy guide to find the perfect headline\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nProviding fake reliability with statistics\n\n\n\nStorytelling\n\nKnowledge Work\n\n\n\nStatistics can help us to make the pro points more potent and the contra points weaker. The statistics serve as a quantitive anchor to your position. Read on to learn how you can twist statistics to your cause.\n\n\n\n\n\nOct 6, 2022\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nAny fool can criticize, condemn and complain - and most fools do\n\n\n\nKnowledge Work\n\nStorytelling\n\n\n\nWhether we communicate with other people verbally or non-verbally, our brain processes any sensory input of our senses.\n\n\n\n\n\nSep 4, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nWorld Sensation, Why remarkably nobody has built your leadership\n\n\n\nLeadership\n\nGrowth\n\n\n\nThe truth: you do not focus on accomplishments, and you do not empower others.\n\n\n\n\n\nJul 6, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nEffective leaders listen for stories that touch the heart and mind\n\n\n\nLeadership\n\nKnowledge Work\n\n\n\nThe management literature has known it for a long time. Leadership is not identical to management.\n\n\n\n\n\nJun 20, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n4 powerful secrets medium user need to know about leadership\n\n\n\nGrowth\n\nLeadership\n\n\n\nToday everybody talks about leadership. Just do a quick search on Medium. But is everybody talking about the same thing?\n\n\n\n\n\nJun 5, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nThe world requires influential engineers with a passion for stories\n\n\n\nSoftware Engineering\n\nStorytelling\n\n\n\nEveryone wants their ideas to strive, even engineers.Engineers are often depicted as uncommunicative cavemen. The talking is best left to other people, isn’t it?\n\n\n\n\n\nMay 18, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nSuccessful cross-functional teams need the luxury of confidence and trust\n\n\n\nLeadership\n\nManagement\n\n\n\nToday, the cross-functional team and entrepreneurial organization are one of the stock solutions to solve complex problems.\n\n\n\n\n\nMay 11, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nThree old but trusted ways to reveal your team’s common story\n\n\n\nLeadership\n\nKnowledge Work\n\n\n\nHow do you unify a bunch of random people to follow a common cause? Quick answer: provide a common identity and, at best, a shared history.\n\n\n\n\n\nMay 9, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nGood presenters embrace these psycho tips in their life\n\n\n\nStorytelling\n\nGrowth\n\n\n\nWe all give presentations, talks, speeches, or dinner toasts. Sometimes we fail to engage with our audience. Try to remember these tips for your next presentation.\n\n\n\n\n\nApr 19, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nThe science of influence and storytelling\n\n\n\nStorytelling\n\n\n\n\n\n\n\n\n\nApr 13, 2022\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nTry these 9 tips to get more and stronger follower growth\n\n\n\nStorytelling\n\nMental Models\n\n\n\nDid you ever wonder why you have problems getting your point across? On the other hand, somebody else quickly confers the message?\n\n\n\n\n\nApr 13, 2022\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nKnowledge advice: 2 Ways to read a book and improve your understanding\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\n\n\n\n\n\n\nApr 9, 2022\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nTry these priceless mental tricks to gain the upper hand in pointless conflicts\n\n\n\nLeadership\n\nMental Models\n\n\n\nImagine your last stressful situation. Your face is getting red. You start to stammer and justify yourself. What if you had some superpowers…\n\n\n\n\n\nFeb 20, 2022\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nQuotes about storytelling\n\n\n\nStorytelling\n\n\n\n\n\n\n\n\n\nNov 28, 2021\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nHow find material to read and how to dig through it.\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\nWhat are the best sources to read on your topic.\n\n\n\n\n\nNov 26, 2021\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nUnder construction Gut ist der Vorsatz\n\n\n\nGrowth\n\n\n\n\n\n\n\n\n\nNov 23, 2021\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nHow technical is too technical\n\n\n\nC++\n\nSoftware Engineering\n\n\n\nWhen you read and write about software, there is always a balance to be struck how technical the books should be. I have read Effective Modern C++, which I found a little too technical.\n\n\n\n\n\nOct 28, 2021\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nWhy yet another storytelling blog\n\n\n\nStorytelling\n\nKnowledge Work\n\nLeadership\n\n\n\n\n\n\n\n\n\nJul 18, 2021\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nI only understand trainstation\n\n\n\nStorytelling\n\n\n\n\n\n\n\n\n\nJul 7, 2021\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nFinding your personal blogs purpose and name\n\n\n\nKnowledge Work\n\nGrowth\n\n\n\nIn this article I want to share some thoughts about creating a personal blog. A blog needs two things:- The blogs main purpose- A name for the blog\n\n\n\n\n\nJul 4, 2021\n\n4 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html",
    "href": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html",
    "title": "Experienced engineers stay away from the flow zone",
    "section": "",
    "text": "Flow is the process that happens when no deliberate control of attention is necessary for a mental task.\nIn the film the Social Network, this is depicted as a desirable state for a programmer."
  },
  {
    "objectID": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#what-is-the-flow-zone",
    "href": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#what-is-the-flow-zone",
    "title": "Experienced engineers stay away from the flow zone",
    "section": "1 What is the flow zone?",
    "text": "1 What is the flow zone?\nThe flow state allows us to shut down the controller instance in our brain. Everything seems to go smoothly. We experience that effortful tasks can make fun.\nThis emotional experience comes from a rise of dopamine and endorphins in your brain.\nSome conditions are beneficial to arrive at the flow zone\n\nbeing engaged in an effortful task\nhaving a good mood or a happy life episode\nlow on depression\nknowledge novices compared to experts\nhigh faith in intuition\nif they are (made to feel) powerful\n\nIn short, a young graduate with an inflated ego in charge of a small team or an important task will quickly arrive in the flow zone.\nA mid-career engineer that has deep experience faced several setbacks at work, and just divorced is less likely to be in the flow zone.\nIf we experience flow together, we usually have the best time. Often this happens at perfect parties. Sometimes it can happen at work. Startups are among those workplaces where flow is the most common.\nWe all wish we were the young graduate again, working with his fellow beginners on a remarkable piece of technology. The world seemed limitless back then."
  },
  {
    "objectID": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#flow-is-terrible-for-the-holistic-approach.",
    "href": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#flow-is-terrible-for-the-holistic-approach.",
    "title": "Experienced engineers stay away from the flow zone",
    "section": "2 Flow is terrible for the holistic approach.",
    "text": "2 Flow is terrible for the holistic approach.\nBut did you ever work on a piece in flow mode and eventually recognize that you were doing a micro-optimization and completely lacked the big picture?\nThe controller in us keeps track of the big picture and what each of our actions adds to it. If we shut it off, we do what seems to be a very reasonable next step. Sometimes this next step leads us in the wrong direction.\nIf you are in a big office, you also face another problem. Interruptions of the zone are experienced as an annoyance. This comes done to a reduction of hormone release. While the exact processes are not yet fully understood, it is clear that the severe decline of endorphin release is experienced as an adverse event.\nThese negative emotions are undoubtedly destructive for you. It can also permanently affect your relationship to your coworkers. Their usually well-intended attempt to communicate with you provoked a negative feeling within you. Your cold response evoked a negative emotion in them and will lead to fewer communication attempts in the future."
  },
  {
    "objectID": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#what-is-better-than-flow-to-be-a-successful-engineer",
    "href": "posts/think-fast-and-slow/experienced-engineers-stay-away-from-the-flow-zone.html#what-is-better-than-flow-to-be-a-successful-engineer",
    "title": "Experienced engineers stay away from the flow zone",
    "section": "3 What is better than flow to be a successful engineer?",
    "text": "3 What is better than flow to be a successful engineer?\nUncle Bob writes about his experience with Flow in “Clean Coder.”\nHe highly warns us to enter the flow zone unprepared. We certainly will write better and faster code but often fail to consider external requirements for our code.\nLater adaptions to the code will be necessary, potentially wrecking the beautiful flow code we created.\nHe recommends doing frequent breaks and switching activities to reactivate the internal controller.\nAt the same time, he suggests pair programming as pairing would not allow flow.\nThis point does not entirely convince me. Two engineers who understand each other well and work in tandem can be so fixed on their solution that they forget the big picture. This is backed up by the evidence that two individuals can also arrive in the flow zone.\nWhat is your opinion? Looking forward to your comment or mail."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "",
    "text": "Photo by Unsplash\nSoftware estimation is every software engineer’s favorite topic. Nobody wants to hack away and just see if it works.\nAnd now the reality."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#planning-in-software-engineering",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#planning-in-software-engineering",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "1 Planning in software engineering",
    "text": "1 Planning in software engineering\nPlanning sessions are experienced by many as a necessary evil. Something you need to do so that the team boss can go to his boss to provide some numbers. These numbers are just there, so the big folks have something to discuss.\nSwitch. Sometimes, people honestly plan the amount of work that is necessary. Fierce discussions follow, and if there was a team before the workshop, there certainly is none left afterward."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#methods-methods-methods",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#methods-methods-methods",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "2 Methods, methods, methods",
    "text": "2 Methods, methods, methods\nThere is nothing like a good new software planning method, or so they say. Get the Fibonacci number generator ready. We will do some serious planning now. The best plans have a fancy Gant chart and some confidence intervals to account for the insecurity.\nStill, many plans are of by weeks, despite the best planning methods. There was just this tiny technical problem that held back delivery for four weeks. And then, testing couldn’t start because the deployment pipeline was not ready."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#missing-the-forest-for-all-the-trees",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#missing-the-forest-for-all-the-trees",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "3 Missing the forest, for all the trees",
    "text": "3 Missing the forest, for all the trees\nMany planning sessions examine every issue for itself. The interplay of the problems, components, or procedures is seldom explored.\nOften a guy (hands up if you were in this unlucky of all roles) says, well, you forgot to factor in x, y and omega. That can not work; it did not work the last time we tried it. The comparison of the current work to a similar reference work is called the outside perspective."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#risk-policies-are-the-plannings-rule-of-thumb.",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#risk-policies-are-the-plannings-rule-of-thumb.",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "4 Risk policies are the planning’s rule of thumb.",
    "text": "4 Risk policies are the planning’s rule of thumb.\nBut equally often, planning for this stuff is not even possible. We are all inside our boxes, having the same limited view. What can help here is a risk policy. Like “never buy extended warranties,” you can assume, “Never plan integration testing with less than two days.” These rules of thumb go everywhere where you have experience but face a lot of uncertainty.\nYou do not know what obstacles you will face, but you know that you will face obstacles."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#risk-policies-do-not-work-with-cutting-corners.",
    "href": "posts/think-fast-and-slow/use-risk-policies-and-avoid-common-planning-fallacies-in-software-development.html#risk-policies-do-not-work-with-cutting-corners.",
    "title": "Use risk policies and avoid common planning fallacies in software development",
    "section": "5 Risk policies do not work with cutting corners.",
    "text": "5 Risk policies do not work with cutting corners.\nThere is often immense pressure to fit the work into a tight deadline. “You must make it work, or we can not take this client.” Who wants to be the dealbreaker in this case? The planning will cut many corners, as it is motivated by loss aversion. A risk policy is the exact opposite of this. Imagine you have a variance for the planning from 2 to 5 days, and a critical subtask like testing has the risk policy to take at least two days. This approach can not work.\nStay tuned to learn how you can still deliver value in this case."
  },
  {
    "objectID": "posts/think-fast-and-slow/taylorism-in-complex-environments.html",
    "href": "posts/think-fast-and-slow/taylorism-in-complex-environments.html",
    "title": "Taylorism in complex environments",
    "section": "",
    "text": "Complicated vs Complex"
  },
  {
    "objectID": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#the-tale-of-two-factories",
    "href": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#the-tale-of-two-factories",
    "title": "Taylorism in complex environments",
    "section": "1 The tale of two factories",
    "text": "1 The tale of two factories\nImagine a traditional toy factory. It is only producing your favorite teddy bear. Nestled among rolling hills next to blubbering torrent, the factory’s quaint brick facade belies the flurry of activity within. Inside, every craftsman is intensely focused on his specialized work. They are surrounded by mountains of soft fabric and baskets brimming with buttons and thread, each according to the needs of their station. The rhythmic hum of sewing machines fills the air, harmonizing with the occasional steam whistle that punctuates the factory’s industrious atmosphere.\nOne morning the factory management realized that the output has dropped in the last week. The cause is immediately identified: the assembly station isn’t performing up to standard, as indicated by a decline in the relevant Key Performance Indicator (KPI). The bright manager of the factory quickly hires additional sewers to stitch the various parts of stuffed animals together. quickly restoring output to normal. The output quickly rebounds to its previous levels\nNow, picture a similar factory in a more modern setting. This factory produces a wide variety of toys to satisfy customers’ increasingly diverse desires.The manufacturing of toys takes place in semi-automated craftshop. Every craftsman makes the complete toy on its own. Each toy is sold with a unique label from the craftsman who made it.\nUnexpectedly, production slows down. Despite intensive investigation, no clear reason emerges.\nEventually, someone suggests that he is feeling cold and the cold winter weather might be to blame.\nThe management of the factory, equal bright than the previous one, feels ashamed. Poor workers can’t operate as efficiently with cold hands.\nWith much fanfare heaters are installed. And then the toy manufacturing goes on smoothly.\nHowever, one summer day, output declines once again.\nOnce again after thorough research, it’s discovered that there had been an unusually large volume of orders a few months prior in both occasions. Many of the craftsmen felt overworked and exhausted. However, the holidays were still months to go. The workers began working at a slower pace and took time for necessary tasks like tool maintenance. This reduced eagerness decreased their toy production time back to the previous level."
  },
  {
    "objectID": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#the-crux-of-management-best-practice",
    "href": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#the-crux-of-management-best-practice",
    "title": "Taylorism in complex environments",
    "section": "2 The crux of management best practice",
    "text": "2 The crux of management best practice\nWhat lessons can we glean from this story? The first time, the toy factory just got lucky. Often a new management initiative is celebrated inside a company. For some time this can lead to an increased motivation, until novelty wears off. After some months this forced motivation was wearing of and people start to think more towards a sustainable long term production.\nThe story from the cold craftsman was very convincing as it appeared coherent. Had the problem not recurred within six months, we might have concluded that keeping toy factories warm in winter is essential. Seasonal effects often can lead to wrong business decisions.\nBut the effect is even larger. Think about the other toy factories in the country. If our toy factory would have been successful, every toy factory would have adapted the process and installed much more heating power. The benefits would have been very low because toy factories are already warm in the first place.\nThis adaption of the wrong tool is a classic example of survivorship bias. The logic often follows that because successful companies adopt certain strategies, these strategies must be the key to their success. This is the statistical phenomenon where, if a variable is extreme on its first measurement, it will tend to be closer to the average on its next measurement. Essentially, every factory experiences phases where worker morale dips below average."
  },
  {
    "objectID": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#check-the-reliability-of-your-kpis",
    "href": "posts/think-fast-and-slow/taylorism-in-complex-environments.html#check-the-reliability-of-your-kpis",
    "title": "Taylorism in complex environments",
    "section": "3 Check the reliability of your KPIs",
    "text": "3 Check the reliability of your KPIs\nTalyorism, more commonly recognized for its more benevolent name, scientific management, revolutionized the 20th Century. It is a management method, which uses resources and transforms them into outputs.\nAt the heart of scientific management is the meticulous control of processes through key performance indicators (KPIs) and the subsequent adjustments as needed.\nSuch a KPI can consist of anything that can be measured.\nNow what is the issue with applying KPIs to anything?\nMuch criticism has been done in the past. Authors such as Jerry Muller in “The Tyranny of Metric” or Kaplan and Norton with “The Balanced Scorecard” have provided in-depth analysis on this subject.\nTaylorism’s Application has significant limitations in complex environments. Its reliance on quantifiable data and rigid systems often classes with the need for adaptability and creative problem-solving. In fact, it is in these areas that human elements and modern management theories flourish. For instance, the issue with the low motivation could have been easily identified in a all-hands inspect-and-adapt session of agile management.\nIf you decide to go for KPIs, i want to shed some light on two hard factors: causality and statistical relevance. Firstly, a drop in a KPI should not be hastily attributed to mere coincidence. KPIs are usually designed on a whiteboard with a top down breakdown. So while a vertical hierarchy might be established, there is usually no link between lower level KPIs.\nMerely identifying a KPI and attempting to rectify it may prove insufficient. The causal story that can be constructed with a KPI is sometimes not enough.\nSecondly, the importance of statistical significance cannot be overstated. Just measuring the output results to a single data point.\nWhile it may reflect reality, it represents a singular instance. It could be part of the normal variance.\nSo, how many data points suffice? Rule of thumb: aim for more than 10. For a waterproof analysis: ask your statistician for a error margin analysis."
  },
  {
    "objectID": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html",
    "href": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html",
    "title": "Investors are living from the greatest of all treasures, which is Hope",
    "section": "",
    "text": "Photo by Unsplash\nThe federal reserve bank started increasing interest rates almost a year ago. Now with the average rate at 3.8%, the Fed waits for the medicine to take effect.\nFrom a factual point of view, the real interest rate is currently at roughly - 7 %.\nMany companies, especially in highly leveraged industries like tech or housing, are reducing investment and are thinking about job cuts. Job cuts These two words alone mean the rates must fall. At least, that is what many hope for and why we currently see a rising stock market."
  },
  {
    "objectID": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#classic-economics-wages-rise-until-the-recession-hits",
    "href": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#classic-economics-wages-rise-until-the-recession-hits",
    "title": "Investors are living from the greatest of all treasures, which is Hope",
    "section": "1 Classic economics: wages rise until the recession hits",
    "text": "1 Classic economics: wages rise until the recession hits\nFrom a traditional point of view, the analysis that we currently have high inflation and, in many regions, due to unfavorable demographics, a labor shortage should lead to an anticipation of rising wages and the onset of the dreaded wage-price spiral.\nWages will rise, which will lead to an average price increase and that to another wage rise.\nThis cycle can only be stopped by firing enough workers to cool down the market.\nBut why should a company fire its workers? There are two ways to cool down the job market, extreme events (corona and war) or via market control mechanisms.\nThe control mechanism means regulating the money supply. Setting it to infinite will lead to a labor shortage. Only allowing free cash flow to pay for work and drying up the funding will reduce labor in the short term.\nIn the long term, this is not necessarily the case, as is predicted by communism. We will all have work and high productivity without debt and free money. At least, that’s what I heard.\nEnter politics."
  },
  {
    "objectID": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#emotions-drive-politicians.",
    "href": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#emotions-drive-politicians.",
    "title": "Investors are living from the greatest of all treasures, which is Hope",
    "section": "2 Emotions drive politicians.",
    "text": "2 Emotions drive politicians.\nIn this game, many people undoubtedly have to lose something. Workers will lose their job and the security of high wages. Investors will lose invested money. Bosses lose their companies.\nPoliticians know that all these events lead to unrest in the population and limit their ability to remain in power. In Europe, the ECB has been reluctant to raise rates. Potentially due to respect for politicians in many countries."
  },
  {
    "objectID": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#investors-are-living-from-the-greatest-of-all-treasures-which-is-hope",
    "href": "posts/think-fast-and-slow/investors-are-living-from-the-greatest-of-all-treasures-which-is-hope.html#investors-are-living-from-the-greatest-of-all-treasures-which-is-hope",
    "title": "Investors are living from the greatest of all treasures, which is Hope",
    "section": "3 Investors are living from the greatest of all treasures, which is Hope",
    "text": "3 Investors are living from the greatest of all treasures, which is Hope\nEmotions have another effect on investors.\nAs an investor, we will likely use the money when invested, or the company will be worthless. Or we lose money when we sell our shares for a lower price than we pay.\nThe rational approach will be to ask if there is a better investment that we could currently have. We should accept our loss and invest the remaining money in the other company.\nHowever, many people are afraid to lose money. Both options are inadequate.\nThere also remains the third option. The stock can go up and people will become more prosperous. We should all buy some more, as it goes up.\nThis behavior is explained by prospect theory. When people face almost certain losses, they become risk-seeking. They favor small probabilities of potential gains.\nThat is what is currently happening."
  },
  {
    "objectID": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html",
    "href": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html",
    "title": "Providing fake reliability with statistics",
    "section": "",
    "text": "![[money-bars.jpg]]"
  },
  {
    "objectID": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#statistics-are-truth",
    "href": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#statistics-are-truth",
    "title": "Providing fake reliability with statistics",
    "section": "1 Statistics are truth",
    "text": "1 Statistics are truth\nToday everything revolves around the truth. Just ask Donald Trump at https://truthsocial.com. Statistics are an excellent way to provide proof of the fact.\nAt least, that is what everybody should believe.\nEvery presenter should have an intended outcome in mind. We want to inform or influence a decision. Every issue has pro and contra arguments.\nStatistics can help us to make the pro points more potent and the contra points weaker. The statistics serve as a quantitative anchor to your position. Read on to learn how you can twist statistics to your cause."
  },
  {
    "objectID": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#statistics-and-the-audiences-attention-span",
    "href": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#statistics-and-the-audiences-attention-span",
    "title": "Providing fake reliability with statistics",
    "section": "2 Statistics and the audience’s attention span",
    "text": "2 Statistics and the audience’s attention span\nMany people assume that a fact is a fact. As such, it does not matter where and when you present your statistics as long as you give them.\nThat is a gross mistake. You are undoubtedly familiar with the concept of attention span. Long monologues usually overload the listener’s attention and lead nowhere. However, even in a well-structured presentation, there are different levels of attention span.\nFor complex ideas, our attention span is usually concise. This is related to the concept of cognitive ease and confusion.\nBut there is also the effect of the structure of the presentation on the attention span. The built-up to the production of facts can lead to a different perception. This is related to the framing effect."
  },
  {
    "objectID": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#confusing-your-audience",
    "href": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#confusing-your-audience",
    "title": "Providing fake reliability with statistics",
    "section": "3 Confusing your audience",
    "text": "3 Confusing your audience\nIn the good old days, the general advice was that it was best not to confuse your audience. However, today many public figures do precisely this. They answer questions that were not asked or change the topic frequently. All this is interwoven with statistics. The audience is usually overwhelmed and will accept any proposal.\nIf you want to do this, I recommend the following article:\nhttps://www.shanesnow.com/articles/intellectual-dishonesty\n\n\n\n\n\n\nNoteUpdate\n\n\n\nI wrote here about [[202107232348 Intellectual Dishonesty Recognizing and Combating Toxic meeting culture|this]]\n\n\nSome tactics are:\n\nDodge the question: Take any question as a starting point to divert to a topic of your choice.\nAttack: Repeat the question and say it is wrong/unfair. Talk about something else.\nRepeat the keywords: Talk about unrelated stuff, but mention the keywords. In the business world, also known as bullshit talk.\nJoke: provide a joke to get laughter from the audience.\nTalk the other down: talk about many, many things to cover up the question.\n\nIf you do not want to do that, follow my article on avoiding ego depletion."
  },
  {
    "objectID": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#influencing-the-attention-frame",
    "href": "posts/think-fast-and-slow/providing-fake-reliability-with-statistics.html#influencing-the-attention-frame",
    "title": "Providing fake reliability with statistics",
    "section": "4 Influencing the attention frame",
    "text": "4 Influencing the attention frame\n\n4.1 You and the audience\nIn a presentation, there is always a relationship between the speaker and the audience. They may both be of the same group or not. The speaker may want to influence the audience, or he is a teacher.\nThe topic and the structure of the speech are important. More important are often the audience’s prior knowledge and their feelings towards the topics. These conditions set the stage.\nWhat do you feel when you read the words:\nelectric cars, climate crisis, milk, golf ball, abortion?\nDo you have the same feelings and constant background thoughts for each word?\n\n\n4.2 Influencing the background thoughts\nAttentive listening is a challenging skill. Many people listen and directly think about what they have heard. They start processing and ordering the information. Direct processing allows us to anchor new knowledge with already existing concepts. However, it makes the reception of further information more error-prone. This kind of chatter in your head is hard to silence. The good news? You can assume that many in your audience are not listening. They will not spot minor errors in your reasoning.\nThere are different approaches to influence this chatter. Among these are your choice of words, the consistency of the information, and providing a sense of reliability.\n\n\n4.3 Activity words lead to activity.\nImagine you want to promote your newest fitness gadget and spread the ideas of a fitness lifestyle.\nYou face a crowd of average Joes and Janes. They are familiar with the sport but know only a little about metabolism.\nHow do you set the stage for your pitch? Do you start with a lecture on the negative effect of fatty foods?\nFirst, you must invoke the need for action. Do this by using active words. Talk about how you love to go hiking on the weekend. This reminds the audience of their weekend activities. The audience is waiting for some action and will likely lapse over a statistical mistake.\n1 in 10 persons does not have a heart attack if he does sport. 2 in 10 persons of those use fitness gadgets. Fitness gadgets have a benefit.\nThis seems like a good deal. 2 are better than 1.\nAnother way to present the information would have been that 8 in 10 people are happy to do sport without gadgets. The data is essentially the same but less activating and does not fit the predisposition of the audience.\n\n\n4.4 Provide a consistent story\nA consistent story helps to reinforce any sentiments the audience had before. If you add details that do not fit, the audience becomes distracted. This is why so many scientists have a hard time presenting a good story. They want a complete picture describing any anomaly in the data.\nHowever, it is not the complete picture, but the most consistent that convinces. Almost nobody is interested in the story of Gandalf’s youth in the story of lord of the rings.\nA good story follows the concept that “What you see is all there is.” The speaker should reinforce this concept. The listener will automatically apply it. A consistent story is believed to be more accurate. This means consistency will lead to higher confidence in the speaker.\nAt the same time, a speaker that neglects details can also be more confident in himself. Daniel Kahneman explains this with our desire to see patterns:\n\n“Paradoxically, it is easier to construct a coherent story when you know little and when there are fewer pieces to fit into the puzzle. Our comforting conviction that the world makes sense rests on a secure foundation: our almost unlimited ability to ignore our ignorance”.\n– Kahnemann\n\n\n\n4.5 Providing a sense of (fake) reliability\nThere are mathematical formulas to express the accuracy of information. Intuitive sampling is often much too small and presents a systematic failure. Nevertheless, many sources only ask a few hundred people. Saying that 70 people asked 14 to use gadgets sounds far less impressive. The relevance is inflated by expressing it relative or in proportion to 10 or 100.\nTalking about ten people adds a level of detail to the narrative. 10 out of 100 people is better visualizable than 10 %. Detailed stories are, therefore, more persuasive. The same applies to the question “how many?” vs. “what percentage?”.\nFrom a statistical perspective, the inverse relation is true. More details make an event less likely and less likely to be true.\nMuch of business success stories and proven business methods rely on this approach. Success stories are cited as proof of a technique. One project’s success does not mean it is a suitable method for all projects. Still, this is an accepted approach in business writing and journalism."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "",
    "text": "Nothing is as controversial as estimation in software engineering. In one corner are the people that plan endlessly and are stuck in analysis paralysis. In another corner are those that plan intuitively and always underestimate the amount of work.\nIn yet another area are those that do not want to estimate, as they have been in the other two corners. Ironically, they often fail to update the delivery schedule flexibly."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#the-holy-war",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#the-holy-war",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "",
    "text": "Nothing is as controversial as estimation in software engineering. In one corner are the people that plan endlessly and are stuck in analysis paralysis. In another corner are those that plan intuitively and always underestimate the amount of work.\nIn yet another area are those that do not want to estimate, as they have been in the other two corners. Ironically, they often fail to update the delivery schedule flexibly."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#everybody-has-his-best-estimation-process-method.",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#everybody-has-his-best-estimation-process-method.",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "Everybody has his best estimation process method.",
    "text": "Everybody has his best estimation process method.\nThere is a never stopping genesis of new methods to plan engineering work. There are one-point or three-point-based methods. Story points or hours. Some use the Fibonacci number or planning poker.\nIf your planning sessions often felt like a voodoo gathering or a bazaar-like trade fair, welcome to the club."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#continuous-improvement-through-retrospection",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#continuous-improvement-through-retrospection",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "Continuous improvement through retrospection",
    "text": "Continuous improvement through retrospection\nRetrospectives are nowadays often performed in engineering organizations. Root causes for missed deadlines and repeated failures in the development process are analyzed, identified, and solved with some remedy.\nHow is it then that still many tasks are delivered late?"
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#self-organization-could-be-the-goal.",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#self-organization-could-be-the-goal.",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "Self Organization could be the goal.",
    "text": "Self Organization could be the goal.\nThe work in the software industry is often very complex. Some argue that this complexity must lead to new ways of organizing the work. A possible solution is the rise of the knowledge worker that owns, uses, and improves his productivity tools.\nMany large organizations struggle with the realization of less hierarchical structures. It remains to be shown if such a transformation can be done by evolution rather than by revolution.\nMany organizations would be better off improving their planning."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#feedback-loops-in-the-planning-cycle",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#feedback-loops-in-the-planning-cycle",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "Feedback loops in the planning cycle",
    "text": "Feedback loops in the planning cycle\nPlanning often happens intuitively. Software engineering breaks down into many tasks. Many of these tasks are usually new to engineers that should perform the job. However, the task is usually not that unique in the engineering world. The standard advice is to have a very experienced developer (architect) comment and influence the estimation of a team. The joint assessment is often better.\nIn many organizations, there are only a few exchanges on how exactly these plans were.\nMany plans still rely on the intuition of the engineers."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#control-the-engineers-intuition-through-a-base-rate",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#control-the-engineers-intuition-through-a-base-rate",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "Control the engineer’s intuition through a base rate",
    "text": "Control the engineer’s intuition through a base rate\nIn the book “Thinking fast and slow,” Kahneman recommends a procedure to reign in our intuitions. He makes the following example.\n“Julie read fluently at age four. What is her GPA? For Americans familiar with the grading system, an intuitive answer is close to 3.7.”\nThis intuitive estimation is based on shared factors influencing reading age and GPA.\nHowever, this estimation completely ignores base rate effects.\nKahneman proposes a correction method\n\nEstimate the average GPA (GPA=3.0)\nMake your intuitive judgment (GPA=3.7)\nEstimate the shared factors between information and base rate (30%)\nCorrect the average by the percentage of the distance 3 + 0.7 x 0.3 = 3.21\n\nI wonder if we can apply this approach to software estimation."
  },
  {
    "objectID": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#a-base-rate-planning-algorithm",
    "href": "posts/think-fast-and-slow/try-to-establish-your-next-planning-predictions-on-welldefined-reference-points.html#a-base-rate-planning-algorithm",
    "title": "Try to establish your next planning predictions on well-defined reference points",
    "section": "A base rate planning algorithm",
    "text": "A base rate planning algorithm\nThis is my take on yet another planning algorithm (YAPA). There are some shared factors between tasks.\nThe first obstacle is the characterization of tasks in categories. Is the task difficult or easy?\nMy suggestion is to use planning poker to value complexity and work amount.\nIn the second step, value how long it will take. Everybody is welcome to add his two cents.\nThen rate the familiarity of the task and the shared factors for the people performing the task. It should be evident that people perform depending on understanding.\nThen use the familiarity to move from the average time of such a task to the intuitive judgment.\nOn completion of the task, modify the base rate of the task category.\nThe five YAPA planning steps:\n\nEstablish a base rate: use planning poker to give story points. Value complexity and work amount of the task.\nPredict how long it will take.\nRate the familiarity with the work (shared factors).\nMove the familiarity percentage of the difference to the base rate.\nRetrospectively update the base rate data\n\nHas anybody tried such a system?\nI have to admit; it seems pretty onerous to establish a base rate for different categories.\nPlease let me know your thoughts."
  },
  {
    "objectID": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html",
    "href": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html",
    "title": "There are no losses; just costs for profits",
    "section": "",
    "text": "“I sell shit” is a quote from the movie “Triangle of Sadness”.\nThe guy speaking is a millionaire. And wouldn’t you want to be a millionaire?"
  },
  {
    "objectID": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#the-marketing-matters",
    "href": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#the-marketing-matters",
    "title": "There are no losses; just costs for profits",
    "section": "1 The marketing matters",
    "text": "1 The marketing matters\nThe way you present your stuff influences how a potential buyer reacts. This is obvious for any shopping window.\n\nPhoto by Unsplash\nBut what about intellectual stuff like ideas and presentations?\nThis selling of information is also affected by its presentation. Even more, usually, the messenger effect takes place. We trust information more if it comes from a trusted messenger. Few people reject a good offer because they dislike the salesman. Of course, being a likable salesman bears still advantageous."
  },
  {
    "objectID": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#bad-apples-and-watermelons",
    "href": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#bad-apples-and-watermelons",
    "title": "There are no losses; just costs for profits",
    "section": "2 Bad apples and Watermelons",
    "text": "2 Bad apples and Watermelons\nWe often face a situation where the information we want to communicate is negative.\nImagine a sales reporting presentation. If sales are down by 30 %, that is not good.\nYou can refer to a bad apple selling strategy. From the outside, the apples look good, but from the inside, worms are already calling it their home.\nIn the business world, this pattern is also known as watermelon reporting. From the outside, all projects are green. Only on the inside are they bright red."
  },
  {
    "objectID": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#selling-shit-the-honest-way.",
    "href": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#selling-shit-the-honest-way.",
    "title": "There are no losses; just costs for profits",
    "section": "3 Selling shit the honest way.",
    "text": "3 Selling shit the honest way.\nThere is a better strategy. Everything can be framed in perspective to a reference point.\nFor the sales reporting: Reporting a 30 % decrease is not as good as reporting that sales are only 70% of last year’s sales. Both mean the same thing, but 70 % sounds better.\nIf you work on an innovation project and meet with your investors, tell them their investment has not realized any gains, but it is not lost. The investment is still in your company. A winning investment just takes time and some more cost to turn into a profit.\nThe psychological reason for this approach is the loss of averseness of your emotional brain. If I told you that lost 10000 $ and got a new car, that sounds more negative than your new car cost 10000$."
  },
  {
    "objectID": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#there-are-no-losses-just-costs-for-profits",
    "href": "posts/think-fast-and-slow/there-are-no-losses-just-costs-for-profits.html#there-are-no-losses-just-costs-for-profits",
    "title": "There are no losses; just costs for profits",
    "section": "4 There are no losses; just costs for profits",
    "text": "4 There are no losses; just costs for profits\nAs a general approach, try to communicate every lousy outcome as the cost of something, not as a loss.\nPlus points if you manage to point out that it is the cost necessary to achieve a formidable gain."
  },
  {
    "objectID": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html",
    "href": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html",
    "title": "Avoid spending mental energy as if would be limitless",
    "section": "",
    "text": "Photo by Unsplash\nFeeling stressed? Do you freak out about small things?\nYou exhausted your supply of mental energy!\nRead on to learn what mental energy is and why a lack of it is dangerous for you."
  },
  {
    "objectID": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#the-concept-of-mental-energy",
    "href": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#the-concept-of-mental-energy",
    "title": "Avoid spending mental energy as if would be limitless",
    "section": "1 The concept of mental energy",
    "text": "1 The concept of mental energy\nMental energy describes the concept that you have a limited energy reserve.\nAny thought requiring a lot of self-control draws on this energy.\nIn the theory of the two minds, the intuitive and the rational mind, this is the energy that the rational mind consumes. Sometimes this energy is also associated with motivation or the drive to do something demanding.\n\nWhen I mention a big white bear sitting next to you and smiling his toothy smile at you, try not to imagine this bear.\nRemember the last emotional film you watched, and you wanted not to be seen crying or having wet eyes?\nYou should have studied for an exam in two days and were invited to a massive party.\nRemember your first job when you wanted to impress and not disappoint your new boss.\nWhen you try to be a better self. When you ignore other people’s bad behavior and instead react kindly and empathic to their problems, especially if it is one of your loved ones.\n\nAll these moments certainly drain your mental energy, and sometimes you may react in a way you regret later on."
  },
  {
    "objectID": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#why-mental-depletion-is-dangerous",
    "href": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#why-mental-depletion-is-dangerous",
    "title": "Avoid spending mental energy as if would be limitless",
    "section": "2 Why mental depletion is dangerous",
    "text": "2 Why mental depletion is dangerous\nJust facing these situations is not a sign that you are depleted. In fact, mastering these situations can be seen as a sign of mental strength. If you have never faced such a situation, congratulations, you are a better human being than I am.\nThere are clear signs that you are mentally depleted and lost your motivation.\n\nYou abandon your diet plans and tell yourself this chocolate bar is the last for this week.\nIt is ok to buy this pair of shoes, the new SmartWatch. You have earned it after this stressful week.\nYour workplace’s arch-enemy attacked you again today, but this time you beat back and insulted him in front of everybody else.\nAt the gym, you tell yourself that today is not the day to go hard on yourself.\nMath never was your thing. We all get older, and there is certainly an easier way to solve complex problems than trying mental acrobatics.\nYou commit any of the logical fallacies.\n\nIn summary, it is dangerous to be mentally spent as you give in to your intuition and desires.\nAnd that often means you will make mistakes you regret further down the road.\nSometimes intuition can be good. The problem is those wrong judgments are difficult to detect. Confidence in your decision is not a good diagnosis.\n\n“Judgments that answer the wrong question can also be made with high confidence.”\n– Kahneman"
  },
  {
    "objectID": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#how-to-build-up-mental-energy",
    "href": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#how-to-build-up-mental-energy",
    "title": "Avoid spending mental energy as if would be limitless",
    "section": "3 How to build up mental energy",
    "text": "3 How to build up mental energy\nNow we know what mental depletion is. Solutions exist to refill and enlarge our reservoir of energy.\nSome Tips that I found:\n\nIncrease your mood by watching comedy. Cat pictures help.\nFocus on the big picture allows you to overcome short-term lows.\nRepeat your values to yourself to collect strength.\nTake a break by pursuing activities you like.\nSleep.\nDeep Breathing and Meditation."
  },
  {
    "objectID": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#how-not-to-drain-other-peoples-energy",
    "href": "posts/think-fast-and-slow/avoid-spending-mental-energy-as-if-would-be-limitless.html#how-not-to-drain-other-peoples-energy",
    "title": "Avoid spending mental energy as if would be limitless",
    "section": "4 How not to drain other people’s energy",
    "text": "4 How not to drain other people’s energy\nIt is not only our energy that is important but also the energy of our fellow human beings. Spending time with unmotivated and depleted people is less fun and, in turn, decreases your motivation.\nIn return, it is also essential not to drain too much energy in your communication.\nIf your listeners experience cognitive stress, they spend more energy.\nIf you present a complex fact, you can help the audience to understand the truth. Use appropriate diagrams and highlight parts by stressing points on slides.\nA mentally spent audience requires far more assistance to understand a complex topic.\nDo not use any complex language, complex names, etc. Quotes from difficult and unknown names are less easy to remember. Verses and figurative language make things more memorable. And easy to remember means often that it is true.\nUse any tricks described in [[202112021706 Try these 9 tips to get more and stronger follower growth]] to appear more familiar to your audience. Talk in their language."
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "",
    "text": "Photo by Unsplash"
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-hedgehog-and-the-fox",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-hedgehog-and-the-fox",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "1 The hedgehog and the fox",
    "text": "1 The hedgehog and the fox\nIn the original essay “The hedgehog and the fox” by Isaiah Berlin, “the author compares two different thinkers.\nHedgehogs know one big thing very well. They have one view of the world. They are reluctant to admit error. A failed prediction is almost always off only on timing or nearly right. They are opinionated and straightforward.\nFoxes are complex thinkers. There is no single big driver in human history. Reality emerges from the interaction of many agents and forces, including luck. While they do not possess a magical crystal ball, they are slightly better at predicting events."
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-software-specialist",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-software-specialist",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "2 The software specialist",
    "text": "2 The software specialist\nThere are usually many technologies if you work on a medium to a large software project. Some of these technologies are so complex that it takes several years to achieve mastery. An expert in this field has put in 10000 hours.\nThese experts often have issues dealing with problems that touch the periphery of their knowledge. They are not used to make predictions based on best guesses.\nThey have seen many applications, and they assume that are only a few right ways to apply their technology. Such behavior makes them like hedgehogs. They are clear in their prescription of a solution that requires implementation. If surprisingly, the solution fails, they will declare that it has almost worked and only a minor technical fault needs fixing in the future."
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-t-shaped-engineer",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#the-t-shaped-engineer",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "3 The T-Shaped engineer",
    "text": "3 The T-Shaped engineer\nWe all only have a certain amount of time in our life. In addition, we should not spend more than 40 to 60 hours a week on our work life.\nHowever, the way we spend these hours is up to everyone on his own. You can decide to learn a lot about the hot technologies in embedded software, internet software, aerospace, or automotive. You can be knowledgeable in many of the applied technologies in your industry.\nSimilar to the expert, you will also spend 10000 hours.\nYou will always have an opinion on every technology, yet you often fail to explain how something works completely. You will never be the expert. You are like the fox."
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#advantage-of-the-foxes",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#advantage-of-the-foxes",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "4 Advantage of the foxes",
    "text": "4 Advantage of the foxes\nProblems usually arise on the borders of domains. Many new technologies are created by applying two old technologies.\nThe amount of uncertainty in these problems makes initial failure very likely.\nEnter the fox. His knowledge in all related domains puts him in the best seat to spot potential failures early.\nShould we all become foxes? I am not sure. Ultimately the fox requires the advice of several hedgehogs. Without the hedgehogs, the fox will identify the problem but could fail to find a solution."
  },
  {
    "objectID": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#when-to-be-a-fox",
    "href": "posts/think-fast-and-slow/look-at-your-industrys-state-and-then-decide-if-you-want-to-become-an-expert.html#when-to-be-a-fox",
    "title": "Look at your industry’s state and then decide if you want to become an expert",
    "section": "5 When to be a fox",
    "text": "5 When to be a fox\nMy suggestion: treat the issue as a question of the maturity level in your field.\n\nWhen you are new in the field, be a fox.\nWhen the field is stable, be a hedgehog.\nWhen the field declines, be a fox to find new adjacent areas that offer innovative solutions.\n\nI am off to the fox den."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html",
    "href": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html",
    "title": "The SAFe confidence vote reveals the state of emotional security in your project",
    "section": "",
    "text": "Photo by Unsplash"
  },
  {
    "objectID": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#the-safe-confidence",
    "href": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#the-safe-confidence",
    "title": "The SAFe confidence vote reveals the state of emotional security in your project",
    "section": "1 The SAFe confidence",
    "text": "1 The SAFe confidence\nIn the Scaled Agile Framework (SAFe), a big group planning takes place to organize the next big product cycle, also called the program increment.\nAll teams come together, discuss features and provide a commitment to a delivery date.\nAt the end of the meeting, the complete plan is presented to the entire development project, and a confidence vote is held. Vote points range from 1 to 5.\nEverything about 2 is ok. Everybody that votes two or less must explain his concerns. The concerns must be resolved for the plan to be valid."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#issues-with-the-power-structure",
    "href": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#issues-with-the-power-structure",
    "title": "The SAFe confidence vote reveals the state of emotional security in your project",
    "section": "2 Issues with the power structure",
    "text": "2 Issues with the power structure\nEverybody that has done such planning knows that it is not much fun to stay at the end of the day and resolve any controversial issues.\nThis procedure brings a psychological load to those that vote with two or fewer. First, they annoy many of their coworkers who want to go home. Second, they can face criticism from the project management, which wants to see the ambitious plan approved. If the head of project management is the boss, few people feel the urge to vote with two or fewer."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#what-a-very-low-but-acceptable-score-means",
    "href": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#what-a-very-low-but-acceptable-score-means",
    "title": "The SAFe confidence vote reveals the state of emotional security in your project",
    "section": "3 What a very low but acceptable score means",
    "text": "3 What a very low but acceptable score means\nWith the votes of 2 or less penalized, only votes of at least 3 are an easy way to express everybody’s opinion.\nMany people vote three to be left alone. This voting behavior can lead to cases where the average vote is between 3 and 4 and little divergent opinions exist.\nThe low but uniform confidence means people do not believe in the plan. Nevertheless, they do not feel secure to raise concerns about any issues.\nEmotional security is not part of your project, and people do not dare to speak up."
  },
  {
    "objectID": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#low-predictability-in-software-programming",
    "href": "posts/think-fast-and-slow/the-safe-confidence-vote-reveals-the-state-of-emotional-security-in-your-project.html#low-predictability-in-software-programming",
    "title": "The SAFe confidence vote reveals the state of emotional security in your project",
    "section": "4 Low Predictability in software programming",
    "text": "4 Low Predictability in software programming\nThen what should we do if we think a plan is not feasible\nSoftware estimation is always a hot topic. In the agile literature, there is a consensus that estimations should not be commitments. To turn predictions into commitments is a management failure.\nThen why are predictions never correct? Is the method wrong? Are the people inexperienced? I presented an idea of how to take care of inexperience in another article.\nBut the issues are more complex. Kahneman pointed out that “errors of prediction are inevitable because the world is unpredictable.” This can lead to a situation where we have high confidence in experienced people. Trust alone is meaningless for the prediction that can be used as commitment.\n\n“The question is not whether these experts are well trained. It is whether their world is predictable”\n\nAnd with this, I am off to the next planning round."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html",
    "href": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html",
    "title": "You should go back to the office, to help your boss understand you",
    "section": "",
    "text": "by uNsplash (https://unsplash.com/photos/6s6ck0P8M_Q )"
  },
  {
    "objectID": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html#what-others-say",
    "href": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html#what-others-say",
    "title": "You should go back to the office, to help your boss understand you",
    "section": "1 What others say",
    "text": "1 What others say\nSome studies try to analyze what kind of person can successfully work from home. Remote work is the future.\nOn the other hand, some CEOs say working from home is for slackers. And it might not be good for your career.\nFor companies, one of the key benefits is the enlargement of the talent pool, which is no longer restricted to geographical locations. This can lead to a salary decrease/stagnation in today’s hotspots."
  },
  {
    "objectID": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html#why-you-should-consider-returning-to-office-even-if-you-think-it-is-a-bad-idea",
    "href": "posts/think-fast-and-slow/you-should-go-back-to-the-office-to-help-your-boss-understand-you.html#why-you-should-consider-returning-to-office-even-if-you-think-it-is-a-bad-idea",
    "title": "You should go back to the office, to help your boss understand you",
    "section": "2 Why you should consider returning to office even if you think it is a bad idea",
    "text": "2 Why you should consider returning to office even if you think it is a bad idea\n\n2.1 Engineers are selfish\nAs an engineer, it is often preferable to think about one’s own needs. What works best for you? How do you get your work done? We prefer tranquil workplaces with a focused daily work schedule. The software developers’ work hell is a noisy environment with lots of spontaneous communication and interruptions.\n\n\n2.2 Manager vs. Maker\nSome articles try to explain why the management prefers working in the office and makers prefer to work from home, the maker vs. manager schedule. It comes down to schedule management and unplanned interruptions. This point is much more related to the current office culture and design.\nWere we all to have our private spaces and proper meeting planning, then there is little difference between the two schedule types.\n\n\n2.3 Management is not the problem.\nThe manager’s schedule only partly explains the manager’s preference for working in an office. After all, many project managers face distributed teams and external collaborators. They spent their day almost entirely on the phone. A more structured day with fewer interruptions is better in this setting.\n\n\n2.4 People management methods\nHowever, this neglects one thing. Most of today’s organizations are still power structures. Hierarchy is still predominant. Even flat hierachies are hierachies. Someone decides, and the majority has to play up.\nThis also includes performance evaluation.\nManagers need to gauge the performance of their associates. During the extended working-from-home periods, many managers saw their effectiveness decrease.\nWith Covid less threatening than before, they prefer to have everybody working in an office. But this is merely saying my trusted method does not work in a new situation; I want to return to the old position.\n\n\n2.5 Why classic supervision fails\nThe traditional evaluation methods fail due to availability bias. We only can judge things we are aware of. Humans tend to think of less visible people as less important.\nEverybody knows this mind trick: Failing to recall an instance of success means there is no success. Does it? This is why personal contribution always feels much more significant than it is in reality. We all are the best engineer of the team.\n\n\n2.6 We like what we know\nThis psychological bias always has been at play in office politics. It is one of the cornerstones of successfully managing your boss. Talk more to the boss, and his perception of yourself will be more present in his consciousness.\nEven more, this process is self-reinforcing. If you always talk to the same person, you have a specific preference for this person’s success. Compared with other people, you will expect your favorite to succeed better.\nPreventing such fallacies requires training and intensive reflection.\nBefore the massive working-from-home period, the brain was busy treating the mental load of daily office work. Reflection is usually the first thing to be abandoned.\nOnly as the in-office interactions dried up did most supervisors realize that they were left apart from what was happening and were less effective in doing their job.\nNaturally, the easiest thing to do is to go back to the office.\n\n\n2.7 The wise engineer is seen and known.\nSo as an engineer, it would be best if you went back to the office to give your supervisor a chance to evaluate your performance with his old methods.\nAs a supervisor, the task is much greater. You need to rise above yourself and overcome your biases and prejudices toward your employees. Give training and reflection the essential place that they deserve. Figure out how to effectively monitor performance during remote work."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html",
    "href": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html",
    "title": "Use mental anchors to determine the start position of high-stakes discussions",
    "section": "",
    "text": "If you enter a bazaar and the seller starts with a price, he has anchored the price discussion on a specific value. The standard advice is to make a counteroffer with an equally offending low price.\nKahneman suggests that the best approach is not to start with an opposing low number. The contrast principle will lead to a higher price on your part, as the seller has anchored the price. Even if you know the contrast principle as a sales strategy, you will bear the psychological load: you will experience your position as unjustified and amorally."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html#anchoring-the-perception",
    "href": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html#anchoring-the-perception",
    "title": "Use mental anchors to determine the start position of high-stakes discussions",
    "section": "",
    "text": "If you enter a bazaar and the seller starts with a price, he has anchored the price discussion on a specific value. The standard advice is to make a counteroffer with an equally offending low price.\nKahneman suggests that the best approach is not to start with an opposing low number. The contrast principle will lead to a higher price on your part, as the seller has anchored the price. Even if you know the contrast principle as a sales strategy, you will bear the psychological load: you will experience your position as unjustified and amorally."
  },
  {
    "objectID": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html#resist-anchoring-by-breaking-the-pattern",
    "href": "posts/think-fast-and-slow/use-mental-anchors-to-determine-the-start-position-of-highstakes-discussions.html#resist-anchoring-by-breaking-the-pattern",
    "title": "Use mental anchors to determine the start position of high-stakes discussions",
    "section": "Resist anchoring by breaking the pattern",
    "text": "Resist anchoring by breaking the pattern\nInstead, Kahnemann suggests that you should abort any interaction. Make a scene and storm out. You will emotionally brand the initial offer as outlandishly high and attach a negative emotion to it.\nWhen you come back to the store, the emotional charge is on the seller to offer a lower price."
  },
  {
    "objectID": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#hippo-in-the-room",
    "href": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#hippo-in-the-room",
    "title": "Intellectual Dishonesty: Recognizing and Combating Toxic meeting culture",
    "section": "1 Hippo in the room",
    "text": "1 Hippo in the room\nAs someone who works in software development, I have been in countless meetings where essential questions are dodged, and those in positions of power dominate the conversation. One particular instance stood out to me when my team raised a crucial question about a new feature we were developing. Still, the head of software development avoided the topic and began discussing something else entirely. The frustration and feeling of being unheard were palpable among the team.\nAt that moment, I realized the importance of maintaining intellectual honesty in discussions. Recognizing the various fallacies used in these discussions is crucial, but finding ways to combat them is equally important."
  },
  {
    "objectID": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#knowledge-is-power-five-techniques-for-dodging-questions",
    "href": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#knowledge-is-power-five-techniques-for-dodging-questions",
    "title": "Intellectual Dishonesty: Recognizing and Combating Toxic meeting culture",
    "section": "2 Knowledge is power: five techniques for dodging questions",
    "text": "2 Knowledge is power: five techniques for dodging questions\nUnderstanding the various methods to avoid intellectual honesty is the first defense against manipulation in any discussion. After reading the five most common approaches, you can spot similar behavior in any toxic conversation.\nOne of the most common techniques to avoid answering a question is “dodging the question.” This can be done by completely ignoring the question or redirecting the conversation to a topic that is easier to discuss. For example, in a debate about the Clinton Foundation, Hilary Clinton might avoid answering the question by saying, “I did everything in this position to help our country. I am happy to talk about the Clinton Foundation.” While this response may be helpful in front of an audience, it does not address the question. Whenever somebody uses this technique, I feel frustrated and confused, as the original question was not answered, and the conversation was redirected to a different topic.\nA more offensive technique is attacking. This involves turning things around before the other person can ask the question. This can be done by accusing the other person of not asking the correct question or by making it appear as though the other person is being unfair or unreasonable. Doing this shifts the focus away from the actual topic and onto the other person’s behavior. In my experience, this often creates a hostile atmosphere and makes it difficult to continue a productive meeting.\nA slightly more subtle dodge involves choosing a keyword in the question and repeating it several times. This shows that the question has been answered, even if it has not. Similarly, responding with a joke diverts attention away from the topic. Whenever somebody opens with a joke I am left with a feeling of belittlement and that my questions do not have any value.\nIf the other side could have valid points, you can always talk them down. This involves discussing so many topics that the other person becomes overwhelmed and forgets the original question. This can be a very effective way to avoid answering difficult questions."
  },
  {
    "objectID": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#and-one-honest-way",
    "href": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#and-one-honest-way",
    "title": "Intellectual Dishonesty: Recognizing and Combating Toxic meeting culture",
    "section": "3 …and one honest way",
    "text": "3 …and one honest way\nThe honest way to answer questions is to say “I do not know” or “I do not want to answer the question.”"
  },
  {
    "objectID": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#the-world-dies-from-good-intentions.",
    "href": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#the-world-dies-from-good-intentions.",
    "title": "Intellectual Dishonesty: Recognizing and Combating Toxic meeting culture",
    "section": "4 The world dies from good intentions.",
    "text": "4 The world dies from good intentions.\nEven if it is not your intention to do harm and be dishonest, there is another way that you can be less truthful, even by accident.\nI am talking about logical fallacies.\nLogical fallacies are errors in reasoning. This website provides a long list.\nThese are techniques used to manipulate the audience’s perception of the situation. For example, bandwagoning involves pretending that millions of people believe something to increase the importance of the argument.\nSimilarly, false cause involves simply pretending that there is an explanation for something by using the word” because.” These are techniques used to manipulate the audience’s perception of the situation.\nOther fallacies include black-or-white thinking, where only extremes are considered; loaded questions, where the answer is included; and anecdotal evidence, where one’s own experience is used to prove a point."
  },
  {
    "objectID": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#how-to-stop-bad-behavior",
    "href": "posts/intellectual-dishonesty-recognizing-and-combating-toxic-meeting-culture.html#how-to-stop-bad-behavior",
    "title": "Intellectual Dishonesty: Recognizing and Combating Toxic meeting culture",
    "section": "5 How to stop bad behavior",
    "text": "5 How to stop bad behavior\nI stole this from the original article that made me write this summary https://www.shanesnow.com/articles/intellectual-dishonesty.\nIt is so good there is nothing to add.\n\n(Stop them.) “Let me stop you for a second.”\n(Gently point out the fallacy. E.g:) “I’m genuinely interested in understanding your point of view. But just because an authority figure said something, doesn’t mean it’s true.”\n(Rewind.) “Is there another way you can back this viewpoint up so that I understand?”\n\nSo please be honest, and do not forget to clap!"
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html",
    "title": "How find material to read and how to dig through it.",
    "section": "",
    "text": "Three years ago I run into the question “What are the best sources to read on programming?”\nNo matter your field of expertise, you certainly have asked yourself the question: How do I best inform myself on topic X.\nYou can search for your answer on web pages and blogs. For many daily life questions like “What is the best way to cook an egg”, this is the way to go. But what about “I want to become the best manager in the world?”. Where do you find the answer to this question? Sometimes it is good to read a good old honest book.\nQuickly, you will find books. Many books. In fact, after one hour you will have more books than you can read in one year.\nLooking over your list of books, the question certainly arises “In which order to start reading?”.\n\n\n\nQuickly, you will find books. Many books."
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#in-which-order-to-start-reading-your-booklist",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#in-which-order-to-start-reading-your-booklist",
    "title": "How find material to read and how to dig through it.",
    "section": "",
    "text": "Three years ago I run into the question “What are the best sources to read on programming?”\nNo matter your field of expertise, you certainly have asked yourself the question: How do I best inform myself on topic X.\nYou can search for your answer on web pages and blogs. For many daily life questions like “What is the best way to cook an egg”, this is the way to go. But what about “I want to become the best manager in the world?”. Where do you find the answer to this question? Sometimes it is good to read a good old honest book.\nQuickly, you will find books. Many books. In fact, after one hour you will have more books than you can read in one year.\nLooking over your list of books, the question certainly arises “In which order to start reading?”.\n\n\n\nQuickly, you will find books. Many books."
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#sunken-cost",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#sunken-cost",
    "title": "How find material to read and how to dig through it.",
    "section": "Sunken cost",
    "text": "Sunken cost\nThe issue you face is the following:\nThere is always a lack of time for the most interesting things in our life. Especially reading. In addition, starting a book, which turns out to be boring and useless is frustrating. You spent your time and energy on this book even though it gave nothing or little back to you.\nThis means the book selection process is almost as important as reading the book. At least if you want to go beyond skimming many books and not only read books on your chosen topic the entire day. Some people recommend Blinkist to get a first impression of the book. I advocate another process: Manage your booklist."
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#managing-your-reading-list",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#managing-your-reading-list",
    "title": "How find material to read and how to dig through it.",
    "section": "Managing your reading list",
    "text": "Managing your reading list\nIn the beginning, there is always the question of the start point.\nThe best method to answer “Where to start?” is a meta-search.\nWhat is a meta-search, you may ask?\nYou ask a lot of people in which order you should read their booklist.\nAsk your colleagues, ask your boss, friend, neighbor, gardener, you name it.\nEvery suggestion of a book gets a +1. You then rank all those answers and voila - you have done a meta-search and compiled your booklist."
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#to-google-or-not-to-google",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#to-google-or-not-to-google",
    "title": "How find material to read and how to dig through it.",
    "section": "To google or not to google",
    "text": "To google or not to google\nIf you are new in a community or there seems to be no community, it may be hard to find the people, who know all the answers. Luckily you and I know a guy who has most of the answers. Google. “Best books on …” is usually a good phrase to start. The search results feature web pages with lists of books.\nOnce you have several such lists the process becomes simple.\nAsk each list like you would ask a person.\nList all the books and mark +1 for every time a book appears on a list.\nThe problem with google is its simple-mindedness of google.\nDepending on the topic, there is no direct answer from google. The art is how to find interesting books via google.\nConsidering my original problem, programming books, there has been an evolution since I first searched. This question is so popular nowadays, that “what is the best book for programming” actually returns pretty good results. Piere de Wulf has automated the process:\nhttps://www.daolf.com/posts/best-programming-books/\nAs of the time of writing this is the third-best result of the google search."
  },
  {
    "objectID": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#digging-through-your-reading-list",
    "href": "posts/how-find-material-to-read-and-how-to-dig-through-it.html#digging-through-your-reading-list",
    "title": "How find material to read and how to dig through it.",
    "section": "Digging through your reading list",
    "text": "Digging through your reading list\nGreat now you have a nicely ordered list. You start and we see us in three years when you are finished? Not so fast. You should not blindly follow the lists.\nDepending on your needs reading the list from top to bottom is not what you want. Usually, you have your very own taste on what you think is important. This means you still need to read the descriptions of the book and why each listed author thinks it is a good book.\nBuilding your reading list is a process. While reading something you will stumble across new sources. As soon as the sources appear twice you can start ranking. Sometimes you get a book recommendation from a trusted source. It would be stupid to put this book at the very bottom of your reading list.\nHappy Reading!"
  },
  {
    "objectID": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html",
    "href": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html",
    "title": "The Hidden Cost of “Magic” Schemas",
    "section": "",
    "text": "Every engineer eventually meets the siren song of the “single source of truth.” DRY, the holy grail of software engineering.\nDon’t Repeat Yourself! Then why define models twice in a backend app? Once for the database, once for the API? Why not auto-generate definitions of one from the other?\nI thought the same while building my recipe scanner app.\nWith a neat utility, I could turn my SQLAlchemy model into a Pydantic schema in one line.\nRecipeOut = sqlalchemy_to_pydantic(RecipeORM)\nIt worked beautifully… until it didn’t.\nWhat started as convenience quietly eroded my trust boundaries. For a deeper explanation of trust boundaries see my post Pydantic vs. Dataclass.\nA harmless migration broke the entire API:\n\nA new internal column appeared in the public OpenAPI docs.\n\nA new nullable database field caused UI validation failures.\n\nEven lazy-loaded relationships started firing extra queries during serialization.\n\nClear symptoms of automation not being useful but hollowing out your design.\nFor early prototypes this shortcut might be acceptable. But how do you know when to stop?\nThe rest of this post explores what to do instead."
  },
  {
    "objectID": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#the-allure-of-auto-generated-schemas",
    "href": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#the-allure-of-auto-generated-schemas",
    "title": "The Hidden Cost of “Magic” Schemas",
    "section": "",
    "text": "Every engineer eventually meets the siren song of the “single source of truth.” DRY, the holy grail of software engineering.\nDon’t Repeat Yourself! Then why define models twice in a backend app? Once for the database, once for the API? Why not auto-generate definitions of one from the other?\nI thought the same while building my recipe scanner app.\nWith a neat utility, I could turn my SQLAlchemy model into a Pydantic schema in one line.\nRecipeOut = sqlalchemy_to_pydantic(RecipeORM)\nIt worked beautifully… until it didn’t.\nWhat started as convenience quietly eroded my trust boundaries. For a deeper explanation of trust boundaries see my post Pydantic vs. Dataclass.\nA harmless migration broke the entire API:\n\nA new internal column appeared in the public OpenAPI docs.\n\nA new nullable database field caused UI validation failures.\n\nEven lazy-loaded relationships started firing extra queries during serialization.\n\nClear symptoms of automation not being useful but hollowing out your design.\nFor early prototypes this shortcut might be acceptable. But how do you know when to stop?\nThe rest of this post explores what to do instead."
  },
  {
    "objectID": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#design-the-data-flow-of-your-application",
    "href": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#design-the-data-flow-of-your-application",
    "title": "The Hidden Cost of “Magic” Schemas",
    "section": "2 Design the data flow of your application",
    "text": "2 Design the data flow of your application\n\n2.1 The “walking-skeleton” mindset\nDefine the end-to-end data flow as one vertical slice through the system.\nIn our case: upload → pipeline → DB → JSON → UI.\n\nVocabulary first\nList the nouns (“Recipe”, “OCR Block”, “Nutrition”) and relationships.\nMinimal DTOs\nHand-write just enough Pydantic schemas for that first slice.\nStub everything else\nFake OCR, canned LLM responses, in-memory cache.\nShip & test\nWhen the UI renders, your contract is real.\nIterate\nReplace stubs with real logic.\n\n\n\n2.2 Controlled Divergence ≠ Incoherence\nIt’s healthy for the storage model and the API schema to diverge. What is needed for database indexing and searching might not even be necessary in your internal services, yet alone any public API.\n\n\n\n\n\n\n\n\nLayer\nOptimised For\nExample\n\n\n\n\nDatabase\nJoins, constraints, indexes, archival columns\nrecipe_version_id, deleted_at, INT2 for tiny enums\n\n\nAPI / Pipeline\nClear intent, validation, front-end friendliness\ningredients: List[str], camelCase, enum labels\n\n\n\nYou can still auto convert from the database entry and drop every additional field, dto = RecipeRead.from_orm(orm_obj)) . Defintions stay coherent, but are not coupled. Or use model_dump() to write a JSON blob of the pydantic model to the database, if you must store it.\n\n\n2.3 Triplet Schemas: Create / Update / Read\nI thought that the triplet schema appraoch utter redundancy when starting to develop my backend. Turns out it is not. You will be thankfully for any Optional field. And it is nice to not fill in fake ids, which are overwritten by the database on creation of a recipe, this removes clutter from your code.\nclass RecipeCreate(BaseModel):\n    title: str               # required\n    calories: float          \n\nclass RecipeUpdate(BaseModel):\n    title: Optional[str]     # patch semantics\n    calories: Optional[float]\n\nclass RecipeRead(BaseModel):\n    id: int\n    title: str\n    calories: float\nFor naming convention, pick a convention early and stick to it. Even if it feels verbose, teammates (and future you) will navigate the repo with ease.\nFurther Benefits:\n\nMake-fields-required-later without breaking PATCH routes.\nDisallow mutation of field id simply by omitting it in Update.\nOpenAPI docs become self-explanatory.\n\n\n\n2.4 Wrapper DTOs Keep Lists Clean\nHaving lists or multiple fields in your routes makes debugging in your browser harder.\nUse a wrapper. Here is pagination of recipe search results:\nclass RecipePage(BaseModel):\n    items: List[RecipeRead]\n    total: int\n    skip:  int\n    limit: int\n    has_more: bool\nThis pattern lets you extend api complexity without disturbing the inner DTO. And of course there is no connection to the database schema."
  },
  {
    "objectID": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#final-take-aways",
    "href": "posts/projects/recipescanner/the-hidden-cost-of-magic-schemas.html#final-take-aways",
    "title": "The Hidden Cost of “Magic” Schemas",
    "section": "3 Final Take-aways",
    "text": "3 Final Take-aways\n\nAutomatic models are a scaffold, not a contract. Use only them only in prototypes.\nModel vocab first, ship a thin end to end slice, iterate.\nEmbrace purposeful divergence between DB and API.\nRedundant names and schema triplets pay dividends in clarity, validation, and future refactors.\n\nGood systems age well not because they’re perfectly DRY, but because their trust boundaries are deliberate.\nWriting your schemas by hand is an act of intent. You decide what is exposed in the API and what remains inside the backend.\nKeep in my mind: Automation can help you move fast, but clarity is what helps you keep moving.\nThat’s the real tradeoff behind “auto-generated schemas”: not speed versus redundancy, but convenience versus comprehension."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html",
    "title": "The Rebirth of the recipescanner - part 2",
    "section": "",
    "text": "Turning half a shelf of cookbooks into a week’s meals shouldn’t take longer than cooking itself. Yet this frequently happenend to me, when I tried to get recipes from my books, copy ingredients, and build a shopping list by hand. Family life can be stressful, and who has time to read through all the books and make creative meal plans? Me, no.\n\n\n\nMy first attempt at this was the Recipescanner, see part 1 In his different versions it turned Book pages in Paprika recipes. Aggregation of the cooking list was done by Paprika. This saved time with the mechanical tasks, but not with creativity. I still hat to hunt for the dishes, which fit well together."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#what-happenend-in-part-1",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#what-happenend-in-part-1",
    "title": "The Rebirth of the recipescanner - part 2",
    "section": "",
    "text": "Turning half a shelf of cookbooks into a week’s meals shouldn’t take longer than cooking itself. Yet this frequently happenend to me, when I tried to get recipes from my books, copy ingredients, and build a shopping list by hand. Family life can be stressful, and who has time to read through all the books and make creative meal plans? Me, no.\n\n\n\nMy first attempt at this was the Recipescanner, see part 1 In his different versions it turned Book pages in Paprika recipes. Aggregation of the cooking list was done by Paprika. This saved time with the mechanical tasks, but not with creativity. I still hat to hunt for the dishes, which fit well together."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#attempt-2-just-ask-chatgpt",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#attempt-2-just-ask-chatgpt",
    "title": "The Rebirth of the recipescanner - part 2",
    "section": "2 Attempt #2 “Just ask ChatGPT”",
    "text": "2 Attempt #2 “Just ask ChatGPT”\nLately I noticed I will just turn to ChatGPT. While the recipes are quite ok, there often lack the little extra. Good cookbooks and special food blogs often provide this extra information. To my experience, online recipe collections do not provide all the little tricks in the recipe, as average cooks often write them. The same applies for complete meal plans. Ok, but somehow not that fascinating.\nLLMs usually provide the average answers. And average cooks do not have recipes with the certain sparkle. Skillful prompt engineering or follow-up prompts could certainly surface this information from the vast amount of training data.\nI think the main issue is one of uncertainty. You assume that there are special tricks for a recipe you do not know. But you do not know in what area of cooking they are: preparation, order of adding, temperature? Doing so requires often a very skillful intuition. In my experience, why expert programmers can get so much more from LLMs than beginners for programming? They have the intuition to ask the right questions."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#idea-lets-just-chat-about-our-recipes",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#idea-lets-just-chat-about-our-recipes",
    "title": "The Rebirth of the recipescanner - part 2",
    "section": "3 Idea: Let’s just chat about our recipes",
    "text": "3 Idea: Let’s just chat about our recipes\nFor our recipes, the solution could be easier. We rephrase the question. Instead of asking for the generation of a new (unique) recipe, we ask just to select from a collection of known recipes. This assumes our recipe collection only has outstanding books and notes, but we do not remember where to look.\nWhat we would then do is a simple vector-based similarity search, which fits our request. Then we either just furnish the recipes or we make up a recipe based on the recipes we found. In the second case, it is much more likely that the answer contains the little extra we search.\nThe entire process of querying a database before generation is called Retrieval Augmented Generation (RAG).\nThis is something which can be done with local chat apps. Gpt4all can create embeddings for the recipes and use a generic chat to talk about them.\n\n3.1 Going beyond chatting\nBut wait, there is more we could do. When we create a meal plan and a shopping list, we create data. We could use that data.\nWhat if we had an agent? We could ask to generate plans for us based on our wishes. It could also check what weekly promotions exist or offer seasonal suggestions. Even better, you would know what you cooked last week. He could know what you like and could ask what you liked or disliked about last week’s meals.\nIt is like a personal chef. Only he does not cook. Maybe that could be an extension :-).\nThis article is not only about the history of the recipescanner. It is the kickoff to an endeavour to create an AI agent that chats with about recipes and meal plans."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#getting-to-work",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner-part.html#getting-to-work",
    "title": "The Rebirth of the recipescanner - part 2",
    "section": "4 Getting to work",
    "text": "4 Getting to work\n\n4.1 Product engineering meets AI Agent\nThe general direction is clear. A software that does all the meal planning.\nWith all the hype about AI agent, we are going to build one.\nOne issue, what kind of tool should the agent actually work with. Integrating it with Paprika, my current app is too complex. I could certainly search for a basic recipe app and try to integrate it.\nOne key aspect of my workflow is the digitalization. Few to no apps have this in a way I want it. Therefore, I built a meal planner from scratch with Python and React.\nThere is some upfront work to generate the meal planned before getting to the actual LLM work.\nThe Versions I currently aim for:\n\nReplacement of current Paprika based workflow. Web-app for manual recipe handling via frontend. Basic chat app with different model providers (local for testing and online for better performance). Scanning and Recipe generation, as in the previous version.\nA Langgraph based chat app to talk about recipes in database and meal plans. RAG Chat.\nTrigger creation of new recipes and meal plans. Iterative workflow.\nTake nutritional and seasonal information into account. Diet plan. Backfill missing data in recipes.\n\n\n\n4.2 How to start\nBack to software engineering. In Do you know the hidden paths of your code, I talked about the importance of architecture.\nAnother question I follow in this project: LLMs are a big missing puzzle piece in creating better architecture, but how to use them effectively? With all the hype on AI code generation, I was quite optimistic. I would advance with the legacy part.\nAfter a lot of discussion, I asked ChatGPT to create a good starting prompt for my idea:\nYou are a senior full-stack engineer and AI-agent architect.  \nTask: walk me step-by-step through building a **chat-based weekly meal-planner** with these features:\n\n\n1. **Tech stack**  \n   - Python 3.12, FastAPI backend  \n   - Postgres + pgvector for recipes & embeddings  \n   - LangChain + LangGraph for an agent with a planning loop and persistent state  \n   - OR-Tools (or PuLP) to solve the nutrient/effort constraint model  \n   - React (Vite) chat UI\n\n1. **Core requirements**  \n   - take pictures and use google ocr to get json\n   - Ingest/parse recipe JSON → add tags, nutrition, effort minutes, fill a database entry. currently i use paprika recipes format to store data\n   - bulk mode for pictures\n   - Vector search for recipe Q&A (RAG node)  \n   - Planning node builds a 7-day plan that:  \n     • hits user kcal/macro targets ±10 %  \n     • caps hands-on cooking time per day  \n     • avoids any recipe used in the previous 3 weeks  \n   - Approval loop: if the user types “change”, the graph re-plans until accepted  \n   - On acceptance, write `meal_plan` table and return a shopping list grouped by aisle  \n   - Persist `recent_recipes` (rolling 21 recipes) and chat history in Redis\n   - ui: similar to chatgpt. left side menu and session overview. ability to browse through recipes. should work on desktop and mobile.\n\n3. **Deliverables to produce in this session**  \n   - High-level architecture diagram  \n   - Database schema SQL  \n   - LangGraph code skeleton with nodes and edges  \n   - Sample FastAPI route that streams assistant responses  \n   - Minimal React chat component calling the API  \n   - Docker-compose file for Postgres+backend\n\nGive concise explanations; focus on runnable code and folder structure. Assume I know the basics—skip introductions. After each section, wait for my “next” before continuing.\nIn stage 3, we already see the issue. The computer would dive directly into coding. With such an extensive project that would lead to a big mess.\nInstead, I spent some time on the architecture. You can find the details below.\n\n\n\nThe first version offered by the language model. Without diving into the details. There seem to be too many blocks.\n\n\n\n\n\nAfter some modifications I settled on this.\n\n\nThis leads me to the next big issue. Big bang building is equal to the Big bang integration. As such, we need incremental working versions.\nI kicked it off with a JetBrains AI Assitant do the coding. It started with the impressive generation of 47 files and a fully functional mocked frontend.\nWow, at that speed, I would finish in a week.\nWell,…\n…\nSpoiler for the next article. Not so fast. Remember: “The only way to go fast is to go well”. And it turned out the LLM does not go well for bigger projects."
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html",
    "title": "When to use pydantic in your app?",
    "section": "",
    "text": "AI agents, LLM api calls and the overall microservice architecture of modernd AI applications passes data over many interfaces. The real challenge behind all this is not speed, but managing complexity and structure.\nToo much validation at the interfaces and your system drags. Too little, and single malformed entry can blow everything up.\n\n\n\nI recently started building a recipe-digitization platform for cookbooks.\nThe data of single “recipe” object snakes through:\n\nThe frontend app.\nFastAPI (request body validation).\nA LangGraph pipeline that does OCR, LLM classification, nutrition maths.\nPostgreSQL for storage.\nRetrieval from storage.\nAnother LangGraph pipeline for recommendations and question answering\n\nThat data crosses six trust boundaries. One malformed field and the whole chain can break. Without proper testing or custom exceptions it will not even be clear where the chain broke.\nImagine the frontend sends \"calories\": \"three hundred\" instead of 300.\nFastAPI happily passes it along, the LangGraph pipeline classifies it, your nutrition module tries to sum up the numbers — and somewhere deep inside, Python raises TypeError: unsupported operand type(s) for +: 'int' and 'str'.\nBy then the stack trace is six layers deep and no one remembers which hop introduced the bad data.\n\n\n\nInterface contracts is where Pydantic shines: every hop can call model_validate(). The invalid or missing fields are found at every link.\nWith an ordinary class you’d need a minefield of if not isinstance() checks or hope that the error explodes somewhere downstream and you have good exception handling in place.\n\n\n\nBut if your code is a tight loop (see also this post), which mutates ten thousand bounding-boxes per second, the extra validation overhead is waste you can’t afford.\nThat’s when a plain @dataclass is better.\n\n\n\nSo how do you decide when to pick which. The decision is usually done early in the development, as switching comes at a cost.\nRead on for my guide of pydantic vs. dataclass."
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#a-tale-of-two-classes",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#a-tale-of-two-classes",
    "title": "When to use pydantic in your app?",
    "section": "",
    "text": "AI agents, LLM api calls and the overall microservice architecture of modernd AI applications passes data over many interfaces. The real challenge behind all this is not speed, but managing complexity and structure.\nToo much validation at the interfaces and your system drags. Too little, and single malformed entry can blow everything up.\n\n\n\nI recently started building a recipe-digitization platform for cookbooks.\nThe data of single “recipe” object snakes through:\n\nThe frontend app.\nFastAPI (request body validation).\nA LangGraph pipeline that does OCR, LLM classification, nutrition maths.\nPostgreSQL for storage.\nRetrieval from storage.\nAnother LangGraph pipeline for recommendations and question answering\n\nThat data crosses six trust boundaries. One malformed field and the whole chain can break. Without proper testing or custom exceptions it will not even be clear where the chain broke.\nImagine the frontend sends \"calories\": \"three hundred\" instead of 300.\nFastAPI happily passes it along, the LangGraph pipeline classifies it, your nutrition module tries to sum up the numbers — and somewhere deep inside, Python raises TypeError: unsupported operand type(s) for +: 'int' and 'str'.\nBy then the stack trace is six layers deep and no one remembers which hop introduced the bad data.\n\n\n\nInterface contracts is where Pydantic shines: every hop can call model_validate(). The invalid or missing fields are found at every link.\nWith an ordinary class you’d need a minefield of if not isinstance() checks or hope that the error explodes somewhere downstream and you have good exception handling in place.\n\n\n\nBut if your code is a tight loop (see also this post), which mutates ten thousand bounding-boxes per second, the extra validation overhead is waste you can’t afford.\nThat’s when a plain @dataclass is better.\n\n\n\nSo how do you decide when to pick which. The decision is usually done early in the development, as switching comes at a cost.\nRead on for my guide of pydantic vs. dataclass."
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#when-pydantic-has-the-top-hand",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#when-pydantic-has-the-top-hand",
    "title": "When to use pydantic in your app?",
    "section": "2 When Pydantic has the top hand",
    "text": "2 When Pydantic has the top hand\n\n2.1 Anything public\nPublic means “untrusted”: browser forms, mobile apps, webhook payloads, micro-service messages.\nA rule of thumb: If humans or foreign code can hit an endpoint, wrap the payload in Pydantic.\nPydantic will:\n\nCoerce \"42\" into int(42) and reject \"forty-two\".\nProduce gorgeous, self-updating OpenAPI docs for your front-enders.\nHand you a neat .model_dump() dict ready for JSON or logging.\n\n\n\n2.2 Pipes, DAGs and other data hurricanes\nIn a LangGraph or Airflow style pipeline, data hops from node to node.\nA single corrupted value will keep blowing up later nodes. It can be hard to track down the root cause.\nDeclaring each node’s input and output as Pydantic acts as formalization of the interface contract. If the contract is broken a validation error is raised immediately.\n\n\n2.3 Anything you need to document\nIf your product requires interface documentation of modules, explaining the interface in a docstring is waste.\nPydantic (especially inside FastAPI) auto-publishes a living JSON schema. Your docs automatically stay aligned with reality; no code-docu schism."
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#when-a-dataclass-wins",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#when-a-dataclass-wins",
    "title": "When to use pydantic in your app?",
    "section": "3 When a dataclass wins",
    "text": "3 When a dataclass wins\n\n3.1 Performance-critical inner loops\nParsing and validating thousands of objects per second costs CPU.\nIf you’re:\n\nTransforming video frames\nRunning physics simulations\nStreaming sensor data\n\n…then a bare @dataclass is often 10-15× faster to instantiate. You already trust the numbers, only the documentation of the interface contract requires more manual effort now.\n\n\n3.2 Immutable configuration\nApp-level settings—API keys, directory paths—are loaded once at boot. After that they never change.\nA frozen @dataclass is lighter. You can still parse env files with tools like python-dotenv.\n\n\n3.3 Library code that must stay dependency-free\nIf you publish a small library, dragging in Pydantic’s dependency tree is overkill for users.\nPlain classes keep your footprint tiny and import times fast.\n\n\n3.4 Behaviour-heavy domain objects\nThe more your class behaves like an actor (lots of methods, cached properties, custom __eq__), the less benefit you get from declarative validation. Pydantic is just additional formalism with little added value."
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#practical-tips-for-your-project",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#practical-tips-for-your-project",
    "title": "When to use pydantic in your app?",
    "section": "4 Practical tips for your project",
    "text": "4 Practical tips for your project\n\n4.1 A hybrid pattern that scales\nFrom my research, I found that most large back-ends settle on three layers:\n\n\n\n\n\n\n\n\nLayer\nTypical choice\nRationale\n\n\n\n\nEdge / API\nPydantic\nStrong validation + OpenAPI\n\n\nCore logic\nMix & match\nPydantic where data hops, dataclass for hot loops\n\n\nPersistence\nSQLAlchemy models\nMirrors DB; cast to/from Pydantic with .model_validate()\n\n\n\nThat means you can convert like so:\ndto   = RecipeRead.model_validate(orm_obj, from_attributes=True)  # ORM → DTO\norm_obj.calories = dto.calories                                   # DTO → ORM\nNo reflection required, and the mapping is crystal-clear.\n\n\n4.2 Naming endings save future tears\nPydantic is frequently used on Public APIs, which support create, update, read methods.\nPick a convention on day one and never break it:\n\nRecipeCreate, RecipeUpdate, RecipeRead\nOr RecipeIn, RecipePatch, RecipeOut\nWrappers like RecipePage, RecipeFilters\n\nWhen I started doing it, I thought three nearly identical models are redundant. Yet when the tar pit of complexity tries to drag you in, you are happy for every stick that you can reach; or in other words if you defined a Update Class with optional fields.\n\n\n4.3 Decision Graph\nYou can use this graph to decide what to use.\n\n\n\n\n\nflowchart TD\n\nA([Start]) --&gt; B{Will external input&lt;br/&gt;populate it?}\n\nB --&gt;|Yes| P1[Pydantic]\n\nB --&gt;|No| C{Does it cross a thread,&lt;br/&gt;process or service boundary?}\n\nC --&gt;|Yes| P1[Pydantic]\n\nC --&gt;|No| D{Instantiated in a tight loop&lt;br/&gt;thousands of times?}\n\nD --&gt;|Yes| D1[Dataclass]\n\nD --&gt;|No| E{Need brainy behaviour:&lt;br/&gt;caching, math ops, etc.?}\n\nE --&gt;|Yes| CL[Plain class]\n\nE --&gt;|No| F{Need OpenAPI or&lt;br/&gt;JSON Schema?}\n\nF --&gt;|Yes| P1[Pydantic]\n\nF --&gt;|No| CL[Plain class]"
  },
  {
    "objectID": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#the-bottom-line",
    "href": "posts/projects/recipescanner/when-to-use-pydantic-in-your-app.html#the-bottom-line",
    "title": "When to use pydantic in your app?",
    "section": "5 The bottom line",
    "text": "5 The bottom line\n\nPydantic is not just syntactic sugar; it is a contract, a validator, and a documentation generator baked into one.\nDataclasses and plain classes are perfect for tight, trusted, logic-heavy cores.\nLarge projects thrive when they mix them intentionally: Pydantic at the boundaries, dataclasses for heavy lifting.\n\nThe real skill isn’t memorizing which decorator to use; it’s learning to see your system as a chain of trust boundaries.\nPydantic, dataclasses, or plain classes are just different ways of declaring that trust, what you verify, and where errors should surface.\nIn larger systems, this mindset scales beyond Python: enterprise teams in any language end up building similar constructs to formalize trust at their interfaces. The principle of trust boundaries endures.\nIn the end that also applies how people work together. Teams thrive on clear contracts and responsibility.\nStructure buys clarity and, and clarity buys speed. Pydantic is one tool to execute this philosophy."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner.html",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner.html",
    "title": "The Rebirth of the recipescanner",
    "section": "",
    "text": "Dear Reader, are you fond of cooking? If yes, then you are facing the challenges of meal planning and searching for recipes. Even more, you still have to go out and buy groceries every week. I do not dislike those tasks. They can be fun but they take time. Time better spent cooking. Personally, I find cooking relaxing, whereas the preparation and shopping often add more strees to my busy schedule.\n\n\nThere are many apps, which can plan, guide and organize shopping list. I did not intend to reinvent the wheel. My specific issue was that my recipes are in books. I have to read through books and then assemble a shopping list. Much like my Grandmother would have done.\nTired of skimming books, I was searching for a way to digitize my existing recipe book collection as easy as possible. In April 2019, I decided to build a small sidekick application whose differentiator would be to to scan and digitize physical cookbooks. This endeavour was about to breathe new life into the dusty cookbook.\nIn the beginning, I started prototyping in python using OpenCV and TesseractOCR.\nI had non-working drafts for the entire software. What I did not have was a working software.\nThis came much to my suprise, as I followed good engineering practices, including test driven development. At least what I believed good practices to be. This is related to the Dunning Kruger Effect. A popular, but wrong representation below. Why this is misleading and more on the actual outcome of the study here.\n\n\n\nDunning Kruger Effect. I am the green Point, back in 2019.\n\n\n\n\n\n\n\n\nNoteTest driven Developement (TDD)\n\n\n\n\n\nTest-Driven Development (TDD) is a software development practice where you write tests before writing the implementation. The ideal programming cycle becomes: write a failing test → write just enough code to pass the test → refactor.\nIn contrast, to me, it meant writing tests close to the implementation. Often after the fact. I only later in my life became to grasp the idea and benefits of test-first.\n\n\n\nAfter two months of experimentation with various new technologies, I had developed a rudimentary approach. It worked based on simple rules of text position and length, as well as some keywords. I relied on domain knowledge of recipe books: title is at the top, ingredients appear as a block and often start with numbers. I realized the limitations of this approach as I developed a working prototype. Too much variation and the rules would fail. However, i thought of creating just enough data to bootstrap an ML process.\nThen the project went dormant for ten months.\n\n\n\nThe first recipe with classified entries. Colors show the different fields\n\n\n\n\n\nIn the meantime, I had discovered Paprika as my recipe organization app.\nThe previous app suffered from poor OCR results using Tesseract. Tesseract works best on traditional scans. I was working on phone pictures shot with a shaky hand during low evening light.\nI got interested in mobile machine learning applications around that time. Any privacy issue becomes much easier compared to cloud based solutions. In addition, any compute cost in data centers could be reduced to almost zero.\nI explored Google's ML Kit, which offers on-device OCR optimized for smartphone. I downloaded the according demo app.\nAround November 2020, I had figured out how to program a OCR app on android using Kotlin. Compared to tesseract the results where not even better, Google’s structured OCR output simplified the recipe extraction problem.\nMy complex problems of getting ingredients from books was reduced:\n\nPaprika handles recipe organizatio and shopping list. Everything must be in English.\nGoogle ML kit is the OCR scanner, and translates to English.\nMy app focuses on parsing structured OCR Output to recipe data.\n\nBy January 2021, I had the core logic working in python. In another project, I was working on custom C++ applications for an Android camera. Therefore, I went the C++ route and used Android NDK. In hindsight, that was a terrible decision as it bloated the tech stack.\nFrom there it took another 4 months until April 2021 up to the working release of the Recipe scanner.\nEven though the app worked and I had cleared many operational stages in the Google Play Store, it never made it to the ultimate public release.\nRecipe Scanner Android Version\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe android app worked well by analysing the Json output of the Google OCR. The rule system was more complex, but still failed if the books were too complex. I decided in 2022 to not go done the machine learning alley, because I focused on storytelling (this blog) and software engineering management.\nBy 2023, managing machine learning projects had become part of my professional life. Simultaneously, the emergence of ChatGPT offered new possibilities. Instead of going the difficult route of doing embeddings, I tried simple prompt engineering.\nInitially, single-step prompts struggled with accuracy, especially with non-English recipes. To overcome this, I designed the following structured prompt:\nThe user provides a recipe. Do not translate anything. Create a YAML file formatted as follows:\n\n---\nname: My Tasty Recipe\nservings: 4-6 servings\nprep_time: 10 min\ncook_time: 30 min\nnutritional_info: 500 calories\ndifficulty: Easy\nnotes: |\n  add interesting notes here\ningredients: |\n  ingredient 1\n  ingredient 2\n  (do not translate)\ndirections: |\n  list necessary steps\n  (do not translate)\nSurprisingly, this simple prompt effectively solved the parsing issue.\nThe remaining work reduced to produce glue code between the Google api, the ChatGPT api and the Paprika api to automate recipe uploads to Paprika.\nTaking the pictures had become the most difficult aspect of digitizing recipe books. In a way this had become a low - to no code solution.\nFrustrated that all the hard work of learning had been for nothing, I stopped development again and did not even bother to write this post.\n\n\n\nSelecting the right programming language is critical but challenging. I explored Python, Java, Kotlin, and C++, each with strengths and drawbacks:\n\nPython: Excellent prototyping, weak Android support\nKotlin: Intuitive syntax but Android-centric\nJava: Robust but hindered by asynchronous callback complexity\nC++: High performance but complexity and segmentation faults with Android NDK\n\nLarge Language Models (LLMs) changed all this.\n\nThe value of 90% of my skills just dropped to $0. The leverage for the remaining 10% went up 1000x.\nKent Beck\n\nI agree. knowing the ins and outs of each language has become low value. For me, what still bears high value: Algorithm design and knowledge of the complete software development cycle. For the very technical aspects a good book on software architecture: Software Architecture in Practice - Len Bass et al..\nFor the recipescanner, what matters most: data structures, architecture, deployment.\nIt feels good to have put out a piece of software in the world. Software, which at least for me makes my life easier.\nHopefully, in the future also for other people as I decided to continue this project."
  },
  {
    "objectID": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner.html#cooking-without-ingredients-is-difficult",
    "href": "posts/projects/recipescanner/the-rebirth-of-the-recipescanner.html#cooking-without-ingredients-is-difficult",
    "title": "The Rebirth of the recipescanner",
    "section": "",
    "text": "Dear Reader, are you fond of cooking? If yes, then you are facing the challenges of meal planning and searching for recipes. Even more, you still have to go out and buy groceries every week. I do not dislike those tasks. They can be fun but they take time. Time better spent cooking. Personally, I find cooking relaxing, whereas the preparation and shopping often add more strees to my busy schedule.\n\n\nThere are many apps, which can plan, guide and organize shopping list. I did not intend to reinvent the wheel. My specific issue was that my recipes are in books. I have to read through books and then assemble a shopping list. Much like my Grandmother would have done.\nTired of skimming books, I was searching for a way to digitize my existing recipe book collection as easy as possible. In April 2019, I decided to build a small sidekick application whose differentiator would be to to scan and digitize physical cookbooks. This endeavour was about to breathe new life into the dusty cookbook.\nIn the beginning, I started prototyping in python using OpenCV and TesseractOCR.\nI had non-working drafts for the entire software. What I did not have was a working software.\nThis came much to my suprise, as I followed good engineering practices, including test driven development. At least what I believed good practices to be. This is related to the Dunning Kruger Effect. A popular, but wrong representation below. Why this is misleading and more on the actual outcome of the study here.\n\n\n\nDunning Kruger Effect. I am the green Point, back in 2019.\n\n\n\n\n\n\n\n\nNoteTest driven Developement (TDD)\n\n\n\n\n\nTest-Driven Development (TDD) is a software development practice where you write tests before writing the implementation. The ideal programming cycle becomes: write a failing test → write just enough code to pass the test → refactor.\nIn contrast, to me, it meant writing tests close to the implementation. Often after the fact. I only later in my life became to grasp the idea and benefits of test-first.\n\n\n\nAfter two months of experimentation with various new technologies, I had developed a rudimentary approach. It worked based on simple rules of text position and length, as well as some keywords. I relied on domain knowledge of recipe books: title is at the top, ingredients appear as a block and often start with numbers. I realized the limitations of this approach as I developed a working prototype. Too much variation and the rules would fail. However, i thought of creating just enough data to bootstrap an ML process.\nThen the project went dormant for ten months.\n\n\n\nThe first recipe with classified entries. Colors show the different fields\n\n\n\n\n\nIn the meantime, I had discovered Paprika as my recipe organization app.\nThe previous app suffered from poor OCR results using Tesseract. Tesseract works best on traditional scans. I was working on phone pictures shot with a shaky hand during low evening light.\nI got interested in mobile machine learning applications around that time. Any privacy issue becomes much easier compared to cloud based solutions. In addition, any compute cost in data centers could be reduced to almost zero.\nI explored Google's ML Kit, which offers on-device OCR optimized for smartphone. I downloaded the according demo app.\nAround November 2020, I had figured out how to program a OCR app on android using Kotlin. Compared to tesseract the results where not even better, Google’s structured OCR output simplified the recipe extraction problem.\nMy complex problems of getting ingredients from books was reduced:\n\nPaprika handles recipe organizatio and shopping list. Everything must be in English.\nGoogle ML kit is the OCR scanner, and translates to English.\nMy app focuses on parsing structured OCR Output to recipe data.\n\nBy January 2021, I had the core logic working in python. In another project, I was working on custom C++ applications for an Android camera. Therefore, I went the C++ route and used Android NDK. In hindsight, that was a terrible decision as it bloated the tech stack.\nFrom there it took another 4 months until April 2021 up to the working release of the Recipe scanner.\nEven though the app worked and I had cleared many operational stages in the Google Play Store, it never made it to the ultimate public release.\nRecipe Scanner Android Version\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe android app worked well by analysing the Json output of the Google OCR. The rule system was more complex, but still failed if the books were too complex. I decided in 2022 to not go done the machine learning alley, because I focused on storytelling (this blog) and software engineering management.\nBy 2023, managing machine learning projects had become part of my professional life. Simultaneously, the emergence of ChatGPT offered new possibilities. Instead of going the difficult route of doing embeddings, I tried simple prompt engineering.\nInitially, single-step prompts struggled with accuracy, especially with non-English recipes. To overcome this, I designed the following structured prompt:\nThe user provides a recipe. Do not translate anything. Create a YAML file formatted as follows:\n\n---\nname: My Tasty Recipe\nservings: 4-6 servings\nprep_time: 10 min\ncook_time: 30 min\nnutritional_info: 500 calories\ndifficulty: Easy\nnotes: |\n  add interesting notes here\ningredients: |\n  ingredient 1\n  ingredient 2\n  (do not translate)\ndirections: |\n  list necessary steps\n  (do not translate)\nSurprisingly, this simple prompt effectively solved the parsing issue.\nThe remaining work reduced to produce glue code between the Google api, the ChatGPT api and the Paprika api to automate recipe uploads to Paprika.\nTaking the pictures had become the most difficult aspect of digitizing recipe books. In a way this had become a low - to no code solution.\nFrustrated that all the hard work of learning had been for nothing, I stopped development again and did not even bother to write this post.\n\n\n\nSelecting the right programming language is critical but challenging. I explored Python, Java, Kotlin, and C++, each with strengths and drawbacks:\n\nPython: Excellent prototyping, weak Android support\nKotlin: Intuitive syntax but Android-centric\nJava: Robust but hindered by asynchronous callback complexity\nC++: High performance but complexity and segmentation faults with Android NDK\n\nLarge Language Models (LLMs) changed all this.\n\nThe value of 90% of my skills just dropped to $0. The leverage for the remaining 10% went up 1000x.\nKent Beck\n\nI agree. knowing the ins and outs of each language has become low value. For me, what still bears high value: Algorithm design and knowledge of the complete software development cycle. For the very technical aspects a good book on software architecture: Software Architecture in Practice - Len Bass et al..\nFor the recipescanner, what matters most: data structures, architecture, deployment.\nIt feels good to have put out a piece of software in the world. Software, which at least for me makes my life easier.\nHopefully, in the future also for other people as I decided to continue this project."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html",
    "href": "posts/projects/recipescanner/text_or_image_page.html",
    "title": "Text or Image",
    "section": "",
    "text": "That is the question I asked myself recently. I ’ve been working on a recipe digitization app, aka the recipe scanner app.\nThe idea is simple: take snapshots of your favourite recipes from books or magazines. Then a pipeline guides you through the digitization with as little manual effort as possible.\nThis pipeline relies on several API calls: OCR for text extraction LLM inference. OCR calls are billed per request and LLMs per token.\nThe pipeline should automatically skip those expensive stages whenever possible.\nHere are two example pages:\n\n\n\n\n\n\nImage Page\n\n\n\n\n\n\n\nText Page\n\n\n\n\n\n\n\nI started with purely computer vision-based methods, based on structure, color simplicity, and edge density. However, on my small test dataset of six images, I did not get a 100% working solution.\nI then reverted to a more complex solution, using a OCR. Even with a local tool like Pytesseract, the results are very good. If more than 50 words are detected, that’s a text page.\nThe solution works but is slow as OCR favors high resolution images.\nIn this notebook I will try to deliver a CNN-based classifier that should run quicker while still achieving high accuracy."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html#what-makes-text-page-a-page-full-of-text",
    "href": "posts/projects/recipescanner/text_or_image_page.html#what-makes-text-page-a-page-full-of-text",
    "title": "Text or Image",
    "section": "",
    "text": "That is the question I asked myself recently. I ’ve been working on a recipe digitization app, aka the recipe scanner app.\nThe idea is simple: take snapshots of your favourite recipes from books or magazines. Then a pipeline guides you through the digitization with as little manual effort as possible.\nThis pipeline relies on several API calls: OCR for text extraction LLM inference. OCR calls are billed per request and LLMs per token.\nThe pipeline should automatically skip those expensive stages whenever possible.\nHere are two example pages:\n\n\n\n\n\n\nImage Page\n\n\n\n\n\n\n\nText Page\n\n\n\n\n\n\n\nI started with purely computer vision-based methods, based on structure, color simplicity, and edge density. However, on my small test dataset of six images, I did not get a 100% working solution.\nI then reverted to a more complex solution, using a OCR. Even with a local tool like Pytesseract, the results are very good. If more than 50 words are detected, that’s a text page.\nThe solution works but is slow as OCR favors high resolution images.\nIn this notebook I will try to deliver a CNN-based classifier that should run quicker while still achieving high accuracy."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html#deep-learning-to-the-rescue",
    "href": "posts/projects/recipescanner/text_or_image_page.html#deep-learning-to-the-rescue",
    "title": "Text or Image",
    "section": "2 Deep learning to the rescue",
    "text": "2 Deep learning to the rescue\nI trained a first model based on existing scans I had available. Due to copyright restrictions, the dataset is not public.\nFor the future, each user could build their own dataset. The initial samples can be selected by the OCR pipeline or the user clicking. Then a classifier is trained. Once it is accurate enough, we switch the pipeline to the quicker CNN classifier.\n\n\nCode\nfrom fastai.vision.all import *\nfrom fastcore.all import *\nfrom PIL import Image, ImageOps\nset_seed(42, reproducible=True)\n\n\n\n2.1 Cleaning the data with help of the first model\n\n\n2.2 Choice of model and setup\nBefore we dive into different options for modeling, we will do a quick pass through the data and see which images do not fit well. The data has two categories image_page or text_page. The dataset is balanced with 330 image pages to 355 text pages. We will therefore stick to accuracy as metric.\nWe use 20 % validation data. The images are too big for the net. Therefore, we resize to 192 px. We pad to preserve aspect ratio. Rotations are dealt with on loading.\nFor the first pass we choose resnet18.\n\ndef correct_exif_orientation(fn):\n    img = Image.open(fn)\n    return ImageOps.exif_transpose(img)\n\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=[Resize(192,method='pad', pad_mode='zeros')]\n)\n\nLet’s load our data and inspect.\n\ndls = pages.dataloaders(\"data/raw/\")\ndls.show_batch()\n\n\n\n\n\n\n\n\nWe define a learner and fine-tune.\n\nset_seed(42, reproducible=True)\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.682892\n0.014835\n0.992754\n00:27\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.063574\n0.009595\n0.992754\n00:26\n\n\n1\n0.044590\n0.019105\n0.985507\n00:28\n\n\n2\n0.031911\n0.012100\n0.985507\n00:28\n\n\n\n\n\nAfter three iterations we already have 100% accuracy. There is certainly something wrong with our training approach.\n\n\n2.3 Avoiding overfitting and data leakage\nI use random splitter, which means that there are no unknown formats in the validation set. The algorithm will just have memorized the formats of the books in the training data. In addition, it overfitted during the first run.\nWe will reserve one format for the validation set. Starting from imageIMG_0552 only images of this new format exist. We will use this information for the splitter.\n\nfrom sklearn.model_selection import GroupShuffleSplit\nimport pandas as pd\n\nitems = get_image_files(\"data/raw/\")\n\ndef get_source(fn):\n    num = int(fn.stem.split(\"_\")[1])\n    return \"A\" if num &lt;= 552 else \"B\"\n\ndf = pd.DataFrame({\"fn\": items})\ndf[\"source\"] = df[\"fn\"].map(get_source)\n\ngss = GroupShuffleSplit(test_size=0.2, random_state=42)\ntrain_idx, valid_idx = next(gss.split(df, groups=df[\"source\"]))\n\nformat_splitter = IndexSplitter(valid_idx)\n\n\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=[Resize(192, method='pad', pad_mode='zeros')]\n\n)\ndls = pages.dataloaders(\"data/raw/\")\n\nAnd run training again\n\nset_seed(42, reproducible=True)\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.643476\n0.222453\n0.946341\n00:28\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.021866\n0.284040\n0.946341\n00:29\n\n\n1\n0.012767\n0.209461\n0.946341\n00:28\n\n\n2\n0.008253\n0.213438\n0.941463\n00:29\n\n\n\n\n\nLet’s look at the poorest performers\n\ninterp = ClassificationInterpretation.from_learner(learn)\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs expected, most of the top losses come from the new category in the validation set: text with big picture. Let’s try cropping instead of padding.\n\npages_crop = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=RandomResizedCrop(192, min_scale=0.3))\n\ndls_crop = pages.dataloaders(\"data/raw/\")\n\n\nset_seed(42, reproducible=True)\nlearn = vision_learner(dls_crop, resnet18, metrics=accuracy)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.572427\n0.259774\n0.936585\n00:28\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.038109\n0.242050\n0.941463\n00:30\n\n\n1\n0.037208\n0.183234\n0.956098\n00:31\n\n\n2\n0.025155\n0.147071\n0.956098\n00:30\n\n\n\n\n\nInterestingly the results are slightly better. But during testing I saw the inverse when using other seeds. To remain consistent we switch to cropping."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html#improving-even-further",
    "href": "posts/projects/recipescanner/text_or_image_page.html#improving-even-further",
    "title": "Text or Image",
    "section": "3 Improving even further",
    "text": "3 Improving even further\nNow with the basics settled, let’s try to improve further our 95.6% accuracy.\n\n3.1 Learning rate tuning\nWe start by tuning the the learning rate. In addition to using the learning rate finder, we increase the duration where we only train the head, as the dataset is small.\n\nset_seed(42, reproducible=True)\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn.lr_find(suggest_funcs=(minimum, steep, valley))\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.05248074531555176, steep=0.00019054606673307717, valley=0.0006918309954926372)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(\n    20,\n    base_lr=6.9e-4,\n    freeze_epochs=5 # train the head\n)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.063496\n0.927946\n0.512195\n00:32\n\n\n1\n0.779015\n0.373030\n0.882927\n00:33\n\n\n2\n0.518703\n0.255721\n0.921951\n00:32\n\n\n3\n0.373917\n0.246510\n0.941463\n00:34\n\n\n4\n0.279082\n0.242445\n0.941463\n00:32\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.018540\n0.215797\n0.941463\n00:35\n\n\n1\n0.016864\n0.187548\n0.951219\n00:37\n\n\n2\n0.012505\n0.173968\n0.956098\n00:35\n\n\n3\n0.009071\n0.161985\n0.960976\n00:35\n\n\n4\n0.006918\n0.166117\n0.956098\n00:32\n\n\n5\n0.005747\n0.176520\n0.956098\n00:33\n\n\n6\n0.004610\n0.178823\n0.956098\n00:35\n\n\n7\n0.004979\n0.168676\n0.960976\n00:36\n\n\n8\n0.004130\n0.163851\n0.960976\n00:36\n\n\n9\n0.003458\n0.168914\n0.965854\n00:35\n\n\n10\n0.002940\n0.190041\n0.956098\n00:37\n\n\n11\n0.002547\n0.178129\n0.956098\n00:37\n\n\n12\n0.002212\n0.184677\n0.956098\n00:36\n\n\n13\n0.002100\n0.182207\n0.960976\n00:34\n\n\n14\n0.001811\n0.182882\n0.956098\n00:32\n\n\n15\n0.001629\n0.184585\n0.956098\n00:30\n\n\n16\n0.001452\n0.182009\n0.956098\n00:31\n\n\n17\n0.001260\n0.187534\n0.956098\n00:31\n\n\n18\n0.001156\n0.192596\n0.956098\n00:32\n\n\n19\n0.001018\n0.186388\n0.956098\n00:31\n\n\n\n\n\nWe managed a higher accuarcy of 96.5%, but training training diverged.\n\n\n3.2 Increasing input data size\nThe text could be too blured at 192px. We increase image size to 320px and follow the same approach as before. To avoid unnecessary calls, when the training is overfitting I added the callbacks.\n\nset_seed(42, reproducible=True)\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=[RandomResizedCrop(320, min_scale=0.3)]\n\n)\ndls = pages.dataloaders(\"data/raw/\")\n\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn.lr_find(suggest_funcs=(minimum, steep, valley))\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.05248074531555176, steep=0.0002290867705596611, valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(\n    20,\n    base_lr=1.4e-3,\n    freeze_epochs=5, # train the head\n    cbs=[\n        EarlyStoppingCallback(monitor='valid_loss', patience=3),\n        SaveModelCallback(monitor='valid_loss')   # saves best model\n    ]\n)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.024766\n0.579390\n0.775610\n00:24\n\n\n1\n0.583699\n0.165269\n0.946341\n00:24\n\n\n2\n0.370840\n0.201217\n0.956098\n00:24\n\n\n3\n0.263847\n0.208855\n0.956098\n00:23\n\n\n4\n0.198083\n0.187529\n0.960976\n00:23\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.5793901085853577.\nBetter model found at epoch 1 with valid_loss value: 0.16526909172534943.\nNo improvement since epoch 1: early stopping\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.037425\n0.131343\n0.960976\n00:23\n\n\n1\n0.034193\n0.105369\n0.965854\n00:23\n\n\n2\n0.023509\n0.091661\n0.975610\n00:24\n\n\n3\n0.016545\n0.084221\n0.975610\n00:24\n\n\n4\n0.012769\n0.091403\n0.975610\n00:23\n\n\n5\n0.010076\n0.113227\n0.970732\n00:23\n\n\n6\n0.008031\n0.133027\n0.960976\n00:23\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.13134345412254333.\nBetter model found at epoch 1 with valid_loss value: 0.10536907613277435.\nBetter model found at epoch 2 with valid_loss value: 0.09166132658720016.\nBetter model found at epoch 3 with valid_loss value: 0.08422137051820755.\nNo improvement since epoch 3: early stopping\n\n\nWe made it to 97.5%.\n\n3.2.1 Data augmentation\nAs a last step we try introducing data augmentation. Same procedure as before.\n\nset_seed(42, reproducible=True)\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_x=correct_exif_orientation,\n    get_y=parent_label,\n    item_tfms=[RandomResizedCrop(320, min_scale=0.3)],\nbatch_tfms=aug_transforms(2),)\n\ndls = pages.dataloaders(\"data/raw/\")\n\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\nlearn.lr_find(suggest_funcs=(minimum, steep, valley))\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.03630780577659607, steep=0.00019054606673307717, valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(\n    20,\n    base_lr=1e-3,\n    freeze_epochs=5, # train the head\n    cbs=[\n        EarlyStoppingCallback(monitor='valid_loss', patience=3),\n        SaveModelCallback(monitor='valid_loss')   # saves best model\n    ]\n)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.149485\n0.779582\n0.668293\n00:23\n\n\n1\n0.707324\n0.202957\n0.921951\n00:22\n\n\n2\n0.463376\n0.184458\n0.960976\n00:21\n\n\n3\n0.335166\n0.195367\n0.960976\n00:21\n\n\n4\n0.252198\n0.193939\n0.960976\n00:21\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.7795820832252502.\nBetter model found at epoch 1 with valid_loss value: 0.20295678079128265.\nBetter model found at epoch 2 with valid_loss value: 0.18445810675621033.\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.042519\n0.198141\n0.951219\n00:21\n\n\n1\n0.032583\n0.187754\n0.956098\n00:22\n\n\n2\n0.022516\n0.144986\n0.960976\n00:23\n\n\n3\n0.017273\n0.113910\n0.960976\n00:22\n\n\n4\n0.013913\n0.097062\n0.970732\n00:22\n\n\n5\n0.011357\n0.096084\n0.975610\n00:23\n\n\n6\n0.009134\n0.102647\n0.975610\n00:23\n\n\n7\n0.007552\n0.121601\n0.965854\n00:23\n\n\n8\n0.007619\n0.155179\n0.960976\n00:26\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.19814081490039825.\nBetter model found at epoch 1 with valid_loss value: 0.18775445222854614.\nBetter model found at epoch 2 with valid_loss value: 0.14498622715473175.\nBetter model found at epoch 3 with valid_loss value: 0.11391040682792664.\nBetter model found at epoch 4 with valid_loss value: 0.0970616415143013.\nBetter model found at epoch 5 with valid_loss value: 0.096084363758564.\nNo improvement since epoch 5: early stopping\n\n\nThe augmentations did not achieve a lower validation loss and training started to diverge earlier.\nAt this point we could certainly try to do more things. Work on weight decay and dropout. That is certainly an optimization, which should be done once the model is in production.\n\n\n\n3.3 Bigger Model\nOne last thing, we will do. Try a bigger model.\n\nset_seed(42, reproducible=True)\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=[RandomResizedCrop(320, min_scale=0.3)]\n\n)\ndls = pages.dataloaders(\"data/raw/\")\n\n\nlearn = vision_learner(dls, resnet34, metrics=accuracy)\n\n\nlearn.lr_find(suggest_funcs=(minimum, steep, valley))\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.04365158379077912, steep=6.309573450380412e-07, valley=0.0012022644514217973)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(\n    20,\n    base_lr=1e-3,\n    freeze_epochs=5, # train the head\n    cbs=[\n        EarlyStoppingCallback(monitor='valid_loss', patience=3),\n        SaveModelCallback(monitor='valid_loss')   # saves best model\n    ]\n)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.027827\n0.761079\n0.585366\n00:24\n\n\n1\n0.634203\n0.074252\n0.980488\n00:23\n\n\n2\n0.415216\n0.089031\n0.985366\n00:24\n\n\n3\n0.295387\n0.111100\n0.980488\n00:23\n\n\n4\n0.225855\n0.114145\n0.990244\n00:24\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.7610787749290466.\nBetter model found at epoch 1 with valid_loss value: 0.07425229251384735.\nNo improvement since epoch 1: early stopping\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.042249\n0.067354\n0.990244\n00:23\n\n\n1\n0.030849\n0.069564\n0.990244\n00:24\n\n\n2\n0.026555\n0.074522\n0.990244\n00:26\n\n\n3\n0.019717\n0.079238\n0.990244\n00:26\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.06735362857580185.\nNo improvement since epoch 0: early stopping\n\n\nThe bigger model lead to 99% accuracy. This certainly is promising. On the other hand, we only have a few different formats in the training set. To guard against out of domain errors we will stick to the resnet18.\n\n\nCode\nset_seed(42, reproducible=True)\npages = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=format_splitter,\n    get_y=parent_label,\n    get_x=correct_exif_orientation,\n    item_tfms=[RandomResizedCrop(320, min_scale=0.3)]\n\n)\ndls = pages.dataloaders(\"data/raw/\")\nlearn.lr_find(suggest_funcs=(minimum, steep, valley))\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\nlearn.fine_tune(\n    20,\n    base_lr=1.4e-3,\n    freeze_epochs=5,  # train the head\n    cbs=[\n        EarlyStoppingCallback(monitor='valid_loss', patience=3),\n        SaveModelCallback(monitor='valid_loss')  # saves best model\n    ]\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.059075\n0.661225\n0.721951\n00:24\n\n\n1\n0.592713\n0.315692\n0.912195\n00:23\n\n\n2\n0.383400\n0.343516\n0.926829\n00:24\n\n\n3\n0.274423\n0.343230\n0.941463\n00:23\n\n\n4\n0.203259\n0.317037\n0.941463\n00:22\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.6612254977226257.\nBetter model found at epoch 1 with valid_loss value: 0.31569164991378784.\nNo improvement since epoch 1: early stopping\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.054644\n0.231042\n0.926829\n00:23\n\n\n1\n0.039082\n0.173815\n0.941463\n00:23\n\n\n2\n0.026822\n0.126490\n0.956098\n00:24\n\n\n3\n0.018999\n0.112197\n0.970732\n00:24\n\n\n4\n0.014812\n0.110572\n0.970732\n00:23\n\n\n5\n0.012533\n0.140026\n0.960976\n00:25\n\n\n6\n0.009940\n0.154067\n0.956098\n00:24\n\n\n7\n0.008640\n0.139433\n0.965854\n00:26\n\n\n\n\n\nBetter model found at epoch 0 with valid_loss value: 0.2310423105955124.\nBetter model found at epoch 1 with valid_loss value: 0.17381496727466583.\nBetter model found at epoch 2 with valid_loss value: 0.12649033963680267.\nBetter model found at epoch 3 with valid_loss value: 0.11219745874404907.\nBetter model found at epoch 4 with valid_loss value: 0.11057160794734955.\nNo improvement since epoch 4: early stopping\n\n\n\n\n\n\n\n\n\n\ninterp =  ClassificationInterpretation.from_learner(learn)\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(10)"
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html#inference",
    "href": "posts/projects/recipescanner/text_or_image_page.html#inference",
    "title": "Text or Image",
    "section": "4 Inference",
    "text": "4 Inference\nOur goal is a pure pytorch inference. To avoid any preproccessing mistakes, we will start with fastai pipeline.\n\n4.1 Fastai first\n\nlearn.export(\"data/models/page_classifier.pkl\")\n\n\nlearn_inf = load_learner(\"data/models/page_classifier.pkl\");\n\n\npred_class, pred_idx, probs = learn_inf.predict(\"pictures/inf_1.jpg\")\n\nprint(f\"Prediction: {pred_class}\")\nprint(f\"Probabilities: {probs}\")\n\n\n\n\n\n\n\n\nPrediction: image_page\nProbabilities: tensor([0.7906, 0.2094])\n\n\n\npred_class, pred_idx, probs = learn.predict(\"pictures/inf_2.jpg\")\n\nprint(f\"Prediction: {pred_class}\")\nprint(f\"Probabilities: {probs}\")\n\n\n\n\n\n\n\n\nPrediction: text_page\nProbabilities: tensor([0.0087, 0.9913])\n\n\nThe result for the second image is correct, whereas for the first it is wrong. Again from the text with big image type.\nWhen we look at the pictures, we see that the text page picture has an image with text. It could be that the CNN learned these patterns and interpreted the image as text.\n\n\n\n\n\n\nInfered as Image Page\n\n\n\n\n\n\n\nInfered as Text Page\n\n\n\n\n\n\n\n4.2 Pytorch\nTo use model in pytorch only we need to convert it to torchscript.\n\nmodel = learn_inf.model\nmodel.eval()\n\n\nexample_input = torch.randn(1, 3, 320, 320)  # batch, channels, H, W\ntraced = torch.jit.trace(model, example_input)\ntraced.save(\"data/models/page_classifier.pt\")\n\nWe will later use the following code in the app\n\nimport torch\nmodel = torch.jit.load(\"data/models/page_classifier.pt\")\nmodel.eval();\n\n\nfrom torchvision import transforms\ntfm = transforms.Compose([\n    transforms.Resize(320, interpolation=transforms.InterpolationMode.BILINEAR),\n    transforms.CenterCrop(320),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n\n\nlabels = [\"image_page\", \"text_page\"]\ndef predict_image(path):\n    img = Image.open(path).convert(\"RGB\")\n    x = tfm(img).unsqueeze(0)  # add batch dim\n    with torch.no_grad():\n        out = model(x)\n        probs = torch.softmax(out, dim=1)[0]\n        pred_idx = probs.argmax().item()\n        return labels[pred_idx], probs.tolist()\n\n\npredict_image(\"pictures/inf_1.jpg\")\n\n('image_page', [0.8300915360450745, 0.16990840435028076])\n\n\n\n%%time\npredict_image(\"pictures/inf_2.jpg\")\n\nCPU times: user 315 ms, sys: 22.1 ms, total: 337 ms\nWall time: 163 ms\n\n\n('text_page', [0.030374446883797646, 0.9696255922317505])\n\n\nThe results are very similar 83% vs 80% for the wrong classification. We will accept the small deviations from fast.ai for now."
  },
  {
    "objectID": "posts/projects/recipescanner/text_or_image_page.html#outlook",
    "href": "posts/projects/recipescanner/text_or_image_page.html#outlook",
    "title": "Text or Image",
    "section": "5 Outlook",
    "text": "5 Outlook\nWe have 160ms runtime for one image at 97.5% accuracy to detect if it is an image. This score could increase if we increase the dataset size and add more layouts.\nA completely different approach could also work. In the next notebook, I will be working with YOLO-doclayout. a fast detector that detects the occurrence of text or image blocks on a page. If there are no text boxes, then there is no text."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "",
    "text": "For ML and embedded engineers, deployment technologies such as Kubernetes can feel distant. But the scaling behavior increasingly shapes how modern products are not only run, but how they are developed; think OTA updates, remote fleet monitoring, and model serving.\nIn the last weeks I built a small Kubernetes autscaling demo.\nMy aim: understand better how Horizontal Pod Autoscaling (HPA) behaves under real and chaotic load.\nMany Kubernetes explanations stay conceptual or stop at the starting of pods.\nI wanted something you can stress and watch adapt in real time."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#motivation",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#motivation",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "",
    "text": "For ML and embedded engineers, deployment technologies such as Kubernetes can feel distant. But the scaling behavior increasingly shapes how modern products are not only run, but how they are developed; think OTA updates, remote fleet monitoring, and model serving.\nIn the last weeks I built a small Kubernetes autscaling demo.\nMy aim: understand better how Horizontal Pod Autoscaling (HPA) behaves under real and chaotic load.\nMany Kubernetes explanations stay conceptual or stop at the starting of pods.\nI wanted something you can stress and watch adapt in real time."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#the-demo",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#the-demo",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "2 The demo",
    "text": "2 The demo\nMy demo model is a tiny web service with a CPU-burning backend in C++. A Typescript frontend simulates impatient users who repeatedly press F5.\n\n\n\nFrontend to adjust user number and load, see video at the end of post.\n\n\nWhen the backend gets overloaded, Kubernetes starts creating more replicas; when the load drops, the cluster scales down. You can see the load rise, the scaling events and even scaling oscillations under chaotic load."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#insights",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#insights",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "3 Insights",
    "text": "3 Insights\nInfrastructure is not my main leg. My top 4 insights from the point of view of an ML/embedded developer.\n\n3.1 Scaling is delayed by design\nEven with aggressive scaling settings, the HPA decisions trail the user load. The information flow is kubelet-&gt; Metrics Server-&gt; HPA, each taking multiple seconds. This avoids reacting to instantaneous load spikes.\n\n\n3.2 CPU-based autoscaling is sensitive to user behavior\nMy earliest attempt was to launch another request after receiving the response. This just overwhelms the CPU with requests, and scaling goes through the roof. I had to add a realistic “think time” to reflect what is actually happening in real life. Press F5, watch the content, only then press F5 again. Another option would be hard rate limits on the server side.\n\n\n3.3 Percentage based scaling is trickier than scale by one scaling\nFor up-scaling, I used an increase-by-one-pod rule. For down-scaling, I allowed withdrawing as many pods as quickly as possible. My thinking: too-slow down-scaling wastes resources. The surprise: aggressive scaling leads to oscillations in the pod numbers.\n\n\n3.4 The demo mirrors real system behavior surprisingly well\nDespite its simplicity, the demo showed aspects that we can also experience in real production settings: the morning user burst, ill-timed lunchtime updates, traffic spikes and scaling overshoot."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#try-it-yourself",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#try-it-yourself",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "4 Try it yourself",
    "text": "4 Try it yourself\nIf you want to experiment with autoscaling to understand better what is happening on your projects Kubernetes cluster, full code, configurations can be found here:\nhttps://github.com/dolind/demo_autoscale\nThe demo is a reminder that infrastructure knowledge is no longer optional. Even for non-cloud or ML-heavy teams, a bit of systems intuition goes a long way.\nThis project is done. I’ll be shifting back to ML-focused work now."
  },
  {
    "objectID": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#bonus-material",
    "href": "posts/projects/kubernetes/why-kubernetes-autoscaling-matters-for-ml-and-embedded-developers.html#bonus-material",
    "title": "Why Kubernetes Autoscaling Matters for ML and Embedded Developers",
    "section": "5 Bonus Material",
    "text": "5 Bonus Material\n\n5.1 Explore the demo by Video\nIf you do not want to run the demo yourself, here is a full recording of a session. Yellow lines indicate a rise of user numbers, greed pod up-scaling, red down-scaling.\n\n\n\n\n\n5.2 Technical deep dive\nA full technical deep dive — including setup, architecture, and detailed scaling analysis — is available here."
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "",
    "text": "Three walking paths in London"
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#the-least-travelled-path-lets-you-explore-new-areas",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#the-least-travelled-path-lets-you-explore-new-areas",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "1 The least travelled path lets you explore new areas",
    "text": "1 The least travelled path lets you explore new areas\nMany now the Dijkstra shortest path algorithm. It allows you to calculate the shortest path in a network.\nThis can be a routing network or a network of streets and ways, like a map.\nUsually we are only interested in the shortest way to get from A to B. Google Maps does this nicely and even considers congestion on the edges of the graph, the streets.\nBut what if you are not interested in getting there the fastest? Or you want always a new way. Sounds strange. I often go for a short stroll in the neighborhood. Because of the street layout, I often visited the same streets. This quickly becomes boring. Sometimes I go astray on purpose and discover interesting new things. This is the least travelled path."
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#help-in-finding-the-least-travelled-path",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#help-in-finding-the-least-travelled-path",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "2 Help in finding the least travelled path",
    "text": "2 Help in finding the least travelled path\nNowadays, it is very easy to find the shortest path. But what about the least travelled path?\nThis is how I came up with the idea. What if your phone could show to you where you have been, and you would simple reveal the map as in a computer game? While certainly easily feasible, such an app has the drawback of huge privacy concerns. It basically tracks your location all the time and aggregates this information. While this is something IOS and android are doing in the core routines, it is difficult to handle in an app. Give me a shout-out if you think otherwise.\nI then though what if we could only plan the route every time different? So, instead of verifying the route, we would suggest additional, uncharted itineraries. This is how I came up with the expression, the least travelled path.\nApplying this approach to central Paris looks like this. Imagine you always start at Notre Dame. From there, you actually concentrically explore the city by always picking another destination. The street layout causes some streets to be frequented more often (purple on the map).\n\n\n\nWalking around in Paris\n\n\nThree unique paths look like this. These paths share some streets. Especially bridges and riverfront ways. But how does it work?\n\n\n\nThree walking paths in Paris"
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#how-did-i-get-there-the-prototype",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#how-did-i-get-there-the-prototype",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "3 How did I get there: the prototype",
    "text": "3 How did I get there: the prototype\n\n3.1 Making a street layout\nI first generated a graph out of random points by identifying neighbors within a 20% margin of the domain. For all neighbors, I have stored the distance. Congestion-enabled algorithms would use the travel time. For every visit, I simply add the original distance to the edge, making it more costly to visit.\nUsing this approach, I have nodes and edges with a length.\n\n\n3.2 The algorithm\nMy least visited path algorithm\n\nRepeat for the number of desired paths\nFind a planned destination point that is within the desired distance as the crow flies.\nUse Dijkstra’s algorithm to build up a path to the planned destination that obeys the smallest cost for the next step. Implementation uses a min heap for efficiency and simplicity. To avoid overly long trips: Check if the return trip is within the planned maximum distance along the path to the destination. If not, shorten it to the node that is just half the maximum travel distance.\nCalculate a fresh path to this updated destination.\nUpdate the travel cost of the visited edges by their original value. Also, record how many times this edge was traveled.\nCalculate a return path to the origin and again update the edges\n\n\n\n\nDifferent paths in a Graph\n\n\n\n\n\nVisited Edges in the Graph; thicker means more often."
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#real-life-algorithm",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#real-life-algorithm",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "4 Real life algorithm",
    "text": "4 Real life algorithm\n\n4.1 Getting the map and setting up the graph\nOsmnx in python allows us to download any map we want.\nInstead of increasing the distance as in the prototype, we now use an attribute travel time for the edge. We also initialize the number of visits.\n\n\n4.2 Algorithm for real map\n\nWe search a random point within a radius, say 800 m.\nGet the shortest path, using NetworkX this time.\nCheck if the path is not too long for the outgoing journey\nUpdate the edges, this time doubling the travel time.\nCalculate the return and update travel time again"
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#walking-in-london-vs-walking-in-paris",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#walking-in-london-vs-walking-in-paris",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "5 Walking in London vs walking in Paris",
    "text": "5 Walking in London vs walking in Paris\nOne thing I discovered while exploring different areas is the difference in the street layout and how it impacts the algorithm. 19th century cities, or even more modern ones with multiple lanes and ways on the same street, lead to a rather uniform choice. The algorithm will simply choose the other lane or sidewalk on the same street because it’s connected by another edge.\nOlder cities, like London or smaller European cities, which have smaller streets, lead to a better experience of exploration. The same is true for more residential areas, which ultimately I had in mind for this idea. See the following image or the initial one of the three paths in London.\n\n\n\nHeatmap of paths in London. Much more diverse compared to Paris."
  },
  {
    "objectID": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#getting-it-into-a-product",
    "href": "posts/projects/road-less-travelled/the-road-less-travelled-from-the-dijkstras-shortest-path-to-the-least-visited-path.html#getting-it-into-a-product",
    "title": "The road less travelled - from the dijkstras shortest path to the least visited path",
    "section": "6 Getting it into a product",
    "text": "6 Getting it into a product\nWell,… a failure. First, there are the privacy concerns I mentioned in the beginning. The app would have the highest impact on a mobile phone platform. A non-cloud version could at least mitigate some of the privacy concerns. However, I could not find an adequate replacement for osmnx, which runs on android. Development would be feasible, but very time-consuming.\nTherefore, I rather try my luck with any unvisited alley I can find and see what life has in store.\nAll code can be found here."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html",
    "title": "Street view game - hit the road",
    "section": "",
    "text": "It was on a Sunday afternoon, as sunny as it gets on January afternoons. We were driving our car through a to us unknown countryside searching for a new home. The most frustrating about the entire experience was that we only had a vague idea of where to go and usually ended up on bigger roads. Sadly, that’s how well-designed street networks work. They should channel the traffic to bigger roads. This is also something I experienced in developing The road less travelled.\nBack at home, I was thinking about how to make life easier.\nGoogle maps to the rescue. Google made the gift of digitalizing much of the world with aerial maps, 3d maps and street view. Personally, I find the 3D maps really cool to get an overview of an area. Especially when planning your holidays, it can provide a better impression than a simple map with elevation levels.\nBut to explore neighbourhoods, I was much more interested in details and not an overview. That’s were Street view hits the nail. It is just Photos Sphere Photos, chained together. 2D VR does not get more realistic than a photo.\nFor me, Street view has a two cumbersome drawbacks. First, you need to click or press a key all the time. Second, the transition effect is visually fatiguing if you watch it several times. The transition effect is like a slide show fades. It is visually supporting, if you slowly transition from one point to the next. But if you hit the button to quick, the transition get’s distracting. In addition, for me rapidly pressing the forward key to let’s to a loading problem."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#the-classic-street-view-is-too-cumbersome",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#the-classic-street-view-is-too-cumbersome",
    "title": "Street view game - hit the road",
    "section": "",
    "text": "It was on a Sunday afternoon, as sunny as it gets on January afternoons. We were driving our car through a to us unknown countryside searching for a new home. The most frustrating about the entire experience was that we only had a vague idea of where to go and usually ended up on bigger roads. Sadly, that’s how well-designed street networks work. They should channel the traffic to bigger roads. This is also something I experienced in developing The road less travelled.\nBack at home, I was thinking about how to make life easier.\nGoogle maps to the rescue. Google made the gift of digitalizing much of the world with aerial maps, 3d maps and street view. Personally, I find the 3D maps really cool to get an overview of an area. Especially when planning your holidays, it can provide a better impression than a simple map with elevation levels.\nBut to explore neighbourhoods, I was much more interested in details and not an overview. That’s were Street view hits the nail. It is just Photos Sphere Photos, chained together. 2D VR does not get more realistic than a photo.\nFor me, Street view has a two cumbersome drawbacks. First, you need to click or press a key all the time. Second, the transition effect is visually fatiguing if you watch it several times. The transition effect is like a slide show fades. It is visually supporting, if you slowly transition from one point to the next. But if you hit the button to quick, the transition get’s distracting. In addition, for me rapidly pressing the forward key to let’s to a loading problem."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#searching-for-something-better",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#searching-for-something-better",
    "title": "Street view game - hit the road",
    "section": "2 Searching for something better",
    "text": "2 Searching for something better\nThere is one thing I particularly like about GitHub. Usually somebody else already solved your problem. You only need to get your head around his solution and then improve from there.\nThere is a custom C++ street view client. https://github.com/TheGreatRambler/streetview_client/\nThis application loads the full street view panoramas and then uses a custom stitching algorithm. This algorithm avoids the transition. By preloading an entire route, you can easily avoid any download lag. This seemed to solve my troubles with street view.\nThen I had the idea. What if street view would be like a computer game? Why press the mouse button to turn and look around? In a game, you usually just move the mouse and use WASD to move around."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#the-first-street-view-game-custom-rendering",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#the-first-street-view-game-custom-rendering",
    "title": "Street view game - hit the road",
    "section": "3 The first street view game: custom rendering",
    "text": "3 The first street view game: custom rendering\n\n3.1 Rapid street view viewing\n\n\n\nThe first version\n\n\nAfter spending a few evenings changing the code, I came up with my first street view based game. And it was true, the speed was amazing. You can see an animation here:\n\n\n\nExploration in the waterpocket fold, Utah.\n\n\n\n\n3.2 Usability and legality are important for a product\nWhen turning an idea into a prototype, there is always the question of where to stop. How far should you continue and when should you share the solution with others? Personally, if I am sharing code, I try to maintain a minimal quality standard.\nI decided against publicly sharing the code for this version because of some drawbacks.\n\n3.2.1 Usability issues\nThe program requires the full download of the panorama, which can be 25MB. If you advance too quickly, the panorama hasn’t loaded yet. Google uses a very intelligent method to avoid this lag by only loading parts of the panorama that are visible. In the Google Street view, this effect is visible when quickly turning around.\nPreloading everything in a radius solves this. A function that already exists in the GitHub version of the streeview_client. While it is working, it is not very practical. As already said, the high res street view panoramas are 25MB. In dense city areas, there are many panoramas, close to each other. If free exploration were to be possible, a lot of data needs to be loaded. Even loading all the panoramas along a predefined route takes a lot of time. The size of your temp directory quickly explodes. In addition, it works only with a quick internet connection.\nStreet view animation works by linking one panorama to the next. Sometimes a panorama hits a dead end, even if the street continues and, in a few hundred meters, another panorama exists.\nGoogle maps solve this dead-end situation by requiring the user to just repositioning the peg man. In a custom engine, the only option would be to advance in the general direction and take the next panorama in that direction. Or reimplement the peg man map.\n\n\n3.2.2 Legal issues\nIf you want to show street view data, you have to do it in a way that Google details in their documentation. And the custom render from the great rambler is probably not part of this."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#second-version-using-the-google-maps-api",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#second-version-using-the-google-maps-api",
    "title": "Street view game - hit the road",
    "section": "4 Second Version: using the Google Maps API",
    "text": "4 Second Version: using the Google Maps API\n\n4.1 Innovative use of the google api to reduce transition effect\nAs mentioned before, the main reason for not releasing the previous version publicly is that it risks violating the Google Maps’ API’s terms of service. Loading multiple panoramas on the same page seems to be allowed. As I detail below, you will just pay more for this.\nThe transition and loading problem is solved by using multiple panorama renderers. Basically you are looking at three panoramas. Depending on your internet connection, you can increase the or decrease the pause between the panoramas. If the loading pause becomes too small, the original transition effect becomes visible.\n\n\n4.2 Travelling around\nThe current version solves the issues with the usability of street view by extending its functionality with the mouse turning, auto rotating, and auto forward. We always transition in the direction of view. If there are no further panoramas to the side, you can even look through the side window while advancing forward.\nIn google Street view you have to look at every panorama, which gets cumbersome on a highway. I use a jump distance to jump over some panoramas. Together with the reload frequency, this defines the speed of the “virtual vehicle”.\nThis leads me to one of the coolest use cases, besides exploring unknown areas. Traveling on scenic highways.\n."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#technical-feasibility-is-not-enough",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#technical-feasibility-is-not-enough",
    "title": "Street view game - hit the road",
    "section": "5 Technical feasibility is not enough",
    "text": "5 Technical feasibility is not enough\nThe hosted version of this project has a limited usage to remain within google’s free range for the google api and serve as demonstrator. It is just too costly to run it otherwise. Using multiple panoramas, you need to pay for every panorama you instantiate. Together with the lookup of the position, this puts the use at almost 3 cent per page load in 2024.\nAdvertisement generates revenue of 1c per page load for a well-working website. A mobile game rarely costs more than €5. All of these results in a loss for the app."
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#hey-google-please-help.",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#hey-google-please-help.",
    "title": "Street view game - hit the road",
    "section": "6 Hey Google, please help.",
    "text": "6 Hey Google, please help.\nI still love the idea of using Google Street view like a video game. It would enable a lot more people to explore the world. I remember the time when Google Earth was new, and we just wanted it to explore unknown corners of the world. Exploring photo realistic content could be much more interesting. In fact, there are some applications for VR glasses. The application does not need VP glasses.\nSo if someone from Google Maps ever reads this: Please develop an official version.\nBonus points:\n\nInclude 3D effects by relying on structure from motion\nAdd a more intelligent routing, which can follow streets"
  },
  {
    "objectID": "posts/projects/streetview-game/street-view-game-hit-the-road.html#demo-and-source",
    "href": "posts/projects/streetview-game/street-view-game-hit-the-road.html#demo-and-source",
    "title": "Street view game - hit the road",
    "section": "7 Demo and Source",
    "text": "7 Demo and Source\nLive Version:\nSource Code"
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html",
    "href": "posts/projects/deejai/deejai-xai.html",
    "title": "How Neural Networks Hear Music",
    "section": "",
    "text": "I recently got to play DJ at a private party. Usually, this involves endless hours of listening through songs. You then try to figure out what track fits best where, how to build energy, and what to avoid. It is like a radio DJ with a static playlist. Creating a static playlist that matches the vibe at different times throughout the night can be tough work.\nBut now we have AI. Everything is soo easy.\nThat was my state of mind, when I started with Deej-AI.\nMy idea was simple: tell the AI what music I like and let it handle the playlist. With clear instructions provided by the creator in the repository, I anticipated having my perfect playlist ready in no time.\n\n\nI started by selecting a few hundred songs I love. I did not care much about the order or proportion of style, hoping the software would seamlessly fill in the gaps. Running the software quickly generated playlists, which looked okayish at a first glance. Looking deeper, imperfections began to show. As I preferred no song repetitions, the playlist noticeably deteriorated towards the end when the algorithm ran out of optimal matches.\nThis highlighted a crucial issue of Deej-AI: the lack of global optimization. Deej-AI could suggest suitable songs individually but struggled to maintain consistency and match the overall mood progression throughout the evening. Think of a good mixtape or a carefully curated DJ playlist. The AI creation was the opposite.\nRespecting different times of day and specific moods was impossible due to the absence of a robust global layout editor. Even though the software offered gap-filling functionality, it still required explicit instructions about what was missing. In the end, creating a truly seamless playlist still required significant manual effort.\n\n\n\nDespite the lack of features, the picks sometimes pleasantly surprised me; sometimes just surprised. This curiosity led me deeper: why exactly was one song selected over another?\nIn this article, we’ll explore these choices through three lenses:\nWe will examine our data at three different scales\n\nMacro-level with t-SNE visualization: to reveal groups of songs and overall patterns in the playlist.\nMeso-level with Grad-CAM: highlighting crucial parts of audio spectrograms that influenced song selection.\nMicro-level with Integrated Gradients: examining the precise contribution of individual audio features.\n\nBy dissecting these layers of explainability, I’ll show how your favourite music app works on auto-listening. I hope this is not only valuable for developers, but anybody wondering about why he often ends up with mainstream music on YouTube ."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#playing-dj",
    "href": "posts/projects/deejai/deejai-xai.html#playing-dj",
    "title": "How Neural Networks Hear Music",
    "section": "",
    "text": "I recently got to play DJ at a private party. Usually, this involves endless hours of listening through songs. You then try to figure out what track fits best where, how to build energy, and what to avoid. It is like a radio DJ with a static playlist. Creating a static playlist that matches the vibe at different times throughout the night can be tough work.\nBut now we have AI. Everything is soo easy.\nThat was my state of mind, when I started with Deej-AI.\nMy idea was simple: tell the AI what music I like and let it handle the playlist. With clear instructions provided by the creator in the repository, I anticipated having my perfect playlist ready in no time.\n\n\nI started by selecting a few hundred songs I love. I did not care much about the order or proportion of style, hoping the software would seamlessly fill in the gaps. Running the software quickly generated playlists, which looked okayish at a first glance. Looking deeper, imperfections began to show. As I preferred no song repetitions, the playlist noticeably deteriorated towards the end when the algorithm ran out of optimal matches.\nThis highlighted a crucial issue of Deej-AI: the lack of global optimization. Deej-AI could suggest suitable songs individually but struggled to maintain consistency and match the overall mood progression throughout the evening. Think of a good mixtape or a carefully curated DJ playlist. The AI creation was the opposite.\nRespecting different times of day and specific moods was impossible due to the absence of a robust global layout editor. Even though the software offered gap-filling functionality, it still required explicit instructions about what was missing. In the end, creating a truly seamless playlist still required significant manual effort.\n\n\n\nDespite the lack of features, the picks sometimes pleasantly surprised me; sometimes just surprised. This curiosity led me deeper: why exactly was one song selected over another?\nIn this article, we’ll explore these choices through three lenses:\nWe will examine our data at three different scales\n\nMacro-level with t-SNE visualization: to reveal groups of songs and overall patterns in the playlist.\nMeso-level with Grad-CAM: highlighting crucial parts of audio spectrograms that influenced song selection.\nMicro-level with Integrated Gradients: examining the precise contribution of individual audio features.\n\nBy dissecting these layers of explainability, I’ll show how your favourite music app works on auto-listening. I hope this is not only valuable for developers, but anybody wondering about why he often ends up with mainstream music on YouTube ."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#music-just-another-form-of-data",
    "href": "posts/projects/deejai/deejai-xai.html#music-just-another-form-of-data",
    "title": "How Neural Networks Hear Music",
    "section": "2 Music, just another form of Data",
    "text": "2 Music, just another form of Data\nBefore we dive into the tools, let’s first clarify what our data looks like. In the following, we look at metadata, audio and embeddings.\n\n2.1 Theme metadata\nTo help the tool generate better playlists, I divided the day into two distinct segments: a calm part and a more energetic, danceable part. We’ll store this information as metadata and revisit it later in our analysis.\nWe note which song is in which sublist, as we will require this later.\n\n\nCode\nimport csv\nfrom pathlib import Path\n\nimport pandas as pd\n\n\ndef create_manifest():\n    with open(\"/app/data/raw-previews/explainabletrack_manifest.csv\", \"w\", newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow([\"filename\", \"theme\"])\n\n        for theme_dir in Path(\"/app/data/raw-previews/separate\").iterdir():\n            if theme_dir.is_dir():\n                theme = theme_dir.name\n                for audio_file in theme_dir.glob(\"*.mp3\"):\n                    writer.writerow([audio_file.name, theme])\n\n\n\ncreate_manifest()\n\nWe now have a table with data, also called tabular data. Your music provider has much bigger tables with a lot more columns (genre, speed, mood, …). For simplicity, we restrict ourselves. Let’s look at the data.\n\nmanifest = pd.read_csv(\"/app/data/raw-previews/explainabletrack_manifest.csv\")\nmanifest.head()\n\n\n\n\n\n\n\n\nfilename\ntheme\n\n\n\n\n0\nWith Or Without You - U2.mp3\nruhig\n\n\n1\nLa javanaise - Serge Gainsbourg.mp3\nruhig\n\n\n2\nDjadja - Aya Nakamura.mp3\nruhig\n\n\n3\nLe chant des sirènes - Fréro Delavega.mp3\nruhig\n\n\n4\nstart.mp3\nruhig\n\n\n\n\n\n\n\nAnd recheck the count in the two categories.\n\nmanifest.theme.value_counts()\n\ntheme\nparty    129\nruhig    116\nName: count, dtype: int64\n\n\n\n\n\n\n\n\nNotePaths in this notebook\n\n\n\n\n\nI use a dockerized version of Deej-Ai, which can be found on my GitHub. Therefore, paths are inside the docker, this is why paths sometimes start with /app and sometimes with /opt.\n\n\n\n\n\n2.2 Audio data\nWe are going to study sound signals. Sound is usually analyzed with the help of a spectrogram. While a lot more complex models exist, spectrogram can be just processed as images. This allows us to a simple classification analysis with something as simple as Resnet model.\nThe following picture shows a spectrogram. On the x-axis is the time. The y-axis shows the frequencies. The color is the amplitude of the wave form at this frequency and time.\n\n\nCode\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load audio\nfilename = '/app/data/raw-previews/combined/Purple Rain - Prince.mp3'\ny, sr = librosa.load(filename, sr=22050)\n\n# Create log-Mel spectrogram, this converts the waveform into a picture\nn_fft = 2048\nhop_length = 512\nn_mels = 96\n\nS = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft,\n                                   hop_length=hop_length, n_mels=n_mels)\nlog_S = librosa.power_to_db(S, ref=np.max)\n\n# normalize the spectogram for further processing\nlog_S = (log_S - np.min(log_S)) / (np.max(log_S) - np.min(log_S))\n\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(log_S, sr=sr, hop_length=hop_length,\n                         x_axis='time', y_axis='mel')\nplt.colorbar(format='%+2.0f dB')\nplt.title(\"Log-Mel Spectrogram\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.2.1 Slicing images\nWe use spectrogram images to classify the songs. The procedure is identical to your favourite bear or chesse classifier. However, classifying the full spectrogram of one song as a whole is often not very helpful. The songs are usually defined by local features. We either need a more complex model than a CNN, or we reduce the data the CNN sees. In practice, the latter option means we are going to slice the image.\nFor the study, we use spotify track previews. They usually provide a good sample of the track itself. A more comprehensive analysis would study the whole track and respect intra-track variation.\nLet’s slice a track.\n\ndef slice_image(slice_size=216, stride=216):\n    slices = []\n    starts_sec = []\n    for start in range(0, log_S.shape[1] - slice_size + 1, stride):\n        end = start + slice_size\n        slices.append(log_S[:, start:end])\n        start_sec = start * hop_length / sr\n        end_sec = end * hop_length / sr\n        starts_sec.append((start_sec, end_sec))\n    return slices, starts_sec\n\nslices, starts_sec = slice_image()\nprint(\"Number of slices\", len(slices))\n\nNumber of slices 5\n\n\nLet’s create a side-by-side view of full spectrogram and slices\n\n\nCode\nnum_slices_to_show = 3\nfig, axs = plt.subplots(2, 1, figsize=(12, 6), gridspec_kw={'height_ratios': [2, 1]}, sharex=True)\n\n## Plot full spectrogram\nlibrosa.display.specshow(log_S, sr=sr, hop_length=hop_length,\n                         x_axis='time', y_axis='mel', ax=axs[0])\naxs[0].set_title(\"Full Log-Mel Spectrogram\")\naxs[0].set_ylabel(\"Mel bin\")\n\n# Overlay slices\nfor i in range(min(num_slices_to_show, len(slices))):\n    start, end = starts_sec[i]\n    axs[0].axvspan(start, end, edgecolor='red', facecolor='none', lw=2, linestyle='--')\n\n# Slice image\n## Slices stitched together horizontally, padded to full time width\nslice_canvas = np.zeros_like(log_S) * np.nan  # fill with NaNs\n\nfor i in range(min(num_slices_to_show, len(slices))):\n    start_frame = int(starts_sec[i][0] * sr / hop_length)\n    slice_data = slices[i]\n    slice_canvas[:, start_frame:start_frame + slice_data.shape[1]] = slice_data\n\nlibrosa.display.specshow(slice_canvas, sr=sr, hop_length=hop_length,\n                         x_axis='time', y_axis='mel', ax=axs[1])\n\nfor i in range(min(num_slices_to_show, len(slices))):\n    start, end = starts_sec[i]\n    axs[1].axvspan(start, end, edgecolor='red', facecolor='none', lw=2, linestyle='--')\n\naxs[1].set_title(f\"{num_slices_to_show} Aligned Slices (padded to full duration)\")\naxs[1].set_ylabel(\"Mel bin\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nFinally, let’s define a function for slicing which we will be using later.\n\ndef mp3_to_slices(path):\n    N_MELS = 96\n    SLICE_SIZE = 216  # must match model input\n    y, sr = librosa.load(path, sr=22050)\n    S = librosa.feature.melspectrogram(y=y, sr=22050, n_fft=2048,\n                                       hop_length=512, n_mels=N_MELS, fmax=sr / 2)\n    x = np.ndarray(shape=(S.shape[1] // SLICE_SIZE, N_MELS, SLICE_SIZE, 1), dtype=float)\n\n    # we use the original code to get the same input batch size\n    for slice in range(S.shape[1] // SLICE_SIZE):\n        log_S = librosa.power_to_db(S[:, slice * SLICE_SIZE: (slice + 1) * SLICE_SIZE], ref=np.max)\n        if np.max(log_S) - np.min(log_S) != 0:\n            log_S = (log_S - np.min(log_S)) / (np.max(log_S) - np.min(log_S))\n        x[slice, :, :, 0] = log_S\n\n    return x\n\n\n\n\n2.3 Embeddings\nInstead of working with the spectrogram images in the model, the author of Deej-AI has done something a little bit more complex. He was not interested in knowing which song sounds similar to another, but which songs are usually played together. From this knowledge, he inferred that similar sounding new songs could be also played together with songs in the database.\nThe understanding of song lyrics and context is implicit in the playlists.\nHe therefore first encoded many playlists and then matched the spectrograms against this in another training.\nThe complete Training Inference Pipeline can be visualized like this.\n\n\n\n\n\n---\nformat:\n  html:\n    mermaid:\n      theme: neutral\n---\nflowchart TB\n  %% === Training #1: Track2Vec ===\n  subgraph T1[Training #1: Track2Vec]\n    A1[Audio Files] --&gt; |Organize| B1[Playlists]\n    B1 --&gt; |Train Track2Vec| C[100D Embeddings]\n  end\n\n\n  %% === Training #2: Mp3ToVec ===\n  subgraph T2[Training #2: Mp3ToVec]\n    D1[Audio Files] --&gt;|Convert & Slice| E1[Log-Mel Spectrograms]\n    C --&gt; |Use| F1[Embeddings as Labels]\n    E1 --&gt;  E2[Training Input]\n    F1 --&gt;  E2[Training Input]\n    E2 --&gt; |Train with Cosine Similarity Loss| G1[CNN with 100D Output]\n  end\n\n  %% === Inference ===\n  subgraph INF[Inference]\n    I1[Audio Files] --&gt; |Convert & Slice| I2[Log-Mel Spectrograms]\n    G1 --&gt; |Use| I3[Inference Model]\n    I2 --&gt; I4[Inference Input]\n    I3 --&gt; I4[Inference Input]\n    I4 --&gt; |run model| I5[100D Embeddings]\n    I6[Query Idx] --&gt; |Cosine Similarity to Find Similar Songs To Query| I7[Best Next Song]\n    I5 --&gt; I6\n  end\n\n    subgraph t[Training]\n        T1\n        T2\n\n    end\n\n\n\n\n\n\nInstead of using strings as Labels, the embeddings from the Spotify playlist-based Training act as such. Therefore, it is better to speak of dependent variable \\(y\\). Our labels have the dimension of 100. The second network is a standard classification.\nDuring inference, the predicted output for every spectrogram is a 100D vector. The spectrogram acts as features \\(X_{inf}\\). In a final step, we rank songs by the best fit to our query.\nTo answer our questions “Why was song A chosen?” we only need to analyze the inference related to training #2.\nWe already had a look at \\(X\\). Now let’s look at the dependent variable \\(y\\)."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#t-sne-for-high-dimensionality-data.",
    "href": "posts/projects/deejai/deejai-xai.html#t-sne-for-high-dimensionality-data.",
    "title": "How Neural Networks Hear Music",
    "section": "3 T-SNE for high dimensionality data.",
    "text": "3 T-SNE for high dimensionality data.\nWe are interested in visualizing our labels. I ran the embedding creation in Deej-Ai with MP3ToVec. This is done via model.predict(x). Where \\(x\\) are the slices we defined earlier. The data was then stored.\n\nimport pickle\n\nfilenames = ['/opt/project/data/raw-previews/combined/' + f for f in manifest['filename']]\n\nwith open(\"/app/data/pickles/combined/mp3tovecs/mp3tovec.p\", \"rb\") as f:\n    mp3tovecs = pickle.load(f)\n\nX = np.vstack([mp3tovecs[f] for f in filenames if f in mp3tovecs])\n\nThe issue, the data is of the form 100D for each file. How to visualize this. A straightforward approach would be a matrix plot.\n\n\nCode\nplt.figure(figsize=(5, 10))\nplt.imshow(X, cmap='viridis')\nplt.colorbar()\nplt.title(\"Embedded Vectors Visualization\")\nplt.ylabel(\"Song Index\")\nplt.xlabel(\"Embedded Vector\")\nplt.show()\n\n\n\n\n\n\n\n\n\nFrom this we can actually not see much. Only that many dimensions are characteristic in their value (vertical lines)\nWe need to reduce the dimensions to plot this data in a scatter plot. T-distributed stochastic neighbor embedding (TNSE) is a popular dimensionality reduction technique. You can read more on wikipedia. But as with any complex method, there are some caveats. A nice article about the limitations is in distill.pub.\n\n3.1 T-SNE Limitations TL;DR;\n\nDistances are not reliable: Global structure is often distorted; distances between clusters are meaningless.\nCluster sizes are misleading: Size/shape doesn’t reflect actual data density or variance.\nClusters can be artifacts: t-SNE can create apparent groupings even from random data.\nSensitive to hyperparameters: Perplexity, learning rate, and iterations drastically affect results.\nNon-deterministic: Results vary with different random seeds; always run multiple times.\nNo generalization: Can’t project new data without retraining (non-parametric).\nSlow on large datasets: Scales poorly; approximations or UMAP may be better.\n\n\n\n3.2 T-SNE Best Practice TL;DR;\n\nTune parameters carefully.\nRun multiple times to check stability.\nDon’t trust distances, cluster sizes, or shapes.\nUse it for exploration, not clustering or quantification.\nCompare with PCA, UMAP, or other embeddings.\n\nIn short, the main issue is the sensitive to the hyperparameters. A recent paper, Gove et al. 2022, came up with a comprehensive study. In contrast to a previous study Kobak and Berens, 2019, the authors found no dependence on the size of the dataset (previously 1% of dataset size). The previous results translate to perplexity of 2.5. This means any point is just influenced by 2 other points. This often overstressed the local structure. Instead, we focus on the newer magic recipe.\n\n\n3.3 The magic recipe\nHere is a summary of the findings:\nBegin with\nperplexity = 16\nlearning_rate = 10\nexaggeration = 1\niters = 1000 # Above 1000 iters low variation\nThen tune by visual inspection\n\nBlobs? → raise exaggeration to 3–4.\nLost global shape? → double learning-rate or bump perplexity (never past 16).\nOver-compressed? → lower exaggeration or learning-rate.\n\nBig data (≫20 k points): try perplexity ≈ n/100 and lr ≈ n/12.\n\n\n3.4 T-SNE for the playlist data\nLet’s apply these findings to our data. To check the stability of the result, we treat this as a convergence issue and write a function that checks the solution for stability.\n\nfrom sklearn.manifold import TSNE\n\n\ndef tsne_until_converged(\n        X,\n        step_iter=250,\n        max_iter=10000,\n        tol=1e-3,\n        random_state=42,\n        verbose=True,\n        perplexity=5,\n        learning_rate=10,\n        exaggeration=1\n):\n    n = X.shape[0]\n\n    common = dict(\n        n_components=2,\n        perplexity=perplexity,\n        learning_rate=learning_rate,\n        early_exaggeration=exaggeration,\n        init=\"pca\",\n        random_state=random_state,\n        verbose=False,\n    )\n\n    # we always start at 250\n    total_iter = 250\n    tsne = TSNE(max_iter=total_iter, **common)\n    Y = tsne.fit_transform(X)\n\n    history = []\n    prev = Y.copy()\n\n    while total_iter &lt; max_iter:\n        total_iter += step_iter\n        tsne = TSNE(\n            max_iter=total_iter,\n            **common,\n        )\n        Y = tsne.fit_transform(X)\n\n        # Check the stability\n        delta = np.linalg.norm(Y - prev, axis=1).mean()\n        history.append(delta)\n        if verbose:\n            print(f\"[{total_iter + step_iter} iters] mean move = {delta:.6f}\")\n\n        if delta &lt; tol:\n            if verbose:\n                print(\"✓ Converged\")\n            break\n\n        prev = Y.copy()\n\n    return Y, history, total_iter\n\nHere are my iterations, which I did follow the magic recipe.\n\n%%capture\nembedding1, movement1, max_iter1 = tsne_until_converged(X)\n\n\n%%capture\nembedding2, movement2, max_iter2 = tsne_until_converged(X, perplexity=10)\n\n\n%%capture\nembedding3, movement3, max_iter3 = tsne_until_converged(X, perplexity=16)\n\n\n%%capture\nembedding4, movement4, max_iter4 = tsne_until_converged(X, perplexity=16, exaggeration=4)\n\n\n%%capture\nembedding5, movement5, max_iter5 = tsne_until_converged(X, perplexity=16, exaggeration=4, learning_rate=40)\n\nLet’s plot the 2D data and the stability of the embeddings.\n\n\nCode\n# for plotting we define a helper function\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n\ndef plot_tsne_results(\n        results,\n        filenames=None,\n        titles=None,\n        palette=\"Set2\",\n        figsize=(6, 12),\n):\n    n = len(results)\n    fig, axes = plt.subplots(nrows=n, ncols=2, figsize=(figsize[0] * n, figsize[1] * 2))\n\n    for i, (embedding, movement) in enumerate(results):\n        # 1. Plot embedding\n        tsne_df = pd.DataFrame({\n            \"x\": embedding[:, 0],\n            \"y\": embedding[:, 1],\n            \"label\": filenames if filenames is not None else [\"\"] * len(embedding)\n        })\n\n        ax1 = axes[i, 0] if n &gt; 1 else axes[0]\n        sns.scatterplot(\n            data=tsne_df,\n            x=\"x\", y=\"y\",\n            hue=\"label\",\n            palette=palette,\n            s=60, edgecolor='k', alpha=0.7,\n            ax=ax1,\n            legend=False if i &gt; 0 else \"auto\"\n        )\n        ax1.set_title(titles[i] if titles else f\"t-SNE Embedding {i + 1}\")\n        ax1.set_xlabel(\"TSNE-1\")\n        ax1.set_ylabel(\"TSNE-2\")\n\n        # 2. Plot movement curve\n        ax2 = axes[i, 1] if n &gt; 1 else axes[1]\n        ax2.plot(movement, marker='o', linewidth=1.5)\n        ax2.set_title(\"Mean Movement per Step\")\n        ax2.set_xlabel(\"Step\")\n        ax2.set_ylabel(\"Mean Δ Position\")\n        ax2.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\nresults = [\n    (embedding1, movement1),\n    (embedding2, movement2),\n    (embedding3, movement3),\n    (embedding4, movement4),\n    (embedding5, movement5),\n]\n\nplot_tsne_results(results, titles=[\"Run 1 p=5\", \"Run 2 p=10\", \"Run 3 p=16\", \"Run 4 p=16,e=3\", \"Run 5 p=16,e=3, l=40\"])\n\n\n\n\n\n\n\n\n\nThere is not much variation. There are three distinctive groups in all pictures. The standard setting in run2 leads to vertically squeezed distribution. The result in this respect seems better in run 5, with early exaggeration and increased learning rate.\n\n\n3.5 Can we see two groups (party and quite) in the data?\nAs mentioned earlier, I was not entirely happy with the matches. As a result, triaged the files into two groups. One which I experienced as quiet. Let’s see if we can confirm this very subjective impression in the data, even though we never told the model that these two groups exist.\nWe define the data to be plotted to include theme and filename.\n\n\nCode\n# Load manifest again\nmanifest = pd.read_csv(\"/app/data/raw-previews/explainabletrack_manifest.csv\")\nlabels = [f for f in manifest['theme']]\ntsne_df = pd.DataFrame({\n    \"x\": embedding5[:, 0],\n    \"y\": embedding5[:, 1],\n    \"theme\": labels,\n    \"filename\": filenames\n})\n\n\n\n\nCode\nsns.scatterplot(\n    data=tsne_df,\n    x='x', y='y',\n    hue='theme',\n    palette='Set2',\n    s=60, edgecolor='k', alpha=0.7\n)\n\nplt.title(\"t-SNE Projection Colored by Manual Theme Label\", fontsize=14)\nplt.xlabel(\"TSNE-1\");\nplt.ylabel(\"TSNE-2\")\nplt.legend(title=\"Theme\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nOverall, the data does not fit the perceived feature of “quietness.” The only think that is noticeable in the picture is a clustering of green points to the left and the bottom of the patch 2 and 3, respectively.\n\n3.5.1 Intra- and inter-theme similarity\nWe can express this in numbers and calculate intra- and inter-theme similarity. The themes should be distinct and have little variation.\n\n\nCode\nfrom sklearn.metrics.pairwise import cosine_distances\nimport itertools\n\ntheme_to_indices = tsne_df.groupby(\"theme\").groups\ntheme_names = list(theme_to_indices.keys())\n\nsimilarity_stats = []\n\nfor t1, t2 in itertools.combinations_with_replacement(theme_names, 2):\n    i1 = list(theme_to_indices[t1])\n    i2 = list(theme_to_indices[t2])\n\n    vec1 = X[i1]\n    vec2 = X[i2]\n\n    distances = cosine_distances(vec1, vec2)\n    mean_distance = distances.mean()\n\n    similarity_stats.append({\n        \"theme_1\": t1,\n        \"theme_2\": t2,\n        \"mean_cosine_distance\": mean_distance\n    })\n\nsimilarity_df = pd.DataFrame(similarity_stats)\nsimilarity_df.sort_values(by=\"mean_cosine_distance\", inplace=True)\nsimilarity_df\n\n\n\n\n\n\n\n\n\ntheme_1\ntheme_2\nmean_cosine_distance\n\n\n\n\n0\nparty\nparty\n0.040207\n\n\n2\nruhig\nruhig\n0.046004\n\n\n1\nparty\nruhig\n0.048002\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.metrics import silhouette_score\n\nscore = silhouette_score(X, labels, metric='cosine')\nprint(f\"Silhouette Score (cosine): {score:.3f}\")\n\n\nSilhouette Score (cosine): 0.085\n\n\nAll of these numbers are very close to zero. This data backs the visual impression: The manual groups have nothing to do with the automatic selection. This explains why I was not satisfied. Features that I deemed important are somehow not in the data. Interesting.\n\n\n\n3.6 Similarity analysis of single songs\nLet’s study more how the model behaves with respect to a query. Our query song is Purple Rain - Prince.\nMy final playlist had this ordering\n\nLuna - Bombay Bicycle Club.mp3\nPurple Rain - Prince.mp3\nEverybody Wants To Rule The World - Tears For Fears.mp3\nKiss from a Rose - Seal.mp3\n\nWe first define some helpers\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_vector_by_name(db, search_term):\n    return db[\"/opt/project/data/raw-previews/combined/\" + search_term + \".mp3\"]\n\n\ndef compare_songs(song_A, song_B, db):\n    song_A_vec = get_vector_by_name(db, song_A)\n    song_B_vec = get_vector_by_name(db, song_B)\n\n    sim = cosine_similarity(song_A_vec.reshape(1, -1), song_B_vec.reshape(1, -1))[0][0]\n    print(f\"Similarity to {song_A}: {sim:.3f}\")\n\n\ndef most_similar_song(song_A_vec, vectors, filenames):\n    sims = cosine_similarity(song_A_vec.reshape(1, -1), vectors)[0]\n    min_idx = np.argmin(sims)\n    min_score = sims[min_idx]\n\n    print(f\"Weakest match cosine similarity: {min_score:.3f}\")\n    sorted_indices = np.argsort(sims)[::-1]  # Descending order\n\n    second_idx = sorted_indices[1]\n\n    return filenames[second_idx], sims[second_idx]\n\nLet’s see what is the best fitting song to Purple Rain.\n\nbest_match, score = most_similar_song(get_vector_by_name(mp3tovecs, \"Purple Rain - Prince\"), X, filenames)\nprint(f\"Best match: {best_match} — cosine sim: {score:.3f}\")\n\nWeakest match cosine similarity: 0.825\nBest match: /opt/project/data/raw-previews/combined/Mesmerise - Temples.mp3 — cosine sim: 0.999\n\n\nAgain, we confirm that the automatic matching produced something different from my selection. Let’s compare all songs and also one which is completely off.\n\ncompare_songs(\"Purple Rain - Prince\", \"Everybody Wants To Rule The World - Tears For Fears\", mp3tovecs)\n\nSimilarity to Purple Rain - Prince: 0.998\n\n\n\ncompare_songs(\"Purple Rain - Prince\", \"Luna - Bombay Bicycle Club\", mp3tovecs)\n\nSimilarity to Purple Rain - Prince: 0.995\n\n\n\ncompare_songs(\"Purple Rain - Prince\", \"Mr. Brightside - The Killers\", mp3tovecs)\n\nSimilarity to Purple Rain - Prince: 0.933\n\n\n\ncompare_songs(\"Purple Rain - Prince\", \"Kiss from a Rose - Seal\", mp3tovecs)\n\nSimilarity to Purple Rain - Prince: 0.990\n\n\n\n3.6.1 Plotting single songs in TSNE plot\nAs a final step, we want to visualize what we have just expressed in numbers. How are the songs related to the plot?\n\n\nCode\nlabels = [\"none\"] * len(filenames)\n\nsongs = [\"Purple Rain - Prince\", \"Mesmerise - Temples\", \"Everybody Wants To Rule The World - Tears For Fears\",\n         \"Mr. Brightside - The Killers\", ]\n\nfor i, f in enumerate(filenames):\n    for song in songs:\n        if song in f:\n            labels[i] = song\n            break\n\ntsne_df = pd.DataFrame({\n    \"x\": embedding5[:, 0],\n    \"y\": embedding5[:, 1],\n    \"theme\": labels,\n    \"filename\": filenames\n})\n\n\n\n\nCode\npalette = {\n    \"none\": \"#bbbbbb\",\n    songs[1]: \"black\",\n    songs[0]: \"green\",\n    songs[2]: \"orange\",\n    songs[3]: \"red\",\n\n}\n\nplt.figure(figsize=(10, 8))\nsns.scatterplot(\n    data=tsne_df,\n    x=\"x\", y=\"y\",\n    hue=\"theme\", hue_order=[\"none\", songs[1], songs[0], songs[2], songs[3]],\n    palette=palette,\n    s=60, edgecolor=\"k\", alpha=0.7\n)\nplt.legend(title=\"Label\", loc=\"best\")\nplt.title(\"t-SNE with three highlighted songs\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe picture confirms it again. Temples - Mesmerise is the best match. It should have been picked. It appears The nearby match Everybody Wants To Rule The World - Tears For Fears was not the closest match and only got taken because I interfered with the playlist creation."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#grad-cam",
    "href": "posts/projects/deejai/deejai-xai.html#grad-cam",
    "title": "How Neural Networks Hear Music",
    "section": "4 Grad-CAM",
    "text": "4 Grad-CAM\nOur Mp3ToVec network already tells us how close two songs are (cosine similarity), but not where that closeness comes from.\nAre there any regions in the spectrogram that lead to the exact match? Which time–frequency zones triggered the network to declare “this query sounds like Song A (and not Song B)”. In the next section, we will look at Integrated Gradients, which observes down to pixel level. Grad-CAM offers a complementary, big-picture view.\n\n4.1 Background\nGrad-CAM works by examining the last convolutional layer, which acts as the model’s feature detector. We then use the gradient of the similarity score with respect to Song A to weight these feature maps.\nFinally, we project the weighted activation maps back onto the spectrogram. This results in a coarse heatmap; red blobs where the CNN focused, and blank areas elsewhere.\nIn terms of interpretability, this allows a visual inspection, which goes beyond simple scores.\n\n\n4.2 Implementation\n\n\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\nmodel = load_model(\n    '/app/speccy_model',\n    custom_objects={\n        'cosine_proximity':\n            tf.compat.v1.keras.losses.cosine_proximity\n    })\nmodel.trainable = False;\nconv_layer = model.get_layer(\"separable_conv2d_3\")\n\n\nfrom scipy.ndimage import gaussian_filter\n\n\ndef score_fn(emb):\n    emb = tf.nn.l2_normalize(emb, axis=1)\n    return tf.tensordot(emb, vec_A, axes=1)\n    \ndef grad_cam(slice_tensor,\n             model, conv_layer, score_fn,\n             eps=1e-8):\n    # build a model that gives conv feature-maps and final embedding\n    grad_model = tf.keras.Model(\n        inputs=model.inputs,\n        outputs=[conv_layer.output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(slice_tensor)\n        tape.watch(conv_out)\n        score = score_fn(preds)\n\n    \n    grads = tape.gradient(score, conv_out) \n    weights = tf.reduce_mean(grads, axis=[1, 2])\n\n    cam = tf.reduce_sum(weights[:, None, None, :] * conv_out, axis=-1)[0] \n    cam = tf.nn.relu(cam)\n\n    cam = tf.image.resize(cam[..., None], slice_tensor.shape[1:3])[..., 0]\n    cam = (cam - tf.reduce_min(cam)) / (tf.reduce_max(cam) - tf.reduce_min(cam) + eps)\n    return cam.numpy()\n\n\ndef full_song_grad_cam(model, query_slices, vec_A, conv_layer,\n                       n_mels=96, slice_size=216, sigma=1.5):\n    \n    vec_A_tf = tf.constant(vec_A / np.linalg.norm(vec_A), tf.float32)\n\n    def score_fn(embedding):\n        return tf.tensordot(tf.nn.l2_normalize(embedding, axis=1), vec_A_tf, axes=1)\n        \n    gc_full = np.zeros((n_mels, query_slices.shape[0] * slice_size))\n\n    for i, slice_tensor in enumerate(query_slices):\n        slice_tensor = slice_tensor[None, ...]\n        gc = grad_cam(slice_tensor, model, conv_layer, score_fn)\n        gc = gaussian_filter(gc, sigma=sigma)\n        gc_full[:, i * slice_size: (i + 1) * slice_size] = gc\n        \n    return gc_full\n\nNow that we have defined a function to do GRAD-CAM for the full song. Let’s study the difference for song A and song B. We will get an answer which regions where more important to which song and which were identically important.\n\nvec_A = mp3tovecs['/opt/project/data/raw-previews/combined/Mesmerise - Temples.mp3']\nvec_B = mp3tovecs['/opt/project/data/raw-previews/combined/Everybody Wants To Rule The World - Tears For Fears.mp3']\nx_query = mp3_to_slices('/app/data/raw-previews/combined/Purple Rain - Prince.mp3')\n\n\ncam_A = full_song_grad_cam(model, x_query, vec_A, conv_layer)\ncam_B = full_song_grad_cam(model, x_query, vec_B, conv_layer)\n\n# we use signed log, as the songs are very close together.\ndiff = tf.math.log((cam_A + 1e-5) / (cam_B + 1e-5))\ndiff_clipped = tf.clip_by_value(diff, -3.0, 3.0)\n\n\n\nCode\nplt.figure(figsize=(8, 3))\n\nplt.imshow(diff_clipped, cmap=\"berlin\", alpha=0.6, origin=\"lower\", aspect=\"auto\")\nplt.colorbar(label=\"Grad-CAM intensity\")\nplt.title(\"Where the CNN ‘looked’ to match Song A\")\nplt.tight_layout();\nplt.show()\n\n\n\n\n\n\n\n\n\nThanks to the clipping, the graph is easy to read. The Song had a lot more information, which made it similar to the query song.\nOnly at the very end are some blue spots. This could indicate that the spotify preview covers only the less relevant sections of the entire song for the particular comparison. Whereas I was listening to the full song. Song B seems better for the rhythm as the blue patches repeat.\nWe will dive deeper into this in the next section."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#integrated-gradients",
    "href": "posts/projects/deejai/deejai-xai.html#integrated-gradients",
    "title": "How Neural Networks Hear Music",
    "section": "5 Integrated gradients",
    "text": "5 Integrated gradients\nWhy did the model prefer Song A over Song B? We know that the model turns spectrograms into 100-D vectors and ranks candidates using cosine similarity. That alone doesn’t tell us why one track got a higher score than another. To dig deeper, we use Integrated Gradients (IG). This method helps identify which parts of a spectrogram contribute most to the similarity score, that is which pixels or frequencies increase the score.\nIn contrast to Grad-Cam, we do not look at the feature level, but on input level through the entire network.\n\n5.1 Background\nIG works by comparing the actual input (the spectrogram) to a baseline input, typically silence.\nWe then gradually transition from the baseline to the real input by scaling the spectrogram with a factor \\(\\alpha\\).\n\\[ x_α = baseline + \\alpha × (input - baseline) \\]\nwhere \\(\\alpha ∈ [0,1]\\)\nAt each step, we compute the gradient of the output with respect to the input. When we average across all steps, we get the average contribution of each pixel.\nIn Pytorch we have the Captum library to directly do this. However, Deej-AI works on an older keras 2.13. We need to implement Integrated Gradients from scratch.\n\n\n5.2 From scratch development of integrated gradients\n\n5.2.1 Method for one slice\nWe define the integrated gradients for one slice\nLet’s first clarify what we expect from the model\nLuckily for a linear model \\[f(x) = w^\\top x + b\\]\nthe Integrated Gradients have the closed-form\n\\[\\mathrm{IG}(x) \\;=\\; (x - x_0)\\,\\odot\\,w\\]\nWe intend to use integrated gradients to check the impact on the cosine similarity score. Therefore, we need to integrate the L2 norm in the function. This has side effects in testing. We need to make the code modular to accommodate for this.\n\nimport tensorflow as tf\n\n# for testing, we will test on raw attribution without normalization\ndef default_score_fn(preds, target_vec=None):\n    if target_vec is not None:\n        t = tf.reshape(tf.convert_to_tensor(target_vec, tf.float32), [-1])\n        return tf.reduce_sum(preds * t, axis=-1)\n    else:\n        return tf.reduce_sum(preds, axis=-1)\n\n\n# we are interested on the effect of the cosine similarity score, therefore, we will need to do L2\ndef cosine_score_fn(preds, target_vec):\n    p = tf.nn.l2_normalize(preds, axis=1)\n    t = tf.nn.l2_normalize(target_vec, axis=0)\n    return tf.reduce_sum(p * t, axis=-1)\n\n\n# this is the function for one slice\ndef ig_one_slice(\n        model,\n        query_slice,\n        target_vec,\n        baseline_slice=None,\n        steps=120,\n        score_fn=default_score_fn\n):\n    if baseline_slice is None:\n        baseline_slice = tf.zeros_like(query_slice, dtype=tf.float32)\n\n    # make sure we work on f32\n    query_slice = tf.convert_to_tensor(query_slice, dtype=tf.float32)\n    baseline_slice = tf.convert_to_tensor(baseline_slice, dtype=tf.float32)\n    if target_vec is not None:\n        target_vec = tf.convert_to_tensor(target_vec, dtype=tf.float32)\n        target_vec = tf.reshape(target_vec, [-1])\n\n    # Remove batch dim for interpolation\n    start = tf.squeeze(baseline_slice, 0)  # (96,216,1)\n    end = tf.squeeze(query_slice, 0)  # (96,216,1)\n\n    alphas = tf.linspace(0.0, 1.0, steps)[:, tf.newaxis, tf.newaxis, tf.newaxis]\n    interpolated = start + alphas * (end - start)\n\n    # Compute gradients\n    with tf.GradientTape() as tape:\n        tape.watch(interpolated)\n        preds = model(interpolated)\n        scores = score_fn(preds, target_vec)\n\n    grads = tape.gradient(scores, interpolated)\n    avg_grads = tf.reduce_mean(grads, axis=0)\n\n    ig = (end - start) * avg_grads\n    return ig\n\nGradients can be noisy. We add some smoothing to get a better visual representation. We use a two-pass smoothing. First on the slice and later on the final output.\n\nfrom scipy.ndimage import gaussian_filter\n\ndef ig_one_slice_smooth(\n        model,\n        query_slice,\n        target_vec=None,\n        baseline_slice=None,\n        steps=120,\n        score_fn=default_score_fn,\n        sigma=0\n):\n    ig_raw = ig_one_slice(\n        model=model,\n        query_slice=query_slice,\n        target_vec=target_vec,\n        baseline_slice=baseline_slice,\n        steps=steps,\n        score_fn=score_fn\n    )\n\n    ig_map = ig_raw.numpy().squeeze()\n    return gaussian_filter(ig_map, sigma=sigma)\n\n\n\n5.2.2 Testing with a closed form solution\n\n\nCode\ndef test_for_ig_one_slice():\n    H, W = 2, 3\n\n    flat_vals = np.arange(H * W, dtype=np.float32)  # [0, 1, 2, 3, 4, 5]\n    x = flat_vals.reshape((1, H, W, 1))  # shape: (1,2,3,1)\n    x = tf.constant(x)\n\n    x0 = tf.zeros_like(x)  # shape: (1,2,3,1)\n\n    w = tf.constant(flat_vals, dtype=tf.float32)  # weights = [0,1,2,3,4,5]\n    b = tf.constant(0., dtype=tf.float32)\n\n    class LinearModel(tf.keras.Model):\n        def __init__(self, w, b):\n            super().__init__()\n            self.w = w\n            self.b = b\n\n        def call(self, inp):\n            flat = tf.reshape(inp, [inp.shape[0], -1])  # (batch, D)\n            # return a *vector* of length 1 so IG still works with a scalar output\n            return tf.matmul(flat, tf.expand_dims(self.w, 1)) + self.b\n\n    model = LinearModel(w, b)\n\n    # For this scalar-output model, set target_vec = [1.], so that\n    # scores = f(interpolated) * 1  and grad(scores) = grad f.\n    target_vec = np.array([1.], dtype=np.float32)\n\n    ig_out = ig_one_slice(model, query_slice=x, target_vec=target_vec, baseline_slice=x0, steps=50)\n    ig_out = ig_out.numpy().reshape(-1)\n\n    closed_form = (x - x0).numpy().reshape(-1) * flat_vals  # shape (6,)\n\n    tf.debugging.assert_near(ig_out, closed_form, atol=1e-6)\n\n\n\ntest_for_ig_one_slice()\n\nq.e.d.\n\n\n5.2.3 Testing with real data\nWe will first examine the result for one slice, without any baseline or target vector. This produces the raw attribution of each pixel to the output value of the model.\n\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model(\n    '/app/speccy_model',\n    custom_objects={\n        'cosine_proximity':\n            tf.compat.v1.keras.losses.cosine_proximity\n    })\nmodel.trainable = False\n\n\nquery_slices = mp3_to_slices(\"/app/data/raw-previews/combined/Purple Rain - Prince.mp3\")\n\n\nig_test_map = ig_one_slice_smooth(model, query_slice=query_slices[0:1])\n\nNow comes the second filtering function, which we only use for postprocessing.\n\n\nfrom scipy.ndimage import gaussian_filter\nimport matplotlib.pyplot as plt\n\n\ndef highlight_ig_regions(\n        ig_map,\n        percentile=90,\n        sigma=2.5,\n        colormap=plt.cm.berlin,\n        alpha=0.85\n):\n    abs_map = np.abs(ig_map)\n    thr = np.percentile(abs_map[abs_map &gt; 0], percentile)\n    mask = abs_map &gt;= thr\n    masked = np.where(mask, ig_map, 0.0)\n\n    masked = gaussian_filter(masked, sigma=sigma)\n\n    # Normalize and map to colormap\n    vmax = np.max(np.abs(masked)) + 1e-9\n    normed = (masked / (2 * vmax)) + 0.5\n    rgba = colormap(normed)\n\n    # Set alpha only where masked &gt; 0\n    rgba[..., 3] = (np.abs(masked) &gt; 0) * alpha\n\n    return rgba, masked\n\n\n\nCode\nrgba_img, smoothed_mask = highlight_ig_regions(ig_test_map, percentile=95, sigma=0.0)\nplt.figure(figsize=(10, 4))\nplt.imshow(smoothed_mask, aspect='auto', origin='lower', cmap='seismic')\nplt.colorbar(label='Attribution')\nplt.title(\"Integrated Gradients Attribution\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"n_mel\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can see which frequencies in the sample added to the model output.\n\n\n\n5.3 Analysis: Why Song A got picked over Song B\nWe did a lot of work until now. Much of which has been the development of the integrated gradients.\nWhat we were originally interested in is the question of why Song A was chosen over Song B for a query Song.\nFor this to work, we now need to take our real model, the one that produced the 100D embeddings.\nAs well as three songs.\n\nFor us this is Purple Rain for the query.\nMesmerise for Song A,\nand Everybody wants to rule the world for Song B.\n\nSong A and Song B are very close together. While experimenting, I found that using the gradients is challenging in this case.\nThere are two ways we can calculate contrastive IG.\nThe standard way: subtract IG\n\\[\n\\mathrm{IG}_A(x) = (x - x') \\odot \\frac{1}{m} \\sum_{k=1}^m \\nabla_x F_A\\left(x' + \\frac{k}{m}(x - x')\\right)\n\\]\n\\[\n\\mathrm{IG}_B(x) = (x - x') \\odot \\frac{1}{m} \\sum_{k=1}^m \\nabla_x F_B\\left(x' + \\frac{k}{m}(x - x')\\right)\n\\]\n\\[\n\\mathrm{ContrastIG}(x) = \\mathrm{IG}_A(x) - \\mathrm{IG}_B(x)\n\\]\nand method 2 that can be helpful if the embeddings are very close. The reason is that first taking the gradient and then calculating the difference amplifies the noise. This method has been introduced by Sundararajan et al. 2017.\nThe second method uses one scoring function, as described in the Captum interpretability library and aligned with contrastive explanation principles from Dhurandhar et al. 2018.\n\\[\nF(x) = \\text{sim}(x, A) - \\text{sim}(x, B)\n\\]\n\\[\n\\mathrm{ContrastIG}(x) = (x - x') \\odot \\frac{1}{m} \\sum_{k=1}^m \\nabla_x \\left[ F\\left(x' + \\frac{k}{m}(x - x')\\right) \\right]\n\\]\nWe will try both.\n\n5.3.1 Getting the data ready\nWe need\n\nload our model: the one that produces the vectors.\nthe spectrogram of the query song. The analysis is built on it\nthe vector of song A, the best Match. We answer which parts of the query made it go to song A? we use song A as direction of analysis.\nthe vector of song B.\n\n\nmodel = tf.keras.models.load_model(\n    \"/app/speccy_model\",\n    custom_objects={'cosine_proximity': tf.compat.v1.keras.losses.cosine_proximity}\n)\nmodel.trainable = False\n\n\nquery_slices = mp3_to_slices(\"/app/data/raw-previews/combined/Purple Rain - Prince.mp3\")\nb_slices = mp3_to_slices(\"/app/data/raw-previews/combined/Everybody Wants To Rule The World - Tears For Fears.mp3\")\n\n\nimport pickle\n\nwith open(\"/app/data/pickles/combined/mp3tovecs/mp3tovec.p\", \"rb\") as f:\n    mp3tovecs = pickle.load(f)\n\nvec_A = mp3tovecs['/opt/project/data/raw-previews/combined/Mesmerise - Temples.mp3']\nvec_B = mp3tovecs['/opt/project/data/raw-previews/combined/Everybody Wants To Rule The World - Tears For Fears.mp3']\n\nLet’s confirm shapes\n\nprint(query_slices.shape)\nprint(model.input_shape)\nprint(vec_A.shape)\n\n(5, 96, 216, 1)\n(None, 96, 216, 1)\n(100,)\n\n\n\n\n5.3.2 Method 1\nWe first run method 1, using silence as baseline.\n\nig_raw_a = ig_one_slice_smooth(\n    model=model,\n    query_slice=query_slices[0:1],\n    target_vec=tf.nn.l2_normalize(tf.convert_to_tensor(vec_A, dtype=tf.float32), axis=0),\n    baseline_slice=None,\n    score_fn=cosine_score_fn,\n)\n\nig_raw_b = ig_one_slice_smooth(\n    model=model,\n    query_slice=query_slices[0:1],\n    target_vec=tf.nn.l2_normalize(tf.convert_to_tensor(vec_B, dtype=tf.float32), axis=0),\n    baseline_slice=None,\n    score_fn=cosine_score_fn,\n)\nig_contrast_method_1 = (ig_raw_a - ig_raw_b)\n\n\n\nCode\nrgba_img, smoothed_mask = highlight_ig_regions(ig_contrast_method_1, percentile=99, sigma=5.0)\nplt.figure(figsize=(12, 4))\nplt.imshow(rgba_img, origin=\"lower\", aspect=\"auto\")\nplt.title(\"Aggregated IG – why model prefers Song A over Song B\")\nplt.colorbar(label=\"A &gt; B (red)   |   B &gt; A (blue)\")\nplt.tight_layout();\nplt.show()\n\n\n\n\n\n\n\n\n\nThere is not much insight that we can gain from this picture. We will see if the full song analysis can help. We define a function that assembles the full heatmap.\n\ndef full_song_contrastive_ig_method1(\n        model,\n        query_slices,\n        vec_A,\n        vec_B,\n        score_fn,\n        steps=120,\n        sigma=0,\n):\n    n_slices, H, W, _ = query_slices.shape\n    full_contrast = np.zeros((H, n_slices * W), dtype=np.float32)\n\n    # Normalize target vectors once\n    vec_a_tf = tf.nn.l2_normalize(tf.convert_to_tensor(vec_A, dtype=tf.float32), axis=0)\n    vec_b_tf = tf.nn.l2_normalize(tf.convert_to_tensor(vec_B, dtype=tf.float32), axis=0)\n\n    # iterate over all slices\n    for i in range(n_slices):\n        q_slice = query_slices[i:i + 1]\n\n        ig_a = ig_one_slice_smooth(\n            model=model,\n            query_slice=q_slice,\n            target_vec=vec_a_tf,\n            baseline_slice=None,\n            score_fn=score_fn,\n            steps=steps,\n            sigma=sigma\n        )\n\n        ig_b = ig_one_slice_smooth(\n            model=model,\n            query_slice=q_slice,\n            target_vec=vec_b_tf,\n            baseline_slice=None,\n            score_fn=score_fn,\n            steps=steps,\n            sigma=sigma\n        )\n\n        ig_contrast = ig_a - ig_b\n\n        full_contrast[:, i * W:(i + 1) * W] = ig_contrast\n\n    return full_contrast\n    # (H,W)\n\n… and run it.\n\nfull_ig_method_1 = full_song_contrastive_ig_method1(\n    model,\n    query_slices=query_slices,\n    vec_A=vec_A,\n    vec_B=vec_B,\n    score_fn=cosine_score_fn,\n)\n\n\n\nCode\nrgba_img, smoothed_mask = highlight_ig_regions(full_ig_method_1, percentile=99, sigma=8.0)\nplt.figure(figsize=(12, 4))\nplt.imshow(rgba_img, origin=\"lower\", aspect=\"auto\")\nplt.title(\"Aggregated IG – why model prefers Song A over Song B\")\nplt.colorbar(label=\"A &gt; B (red)   |   B &gt; A (blue)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe result is somewhat disappointing. Overall, the algorithm should have identified song B as the next song. There are only some red spots at the bottom in the lower frequencies.\nLet’s again switch to a quantitative analysis and plot frequencies in bins.\n\n\nCode\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulated IG data, for example,\n# Replace with your actual full_ig array\ndef plot_ig_to_bins(full_ig):\n    band = full_ig.sum(axis=1)\n    sr = 22050\n    num_bins = 96\n    # Mel frequency bin edges and centers\n    mel_edges = librosa.mel_frequencies(n_mels=full_ig.shape[0] + 1, fmin=0, fmax=sr / 2)\n\n    centres = 0.5 * (mel_edges[1:] + mel_edges[:-1]) / 1000  # in kHz\n    mel_widths = np.diff(librosa.hz_to_mel(mel_edges))\n\n    # Color by attribution sign\n    colors = np.where(band &gt;= 0, \"crimson\", \"royalblue\")\n    ig, axs = plt.subplots(1, 2, figsize=(14, 4), sharey=True)\n\n    new_mel_edges = np.linspace(0, len(band), num_bins + 1, dtype=int)\n\n    # Aggregate original bins into fewer bins\n    band_reduced = np.array([\n        band[new_mel_edges[i]:new_mel_edges[i + 1]].sum()\n        for i in range(num_bins)\n    ])\n\n    # Compute centers of the new bins (in kHz)\n    mel_centers_reduced = np.array([\n        (mel_edges[new_mel_edges[i]] + mel_edges[new_mel_edges[i + 1]]) / 2 / 1000\n        for i in range(num_bins)\n    ])\n\n    # Colors based on attribution sign\n    colors = np.where(band_reduced &gt;= 0, \"crimson\", \"royalblue\")\n\n    # --- Left: Simple index-based plot ---\n    axs[0].bar(np.arange(len(band)), band, color=colors, edgecolor='black')\n    axs[0].set_title(\"X-axis: Mel Band Index (0–95)\")\n    axs[0].set_xlabel(\"Mel Band Index\")\n    axs[0].set_ylabel(\"Net Attribution\")\n    axs[0].axhline(0, color='k', linewidth=0.8)\n\n    # --- Right: Mel-scale-accurate plot ---\n    plt.bar(mel_centers_reduced, band_reduced,\n            width=np.diff(mel_edges[new_mel_edges]) / 1000,\n            color=colors, edgecolor='black')\n    axs[1].set_title(\"X-axis: Frequency (kHz)\")\n    axs[1].set_xlabel(\"Frequency (kHz)\")\n    axs[1].axhline(0, color='k', linewidth=0.8)\n\n    plt.tight_layout()\n    plt.suptitle(\"Comparison: Index vs Khz Attribution\", y=1.05, fontsize=14)\n    plt.show()\n\n\nplot_ig_to_bins(full_ig_method_1)\n\n\n\n\n\n\n\n\n\nThe heatmap is transformed into two barcharts:\n\nAs mel band index (aligned with the vertical axis of the IG heatmap)\nConverted to real-world frequency in kHz. We can see the nonlinear nature of the mel scale from this.\n\nBoth songs seem quite balanced in terms of attribution. It is not clear why the song was picked.\nOne potential reason: The embeddings are very close. Therefore, the noise in the gradient generation dominates. We can rerun the analysis with smoothing per slice.\n\n\nCode\nfull_ig_method_1_smoothed = full_song_contrastive_ig_method1(\n    model,\n    query_slices=query_slices,\n    vec_A=vec_A,\n    vec_B=vec_B,\n    score_fn=cosine_score_fn,\n    sigma=2.0\n)\nplot_ig_to_bins(full_ig_method_1_smoothed)\n\n\n\n\n\n\n\n\n\nThe smoothing made the graphs easier to read. Attribution is very low. Song B is better in the low frequencies. Whereas a song A is better in the high frequencies. The graphs look nice, but there is a catch… Let’s look at method2 first.\n\n\n5.3.3 Method 2\nIn the presence of weak gradients, method 2 suggests not calculating extra differences but using a single scoring function. This is done by making song B the baseline.\n\n5.3.3.1 Implementation\n\n\ndef full_song_ig_method_2(\n        model,\n        query_slices,\n        vec_A,\n        baseline_slices,\n        score_fn,\n        steps=120,\n        sigma=0\n):\n    n_slices, H, W, _ = query_slices.shape\n    full_contrast = np.zeros((H, n_slices * W), dtype=np.float32)\n\n    # Normalize target vectors once\n    vecA_tf = tf.nn.l2_normalize(tf.convert_to_tensor(vec_A, dtype=tf.float32), axis=0)\n\n    for i in range(n_slices):\n        q_slice = query_slices[i:i + 1]\n        b_slice = baseline_slices[i:i + 1]\n\n        ig_slice_m2 = ig_one_slice_smooth(\n            model=model,\n            query_slice=q_slice,\n            target_vec=vecA_tf,\n            baseline_slice=b_slice,\n            score_fn=score_fn,\n            steps=steps,\n            sigma=sigma\n        )\n\n        full_contrast[:, i * W:(i + 1) * W] = ig_slice_m2.squeeze()\n\n    return full_contrast\n\n\n\n5.3.3.2 Without Filtering\n\n\nCode\nfull_ig_method_2 = full_song_ig_method_2(\n    model,\n    query_slices=query_slices,\n    vec_A=vec_A,\n    baseline_slices=b_slices,\n    score_fn=cosine_score_fn,\n)\n\n\n\n\nCode\nrgba_img, smoothed_mask = highlight_ig_regions(full_ig_method_2, percentile=95, sigma=2.5)\nplt.figure(figsize=(12, 4))\n\nplt.imshow(rgba_img, origin=\"lower\", aspect=\"auto\")\nplt.title(\"Aggregated IG – why model prefers Song A over Song B\")\nplt.colorbar(label=\"A &gt; B (red)   |   B &gt; A (blue)\")\nplt.tight_layout();\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_ig_to_bins(full_ig_method_2)\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.4 With Filtering\n\nfull_ig_method_2_smoothed = full_song_ig_method_2(\n    model,\n    query_slices=query_slices,\n    vec_A=vec_A,\n    baseline_slices=b_slices,\n    score_fn=cosine_score_fn,\n    sigma=2.0\n)\nplot_ig_to_bins(full_ig_method_2_smoothed)\n\n\n\n\n\n\n\n\nNow, Song A is favored in the lower frequencies, while Song B shows more influence in the upper bands.\n\n\n\n5.4 Conclusion Method 1 vs. Method 2\nOne possible reason why Method 1 (subtracting filtered IGs) gives misleading results: If we apply Gaussian filtering before computing the difference, we might distort subtle but meaningful gradients. Since the raw attributions are weak overall, smoothing may disproportionately amplify or suppress regions — leading to an inaccurate contrast map. In fact, the raw IG maps for A and B look much more similar, and only diverge sharply after filtering.\nThis suggests that Method 2, which uses a single contrastive score function (sim(x, A) - sim(x, B)), is more stable and reliable in cases where the attribution signal is weak and gradients are low.\n\n\n5.5 Interpretation\nAssuming Method 2 provides the correct contrastive explanation, we can proceed with an interpretation. Overall, a Song A is a much better match in the low and mid-frequencies. These findings suggest that the song A’s similarity to the query (in this case, Purple Rain) is driven by features like kick drums, basslines, or low-mid instrumentation — all of which live in those bands.\nBetween 5 kHz and 9 kHz, we see increasing attribution for Song B. These frequencies often correspond to vocals, snares, cymbals, or presence-related features.\nInterestingly, I listened to the tracks on a phone-conference headset, which emphasizes exactly that frequency range. So this auditory similarity aligns with what we hear — and validates the contrastive IG result."
  },
  {
    "objectID": "posts/projects/deejai/deejai-xai.html#summary",
    "href": "posts/projects/deejai/deejai-xai.html#summary",
    "title": "How Neural Networks Hear Music",
    "section": "6 Summary",
    "text": "6 Summary\n\n6.1 What did we learn?\nT-SNE analysis showed no clear clusters labeled “silent” or “party.” My subjective categories don’t appear to have a strong representation in the embedding space — at least not visibly\nFor two nearly identical songs:\n\nT-SNE placed their embeddings close together in 2D space, confirming high similarity.\nGrad-CAM revealed that Song A (the model’s top match) contained more regions that aligned well with the query’s audio features.\nIntegrated Gradients highlighted that Song A had stronger matches in the lower frequencies, whereas my personal impression focused on higher-frequency features where Song B was better.\n\n\n\n6.2 Take away\nStreaming platforms don’t just recommend popular songs; they can also suggest new or unknown music by analyzing the audio content directly through audio embeddings. While commercial systems use more advanced models and larger infrastructure, the core principles are the same as the methods demonstrated here. In addition, platforms incorporate collaborative filtering, user history, and social data to drive final recommendations.\nWhat started as an experiment with a small CNN and a few audio clips turned into a concrete example of how machines “hear” music. Deep learning allows us to go beyond surface-level metadata like genre or artist, learning fine-grained acoustic patterns directly from the audio.\nBy exploring techniques like Grad-CAM, Integrated Gradients, and embedding visualization, we’ve opened a window into how machine learning models make decisions about music — and how we can interpret those decisions.\nThis type of analysis helps explain:\n\nWhy a recommendation “feels right”; even if you can’t explain it yourself\nWhy playlist transitions often make musical sense, even when songs come from different genres\n\nIf a basic model trained on a few spectrogram slices can already show interpretable behavior, imagine the scale and nuance of systems like Spotify, Apple Music, or TikTok.\nThis project isn’t just about “how one match happened.” It’s a glimpse into how modern recommendation systems think. Understanding these systems is important for a thoughtful usage."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html",
    "title": "Which cheese are we eating?",
    "section": "",
    "text": "I love cheese. Sometimes it is quite difficult to distinguish the varieties. Think about the embarrasement when you are in front of a mountain of cheese and can only point with your finger.\nTherefore, I decided to built a ML classifier to help me.\nThe special difficulty here is that cheeses all look quite similar. Take, for example, the swiss Gruyere and the French Comte.\nThey are twins."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#lets-start-with-the-why",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#lets-start-with-the-why",
    "title": "Which cheese are we eating?",
    "section": "",
    "text": "I love cheese. Sometimes it is quite difficult to distinguish the varieties. Think about the embarrasement when you are in front of a mountain of cheese and can only point with your finger.\nTherefore, I decided to built a ML classifier to help me.\nThe special difficulty here is that cheeses all look quite similar. Take, for example, the swiss Gruyere and the French Comte.\nThey are twins."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#lets-continue-with-with-the-data.",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#lets-continue-with-with-the-data.",
    "title": "Which cheese are we eating?",
    "section": "2 Let’s continue with with the data.",
    "text": "2 Let’s continue with with the data.\nFirst, we need some data. Fast.ai provides an easy download module to download images from DuckDuckGo.\nAs an alternative, we could use a dataset, if we have one. Let’s start by downloading the files and then create a dataset.\n\n2.1 Getting data from DuckDuckGo\nLet’s start by defining what we want to download. We want cheese. In particular, French cheese.\n\ncheeses = [\n    \"Camembert\",\n    \"Roquefort\",\n    \"Comté\",\n    \"Époisses de Bourgogne\",\n    \"Tomme de Savoie\",\n    \"Bleu d’Auvergne\",\n    \"Brie de Meaux\",\n    \"Mimolette\",\n    \"Munster\",\n    \"Livarot\",\n    \"Pont-l’Évêque\",\n    \"Reblochon\",\n    \"Chabichou du Poitou\",\n    \"Valençay\",\n    \"Pélardon\",\n    \"Fourme d’Ambert\",\n    \"Selles-sur-Cher\",\n    \"Cantal\",\n    \"Neufchâtel\",\n    \"Banon\",\n    \"Gruyere\"\n]\n\nTo have a larger variety of images we define some extra search terms.\n\nsearch_terms = [\n    \"cheese close-up texture\",\n    \"cheese macro shot\",\n    \"cheese cut section\"\n]\n\nAs we work with Fast.ai , let’s import the basic stuff.\n\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\nfrom fastai.vision.all import *\ndef search_images(keywords, max_images=20): return L(DDGS().images(keywords, max_results=max_images)).itemgot('image')\nimport time, json\n\nAnd then define our download function:\n\nfrom fastdownload import download_url\nfrom pathlib import Path\nimport time\n\ndata_acquisition=False\n\ndef download():\n    # Loop through all combinations of cheeses and search terms\n    for cheese in cheeses:\n        dest = Path(\"which_cheese\") / cheese  # Create subdirectory for each cheese\n        dest.mkdir(exist_ok=True, parents=True)\n\n        for term in search_terms:\n            query = f\"{cheese} {term}\"\n            download_images(dest, urls=search_images(f\"{query} photo\"))\n            time.sleep(5)\n\n        # Resize images after downloading\n        resize_images(dest, max_size=400, dest=dest)\n\n# Run download only if data acquisition is enabled\nif data_acquisition:\n    download()\n\nWe can verify the images now or later.\n\nif data_acquisition:\n    failed = verify_images(get_image_files(path))\n    failed.map(Path.unlink)\n    len(failed)\n    failed\n\n\n\n2.2 Loading data from a Kaggle dataset\nI created a dataset of these images to avoid having to download again when I start over.\nSadly to uncertain copyright issues of this data, my dataset needs to remain private. But you can easily create your own.\nAs I run most of my code locally, I have some code to get it from Kaggle\n\ncompetition_name= None\ndataset_name = 'cheese'\n\nimport os\nfrom pathlib import Path\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif competition_name:\n    if iskaggle: \n        comp_path = Path('../input/'+ competition_name)\n    else:\n        comp_path = Path(competition_name)\n        if not path.exists():\n            import zipfile,kaggle\n            kaggle.api.competition_download_cli(str(comp_path))\n            zipfile.ZipFile(f'{comp_path}.zip').extractall(comp_path)\n\n\nif dataset_name:\n    if iskaggle:\n        path = Path(f'../input/{dataset_name}')\n    else:\n        path = Path(dataset_name)\n        if not path.exists():\n            import zipfile, kaggle\n            kaggle.api.dataset_download_cli(dataset_name, path='.')\n            zipfile.ZipFile(f'{dataset_name}.zip').extractall(path)        \n\nNow we have downloaded the data, we can start using it."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#cleaning-the-data-with-the-help-of-our-first-model",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#cleaning-the-data-with-the-help-of-our-first-model",
    "title": "Which cheese are we eating?",
    "section": "3 Cleaning the data with the help of our first model",
    "text": "3 Cleaning the data with the help of our first model\nBefore we dive into different options for modelling, we will do a quick pass through the data and see which images are bad.\nThe background is that the scrapper picks up many images, which are not good for training.\nWe start by creating a working copy of the dataset.\n\n!mkdir -p working/which_cheese_first \n!cp -r cheese/which_cheese  working/which_cheese_first \n\nTo be sure that all images are valid, we check again for corrupeted files and remove them.\n\nfrom pathlib import Path\nfrom PIL import Image\n\ndata_path = Path(\"working/which_cheese_first\")\n\n# Check all images\ncorrupt_files = []\nfor img_path in data_path.rglob(\"*.*\"):  # Match all files inside subfolders\n    try:\n        with Image.open(img_path) as img:\n            img.verify()  # Verify if it's a valid image\n    except (IOError, SyntaxError):\n        corrupt_files.append(img_path)\n\n# Remove corrupt images\nprint(f\"Found {len(corrupt_files)} corrupt images.\")\nfor corrupt in corrupt_files:\n    print(f\"Deleting {corrupt}\")\n    corrupt.unlink()  # Delete the file\n\nFound 48 corrupt images.\nDeleting working/which_cheese_first/which_cheese/Roquefort/350d3e67-dcf6-4292-b963-c1d5841b8788.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/594d40b1-f655-4db1-b3a9-4e7d6bb6c631.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/32a9069e-52c2-47e1-9db4-16197556c4fb.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/c73fb213-3813-43fd-b5ae-2d390ca8e3d5.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/2c426320-24bd-4869-8f1c-d09171ac6294.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/83a95414-4083-48d7-9956-be5d82b05caf.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/f4f09c62-652b-400c-8e09-419389635fc4.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/dfa07f3c-0931-49aa-b3c2-9c4a5901565d.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/609abf59-c1f0-4a34-b2cf-1bedf1b4cea0.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/b56ab8cc-5b37-40c9-be31-57d14c843978.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/422aec71-31d9-421e-880c-91867eaa5dfb.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/5591880b-37f4-4bcc-9927-8f60b6d6bb37.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/a9e2a7ad-038e-4b6d-8dee-19fd1661ebe1.jpg\nDeleting working/which_cheese_first/which_cheese/Roquefort/4a572868-b982-47ed-b96e-3eb1a755e32a.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/8903d049-4256-4fe5-9716-48e5fc8ef52b.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/849c9bb0-b717-40a7-922e-091e22e36579.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/4582e06a-0218-4b6b-aeaf-7e7d61dd3827.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/bf950a7d-6ab2-4dd3-81dc-5ec14b9964dc.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/052b599d-f560-473c-947c-74bb3c138167.jpg\nDeleting working/which_cheese_first/which_cheese/Camembert/ccf3f8e7-aa87-426d-bea2-a1f18a89be05.jpg\nDeleting working/which_cheese_first/which_cheese/Manchego/f7de39d9-0ff2-4a99-aa92-807b27fa7d90.jpg\nDeleting working/which_cheese_first/which_cheese/Manchego/0352de9a-3f83-4ce7-bfbe-207da04840a3.jpg\nDeleting working/which_cheese_first/which_cheese/Manchego/0592b012-96e5-4f22-ac2e-acc8ab41ecc4.jpg\nDeleting working/which_cheese_first/which_cheese/Fourme d’Ambert/0e36dc86-5e2a-4635-afcc-e3e0ec972aee.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/d827858f-aac0-49f4-b397-facadcfb70fb.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/bed8cf04-9305-4f00-9a8a-1b869e00701c.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/8963c142-9a63-43dc-8268-f54a1b6fbb2b.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/bbf224a3-5033-49c0-8b0c-92068e50382f.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/19d6e4f5-0393-455c-b2d4-7ecccfd93431.jpg\nDeleting working/which_cheese_first/which_cheese/Neufchâtel/6ad1c9d8-1f29-4da8-ae7d-78915460cf35.jpg\nDeleting working/which_cheese_first/which_cheese/Selles-sur-Cher/93d14546-21bf-46e5-89de-e336b474baf3.jpg\nDeleting working/which_cheese_first/which_cheese/Mimolette/17abeba3-b113-4c84-90ed-b17b6152c71d.jpg\nDeleting working/which_cheese_first/which_cheese/Mimolette/72f3db51-da86-4934-bad7-c1b5e54cfb46.jpg\nDeleting working/which_cheese_first/which_cheese/Mimolette/16f74a99-f1ef-46fd-a809-8f332ad235b7.jpg\nDeleting working/which_cheese_first/which_cheese/Époisses de Bourgogne/9484a03b-af27-4155-a950-bc07187f00f0.jpg\nDeleting working/which_cheese_first/which_cheese/Livarot/ffe3e263-a49b-41bc-bdba-4b66cdc12475.jpg\nDeleting working/which_cheese_first/which_cheese/Livarot/57e84bd7-8936-4d55-8ec4-cfcc1073b9a4.jpg\nDeleting working/which_cheese_first/which_cheese/Gruyere/9316e837-a0b2-468a-a287-69ee27b840ba.jpg\nDeleting working/which_cheese_first/which_cheese/Gruyere/dcc3320a-408c-4b93-a1b6-bf2f3f25aa15.jpg\nDeleting working/which_cheese_first/which_cheese/Gruyere/3d5755ba-b8b3-4636-8213-54a3bf19613d.jpg\nDeleting working/which_cheese_first/which_cheese/Comté/5b92cce2-46d4-46f8-9f0f-7952076ded0a.jpg\nDeleting working/which_cheese_first/which_cheese/Reblochon/3ff8d8f8-09c4-4f83-85b8-9c089fcd6805.jpg\nDeleting working/which_cheese_first/which_cheese/Pélardon/a0e86302-8ca3-47ab-ab4c-bdf4834ca208.jpg\nDeleting working/which_cheese_first/which_cheese/Pélardon/6370f787-f13e-4acf-aefb-ad67f68d32c2.jpg\nDeleting working/which_cheese_first/which_cheese/Pont-l’Évêque/4efc1ad3-575d-4a32-9063-e403fd57d7c9.jpg\nDeleting working/which_cheese_first/which_cheese/Tomme de Savoie/5e23fd21-574a-47a0-bc9b-ca52984ae9a5.jpg\nDeleting working/which_cheese_first/which_cheese/Tomme de Savoie/5cf2571c-74f7-4a5b-9374-ef4c480267df.jpg\nDeleting working/which_cheese_first/which_cheese/Valençay/a45d3613-5dbc-45b5-85c0-2ead70ccf221.jpg\n\n\n\n3.1 Model definition\nWe will define a simple model and check if the data is loaded correctly. The most simple model for image classification is resnet18.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\n\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n)\n\n\ndls = cheese.dataloaders(\"working/which_cheese_first\")\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\nFor the metrics, I chose accuracy as this is the most easy to analyze. We later see that the dataset becomes slightly imbalanced in training and F1-score would be better.\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\nWe then do a quick learning pass.\n\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.307302\n2.287525\n0.356164\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.265255\n1.649305\n0.547945\n00:03\n\n\n1\n1.552460\n1.265489\n0.662100\n00:03\n\n\n2\n1.129812\n1.213783\n0.666667\n00:03\n\n\n\n\n\nAs we can see, accuracy increased to 66% after 3 epochs."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#data-cleaning",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#data-cleaning",
    "title": "Which cheese are we eating?",
    "section": "4 Data Cleaning",
    "text": "4 Data Cleaning\nWe can have a look at the confusion matrix. There are some cheeses that are easily confused with each other. For example Bleu d’Auvergne with Fourme d’Ambert. In fact, in cheese stores outside France, few people seem to know the second one. But also the hard cheeses, Cantal, Comte, and Gruyere. The last two are two standard mountain cheeses, one from France and the other from Switzerland. The only differ by their texture. Comte of the same age are a little creamier and have fewer crevices. I especially added the Gruyere to make the dataset harder.\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s have a look at the top losses.\n\ninterp.plot_top_losses(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1 All the same?\nAs expected, similar cheese from the same group is difficult to distinguish.\nLet’s do some data cleaning.\nFor the Comte, Gruyere, Munster: pictures with the highest loss are those with little detail or other accessories like bread or knifes.\n\nfrom fastai.vision.widgets import *\n\n\nfiles_to_clean=[]\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 IMPORTANT: How to use the cleaner\nFor each category and train & valid sets, select the images and then run the following cell. It seems the cleaner doesn’t remember the selections in other categories.\nWe can also not run the above cell multiple times after we cleaned some files, as those will be missing. Instead, we go through all categories and collect files to be deleted.\nWe do not change categories for now.\n\nfor idx in cleaner.delete(): \n    files_to_clean.append(cleaner.fns[idx])\n\n\nfor file in files_to_clean:\n    try:\n        file.unlink()\n    except:\n        pass\n\nAfter a lot of examination I cleaned my dataset from 1100 files to 1029. I have run the following cells to create a copy of the cleaned data. For protection of the data, this cell is commented.\n\n#!mkdir -p working/which_cheese_cleaned\n#!cp -r working/which_cheese_first  working/which_cheese_cleaned"
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#fast-iterations-to-improve-to-analyze-the-data",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#fast-iterations-to-improve-to-analyze-the-data",
    "title": "Which cheese are we eating?",
    "section": "5 Fast iterations to improve to analyze the data",
    "text": "5 Fast iterations to improve to analyze the data\n\n5.1 Working with cleaned data\nNow we have cleaned some data, we can train again, using more advanced techniques.\nWe will start by a simple training again, to see if the cleaning was successful.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\n\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n)\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.137223\n2.343409\n0.326829\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.324481\n1.571146\n0.570732\n00:02\n\n\n1\n1.581721\n1.212596\n0.643902\n00:02\n\n\n2\n1.146727\n1.148679\n0.678049\n00:02\n\n\n\n\n\nWe now roughly archieve 68% accuracy. Let’s train further to see how far when can get.\n\nlearn.fine_tune(13)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.523904\n1.073870\n0.717073\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.314336\n1.042765\n0.721951\n00:02\n\n\n1\n0.260081\n0.991794\n0.741463\n00:02\n\n\n2\n0.203073\n0.943358\n0.741463\n00:02\n\n\n3\n0.158532\n0.913470\n0.756098\n00:02\n\n\n4\n0.141772\n0.872876\n0.751220\n00:02\n\n\n5\n0.121437\n0.816914\n0.751220\n00:02\n\n\n6\n0.101683\n0.836497\n0.765854\n00:02\n\n\n7\n0.085780\n0.845604\n0.751220\n00:02\n\n\n8\n0.071734\n0.842247\n0.760976\n00:02\n\n\n9\n0.062432\n0.823996\n0.765854\n00:02\n\n\n10\n0.053119\n0.811724\n0.760976\n00:02\n\n\n11\n0.044131\n0.817966\n0.760976\n00:02\n\n\n12\n0.038983\n0.820316\n0.760976\n00:02\n\n\n\n\n\nWe seem to have hit a wall at 76% accuracy as early as iteration 6.\n\n5.1.1 A word on the choice of metrics\nEarlier I chose accuracy as the metric. Let’s examine our data to see if the choice is still valid.\n\npd.Series([dls.vocab[o[1]] for o in dls.train_ds]).value_counts()\n\nFourme d’Ambert          48\nChabichou du Poitou      47\nMimolette                44\nPont-l’Évêque            44\nBrie de Meaux            43\nComté                    41\nTomme de Savoie          41\nCantal                   40\nPélardon                 40\nReblochon                39\nValençay                 39\nBleu d’Auvergne          38\nNeufchâtel               37\nLivarot                  36\nSelles-sur-Cher          35\nCamembert                34\nÉpoisses de Bourgogne    33\nManchego                 32\nMunster                  32\nGruyere                  29\nRoquefort                27\nBanon                    24\nName: count, dtype: int64\n\n\nAs I mentioned earlier, the dataset is no longer balanced. However, it is also not imbalanced, as the imbalance is 2:1 and not 1:10, an order of magnitude. We stick with accuracy.\n\n\n\n5.2 Data Augmentation\nWe do not have many images in the data. Therefore, we will use data augmentation and move from squishing to RandomResizedCrop.\n\ncheese_augmented = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(192, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese_augmented.dataloaders(\"working/which_cheese_cleaned\")\n\n\nNote: I choose here to override the variables. A standard programming approach would use new variables. However, the learner reserves memory on the GPU. We will hit an out of memory error. One option is to delete the previous variable and free up the memory. The other option, which I chose here, is to override it with a new learner. This override implicitly deleted the old learner.\n\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy)\n\nWe will pull another trick and use a better learning rate.\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(16, 1.44e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.298504\n2.772096\n0.278049\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.559263\n2.476911\n0.331707\n00:02\n\n\n1\n3.395612\n2.182159\n0.370732\n00:02\n\n\n2\n3.096542\n1.812795\n0.492683\n00:02\n\n\n3\n2.789779\n1.489513\n0.570732\n00:02\n\n\n4\n2.507986\n1.255989\n0.629268\n00:02\n\n\n5\n2.255753\n1.103503\n0.687805\n00:02\n\n\n6\n1.996111\n1.050033\n0.726829\n00:02\n\n\n7\n1.788129\n0.995375\n0.741463\n00:02\n\n\n8\n1.612162\n0.972283\n0.741463\n00:02\n\n\n9\n1.448160\n0.921064\n0.736585\n00:02\n\n\n10\n1.303951\n0.902030\n0.751220\n00:02\n\n\n11\n1.197405\n0.879721\n0.765854\n00:02\n\n\n12\n1.133353\n0.869218\n0.760976\n00:02\n\n\n13\n1.073917\n0.860385\n0.775610\n00:02\n\n\n14\n1.003178\n0.850505\n0.770732\n00:02\n\n\n15\n0.972047\n0.851660\n0.775610\n00:02\n\n\n\n\n\n\nlearn.fine_tune(6, 1.44e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.824386\n0.848143\n0.780488\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.778520\n0.854400\n0.780488\n00:02\n\n\n1\n0.784403\n0.840095\n0.770732\n00:02\n\n\n2\n0.752580\n0.833080\n0.760976\n00:02\n\n\n3\n0.711079\n0.824473\n0.775610\n00:02\n\n\n4\n0.661186\n0.804503\n0.760976\n00:02\n\n\n5\n0.619942\n0.800512\n0.765854\n00:02\n\n\n\n\n\n\nlearn.fine_tune(6, 1.44e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.536938\n0.783610\n0.775610\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.553907\n0.786242\n0.775610\n00:02\n\n\n1\n0.547560\n0.848543\n0.765854\n00:02\n\n\n2\n0.524134\n0.848381\n0.756098\n00:02\n\n\n3\n0.499666\n0.811153\n0.780488\n00:02\n\n\n4\n0.473074\n0.783625\n0.780488\n00:02\n\n\n5\n0.465626\n0.781733\n0.785366\n00:02\n\n\n\n\n\nThe training advanced more slowly. It seems to have hit the same block at 76%, 77%. Only after 12 more iterations, we seem to have converged on a path with over 78%. The Validation loss is only going down after 6 iterations, showing convergence issues of the gradient descent.\nLet’s look at the solution\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe fourme d'ambert uncertainty has almost vanished. The top losses are from images that have slipped my cleaning efforts and are indeeed misleading.\n\n\n5.3 Label smoothing\nAs the data still has a lot of noise, we can try label smoothing. Labelsmoothing assumes a natural uncertainty and no label can have 100%. Instead, Label smoothing redistributes a small portion of the correct class’s probability across all classes to prevent overconfidence and improve generalization.\nWe will start with 28 iterations.\n\nfrom fastai.losses import LabelSmoothingCrossEntropy\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy, loss_func=LabelSmoothingCrossEntropy())\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.00363078061491251)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(28, 3.6e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.273853\n2.742732\n0.307317\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.933313\n2.152079\n0.429268\n00:02\n\n\n1\n2.757924\n1.957854\n0.531707\n00:02\n\n\n2\n2.600373\n1.795183\n0.595122\n00:02\n\n\n3\n2.414058\n1.652869\n0.648780\n00:02\n\n\n4\n2.251830\n1.555603\n0.692683\n00:02\n\n\n5\n2.109990\n1.569267\n0.702439\n00:02\n\n\n6\n1.985083\n1.525316\n0.717073\n00:02\n\n\n7\n1.878232\n1.548784\n0.717073\n00:02\n\n\n8\n1.782599\n1.508083\n0.726829\n00:02\n\n\n9\n1.692580\n1.468358\n0.746341\n00:02\n\n\n10\n1.610464\n1.430262\n0.741463\n00:02\n\n\n11\n1.544696\n1.419962\n0.721951\n00:02\n\n\n12\n1.477807\n1.413017\n0.751220\n00:02\n\n\n13\n1.419630\n1.305687\n0.760976\n00:02\n\n\n14\n1.370959\n1.298595\n0.795122\n00:02\n\n\n15\n1.320189\n1.298479\n0.814634\n00:02\n\n\n16\n1.275702\n1.271670\n0.785366\n00:02\n\n\n17\n1.247922\n1.282414\n0.770732\n00:02\n\n\n18\n1.205016\n1.259176\n0.775610\n00:02\n\n\n19\n1.168169\n1.248492\n0.775610\n00:02\n\n\n20\n1.135880\n1.244297\n0.780488\n00:02\n\n\n21\n1.108426\n1.244742\n0.785366\n00:02\n\n\n22\n1.088607\n1.238094\n0.775610\n00:02\n\n\n23\n1.073189\n1.241032\n0.780488\n00:02\n\n\n24\n1.053456\n1.239150\n0.775610\n00:02\n\n\n25\n1.044365\n1.244962\n0.780488\n00:02\n\n\n26\n1.034709\n1.242740\n0.780488\n00:02\n\n\n27\n1.029999\n1.233360\n0.790244\n00:02\n\n\n\n\n\nStarting at iteration 13, issues emerged with the loss function. We observed an accuracy of approximately 81%. Yet, our accuracy is just 79%, despite the reduced loss\n\n\n5.4 Summary\nData augmentation and Label Smoothing both help with very noisy data and a low amount of samples. We got the accuracy from 76% to 81%."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#bigger-is-better",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#bigger-is-better",
    "title": "Which cheese are we eating?",
    "section": "6 Bigger is better",
    "text": "6 Bigger is better\nSo they say in mechanical engineering.\nLet’s try improvements for size.\n\n6.1 Bigger images\nFirst, we increase the images.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\n\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(256, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\n\n\nlearn_better = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0008317637839354575)\n\n\n\n\n\n\n\n\n\n\n6.1.1 Note: Beware CUDA out of memory\nAs we increase the size of the data and the model we can run of memory. After the crash, the memory stays allocated.\nThe standard approach is to run torch.cuda.empty_cache() and run garbage collection..\nSometimes, the memory still keeps being allocated and i need multiple passes to free up the memory. I wrote a utility function to do just that.\nAs I use an old GPU with only 8GB, I frequently run in the out-of-memory error.\n\ndef free_cuda_memory(var_name, globals_dict, max_attempts=5, delay=0.5):\n    \"\"\"\n    Deletes a variable by name, collects garbage, and repeatedly clears CUDA memory until freed.\n    \n    Args:\n        var_name (str): Name of the variable to delete.\n        globals_dict (dict): Pass `globals()` to delete from the global scope.\n        max_attempts (int): Maximum attempts to clear memory.\n        delay (float): Time (in seconds) to wait between attempts.\n    \"\"\"\n    import torch\n    import gc\n    import time\n    if var_name in globals_dict:\n        del globals_dict[var_name]\n    else:\n        print(f\"Variable '{var_name}' not found in globals.\")\n        return\n\n    for _ in range(max_attempts):\n        gc.collect()\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n        time.sleep(delay)\n\n        # Check if memory is freed\n        allocated = torch.cuda.memory_allocated()\n        cached = torch.cuda.memory_reserved()\n\n        if allocated == 0 and cached == 0:\n            print(\"CUDA memory successfully freed.\")\n            return\n    \n    print(\"Warning: Some CUDA memory may still be blocked.\")\n    print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n    print(f\"Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n\n\nfree_cuda_memory(\"learn_better\",globals())\n\nVariable 'learn_better' not found in globals.\n\n\n\nlearn_better.fine_tune(20, 8.3e-4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.542337\n3.085513\n0.146341\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.000002\n2.851287\n0.180488\n00:03\n\n\n1\n3.854214\n2.640312\n0.214634\n00:03\n\n\n2\n3.678350\n2.329466\n0.321951\n00:03\n\n\n3\n3.460999\n1.959772\n0.409756\n00:03\n\n\n4\n3.187331\n1.625292\n0.536585\n00:03\n\n\n5\n2.932109\n1.408548\n0.604878\n00:03\n\n\n6\n2.674737\n1.244989\n0.668293\n00:03\n\n\n7\n2.424846\n1.146155\n0.663415\n00:03\n\n\n8\n2.201131\n1.025524\n0.707317\n00:03\n\n\n9\n2.034413\n0.931238\n0.726829\n00:03\n\n\n10\n1.865840\n0.851306\n0.756098\n00:03\n\n\n11\n1.716559\n0.824157\n0.741463\n00:03\n\n\n12\n1.578321\n0.804028\n0.770732\n00:03\n\n\n13\n1.461851\n0.793212\n0.775610\n00:03\n\n\n14\n1.359122\n0.781659\n0.795122\n00:03\n\n\n15\n1.279223\n0.774161\n0.795122\n00:03\n\n\n16\n1.229434\n0.775929\n0.795122\n00:03\n\n\n17\n1.166556\n0.768999\n0.795122\n00:03\n\n\n18\n1.123601\n0.767946\n0.800000\n00:03\n\n\n19\n1.104936\n0.771056\n0.790244\n00:03\n\n\n\n\n\n\nlearn_better.export('resnet.pkl')\n\nAlmost 80%. After 20 epochs, the goal seems to have been reached. In another run I had 82%. Despite the lack of consistency, I count this as a record.\n\n\n\n6.2 Bigger Model\nInstead of the images we can increase the model, we will go for resnet34 and resnet50.\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(192, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\n\n\nlearn_better = vision_learner(dls, resnet34, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0020892962347716093)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 2e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.319314\n2.530106\n0.243902\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.351670\n2.044574\n0.380488\n00:03\n\n\n1\n3.058213\n1.685639\n0.507317\n00:03\n\n\n2\n2.746131\n1.313843\n0.639024\n00:03\n\n\n3\n2.436243\n1.013334\n0.731707\n00:03\n\n\n4\n2.142230\n0.840266\n0.775610\n00:03\n\n\n5\n1.898090\n0.805258\n0.770732\n00:03\n\n\n6\n1.671135\n0.764192\n0.800000\n00:03\n\n\n7\n1.478277\n0.738444\n0.809756\n00:03\n\n\n8\n1.305836\n0.683891\n0.785366\n00:03\n\n\n9\n1.142530\n0.632159\n0.790244\n00:03\n\n\n10\n1.006283\n0.622701\n0.814634\n00:03\n\n\n11\n0.882134\n0.641913\n0.790244\n00:03\n\n\n12\n0.775799\n0.630769\n0.780488\n00:03\n\n\n13\n0.712351\n0.629713\n0.790244\n00:03\n\n\n14\n0.638866\n0.643542\n0.790244\n00:03\n\n\n15\n0.576997\n0.637436\n0.790244\n00:03\n\n\n16\n0.545079\n0.637268\n0.804878\n00:03\n\n\n17\n0.505899\n0.642498\n0.804878\n00:03\n\n\n18\n0.472322\n0.642579\n0.800000\n00:03\n\n\n19\n0.449359\n0.632896\n0.804878\n00:03\n\n\n\n\n\n\nlearn_better = vision_learner(dls, resnet50, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.393582\n2.744330\n0.204878\n00:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.321695\n2.486286\n0.287805\n00:06\n\n\n1\n3.125788\n2.221527\n0.356098\n00:06\n\n\n2\n2.849939\n1.930392\n0.439024\n00:06\n\n\n3\n2.639139\n1.629388\n0.502439\n00:06\n\n\n4\n2.387037\n1.396374\n0.600000\n00:06\n\n\n5\n2.145477\n1.242509\n0.648780\n00:06\n\n\n6\n1.933496\n1.132375\n0.687805\n00:06\n\n\n7\n1.738567\n1.025986\n0.717073\n00:06\n\n\n8\n1.557685\n0.977237\n0.756098\n00:06\n\n\n9\n1.412416\n0.930118\n0.765854\n00:06\n\n\n10\n1.275174\n0.908866\n0.756098\n00:06\n\n\n11\n1.159127\n0.913954\n0.765854\n00:06\n\n\n12\n1.066809\n0.898841\n0.775610\n00:06\n\n\n13\n0.990926\n0.876705\n0.780488\n00:06\n\n\n14\n0.921643\n0.868463\n0.785366\n00:06\n\n\n15\n0.874949\n0.841853\n0.780488\n00:06\n\n\n16\n0.826003\n0.845446\n0.765854\n00:06\n\n\n17\n0.782675\n0.861964\n0.765854\n00:06\n\n\n18\n0.737917\n0.838224\n0.770732\n00:06\n\n\n19\n0.717874\n0.844599\n0.765854\n00:06\n\n\n\n\n\nRemarkably the bigger model resnet34 also can achieve 81% and the training is better converging. Conversely, the even larger ResNet50 model yields inferior results. This could be due to the limited amount of data.\nLet’s see how the big model handles big images.\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(256, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\nlearn_better = vision_learner(dls, resnet34, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0006918309954926372)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 6.9e-4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.543718\n3.211622\n0.092683\n00:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.034224\n2.881157\n0.180488\n00:05\n\n\n1\n3.940435\n2.636389\n0.229268\n00:05\n\n\n2\n3.715499\n2.337412\n0.326829\n00:05\n\n\n3\n3.486756\n1.973952\n0.429268\n00:05\n\n\n4\n3.248124\n1.657461\n0.507317\n00:05\n\n\n5\n2.996700\n1.410418\n0.595122\n00:05\n\n\n6\n2.718238\n1.225778\n0.673171\n00:05\n\n\n7\n2.460284\n1.119877\n0.697561\n00:05\n\n\n8\n2.235554\n1.047230\n0.692683\n00:05\n\n\n9\n2.015765\n0.982388\n0.717073\n00:05\n\n\n10\n1.827305\n0.939780\n0.726829\n00:05\n\n\n11\n1.672784\n0.906191\n0.741463\n00:05\n\n\n12\n1.559439\n0.882196\n0.756098\n00:05\n\n\n13\n1.426843\n0.865841\n0.765854\n00:05\n\n\n14\n1.338417\n0.850578\n0.765854\n00:05\n\n\n15\n1.243912\n0.847275\n0.746341\n00:05\n\n\n16\n1.178589\n0.844610\n0.751220\n00:05\n\n\n17\n1.117920\n0.846011\n0.746341\n00:05\n\n\n18\n1.063974\n0.839167\n0.751220\n00:05\n\n\n19\n1.025944\n0.836000\n0.765854\n00:05\n\n\n\n\n\nFirst, it needs to be noted that the learning rate is lower. But also the results are worse than for resnet18.\n\n\n6.3 Even bigger images\nWe will increase the images even further. We resized our images to 400px, so there is no point in going larger than 312px.\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(312, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\nlearn_better = vision_learner(dls, resnet34, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.543712\n3.039113\n0.146341\n00:06\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.761286\n2.706118\n0.234146\n00:07\n\n\n1\n3.621768\n2.441219\n0.297561\n00:07\n\n\n2\n3.425048\n2.090192\n0.409756\n00:08\n\n\n3\n3.118869\n1.713392\n0.507317\n00:07\n\n\n4\n2.836166\n1.382881\n0.585366\n00:07\n\n\n5\n2.560673\n1.180610\n0.629268\n00:07\n\n\n6\n2.283780\n1.015514\n0.697561\n00:07\n\n\n7\n2.033190\n0.904861\n0.736585\n00:07\n\n\n8\n1.819672\n0.865400\n0.731707\n00:07\n\n\n9\n1.640550\n0.837150\n0.736585\n00:07\n\n\n10\n1.489337\n0.794789\n0.765854\n00:07\n\n\n11\n1.336533\n0.753989\n0.770732\n00:07\n\n\n12\n1.211884\n0.724643\n0.775610\n00:07\n\n\n13\n1.124595\n0.710352\n0.790244\n00:07\n\n\n14\n1.030781\n0.710033\n0.785366\n00:07\n\n\n15\n0.960203\n0.696822\n0.790244\n00:07\n\n\n16\n0.899652\n0.694591\n0.795122\n00:07\n\n\n17\n0.841474\n0.690466\n0.809756\n00:07\n\n\n18\n0.791879\n0.689909\n0.795122\n00:07\n\n\n19\n0.763160\n0.689728\n0.800000\n00:07\n\n\n\n\n\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(312, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\nlearn_better = vision_learner(dls, resnet18, metrics=accuracy)\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.559435\n2.919010\n0.170732\n00:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.794993\n2.674616\n0.239024\n00:05\n\n\n1\n3.646426\n2.417594\n0.307317\n00:05\n\n\n2\n3.475905\n2.064787\n0.375610\n00:05\n\n\n3\n3.235945\n1.699186\n0.502439\n00:05\n\n\n4\n2.987770\n1.406921\n0.560976\n00:05\n\n\n5\n2.700939\n1.190468\n0.643902\n00:05\n\n\n6\n2.444276\n1.058556\n0.712195\n00:05\n\n\n7\n2.220634\n0.985898\n0.726829\n00:05\n\n\n8\n2.032653\n0.906098\n0.760976\n00:05\n\n\n9\n1.847860\n0.848331\n0.765854\n00:05\n\n\n10\n1.679043\n0.809622\n0.746341\n00:05\n\n\n11\n1.530006\n0.772010\n0.736585\n00:05\n\n\n12\n1.410453\n0.746380\n0.765854\n00:05\n\n\n13\n1.309522\n0.737125\n0.780488\n00:05\n\n\n14\n1.227750\n0.726092\n0.790244\n00:05\n\n\n15\n1.161594\n0.708379\n0.785366\n00:05\n\n\n16\n1.102717\n0.702760\n0.775610\n00:05\n\n\n17\n1.054643\n0.707285\n0.785366\n00:05\n\n\n18\n1.007804\n0.689951\n0.790244\n00:05\n\n\n19\n0.993321\n0.692554\n0.785366\n00:05\n\n\n\n\n\nInterestingly, the even bigger size brings the bigger model to a slight advantage, but not much.\nIt could be that the bigger model has a better capacity to learn from more data. Whereas the smaller model generalizes better on a smaller dataset.\nResearch has also shown this: https://en.wikipedia.org/wiki/Neural_scaling_law.\nLarger models often perform better with more data because of their capacity to learn complex patterns, while smaller models may generalize better on smaller datasets, reducing overfitting.\n\n\n6.4 Label smoothing\nWe will try the size together with the label smoothing.\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(312, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\")\nlearn_better = vision_learner(dls, resnet18, metrics=accuracy, loss_func=LabelSmoothingCrossEntropy())\n\n\nlearn_better.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\n\nlearn_better.fine_tune(20, 1.4e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.394593\n2.871440\n0.229268\n00:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.653049\n2.588406\n0.317073\n00:05\n\n\n1\n3.530752\n2.326544\n0.365854\n00:05\n\n\n2\n3.368824\n2.011567\n0.502439\n00:05\n\n\n3\n3.158019\n1.743854\n0.590244\n00:05\n\n\n4\n2.937979\n1.583111\n0.668293\n00:05\n\n\n5\n2.703008\n1.478423\n0.707317\n00:05\n\n\n6\n2.499692\n1.461678\n0.785366\n00:05\n\n\n7\n2.328650\n1.402460\n0.770732\n00:05\n\n\n8\n2.176972\n1.380992\n0.760976\n00:05\n\n\n9\n2.045058\n1.355799\n0.751220\n00:05\n\n\n10\n1.940953\n1.329172\n0.780488\n00:05\n\n\n11\n1.850078\n1.313228\n0.809756\n00:05\n\n\n12\n1.770922\n1.311223\n0.809756\n00:05\n\n\n13\n1.706659\n1.292058\n0.819512\n00:05\n\n\n14\n1.641106\n1.296595\n0.800000\n00:05\n\n\n15\n1.590719\n1.295866\n0.814634\n00:05\n\n\n16\n1.561213\n1.287696\n0.800000\n00:05\n\n\n17\n1.523102\n1.286888\n0.809756\n00:05\n\n\n18\n1.498262\n1.279946\n0.809756\n00:05\n\n\n19\n1.474353\n1.274973\n0.814634\n00:05\n\n\n\n\n\nSadly the LabelSmoothing only improved the convergence. The final score is not better than the initial try with bigger images."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#modern-model-architectures",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#modern-model-architectures",
    "title": "Which cheese are we eating?",
    "section": "7 Modern model architectures",
    "text": "7 Modern model architectures\nResnet is quite dated. A newer model, ConvNext is reported to deliver better results.\nWe will start with the base variant of the model. Due to its size, we need to limit the batch size to 16. Currently, I found no other way than trial and error to determine the batch size.\nDuring the discovery of the correct batch size, I multiple times hit the memory ceiling. My free_cuda_memory function came in handy.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\n\n\ncheese = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(256, min_scale=0.3),\n    batch_tfms=aug_transforms(mult=2))\n\ndls = cheese.dataloaders(\"working/which_cheese_cleaned\", bs=16)\nlearn = vision_learner(dls, convnext_base, metrics=accuracy)\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(20, 1.e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.031354\n2.283592\n0.321951\n00:37\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.887947\n2.005787\n0.385366\n01:28\n\n\n1\n2.703871\n1.712844\n0.492683\n01:28\n\n\n2\n2.446322\n1.513336\n0.585366\n01:27\n\n\n3\n2.149493\n1.298572\n0.614634\n01:30\n\n\n4\n1.878358\n0.989779\n0.712195\n01:29\n\n\n5\n1.694279\n0.902841\n0.731707\n01:29\n\n\n6\n1.502565\n0.791859\n0.775610\n01:30\n\n\n7\n1.361015\n0.699819\n0.795122\n01:30\n\n\n8\n1.272284\n0.713360\n0.809756\n01:30\n\n\n9\n1.163435\n0.629532\n0.804878\n01:29\n\n\n10\n1.010350\n0.623500\n0.829268\n01:30\n\n\n11\n0.907372\n0.668074\n0.785366\n01:30\n\n\n12\n0.915707\n0.625355\n0.804878\n01:29\n\n\n13\n0.833985\n0.539842\n0.829268\n01:30\n\n\n14\n0.772828\n0.531026\n0.824390\n01:30\n\n\n15\n0.735248\n0.518410\n0.824390\n01:30\n\n\n16\n0.715735\n0.510863\n0.819512\n01:30\n\n\n17\n0.726851\n0.512946\n0.829268\n01:30\n\n\n18\n0.732415\n0.508770\n0.824390\n01:30\n\n\n19\n0.737635\n0.505515\n0.829268\n01:29\n\n\n\n\n\nThe convnext-base model reached 83% already after 10 iterations. Afterwards, the loss improved, but accuracy did not. However, the model is big with 350mb. We will save it for later.\n\nlearn.export('convnext_base.pkl')\n\n\n7.1 Trying something smaller\nThere is also a convnext-tiny model, which should produce a smaller model file.\n\ndls_better_tiny = cheese.dataloaders(\"working/which_cheese_cleaned\", bs=32)\nlearn = vision_learner(dls_better_tiny, convnext_tiny, metrics=accuracy)\n\n\ndls_better_tiny.bs\n\n64\n\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(20,1.44e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n4.244600\n2.932380\n0.165854\n00:15\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.287429\n2.501591\n0.287805\n00:53\n\n\n1\n3.098157\n2.106716\n0.395122\n00:53\n\n\n2\n2.910831\n1.777798\n0.512195\n00:53\n\n\n3\n2.688967\n1.506041\n0.590244\n00:53\n\n\n4\n2.420423\n1.393299\n0.653659\n00:53\n\n\n5\n2.151483\n1.200701\n0.653659\n00:53\n\n\n6\n1.887403\n1.033586\n0.697561\n00:52\n\n\n7\n1.715113\n0.973459\n0.702439\n00:53\n\n\n8\n1.539306\n0.942053\n0.702439\n00:54\n\n\n9\n1.360577\n0.849999\n0.697561\n00:53\n\n\n10\n1.227610\n0.811377\n0.746341\n00:54\n\n\n11\n1.121673\n0.766563\n0.760976\n00:53\n\n\n12\n1.017336\n0.724510\n0.785366\n00:52\n\n\n13\n0.960135\n0.694766\n0.790244\n00:52\n\n\n14\n0.924193\n0.685870\n0.790244\n00:52\n\n\n15\n0.853204\n0.688712\n0.785366\n00:53\n\n\n16\n0.816196\n0.688337\n0.795122\n00:53\n\n\n17\n0.769849\n0.678705\n0.790244\n00:53\n\n\n18\n0.743718\n0.687633\n0.804878\n00:52\n\n\n19\n0.744009\n0.674999\n0.809756\n00:52\n\n\n\n\n\n\nlearn.export(\"tiny.pkl\")\n\nThe tiny model is not as good as the base model. However, the exported model is only 114MB. Still compared to good old resnet (47MB), that is more than twice the size."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#inference-and-getting-ready-for-deployment",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#inference-and-getting-ready-for-deployment",
    "title": "Which cheese are we eating?",
    "section": "8 Inference and getting ready for deployment",
    "text": "8 Inference and getting ready for deployment\nLet’s check if our models work in inferences.\nWe only test one image and do a visual inspection of the results. As already mentioned before, I did not provide a test set.\nThis is the biggest open TODO.\nAnother important aspect would be how certain the prediction is. How high is the probability for the second candidate? Many improvements are possible in problem definition and post-processing.\n\n8.1 Comparison of three models\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\n\n\nfrom fastai.learner import load_learner\n\n# Load the FastAI Learner\nlearn_inf_tiny = load_learner(\"models/tiny.pkl\")\nlearn_inf_base= load_learner(\"models/base.pkl\")\nlearn_inf_resnet = load_learner(\"models/resnet.pkl\")\n\n\nlearn_inf_tiny.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")\n\n\n\n\n\n\n\n\n('Cantal',\n tensor(4),\n tensor([9.7780e-05, 9.0306e-06, 2.1395e-05, 1.0606e-05, 9.9840e-01, 1.2682e-07,\n         4.7644e-04, 1.4753e-06, 9.9773e-06, 4.0509e-06, 2.3105e-05, 8.3267e-05,\n         8.9159e-05, 2.2647e-06, 3.8224e-06, 4.5492e-07, 2.8718e-04, 2.2553e-06,\n         7.6010e-07, 3.5029e-04, 2.3085e-07, 1.2567e-04]))\n\n\n\nlearn_inf_base.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")\n\n\n\n\n\n\n\n\n('Cantal',\n tensor(4),\n tensor([1.5877e-06, 5.6175e-05, 1.3185e-06, 4.0135e-06, 9.9739e-01, 1.9972e-06,\n         1.6469e-03, 1.1616e-05, 1.5650e-04, 2.0251e-05, 1.6810e-05, 3.3364e-04,\n         1.2042e-05, 1.8571e-06, 7.5011e-06, 5.5109e-07, 1.8472e-04, 2.0955e-06,\n         1.5077e-05, 8.5131e-05, 1.5477e-07, 4.9878e-05]))\n\n\n\nlearn_inf_resnet.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")\n\n\n\n\n\n\n\n\n('Cantal',\n tensor(4),\n tensor([1.2273e-06, 1.0518e-04, 2.1162e-05, 9.5564e-07, 9.9687e-01, 5.3281e-06,\n         2.2306e-03, 5.5073e-08, 9.4349e-05, 1.3493e-06, 2.2718e-04, 2.3397e-04,\n         8.0347e-06, 5.4313e-06, 4.4896e-06, 8.3956e-07, 3.2568e-05, 1.5521e-05,\n         2.5339e-06, 1.2194e-04, 1.5376e-05, 4.0610e-07]))\n\n\n\n\n8.2 Comparison of ONNX and Pytorch\nWe’ll require an onnx model at a later time. Let’s evaluate the resnet model’s prediction accuracy.\n\n!pip install onnx\n\n\nimport torch\n\n\nmodel = learn_inf_resnet.model\ndummy_input = torch.randn(1, 3, 256, 256)  # Use batch size 1 for export\ntorch.onnx.export(\n    model, \n    dummy_input, \n    \"model.onnx\", \n    export_params=True, \n    opset_version=11, \n    do_constant_folding=True, \n    input_names=[\"input\"], \n    output_names=[\"output\"], \n    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}  # Allow variable batch size\n)\n\n\n!pip install onnxruntime numpy pillow torchvision\n\n\nclass_names = learn_inf_resnet.dls.vocab\nprint(class_names)  # List of class names\n\n['Banon', 'Bleu d’Auvergne', 'Brie de Meaux', 'Camembert', 'Cantal', 'Chabichou du Poitou', 'Comté', 'Fourme d’Ambert', 'Gruyere', 'Livarot', 'Manchego', 'Mimolette', 'Munster', 'Neufchâtel', 'Pont-l’Évêque', 'Pélardon', 'Reblochon', 'Roquefort', 'Selles-sur-Cher', 'Tomme de Savoie', 'Valençay', 'Époisses de Bourgogne']\n\n\n\nimport onnxruntime as ort\nimport numpy as np\nfrom PIL import Image\nimport torchvision.transforms as transforms\n# Load ONNX model\nsession = ort.InferenceSession(\"model.onnx\", providers=[\"CPUExecutionProvider\"])\n\n# Preprocessing function\ndef preprocess_image(image_path):\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).numpy().astype(np.float32)  # Add batch dim and convert to NumPy\n    return image\n\n# Load and preprocess image\nimage_path = \"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\"  # Replace with your image path\ninput_tensor = preprocess_image(image_path)\n\n# Run inference\noutputs = session.run(None, {\"input\": input_tensor})\n\n\nimport torch\noutputs = session.run(None, {\"input\": input_tensor})[0]  # Raw logits\nprobabilities = torch.nn.functional.softmax(torch.tensor(outputs), dim=1)  # Convert to probabilities\npredicted_class = torch.argmax(probabilities, dim=1).item()\n# Get predicted class index and label\npredicted_idx = np.argmax(probabilities)\npredicted_label = class_names[predicted_idx]\n\nprint(f\"Predicted Class: {predicted_label} (Confidence: {probabilities[0][predicted_idx]:.6f})\")\n\n\nPredicted Class: Cantal (Confidence: 0.971699)\n\n\nThe prediction is correct, but the confidence is slightly different. We will try it anyway in deployment."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#deployment-delivering-an-experience",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#deployment-delivering-an-experience",
    "title": "Which cheese are we eating?",
    "section": "9 Deployment: Delivering an experience",
    "text": "9 Deployment: Delivering an experience\nOf course we want to share our model and not only by posting the source code on GitHub or hugging face. What we want is a live version of the model. Something users can experience.\nYou can deploy via cloud computing or on-device/edge computing. The used technologies are different.\n\n9.1 Cloud based deployment\nYou cannot evaluate PyTorch ML models using simple JavaScript. A server runs a python backend, which provides an endpoint that is only doing the code of the previous section.\nHere is a good tutorial how to get a simple setup running on hugging face with gradio.\nI developed a webcam based app; the code is in the repo. And the app is live.\nIn the app you can select the convnext-base, convnext-tiny and the resnet model. All models are trained with 256px images. Just point the camera towards a cheese.\nI used the Gradio framework, popular in ML and featured on Hugging Face. The processing takes several milliseconds, despite being server based. The Gradio app offers no frame dropping. I try to include dynamic throttling to avoid frame congestion.\nOne thing I observed from this app is that the Convnext models have high numbers for the second and third best candidate. The app tries to predict a cheese when there is no cheese present. Two points worth to examine.\n\n\n9.2 Edge based deployment\nThe issue with edge-based deployment is python. Python is by default not available on mobile. And because of secure concerns, it is becoming more and more complex to run a full blown linux with a python installation.\nThe other two ways are mobile apps and browser-based inference. We limit ourselves to browser based, because this is accessible via desktop and mobile.\nONNX format is necessary for web browser model deployment. At the end of this, we will evaluate if inferring onnx gives us the same probability. Due to differences in preprocessing between fast.ai and manual methods, some variations may occur.\nUsing my knowledge of web development, I constructed a basic app that does inferring the resnet model.\nMy impressions were that the results were less good. But, the startup and inference time were acceptable and comparable to the python app. This is a point worth to examine once I have defined a proper test set."
  },
  {
    "objectID": "posts/projects/cheese_classifier/meet-the-cheese.html#the-end",
    "href": "posts/projects/cheese_classifier/meet-the-cheese.html#the-end",
    "title": "Which cheese are we eating?",
    "section": "10 The End",
    "text": "10 The End\nThis was my first basic study in low level ML. I dabbled in pose recognition before and did work manage AI projects. I’m very impressed with the progress these tools have made.\nIf you have enjoyed the read, come back for the next project. We will revisit a recipe classification app, which I programmed in 2021 and which we will improve with AI.\n\n10.1 Links\nGithub Repo\nJavascript App\nGradio App"
  },
  {
    "objectID": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html",
    "href": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html",
    "title": "Knowledge advice: 2 Ways to read a book and improve your understanding",
    "section": "",
    "text": "Do you read? Yes? Then this post is for you.\nIf not, consider why to read.\nAs you may know, there are different purposes for reading: for pleasure or information. When you pick up a book for information, your intention dictates how to approach the book: do you do investigative reading and exploratory reading?"
  },
  {
    "objectID": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#exploring-the-unknown",
    "href": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#exploring-the-unknown",
    "title": "Knowledge advice: 2 Ways to read a book and improve your understanding",
    "section": "Exploring the unknown",
    "text": "Exploring the unknown\nIf we do not know what to search for, exploratory reading is the way. Assume you are new to a field. Overviews on the topic are rare to find. To reduce the so-called unknown unknowns to the known unknowns, we have to create a knowledge map.\nIf you want to be fast, you can skim the book. Sometimes scanning is not enough, and it is better to read quickly over parts of a book. After we finish the explorative task, we do not know the answers. Still, we have an idea of the responses we will find most likely find."
  },
  {
    "objectID": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#investigating-the-known",
    "href": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#investigating-the-known",
    "title": "Knowledge advice: 2 Ways to read a book and improve your understanding",
    "section": "Investigating the known",
    "text": "Investigating the known\nOnce we know what to search for, the task becomes more apparent, while not necessarily easier. We read investigative. Assume you have a particular question or are only interested in a specific topic. This question can come from your knowledge map or anywhere else.\nNowadays, access to information is easy. Our brain is easily overwhelmed by too much information. It is necessary to filter the important from the less important. We need to separate the wheat from the chaff. While a book may be helpful, maybe not all the book’s insights are valuable.\nKnowing how to google is most often a quicker solution to many problems. Google acts as a natural filter for information. (And with this, I do not mean the advertisement-based filter bubble).\nWhat if google does not know the answer? Assume the question is quite creative and the topic quite particular. You are on your own, and you have to deal with the raw material yourself."
  },
  {
    "objectID": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#approaching-a-book-with-a-question",
    "href": "posts/knowledge-advice-ways-to-read-a-book-and-improve-your-understanding.html#approaching-a-book-with-a-question",
    "title": "Knowledge advice: 2 Ways to read a book and improve your understanding",
    "section": "Approaching a book with a question",
    "text": "Approaching a book with a question\nThe most important part is to have a question.\nIn many sciences, work usually starts with a hypothesis. The aim is to prove or falsify this hypothesis.\nWe do not need to go so far as to create a hypothesis, but we can think of questions we believe the book can answer for us.\n\nExample: Influence by Robert Cialdini\nAn example is in order here.\nI recently read Influence by R. Cialdini. Summaries of the book are available in many places).\nAs detailed in How to read a book, an informative book should lead to possible actions. For the book influence, there are two main activities possible: we can defend ourselves against psychological triggers, or we learn how to exploit these triggers.\nThe primary question is:\nHow to defend against triggers?\nThe best self-defense is the offense. However, Cialdini blames the exploitation of these principles for hindering their beneficial use as social shortcuts.\nThis accusation raises the question:\nWhy apply the principles of psychological influence in your communication?\nand related to this one:\nHow to use them?\nNow we have generated some initial questions.\nThe answers: go back to the book or the summary of the book with the questions. Try to find more specific questions."
  },
  {
    "objectID": "posts/clean-architecture/clean-coders-use-lambda-expressions.html",
    "href": "posts/clean-architecture/clean-coders-use-lambda-expressions.html",
    "title": "Clean coders use lambda expressions",
    "section": "",
    "text": "Lambda expressions are small, anonymous functions designed for short-lived tasks with limited scope. Unlike named functions, they do not require a definition at module level. Instead they exist within a function. This makes them ideal for any operation where defining a full-fledged function would be overkill."
  },
  {
    "objectID": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#what-are-lambda-expressions",
    "href": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#what-are-lambda-expressions",
    "title": "Clean coders use lambda expressions",
    "section": "",
    "text": "Lambda expressions are small, anonymous functions designed for short-lived tasks with limited scope. Unlike named functions, they do not require a definition at module level. Instead they exist within a function. This makes them ideal for any operation where defining a full-fledged function would be overkill."
  },
  {
    "objectID": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#immutability-as-goal",
    "href": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#immutability-as-goal",
    "title": "Clean coders use lambda expressions",
    "section": "Immutability as goal",
    "text": "Immutability as goal\nLambda expressions originated from lambda calculus, a mathematical framework for describing functions. Functional programming languages like Lisp first adopted the concept, and it eventually trickled down to more general-purpose languages.\nBut why were lambdas introduced into Python and C++? The goal was to enable functional programming paradigms, like mapping, filtering, and reducing data.\n\n\n\n\n\n\nNote\n\n\n\nThe benefit of functional programming is that it renders a function immutable.\n\n\nThis has enormous benefits for complex logic and especially for multithreaded applications. By making a function immutable, race conditions and deadlocks can not origin from this function. By limiting the mutuabitliy of code to certain blocks, multithreading errors are easier to find."
  },
  {
    "objectID": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#syntax-and-usage",
    "href": "posts/clean-architecture/clean-coders-use-lambda-expressions.html#syntax-and-usage",
    "title": "Clean coders use lambda expressions",
    "section": "Syntax and Usage",
    "text": "Syntax and Usage\n\nHow Do Lambda Expressions Work?\nThe syntax differs between Python and C++:\n\nPython: lambda arguments: expression\nExample: lambda x: x * 2 creates a function that doubles the input.\nC++: [capture](arguments) { body }\nExample: [&](int x) { return x * 2; } defines a lambda that doubles x while capturing variables by reference.\n\n\n\nWhen Should You Use Them?\n\nPython:\n\nSorting: sorted(data, key=lambda x: x.value)\nFiltering: filter(lambda x: x &gt; 10, numbers)\nFunctional constructs: map, reduce\nOne-liners: Embedding logic where defining a named function is unnecessary.\n\n\nC++:\n\nSTL algorithms: std::sort, std::for_each, std::transform\nReplacing verbose function objects\nWhen relying heavily on functional programming."
  },
  {
    "objectID": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html",
    "href": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html",
    "title": "Successful teams strike the right Balance between Immediate Needs with Long-Term Architecture",
    "section": "",
    "text": "Which side of the product are you on?"
  },
  {
    "objectID": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#a-tug-of-war-product-vs.-architecture",
    "href": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#a-tug-of-war-product-vs.-architecture",
    "title": "Successful teams strike the right Balance between Immediate Needs with Long-Term Architecture",
    "section": "1 A Tug of War: Product vs. Architecture",
    "text": "1 A Tug of War: Product vs. Architecture\nImagine a software architect and a project manager locked in a metaphorical tug-of-war. In the middle hangs the product, caught between the architect’s vision for a scalable future and the project manager’s commitment to immediate delivery. The struggle is not just symbolic; it mirrors the reality in many software teams."
  },
  {
    "objectID": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#the-senior-stakeholder-perspective",
    "href": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#the-senior-stakeholder-perspective",
    "title": "Successful teams strike the right Balance between Immediate Needs with Long-Term Architecture",
    "section": "2 The Senior Stakeholder Perspective",
    "text": "2 The Senior Stakeholder Perspective\nSenior stakeholders often emphasize the immediate need for a working product, reinforcing the mantra: “The most important thing is that it works.” This perspective prioritizes current functionality over future flexibility, reflecting a common bias toward short-term gains. This principle encapsulates the philosophy that “current functionality trumps architectural foresight.”\n\n2.1 The Eisenhower Matrix and the HIPPO Effect\n+-------------------------------+----------------------------------+\n| 1. IMPORTANT / URGENT     ↑   | 2. IMPORTANT / NOT URGENT        |\n|                 Hippo-Effect  |                                  |\n+---------------------------|---+----------------------------------+\n| 3. UNIMPORTANT / URGENT   |   | 4. NOT IMPORTANT / NOT URGENT    |\n|                           ↑   |                                  |\n+-------------------------------+----------------------------------+\nUrgency bias often causes us to prioritize urgent but unimportant tasks (Quadrant 3 in the Eisenhower Matrix), elevating them to the status of urgent and important tasks (Quadrant 1). This shift is frequently driven by the HIPPO (Highest Paid Person’s Opinion), individuals who may lack the expertise to make architectural decisions yet dominate because of their hierarchical position.\n\n\n2.2 The Corporate Dilemma\nIn traditional companies, the appetite for this necessary struggle is often lacking. While escalation to open conflict is undesirable, friction between stakeholders and opposing priorities is crucial. When this healthy tension is missing, the architecture gets deprioritized. The system in return becomes more expensive to develop and maintain."
  },
  {
    "objectID": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#a-call-to-action",
    "href": "posts/clean-architecture/successful-teams-strike-the-right-balance-between-immediate-needs-with-longterm-architecture.html#a-call-to-action",
    "title": "Successful teams strike the right Balance between Immediate Needs with Long-Term Architecture",
    "section": "3 A Call to Action",
    "text": "3 A Call to Action\nOrganizations must recognize the value of this struggle. Software teams can strike a balance by fostering informed debates and ensuring that architectural concerns receive the same attention as immediate needs. Failure to do so risks escalating technical debt and jeopardizing the long-term viability of their systems.\nIn conclusion, while satisfying immediate business demands is critical, sustainable growth demands that architecture takes its rightful place—not as an afterthought, but as a cornerstone of development."
  },
  {
    "objectID": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html",
    "href": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html",
    "title": "Premature optimization and the importance of algorithms",
    "section": "",
    "text": "Premature Optimization"
  },
  {
    "objectID": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html#static-polymorphism-is-fast-but-complex",
    "href": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html#static-polymorphism-is-fast-but-complex",
    "title": "Premature optimization and the importance of algorithms",
    "section": "Static polymorphism is fast, but complex",
    "text": "Static polymorphism is fast, but complex\nI once had a colleague who was a C++ genius. For him, every function had to be templated. However, in my experience, the excessive template boilerplate made the code harder to read.\nWhile templates offer a great way to make code modular and enable static polymorphism for potential performance gains, they also add complexity and reduce readability. Striking a balance is key."
  },
  {
    "objectID": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html#the-importance-of-algorithms",
    "href": "posts/clean-architecture/premature-optimization-and-the-importance-of-algorithms.html#the-importance-of-algorithms",
    "title": "Premature optimization and the importance of algorithms",
    "section": "The importance of Algorithms",
    "text": "The importance of Algorithms\nAt the lower level, less experienced developers often implemented slow algorithms. This felt more like premature optimization, with senior developers focusing on obscure details instead of improving the overall system.\nProponents of this approach often argue, “We need flexibility and performance.” Unfortunately, if your senior devs insist on this direction, there’s little that can be done without triggering lengthy debates and widespread frustration.\nA quick search revealed the following:\nIn performance-critical applications, optimizing data structures and algorithms yields far greater benefits than micro-optimizations like avoiding virtual function calls.\n\nRight Data Structures: Use hash tables, binary trees, heaps depending to minimize access time and memory overhead.\nAlgorithm Efficiency: Reducing O(n^2) to O(nlogn) saves millions of operations, far outweighing nanoseconds gained from avoiding virtual calls.\nProfile First: Use profiling tools to identify real bottlenecks; focus on hotspots that impact runtime significantly.\nWhen to Optimize Virtual Calls: Only for tight loops, where every cycle matters.\n\n\n\n\n\n\n\nNoteWhat is a Tight Loop?\n\n\n\nA “tight loop” refers to:\n\nA loop that runs a large number of iterations (e.g., millions to billions).\nContains minimal work per iteration (e.g., function calls, basic arithmetic).\nBecomes a performance bottleneck due to repetitive operations."
  },
  {
    "objectID": "posts/technical/be-careful-using-pythons-dataclass.html",
    "href": "posts/technical/be-careful-using-pythons-dataclass.html",
    "title": "Be careful using python’s dataclass",
    "section": "",
    "text": "## 1 What’s the Problem with Mutable Defaults?\nWhen using @dataclass, attributes defined with default values can behave unexpectedly if the default value is a mutable object. In Python, mutable objects (e.g., lists, dictionaries, NumPy arrays) are shared across all instances if defined at the class level. This can lead to unintentional coupling between instances."
  },
  {
    "objectID": "posts/technical/be-careful-using-pythons-dataclass.html#why-this-happens-the-core-of-mutable-defaults",
    "href": "posts/technical/be-careful-using-pythons-dataclass.html#why-this-happens-the-core-of-mutable-defaults",
    "title": "Be careful using python’s dataclass",
    "section": "2 Why This Happens: The Core of Mutable Defaults",
    "text": "2 Why This Happens: The Core of Mutable Defaults\nIn Python:\n\nImmutable types (e.g., integers, floats, strings) are passed by value.\nMutable types (e.g., lists, dictionaries, NumPy arrays) are passed by reference.\n\nWhen you define a default value like np.zeros(4), it becomes a class attribute, shared among all instances of the class. Any modification affects every instance referencing the same object.\nIn our example, both model1.stress_strain.eps_total and model2.stress_strain.eps_total point to the same NumPy array.\n\n2.1 Fixing the Mutable Default Issue\nThe solution is to ensure that each instance gets its own copy of the mutable object. In @dataclass, this can be achieved using field(default_factory=...) for mutable defaults.\nHere’s the corrected version:\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass CStressStrainData:\n    stress: np.ndarray = field(default_factory=lambda: np.zeros(4))\n    eps_total: np.ndarray = field(default_factory=lambda: np.zeros(4))\n    energy: float = 0\n\n\n2.2 Why Does This Work?\n\nThe expression field(default_factory=...) ensures that a new object is created for each instance during initialization.\nThe lambda function (lambda: np.zeros(4)) ensures that the factory function is called each time, creating an independent NumPy array.\n\nNow, the behavior is as expected:\nmodel1 = MaterialModel()\nmodel2 = MaterialModel()\n\nmodel1.stress_strain.eps_total += np.array([1, 0, 0, 0])\nprint(model2.stress_strain.eps_total)  # Output: [0. 0. 0. 0.]\nEach instance of CStressStrainData now has its own independent eps_total."
  },
  {
    "objectID": "posts/technical/be-careful-using-pythons-dataclass.html#when-to-use-dataclass-and-mutable-defaults",
    "href": "posts/technical/be-careful-using-pythons-dataclass.html#when-to-use-dataclass-and-mutable-defaults",
    "title": "Be careful using python’s dataclass",
    "section": "3 When to Use @dataclass and Mutable Defaults",
    "text": "3 When to Use @dataclass and Mutable Defaults\n\n3.1 Pros of @dataclass:\n\nReduces boilerplate code by generating __init__, __repr__, and other methods.\nWorks well for simple data containers with default values.\n\n\n\n3.2 Cons of @dataclass with Mutable Defaults:\n\nRequires careful handling of mutable types to avoid shared state issues.\nCan become awkward for complex initialization logic.\n\n\n\n3.3 General Rules:\n\nUse field(default_factory=...) for mutable defaults.\nAvoid defining mutable objects directly as default values.\n\n\n\n3.4 For complex classes switch back to traditional classses\nIf the class has complex initialization or significant behavior, a traditional class definition might be more appropriate:\nclass CStressStrainData:\n    def __init__(self):\n        self.stress = np.zeros(4)\n        self.eps_total = np.zeros(4)\n        self.energy = 0\nThis approach avoids the pitfalls of shared mutable defaults and offers greater flexibility."
  },
  {
    "objectID": "posts/technical/be-careful-using-pythons-dataclass.html#key-takeaways",
    "href": "posts/technical/be-careful-using-pythons-dataclass.html#key-takeaways",
    "title": "Be careful using python’s dataclass",
    "section": "4 Key Takeaways",
    "text": "4 Key Takeaways\n\nUnderstand mutable defaults:\n\nAvoid using mutable objects like lists or NumPy arrays as direct default values.\n\nUse field(default_factory=...):\n\nIt’s the correct way to define mutable defaults in @dataclass.\n\nTest for shared references:\n\nUse id() or inspect behavior to confirm objects are independent.\n\nKnow when to skip @dataclass:\n\nIf initialization or behavior is complex, a regular class might be a better choice.\n\n\nBy following these best practices, you can leverage the power of @dataclass without falling into the mutable defaults trap."
  },
  {
    "objectID": "posts/technical/be-careful-using-pythons-dataclass.html#conclusion",
    "href": "posts/technical/be-careful-using-pythons-dataclass.html#conclusion",
    "title": "Be careful using python’s dataclass",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nMutable defaults can be a subtle but impactful bug in Python. Using @dataclass is a great way to simplify your code, but you must handle mutable objects carefully. With field(default_factory=...) and proper design, you can avoid unexpected behavior and keep your code clean and robust."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "",
    "text": "When evaluating machine learning models, accuracy is often the first metric that comes to mind. However, accuracy alone can be misleading, especially in cases where the dataset is imbalanced or when different types of misclassifications have different consequences. Choosing the right evaluation metric is crucial for ensuring that the model performs well in real-world applications."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#accuracy-is-best-for-balanced-datasets",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#accuracy-is-best-for-balanced-datasets",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "1 Accuracy is best for balanced datasets",
    "text": "1 Accuracy is best for balanced datasets\nAccuracy measures the percentage of correctly classified instances in a dataset. It is calculated as:\n\\[Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\]\nWhere:\n\nTP (True Positives) = Correctly predicted positives\nTN (True Negatives) = Correctly predicted negatives\nFP (False Positives) = Incorrectly predicted positives\nFN (False Negatives) = Incorrectly predicted negatives\n\nFor a more detailed definition see, Precision, Recall, and the Confusion Matrix.\nAccuracy works well when the dataset is balanced and the cost of false positives and false negatives is roughly the same.\nExample:\nIn image classification, where we classify objects like “dog vs. cat” with roughly equal numbers of each class, accuracy is a reliable metric.\nCounter-Example:\nImagine a fraud detection system where only 1% of transactions are fraudulent. A naive model that predicts “non-fraud” for every transaction would be 99% accurate but completely useless in identifying fraud."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#precision-when-false-positives-are-costly",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#precision-when-false-positives-are-costly",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "2 Precision, when false positives are costly",
    "text": "2 Precision, when false positives are costly\nPrecision measures how many of the positive predictions are actually correct:\n\\[Precision = \\frac{TP}{TP + FP}\\]\nA high precision means fewer false positives, which is important when a false positive carries significant consequences.\nExample:\n\nSpam email filtering → Marking an important email as spam (false positive) can cause users to miss critical messages.\nHiring decisions → Selecting the wrong candidate (false positive) could be costly for a company.\n\nCounter-Example:\nIf false negatives (missed positive cases) are more harmful, recall is the better metric."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#recall-when-false-negatives-are-costly",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#recall-when-false-negatives-are-costly",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "3 Recall, when false negatives are costly",
    "text": "3 Recall, when false negatives are costly\nRecall (also called sensitivity or true positive rate) measures how many actual positives are correctly identified:\n\\[Recall = \\frac{TP}{TP + FN}\\]\nA high recall means the model captures most actual positive cases, even if it produces some false positives.\nExample:\n\nCancer detection → A false negative (failing to detect cancer) is much worse than a false positive (a healthy person being sent for more tests).\nFraud detection → Missing a fraudulent transaction is riskier than investigating a few false alarms.\n\nCounter-Example:\nIf false positives are expensive or disruptive, precision is the better metric."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#f1-score-when-you-need-a-balance",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#f1-score-when-you-need-a-balance",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "4 F1-Score, when you need a balance",
    "text": "4 F1-Score, when you need a balance\nF1-score is the harmonic mean of precision and recall:\n\\[F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\]\nF1-score is particularly useful in cases where the dataset is imbalanced, and both false positives and false negatives matter.\nExample:\n\nFake news detection → You need to both catch fake news (recall) and avoid falsely labeling real news as fake (precision).\nMedical diagnostics → It’s important to minimize both missed diagnoses (FN) and false alarms (FP).\n\nCounter-Example:\nIf the dataset is balanced and errors are equally costly, accuracy is often sufficient."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#auc-roc-when-you-need-to-rank-predictions",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#auc-roc-when-you-need-to-rank-predictions",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "5 AUC-ROC, when you need to rank predictions",
    "text": "5 AUC-ROC, when you need to rank predictions\nAUC-ROC (Area Under the Receiver Operating Characteristic Curve) measures a model’s ability to distinguish between classes at different thresholds.\nThe ROC curve plots:\n\nTrue Positive Rate (Recall) vs. False Positive Rate\nAUC (Area Under Curve) closer to 1 means better classification performance.\n\nExample:\n\nCredit risk assessment → Banks rank loan applicants from “low risk” to “high risk” rather than making a strict yes/no decision.\nMedical triage systems → Doctors prioritize high-risk patients based on a ranking rather than a strict diagnosis.\n\nCounter-Example:\nAUC-ROC is great for ranking, but for specific misclassification penalties, precision, recall, or F1-score might be better."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#decision-graph",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#decision-graph",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "6 Decision Graph",
    "text": "6 Decision Graph\nI came up with a simple decision graph\n\n\n\n\n\nflowchart TD\n\nA[Start] --&gt; B{Dataset balanced?}\n\nB -- Yes --&gt; C[Use Accuracy]\n\nB -- No --&gt; D{What matters more?}\n\nD -- Balance FP & FN --&gt; E[F1-score]\n\nD -- Avoid False Positives --&gt; F[Precision]\n\nD -- Avoid False Negatives --&gt; G[Recall]\n\nC --&gt; H{Need ranking?}\n\nE --&gt; H\n\nF --&gt; H\n\nG --&gt; H\n\nH -- Yes --&gt; I[AUC-ROC]\n\nH -- No --&gt; J[Done]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenario\nBest Metric\nWhy?\n\n\n\n\nBalanced dataset\nAccuracy\nErrors are equally important.\n\n\nImbalanced dataset\nF1-score\nBalances false positives & false negatives.\n\n\nFalse positives are costly\nPrecision\nAvoids unnecessary alarms.\n\n\nFalse negatives are costly\nRecall\nEnsures we catch as many positives as possible.\n\n\nNeed ranking, not classification\nAUC-ROC\nMeasures how well the model separates classes."
  },
  {
    "objectID": "posts/technical/choosing-the-right-metric-for-classification-models.html#final-thoughts",
    "href": "posts/technical/choosing-the-right-metric-for-classification-models.html#final-thoughts",
    "title": "Choosing the Right Metric for Classification Models",
    "section": "7 Final Thoughts",
    "text": "7 Final Thoughts\nChoosing the right metric is critical to building a model that truly performs well in its intended application. Instead of blindly relying on accuracy, always consider:\n\nIs the dataset balanced or imbalanced?\nIs it worse to have a false positive or a false negative?\nAre you making a hard classification or ranking predictions?\n\nBy aligning the evaluation metric with your real-world goals, you’ll ensure that your model delivers meaningful and impactful results."
  },
  {
    "objectID": "posts/technical/avoiding-python-version-chaos-in-ml.html",
    "href": "posts/technical/avoiding-python-version-chaos-in-ml.html",
    "title": "Avoiding Python version chaos in ML",
    "section": "",
    "text": "When I started with my first machine learning (ML) project in 2020 it naively tried to install cuda on my pc. It took me a day. There were multiple incompatible libraries and difficult to install packages.\nEven recently, another issue arose, when switching between projects quickly. A bare-metal installation is not practical in this setup. It gets messy fast — especially when one project needs Python 3.10 with TensorFlow 2.15 + GPU, and another wants 3.12 with different dependencies.\nThankfully, Docker solves all of that.\n\n\nDocker lets you isolate your dev environment per project, without affecting your system Python. This also can be done via a virtual environment. However, once you need another base python version, you still need to change your system.\nThat means you can use any Python version inside the container, e.g., Python 3.10 even if your host has 3.12.\nYou can install TensorFlow, PyTorch as well as CUDA with NVIDIA containers without polluting your system."
  },
  {
    "objectID": "posts/technical/avoiding-python-version-chaos-in-ml.html#frequently-changing-projects",
    "href": "posts/technical/avoiding-python-version-chaos-in-ml.html#frequently-changing-projects",
    "title": "Avoiding Python version chaos in ML",
    "section": "",
    "text": "When I started with my first machine learning (ML) project in 2020 it naively tried to install cuda on my pc. It took me a day. There were multiple incompatible libraries and difficult to install packages.\nEven recently, another issue arose, when switching between projects quickly. A bare-metal installation is not practical in this setup. It gets messy fast — especially when one project needs Python 3.10 with TensorFlow 2.15 + GPU, and another wants 3.12 with different dependencies.\nThankfully, Docker solves all of that.\n\n\nDocker lets you isolate your dev environment per project, without affecting your system Python. This also can be done via a virtual environment. However, once you need another base python version, you still need to change your system.\nThat means you can use any Python version inside the container, e.g., Python 3.10 even if your host has 3.12.\nYou can install TensorFlow, PyTorch as well as CUDA with NVIDIA containers without polluting your system."
  },
  {
    "objectID": "posts/technical/avoiding-python-version-chaos-in-ml.html#quick-setup-for-ml-dev",
    "href": "posts/technical/avoiding-python-version-chaos-in-ml.html#quick-setup-for-ml-dev",
    "title": "Avoiding Python version chaos in ML",
    "section": "2 Quick Setup for ML Dev",
    "text": "2 Quick Setup for ML Dev\nDockerfile (GPU + TensorFlow + Keras):\nFROM tensorflow/tensorflow:2.15.0-gpu\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCMD [\"bash\"]\ndocker-compose.yml (GPU enabled):\nversion: \"3.8\"\n\nservices:\n  keras-dev:\n    build: .\n    image: keras-dev\n    volumes:\n      - .:/app\n      - /your/local/data:/mnt/storage\n    runtime: nvidia\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n    tty: true\nBuild and run:\ndocker-compose up --build"
  },
  {
    "objectID": "posts/technical/avoiding-python-version-chaos-in-ml.html#ide-integration-using-in-pycharm-pro",
    "href": "posts/technical/avoiding-python-version-chaos-in-ml.html#ide-integration-using-in-pycharm-pro",
    "title": "Avoiding Python version chaos in ML",
    "section": "3 IDE Integration, Using in PyCharm (Pro)",
    "text": "3 IDE Integration, Using in PyCharm (Pro)\n\nAdd Docker-Compose interpreter\nPoint to your docker-compose.yml\nSelect the keras-dev service\nUse /usr/local/bin/python as the interpreter path\nEnable GPU with NVIDIA Container Toolkit\n\nFull dev environment with terminal, debugging, and Python completion — inside the container.\n\n\n3.1 Bonus: One-Time Setup for GPU Access\nInstall NVIDIA Container Toolkit:\nsudo apt install nvidia-container-toolkit\nsudo nvidia-ctk runtime configure --runtime=docker\nsudo systemctl restart docker\nAllow docker without sudo:\nsudo usermod -aG docker $USER\nnewgrp docker"
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html",
    "title": "What I have been reading: What is a ml compiler",
    "section": "",
    "text": "It all started with a big failure. I had bought a coral TPU with the intention to create a Webcam Software which modifies the users appereance. Something similar to https://avatarify.ai/.\nThis is not possible, as the coral TPU only supports a subset of TensorflowLite instructions. Probably a project down the line, to make a clear writeup of the findings and learnings.\nI came across Pete Warden’s article,and a few other resources, and I wanted to collect my thoughts and notes here.\nThis is not a deep dive into implementation details but rather an attempt to connect the dots on what ML compilers are, why they’re challenging, and where the ecosystem is headed."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#what-is-a-ml-compiler",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#what-is-a-ml-compiler",
    "title": "What I have been reading: What is a ml compiler",
    "section": "",
    "text": "It all started with a big failure. I had bought a coral TPU with the intention to create a Webcam Software which modifies the users appereance. Something similar to https://avatarify.ai/.\nThis is not possible, as the coral TPU only supports a subset of TensorflowLite instructions. Probably a project down the line, to make a clear writeup of the findings and learnings.\nI came across Pete Warden’s article,and a few other resources, and I wanted to collect my thoughts and notes here.\nThis is not a deep dive into implementation details but rather an attempt to connect the dots on what ML compilers are, why they’re challenging, and where the ecosystem is headed."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#ml-compilers-aim-at-optimizing-model-execution",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#ml-compilers-aim-at-optimizing-model-execution",
    "title": "What I have been reading: What is a ml compiler",
    "section": "2 ML Compilers aim at optimizing model execution",
    "text": "2 ML Compilers aim at optimizing model execution\nIn frameworks like TensorFlow or PyTorch, ML models are represented as graphs—directed acyclic graphs (DAGs) of computations. These frameworks typically interpret the graph at runtime, similar to how Python interprets code line by line.\nAn ML compiler takes this model graph and optimizes it for performance and/or portability. nstead of executing the model exactly as defined, the compiler transforms the graph into a more efficient form or into a representation that can run on a wider range of devices (CPUs, GPUs, TPUs, edge hardware, etc.).\nFor example, XLA (Accelerated Linear Algebra) — TensorFlow’s compiler — takes the layers of a graph and converts them into HLOs (High-Level Operations). These HLOs form an intermediate representation (IR) that XLA can analyze and optimize before generating code for the target device.\nThe “high” in High-Level Operation refers either to the level of abstraction or to the fact that it sits at the top of XLA’s compilation pipeline."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#not-the-same-as-your-standard-compiler",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#not-the-same-as-your-standard-compiler",
    "title": "What I have been reading: What is a ml compiler",
    "section": "3 Not the same as your standard compiler",
    "text": "3 Not the same as your standard compiler\nFor traditional software engineers, a compiler usually means something straightforward:\n\nTake a text file (e.g., C++ source code)\nTurn it into a binary executable\nRun it directly on the target platform\n\nML compilers, on the other hand, often don’t produce a final executable. Instead, they transform the model into another intermediate representation. In many cases, the “compiled” model is not ready to execute on its own. It requires further processing before running.\nThis can make the term “compiler” a bit misleading. It’s less like GCC and more like a pipeline of transformations where performance tuning, graph simplification, and device-specific optimizations happen in stages."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#early-stage-of-standardization",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#early-stage-of-standardization",
    "title": "What I have been reading: What is a ml compiler",
    "section": "4 Early stage of standardization",
    "text": "4 Early stage of standardization\nMachine learning is experiencing the age of the the wild west. Everybody is defining their own functions, operators, and layers.Reuse does not exist.\nUnlike C++—which has around 60 keywords and ~105 STL algorithms—there’s no common “vocabulary” for ML models.\nSome Symptoms:\n\nEven small 1% performance gains can lead teams to define new custom operators.\nThese operators may improve benchmark scores but hurt portability.\nWhen it comes time to deploy models across devices, you quickly discover that many operations aren’t supported on certain hardware.\n\nWhat’s missing is a meta-language for layers—a standard abstraction layer that frameworks, compilers, and hardware vendors could agree on. Without this, interoperability remains painful."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#digging-deeper-high-level-irs-a-key-abstraction",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#digging-deeper-high-level-irs-a-key-abstraction",
    "title": "What I have been reading: What is a ml compiler",
    "section": "5 Digging Deeper High-Level IRs: A Key Abstraction",
    "text": "5 Digging Deeper High-Level IRs: A Key Abstraction\nA great explanation of this comes from Udit Agarwal’s article.\nUnlike traditional compilers, where intermediate representations (IRs) are close to the hardware,“high-level IRs are hardware-agnostic and provides a much-needed abstraction”\nThese IRs provide:\n\nA unified representation of the model\nA way to perform graph-level optimizations\nAn abstraction layer that allows targeting multiple backends\n\nBecause ML models are represented as DAGs, the IR captures both the operations (nodes) and the data dependencies (edges). These DAGs can be symbolic (fully defined before execution, like in TensorFlow 1.x) or imperative (built on the fly, like in PyTorch)."
  },
  {
    "objectID": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#graph-optimization-making-models-faster",
    "href": "posts/technical/what-i-have-been-reading-what-is-a-ml-compiler.html#graph-optimization-making-models-faster",
    "title": "What I have been reading: What is a ml compiler",
    "section": "6 Graph Optimization: Making Models Faster",
    "text": "6 Graph Optimization: Making Models Faster\nOnce a model is converted into a graph, ML compilers apply a range of optimization techniques:\n\nOperator fusion – Combine multiple layers into a single kernel\nConstant folding – Precompute values where possible\nMemory optimizations – Reuse buffers and reduce allocations\nQuantization – Use lower-precision arithmetic where safe\nthe side lists different optimization techniques\n\nThese transformations can significantly improve performance on specialized hardware. If you want a deeper dive, check out another of Agarwal’s articles another of Agarwal’s articles"
  },
  {
    "objectID": "posts/i-only-understand-trainstation.html",
    "href": "posts/i-only-understand-trainstation.html",
    "title": "I only understand trainstation",
    "section": "",
    "text": "If you a native English speaker you certainly got confused by the heading. The phrase was double dutch to you. But fear not you are not alone.\n\nTravelling arround the world\nCorona restrictions are easing in many developed countries and air traffic bans are lifted.\nMany people plan their next vacation. And with that the comes the question should you only travel to countries where you speak the language? Or a you one of the global cosmopolitans who are at home everywhere.\nRegardless of the group you belong to, you certainly know this desperate feeling when you run out of words to make yourself understood in a foreign tongue. \nImagine you next trip to Italy and your hotel suite with a view on the river. And then picture yourself that you arrive in that hotel and are shown to your room. Your host is of the most amiable nature. He opens the door and points to your abode for the next fortnight:\nA humid cramped room with a look in the back yard, which is full of waste bins and air conditions outlets.\nDesperately you try to explain that this can not be your room. Your host keeps smiling and answers with a long explanation in Italian.\nAt this point the feeling of despair is rising in you, you holiday is certainly doomed.\n\n\nProverbs around the world\nOf course travel is something which is done by every culture and this situation or similar situations are known to every traveler.\nSimilar situation also arrive in daily live. You understand the language you colucator is using, but not the sense of the words. Be it because he is talking gibberish or because the topic is intellectually over you head.\nMost interestingly the pro-verb different cultures use to describe the feeling in these situations vary quite dramatically.\nI stumbled on this in a magazine article by Martina Koch, originally written in German. I could not find the article and translate the content here to English.\nThe drum is in (the city of) Harasta, but the marriage is in Duma.\nHarasta wa I ’irs fi Düma ()\n- Arabic\nI listen to a book from the heavens.\nWo zai ting tianshu\n- Chinese\nhä? Ich verstehe nur Bahnhof\nEh? I only understand train station\n- German\nThat is Volapük to me\nTio estas volapukajo por mi\n- Esperanto; Volapük is another artificial language\nI only understand stone plate\nJ’ y comprends que dalle\n- French\nI do not even understand oink\nDen katalawäno gri\n- Greek\nI understand neither upwards nor downwards\nEg skil hvorki upp ne niöur i ~essu\n- Icelandic\nI did not understand any dried fig\nNon ho capito un fico secco\n- Italian\nI can not attach a tow to it\nIk kan er geen touw aan vastknopen\n- Dutch\nI am sitting here as in a turkish sermon\nSiedze jak na tureckim kazaniu\n- Polish\nI am looking at a new Gate like a sheep\nJa smotrju kak baran na novye vorota\n- Russian\nThat is chinese to me\nMe suena a Chino\n- Spanish\nI understand mushrooms\nTomu jä houby rozumim\n- Czech\nIf I had understood something, I would be an arabian.\nAnladiysam Arap olayim\n- Turkish\nThere are some similarities. The verb understand appears almost in every language, but not all.\nRussian and polish are quite figuratively expressing the confusion. Russian goes so far as to compare the situation a confused sheep.\nNext time you are confused when traveling, think about it this way:\nthe people confusing to you would be equally confused, if they were to visit your own country."
  },
  {
    "objectID": "posts/quotes-about-storytelling.html",
    "href": "posts/quotes-about-storytelling.html",
    "title": "Quotes about storytelling",
    "section": "",
    "text": "Sometimes one person said it all. You read a phrase and it is all there. This is my selection of quotes on storytelling.\n\n“The world’s second oldest profession”\n\nGershon & Page: What storytelling can do for information visualisation\n\n“People have begun to forget how powerful human stories are, exchanging their sense of empathy for a fetishistic fascination with data… the human stuff is the main stuff, and the data should enrich it”\n\nJonathan Harris\n\n“Data journalism is not graphics an visualizations. it’s about telling the story in the best way possible. someties that will be a visualization… but sometimes it’s a news story. sometimes ust publishing the number is enough”\n\nSimon Rogers\n\n“At the end of the day people won’t remember what you said or did, they will remember how you made them feel”\n\nMaya Angelou\n\n“Marketing is no longer about the stuff that you make, but about the stories that you tell.”\n\nSeth Godin\n\n“Your purpose is to make your audience see what you saw, hear what you heard, feel what you felt. Relevant detail, couched in concrete, colorful language, is the best way to recreate the incident as it happened and to picture it for the audience.”\n\nDale Carnegie\n\n“The purpose of a storyteller is not to tell you how to think, but to give you questions to think upon.”\n\nBrandon Anderson\n\n“Everything is more compelling when you talk like a human being, when you talk like yourself.”\n\nIra Glass\n\n“Fools learn from experience. I prefer to learn from the experience of others.”\n\nOtto von Bismarck\n\n“Some of his stories became my stories, and just by telling them again and again, he gets to stay alive forever. That’s the magic of storytelling. It’s a time machine that can heal the world.”\n\nKevin van Valkenburg\n\n“There is no such thing as a new idea. It is impossible. We simply take a lot of old ideas and put them into a sort of mental kaleidoscope. We give them a turn and they make new and curious combinations.”\n\nMark Twain\n\n“We keep on turning and making new combinations indefinitely; but they are the same old pieces of colored glass that have been in use through all the ages.”\n\nMark Twain\n\n“We keep on turning and making new combinations indefinitely; but they are the same old pieces of colored glass that have been in use through all the ages.” - Mark Twain\n“ideas are the currency of the twenty-first century” - camine gallo - talk like ted\n\nIt is human nature to want to explain the universe. To do that right, you need to see the world through other people’s eyes."
  },
  {
    "objectID": "posts/why-yet-another-storytelling-blog.html",
    "href": "posts/why-yet-another-storytelling-blog.html",
    "title": "Why yet another storytelling blog",
    "section": "",
    "text": "How we got here\nSo you want to do storytelling? Telling tall tales? But how to start? You are probably much in the same situation as I was in late 2019:\nI had a story to tell, of this I was sure but I did not know how to tell it. Nor did I know where to start to learn how to tell it.\nOriginally, I decided to start a blog to gather resources about storytelling. Very soon I got overwhelmed by the sheer material out there. Just checking the calendar: it is already July 2021. Certainly, it took some time to get here. I used this time to dig into the topic and to clarify my blog’s purpose:\nMy main idea for the blog was storytelling. I want to write about the topic of effective communication and getting the point across. How to not get lost in the myriad of options that we have today.\nI know not every much more precise, but I hope it will help me.\nSo let’s descend down into the mine of storytelling.\n\n\nWhat is storytelling?\nThe most obvious way to obtain this answer could be to look up Wikipedia.\n“Storytelling describes the social and cultural activity of sharing stories, sometimes with improvisation, theatrics, or embellishment.”\nA glance over this article reveals: storytelling is quite a vast field.\nThe two most prominent and established thematic fields are storytelling in fiction and storytelling in marketing.\nStorytelling in fiction is the very process of writing a story.\nStorytelling in marketing is the process to wrap the product in a story to provide a better possibility for the customer to identify with his potential next buy.\n\n\nBusiness storytelling\nI will try to write about a far less popular part of storytelling:\nStorytelling in business decisions.\n“Business decisions” generally means a very large field.\nAspects of business storytelling:\n\nHow to pitch your business idea?\nHow to build a team?\nHow to sell your products?\n\n\n\nBusiness storytelling as an engineer\nDue to my background as a scientist and engineer, I will restrict myself to the question:\nHow to influence business decisions as an engineer?\n\nExamples:\n\nYou have an idea, which you think to be great. How do you convince other people that it is a great idea?\nYou want to change the course of things in you department. What do you need to do?\nYou did something brilliantly in a small team. How do you scale your idea to a larger team, in short how to make your ideas grow?\n\n\n\n\nImpact without power\nThese situations are certainly applicable to many professions. A recurring theme is acting impactful without formal power. There is a high probability that this getting more important as the knowledge economy spreads and we all want to sell on the “marketplace of ideas”.\nThe rise of influencers on platforms such as Youtube and Instagram is one such aspect.\nAt the same time, many big companies aim to democratize decision-making and reduce silo structures by fostering internal communication platforms. In a knowledge network power arises from being a node with many connections. The connections can be two ways, like in a classic network or oneway as for the modern followers.\n\n\nWhat to expect\nThe aim is to have an overview of some good resources on storytelling. In addition, I want to explain key elements like the influence of the audience, story structure, and of course story delivery.\nStay tuned for the next article!"
  },
  {
    "objectID": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#is-leadership-about-the-position",
    "href": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#is-leadership-about-the-position",
    "title": "4 powerful secrets medium user need to know about leadership",
    "section": "1 Is leadership about the position?",
    "text": "1 Is leadership about the position?\nI recently finished my summary of 21 Laws of Leadership. The book by John C. Maxwell is one of the canonical books in the leadership field.\nMaxwell, too uses an ambiguous meaning. Sometimes he says leadership is not positional. In other passages, he assumes someone found his way into a leadership position without knowing how to lead. Such a situation is only possible with positional leadership.\nMaxwell already structured the book into 21 easily digestible chapters. Everybody has to see for himself which laws are most important for him. Maxwell offers a simple evaluation questionary, which for me, proved helpful.\nRead on if you want to use four of the laws to build up your leadership on a platform like Medium."
  },
  {
    "objectID": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#in-the-future-we-will-all-be-influencers.",
    "href": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#in-the-future-we-will-all-be-influencers.",
    "title": "4 powerful secrets medium user need to know about leadership",
    "section": "2 In the future, we will all be influencers.",
    "text": "2 In the future, we will all be influencers.\nThe law of influence provides the definition I would agree with: “The true measure of leadership is influence.” Having experienced many positional leaders, I agree with his. However, there certainly are people who have no position and whose wisdom I follow, and who I seek out for advice. Connected to this law is the importance of relationships. Influence requires successful relationships.\nFor the medium user or users of any other platform, it is essential to engage in discussions of other content. Through the comments, we build up relationships."
  },
  {
    "objectID": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#strive-to-become-better.",
    "href": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#strive-to-become-better.",
    "title": "4 powerful secrets medium user need to know about leadership",
    "section": "3 Strive to become better.",
    "text": "3 Strive to become better.\nThe second important law is the law of the process. Do every day some small steps to advance. Write and read every day. There is not much to add here, and the most challenging part about it is the execution."
  },
  {
    "objectID": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#who-you-are-is-who-you-attract.",
    "href": "posts/21-laws-leadership/powerful-secrets-medium-user-need-to-know-about-leadership.html#who-you-are-is-who-you-attract.",
    "title": "4 powerful secrets medium user need to know about leadership",
    "section": "4 Who you are is who you attract.",
    "text": "4 Who you are is who you attract.\nThe other laws are connected to these two laws. They describe more how to build up the influence or apply a process.\nFor someone without followers, some laws address the creation of a follower base. I found the most striking the law of magnetism “Who you are is who you attract.”\nConstructing fruitful relationships requires one critical thing: respect. Therefore, the law of respect is essential to building up those relationships.\nAnd that’s it—four laws to start growing your follower base."
  },
  {
    "objectID": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html",
    "href": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html",
    "title": "A new writer’s easy guide to find the perfect headline",
    "section": "",
    "text": "So far, I have written 13 stories on medium over the last six months.\nThe number of views and reads I get varies from month to month but overall remains relatively low.\nI have noticed that some stories seem to be more popular than others.\nOne thing I regularly ask myself: Is the problem in the title?"
  },
  {
    "objectID": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#burying-the-lead",
    "href": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#burying-the-lead",
    "title": "A new writer’s easy guide to find the perfect headline",
    "section": "Burying the lead",
    "text": "Burying the lead\nThere is the concept of burying the lead. The title should declare the main aim of the article. A novice fails by burying his most exciting fact under a lot of auxiliary information.\nSometimes one of my paragraph’s headings is more exciting than the article heading.\nThe only way to fix this is to write more and reflect on the titles. As a moonlight writer, I rarely have the time and energy to write hundreds of headlines to train my inner title generator.\nNevertheless, I guess that I will get better over time."
  },
  {
    "objectID": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#avoid-clipping-titles",
    "href": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#avoid-clipping-titles",
    "title": "A new writer’s easy guide to find the perfect headline",
    "section": "Avoid clipping titles",
    "text": "Avoid clipping titles\nThen there is the tip from Niklas Göke: you should avoid clipping your titles and subtitles.\nI am guilty of having 4 clipped sub-titles, amounting to roughly 25 % of my titles.\nI changed that and vow to oversee the limit in the future."
  },
  {
    "objectID": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#using-headline-analyzer",
    "href": "posts/a-new-writers-easy-guide-to-find-the-perfect-headline.html#using-headline-analyzer",
    "title": "A new writer’s easy guide to find the perfect headline",
    "section": "Using headline analyzer",
    "text": "Using headline analyzer\nSoftware engineer that I am, I wondered if there is any software helping you get better. These analyzers could be rule-based or machine-learning-trained.\nSadly I found no machine learning-based solution. All solutions work with word bags and reading-level statistics.\nI settled for https://headlines.coschedule.com.\nThese are the improvements to my current headings. I aimed to reach at least a score of 70 points.\nThe general pattern is that the headlines are longer and feature more attention-grabbing words.\nThere are different categories of words (e.g., power words or emotional words). I tried to have at least one word in each category.\nAt the same time, I wanted an intelligible sentence and one that partly reflects the content.\n\n\n\n\n\n\n\n\n\nBefore improvement\nOld Score\nAfter improvement\nNew Score\n\n\n\n\nAre you mentally depleted?\n41\nknow, if you unwisely exhausted your mental energy supply for the day\n71\n\n\nEffective cheating with statistics\n51\n2 intricate ways statistics can influence the perception of the truth\n86\n\n\nWhy do we like other people?\n63\nHow a good mood helps to smoothen things\n75\n\n\nWhy nobody has built your leadership\n60\nWorld Sensation: Why remarkably nobody has built your leadership\n77\n\n\nEffective leaders listen for stories\n56\nEffective leaders listen for stories that touch the heart and mind\n78\n\n\nWhat medium user need to know about leadership\n67\n4 powerful secrets a medium user needs to know about leadership\n92\n\n\nStorytelling for engineers\n33\nThe world requires influential engineers with a passion for stories\n71\n\n\nSelf-organizing cross-functional teams need a cooperative environment\n57\nSuccessful cross-functional teams need the luxury of confidence and trust\n73\n\n\nDiscover your team’s common story\n39\nThree old but trusted ways to reveal your team’s common story;\n91\n\n\nSpice up your presentations with some psychology\n44\nGood presenters embrace these psycho tips in their life\n92\n\n\nTry these tips before lunch to get more followers\n57\nTry these 9 tips to get more and stronger follower growth\n81\n\n\nDo you read?\n37\nKnowledge advice: 2 Ways to read a book and improve your understanding\n89\n\n\nTry these mental tricks to gain the upper hand in conflicts\n64\nTry these priceless mental tricks to gain the upper hand in pointless conflicts\n71\n\n\nAverage Score\n51\n\n80\n\n\n\nI raised my average score from 51 to 80 points. I must admit that most of the headings have a certain edge. They sound like many other social media posts.\nWhat is your opinion? Should a new writer rely on the help of software to improve his headings?"
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "",
    "text": "Somewhere a project failed\n\n\nPicture this: somewhere out there, a remote project is teetering on the edge of failure. We’ve all heard about the fantastic benefits of remote work—the flexibility, the comfort of working from home, the time saved on commuting.\nBut behind this rosy facade, a sinister reality lurks: a creeping disengagement is spreading through teams like a slow-acting poison.\nYou, the reader, may even think, “But isn’t disengagement, apathy, or even that dreaded ‘quiet quitting’ a part of any work environment? It’s common at on-site work, too!”\nYou’re right. These issues have always existed. Now, they are just disguised under different names in our modern office culture."
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#iceberg-approaching",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#iceberg-approaching",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "",
    "text": "Somewhere a project failed\n\n\nPicture this: somewhere out there, a remote project is teetering on the edge of failure. We’ve all heard about the fantastic benefits of remote work—the flexibility, the comfort of working from home, the time saved on commuting.\nBut behind this rosy facade, a sinister reality lurks: a creeping disengagement is spreading through teams like a slow-acting poison.\nYou, the reader, may even think, “But isn’t disengagement, apathy, or even that dreaded ‘quiet quitting’ a part of any work environment? It’s common at on-site work, too!”\nYou’re right. These issues have always existed. Now, they are just disguised under different names in our modern office culture."
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#why-good-compensation-alone-is-not-enough",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#why-good-compensation-alone-is-not-enough",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "Why good compensation alone is not enough",
    "text": "Why good compensation alone is not enough\n\n\n\nAre you living in Maslow’s basement and only crave for food and shelter?\n\n\nOne common thread is a sense of diminishing trust and dwindling recognition of each other’s work. With recognition, we mostly talk about compensation. Oddly enough, many of us believe everyone else is content living in Maslow’s basement.\nWe assume that while we may crave recognition and self-esteem, meeting others’ basic needs satisfies them, making them pure money hogs.\nThis isn’t just a remote work problem, it’s a leadership problem. It’s about understanding our team’s needs, building trust, and acknowledging their efforts - regardless of where they are. And it’s high time we address it."
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#remotes-works-triangle-of-trust.",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#remotes-works-triangle-of-trust.",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "Remotes work’s triangle of trust.",
    "text": "Remotes work’s triangle of trust.\nRemote work suffers heavily in the three clusters: Communication, Engagement, and Conflict Resolution. A common currency in at work is trust. Trust influences the three clusters. In addition, the three clusters affect each other.\n\n\n\nThe triangle of trust\n\n\n\nThe relationships in detail\nEverything can be read from several sides\n\nThe relationships to trust\nIt all starts with communication. Communication is everything how we speak, write, dress, behave.\nCommunication with more Transparency builds up trust. If trust exists, communication is done with more honesty\nAll work comes with conflicts and conflict resolution is an essential part of work.\nConflict Resolution with more Fairness builds up trust. If trust exists, conflict resolution is done with more openness.\nEngagement is the amount of energy every single person puts into a collective effort. Engagement with more Involvement builds up trust. If trust exists, engagement is done with more reliability.\n\n\nThe relationships to each other\nBetter Communication leads to better Conflict Resolution through Understanding. Better Conflict Resolution leads to better Communication through Dialogue.\nBetter Communication leads to better Engagement through Inclusion. Better Engagement leads to better Communication through Feedback.\nBetter Conflict Resolution leads to Engagement simply through its Resolution Better Engagement leads to better Conflict Resolution through more Participation."
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#when-and-how-the-triangle-of-trust-breaks",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#when-and-how-the-triangle-of-trust-breaks",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "When and how the triangle of trust breaks",
    "text": "When and how the triangle of trust breaks\n\nBreak down of Communication\nRemote work productivity often falters when the Triangle of Trust—Communication, Engagement, and Conflict Resolution—is not balanced. Here are three situations, I experienced myself, and how to ameliorate them.\n\n“Nobody is listening”:\nWhen emails, chats, and tickets pile up with no response, Communication is broken, and Trust erodes due to limited Transparency. Feedback is shared less frequently. This leads to frustration and a lack of Engagement.\nTo address this, clarity and routine updates must restore Trust by showing that voices are heard and valued, be transparent and be inclusive.\n“Nobody can remember”:\nDeadlines are not met, Engagement is superficial, and Trust suffers as promises go unmet. A lack of concrete action undermines confidence in collaboration. Strengthening Communication through actionable, clear messages is essential to rebuild alignment. Be transparent and show understanding\n“Everybody is talking past each other”:\nThis escalation reflects a breakdown of Conflict Resolution. Frustrating meetings without resolution erode Trust and Engagement, leaving teams demoralized. Clear expectations and effective facilitation can prevent this collapse of the triangle. Be transparent and inclusive and show understanding when not all issues can be accounted for.\n\n\n\nReigniting Engagement\nEngagement wanes when Trust, Communication, and Conflict Resolution are not upheld.\n\nThe silence after a question:\nA lack of Engagement often signals diminished Trust. If team members feel their input won’t be valued or acted upon, they become less reliable. Structuring tasks as opportunities for learning can rebuild their Trust and renew their sense of purpose/involvement.\n‘Yes-people’ trap:\nWith low engagement comes low participation in Conflict Resolution. The team operates without meaningful feedback, weakening Communication . Encouraging challenges and creative problem-solving restores balance by addressing underlying apathy. Provide feedback and opportunities for particapation.\n\n\n\nTrust as common currency\nTrust is build up when all sides of the triangle—Communication, Engagement, and Conflict Resolution—work in harmony. When just one point is not optimal, the others suffer.\n\nLack of transparency:\nWithout detailed and thoughtful communication, Trust and Engagement falter. Teams doubt intentions, leading to disengagement and potential conflicts. Transparency ensures Trust is build up.\nOver-reliance on authority:\nA top-down approach damages Engagement and undermines Conflict Resolution, as it stifles collective input. Highlighting external examples fosters mutual respect and strengthens Communication.\n\n\n\nConflict resolution must be done without personal conflicts\nAs said previously, conflict resolution is necessary. But Conflict becomes detrimental when it overwhelms the Triangle of Trust.\n\nUnproductive meetings:\nHeated discussions indicate a failure of Conflict Resolution, which spills over into poor Communication and disengagement. Using success stories as springboards can redirect the conversation, reminding teams of their capabilities and strengthening Engagement.\nExcessive tension:\nWhen conflict dominates, Trust erodes as teams feel unsafe or undervalued. Balancing conflict by fostering constructive dialogue reinforces all sides of the triangle and encourages innovative problem-solving."
  },
  {
    "objectID": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#the-triangle-of-trust-captures-todays-complex-work-situations",
    "href": "posts/management/the-triangle-of-trust-reveals-your-projects-issues.html#the-triangle-of-trust-captures-todays-complex-work-situations",
    "title": "The triangle of trust reveals your projects issues.",
    "section": "The triangle of trust captures todays complex work situations",
    "text": "The triangle of trust captures todays complex work situations\nI came up with the triangle of trust, when I thought about how distinct problems all seem to be connected to each other.\nOf course, a simple solution is just: Talk to each other :-)."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html",
    "href": "posts/management/what-i-learned-about-risk-management.html",
    "title": "What I learned about risk management",
    "section": "",
    "text": "Dilbert’s Risks, by Scott Adams\n\n\nRisk management is the cornerstone of sound decision-making in uncertain environments. By understanding the nuances of risk and uncertainty, businesses and individuals can prepare for challenges and seize opportunities. This guide is structured into four key sections, each building on the last to provide a comprehensive strategy for navigating the unpredictable: concepts, mindset to handle risks, strategies to handle risks, methods to act on risks."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#mastering-risk-management-working-on-a-framework",
    "href": "posts/management/what-i-learned-about-risk-management.html#mastering-risk-management-working-on-a-framework",
    "title": "What I learned about risk management",
    "section": "",
    "text": "Dilbert’s Risks, by Scott Adams\n\n\nRisk management is the cornerstone of sound decision-making in uncertain environments. By understanding the nuances of risk and uncertainty, businesses and individuals can prepare for challenges and seize opportunities. This guide is structured into four key sections, each building on the last to provide a comprehensive strategy for navigating the unpredictable: concepts, mindset to handle risks, strategies to handle risks, methods to act on risks."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#defining-risk-and-uncertainty",
    "href": "posts/management/what-i-learned-about-risk-management.html#defining-risk-and-uncertainty",
    "title": "What I learned about risk management",
    "section": "2 Defining Risk and Uncertainty",
    "text": "2 Defining Risk and Uncertainty\nUnderstanding the foundational difference between risk and uncertainty is the first step in managing them effectively. These concepts form the basis for strategic decision-making and influence how we approach the unknown.\n\n2.1 Risk vs. Uncertainty\n\nRisk: Involves measurable probabilities of outcomes, such as rolling dice or forecasting based on historical data.\nUncertainty: Represents scenarios where outcomes and probabilities are entirely unknown, like groundbreaking innovations or market disruptions.\n\nFor more information see this link and this link\n\n\n2.2 Key Distinctions\n\nPredictability: Risk is predictable; uncertainty is not.\nControl: Risks can be managed; uncertainty cannot.\nMeasurability: Risks are quantifiable; uncertainty resists precise measurement.\n\n\n\n2.3 Why Both Matter\nWhile risks allow for control and mitigation, real opportunities for profit and innovation arise in the face of uncertainty. Embracing uncertainty, rather than fearing it, is vital for achieving transformative outcomes.\nIn fact, this is what defines the full risk opportunity matrix. Do not always talk about the risks. Talk about the opportunities, too.\n\n\n\nThe full risk matrix, also features opportunities, https://rolandwanner.com/do-you-really-know-the-risk-matrix/"
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#the-spectrum-of-action-from-risk-to-uncertainty",
    "href": "posts/management/what-i-learned-about-risk-management.html#the-spectrum-of-action-from-risk-to-uncertainty",
    "title": "What I learned about risk management",
    "section": "3 The Spectrum of Action: From Risk to Uncertainty",
    "text": "3 The Spectrum of Action: From Risk to Uncertainty\nOnce we understand the difference, the next challenge is deciding how to act. Businesses often face a spectrum where actions are either overly confident in quantifying risks or paralyzed by the fear of uncertainty.\nThere are two common issues: over-quantifiying risks and avoiding all risks,\nOver-Quantifying Risk\n\nAssigning subjective probabilities to problems creates a false sense of objectivity.\nTools like risk matrices may provide clarity but can oversimplify complex situations.\n\nAvoiding All Risks\n\nFear of uncertainty often leads to inaction.\nBalancing confidence and caution is crucial—neither overestimating predictability nor succumbing to indecision.\n\nRecognizing the limits of predictability helps us avoid both extremes. The goal is to embrace uncertainty methodically while making informed decisions wherever risks are identifiable."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#practical-strategies-for-navigating-the-unknown",
    "href": "posts/management/what-i-learned-about-risk-management.html#practical-strategies-for-navigating-the-unknown",
    "title": "What I learned about risk management",
    "section": "4 Practical Strategies for Navigating the Unknown",
    "text": "4 Practical Strategies for Navigating the Unknown\nArmed with a balanced mindset, businesses can employ structured strategies to handle uncertainty and identify hidden risks.\n\n4.1 Managing Uncertainty\n\nAggregate Data: Use statistics and testing to transform some uncertainties into manageable risks.\nSeek Opportunity: Recognize that uncertainty often hides high-reward possibilities.\nEvaluate Retrospectively: Measure failures and waste as indicators of past uncertainty, improving future planning.\n\n\n\n4.2 Uncovering Unknown Unknowns\nWhen we talk about uncertainty and risks. a concept closely related are the known-unknowns and the unknown-unknwons.\n\n\n\nThe unknown unknowns make life complex. https://www.managementyogi.com/2019/09/risk-classification-known-knowns-known-unknowns-unknown-knowns-and-unknown-unknowns.html\n\n\nUnknown unknowns often involve factors we don’t even consider. It is important to look at the right places to uncover these.\nThe following methods exists, to help us.\n\nDecompose Projects: Analyze subsystems and interrelations to expose complexity.\nScenario Analysis: Develop multiple possible futures and examine their impacts.\nUse Long Interviews: Engage stakeholders deeply to surface latent risks.\nSpot Weak Signals: Look for subtle patterns or behaviors indicating hidden issues.\n\n\n\n\nReveal unknown unknowns through systematic exploration.\n\n\nCulture does not only eat strategy for breakfast. An appropriate culture, which is adaptive can help in uncovering risks.\n\nEncourage open communication and allow bad news to surface.\nIncentivize risk discovery by rewarding transparency and a no-blame culture.\nPromote education about how unknowns emerge and why they matter.\n\nFostering transparency is a point where the triangle of trust can help, See my article on the triangle of trust.."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#turning-knowledge-into-action",
    "href": "posts/management/what-i-learned-about-risk-management.html#turning-knowledge-into-action",
    "title": "What I learned about risk management",
    "section": "5 Turning Knowledge into Action",
    "text": "5 Turning Knowledge into Action\nFinally, effectively identifying, analyzing, and managing risks ensures that businesses and individuals can act confidently, even in uncertain environments.\n\n5.1 Risk Identification\n\nDivergent Thinking: Use techniques like brainstorming, mind mapping, and the “Five Whys” to uncover potential risks, but see [[202501262201 Why the Fishbone Diagram Triumphs Over 5 Whys]].\nConvergent Thinking: Cluster risks into categories (e.g., technical, commercial, external, or management).\n\n\n\n5.2 Risk Management\nOnce a risk is known the actual risk management becomes rather mechanical.\nFirst, classify and quantify the Risk.\n\nQualitative: Classify risks based on ownership, urgency, and dependencies.\nQuantitative: Assess impacts, costs, schedule shifts, and expected monetary values.\n\nThen develop measures and classify the measures according to this methodology.\n\nFor risks:\n\nAvoid: Eliminate exposure.\nMitigate: Reduce likelihood or impact.\nTransfer: Shift responsibility.\nAccept: Prepare to manage the fallout.\nEscalate: Elevate critical risks to leadership.\n\nFor opportunities:\n\nExploit: Maximize benefits.\nShare: Collaborate for mutual gain.\nEnhance: Improve likelihood or impact."
  },
  {
    "objectID": "posts/management/what-i-learned-about-risk-management.html#conclusion",
    "href": "posts/management/what-i-learned-about-risk-management.html#conclusion",
    "title": "What I learned about risk management",
    "section": "6 Conclusion",
    "text": "6 Conclusion\nBy integrating these four elements—defining concepts, balancing action, strategizing, and executing plans—risk management becomes a cohesive framework. Embracing uncertainty alongside managing risk enables businesses to minimize threats, seize opportunities, and foster innovation in an ever-changing world."
  },
  {
    "objectID": "posts/made-to-stick/the-stickiness-improvement-plan.html",
    "href": "posts/made-to-stick/the-stickiness-improvement-plan.html",
    "title": "The Stickiness Improvement Plan",
    "section": "",
    "text": "There is no better feeling than to tick off boxes."
  },
  {
    "objectID": "posts/made-to-stick/the-stickiness-improvement-plan.html#what-makes-ideas-stick",
    "href": "posts/made-to-stick/the-stickiness-improvement-plan.html#what-makes-ideas-stick",
    "title": "The Stickiness Improvement Plan",
    "section": "What makes ideas stick",
    "text": "What makes ideas stick\nMade to stick needs no introduction. If you have not read the book, then buy a copy! There are many good ideas to read the book several times. But how to keep track of what to do? The authors themselves present the most basic advice: think about SUCCES.\nThe first S stands for Simple. Simple is about the Answer stage of your question.\nThe UCCES-part focuses on the delivery of your message.\nFor an idea to stick, to be lasting and useful, it’s got to make the audience\n\nPay attention (Unexpected)\nUnderstand and remember it (Concrete)\nAgree/Believe (Credible)\nCare (Emotional)\nBe able to act on it (Story)\n\nSometimes it’s difficult to know where to start. I already wrote about this previously. Here is a checklist that you can use to place your own stepping stones. If a question strikes a tune, I provide the related keyword. Refer to the book or the internet to learn more about the topic. Look and see how many boxes you can tick."
  },
  {
    "objectID": "posts/made-to-stick/the-stickiness-improvement-plan.html#the-sticky-improvement-plan",
    "href": "posts/made-to-stick/the-stickiness-improvement-plan.html#the-sticky-improvement-plan",
    "title": "The Stickiness Improvement Plan",
    "section": "The sticky improvement plan",
    "text": "The sticky improvement plan\n\nSimplicity: “be masters of exclusion”. Relentlessly prioritize. Be simple and profound. “A one-sentence statement so profound that an individual could spend a lifetime learning to follow it”\n\nHave you organized your message by presenting the most important information first, and all the other stuff in order of descending importance? - Inverted Pyramid.\nHave you identified the most crucial aspects of your message? - Forced Prioritization.\nHave you taken steps to streamline your decision-making process and prevent getting overwhelmed by too many options? - Overcome Decision Paralysis.\nHave you incorporated specific names and examples in your message to make it more relatable and memorable? - Names-Names-Names.\nHave you used relevant analogies and metaphors to simplify complex concepts and make your message more engaging? - Analogies & Metaphors.\n\nUnexpectedness: violate the expectation. Generate interest and curiosity.\n\nHave you incorporated unexpected elements in your message to activate System 2 thinking and provoke deeper engagement? - Break Schemes.\nHave you challenged common assumptions in your message, offering fresh perspectives and added value to engage your audience? - Challenge common sense , fix the guessing machine.\nHave you created curiosity by highlighting gaps in knowledge or understanding, encouraging your audience to seek more information? - Gap Theory of Curiosity.\n\nConcreteness: be human\n\nHave you used concrete examples and sensory details to make your message more relatable and easier to remember? - Sensory Information.\nHave you built up on previously existing knowledege? - Velcro Theory of Mind.\n\nCredibility: Make people accept ideas without skepticism. Avoid hard numbers\n\nHave you provided enough credible evidence and logical reasoning to address potential objections? - not possible to convince a critic.\nHave you utilized authoritative figures or counterexamples to support your message? - Authority and Anti-Authority.\nHave you allowed your topic to demonstrate its credibility by providing testable evidence? - Testable Credentials\nHave you made your message relatable by presenting it on a human scale? - Human Scale.\nHave you used statistics to inform and support your message without overwhelming your audience? - Statistics as an Input.\n\nEmotions: built on the right emotions. Focus on the specific and individual\n\nHave you focused on individuals or specific cases instead of generalizing to avoid group neglect? - Mother Teresa Principle\nHave you used statistics or examples to evoke emotions and create a context for your message? - Statistics act as a Priming Event.\nHave you not overused known concepts and analogies to transport your message? - Avoid Semantic stretch.\nHave you ensured that your message does not solely focus on basic needs or negative emotions? - Avoid Maslow’s Basement.\n\nStories: stories allow easier storage and retrieval of information\n\nHave you organized your message as a coherent story to make it easier for the audience to follow and remember? - Story Map in Head.\nHave you crafted your story in a way that allows the audience to empathize and experience the events themselves? - Mirror Neurons in Story Experience.\nHave you considered using one of the three basic plots (the challenge plot, the connection plot, and the creativity plot) to structure your story? - Three Basic Plots."
  },
  {
    "objectID": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html",
    "href": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html",
    "title": "The one thing missing in your perfect presentation",
    "section": "",
    "text": "What do you care about?"
  },
  {
    "objectID": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#how-to-make-your-ideas-stick-in-a-world-of-endless-noise",
    "href": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#how-to-make-your-ideas-stick-in-a-world-of-endless-noise",
    "title": "The one thing missing in your perfect presentation",
    "section": "1 How to Make Your Ideas Stick in a World of Endless Noise",
    "text": "1 How to Make Your Ideas Stick in a World of Endless Noise\nIn today’s world of constant information overload, standing out is a necessity. Whether you’re sharing an idea, selling a product, or rallying support for a cause, making your message stick is the secret to success. But what makes an idea stick? It must be understandable, memorable, and, most importantly, capable of inspiring action.\nThe hard truth? Most ideas don’t hit the mark. Even if they’re truthful, relevant, or even fascinating, they can still cannot connect. Why? Because they lack one critical ingredient: emotional resonance."
  },
  {
    "objectID": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#why-people-dont-care",
    "href": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#why-people-dont-care",
    "title": "The one thing missing in your perfect presentation",
    "section": "2 Why People Don’t Care",
    "text": "2 Why People Don’t Care\nEven you have a great delivery. The delivery alone won’t save a message if the audience doesn’t care. Facts and logic may inform, but they rarely inspire action.\nTo truly engage people, you need to tap into their emotions and make your message personal.\nConsider how successful charities operate. They don’t just ask for donations to help millions of unnamed people; they focus on one face, one story—a child, an animal, a life you can change. This strategy transforms a broad, abstract cause into a relatable connection."
  },
  {
    "objectID": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#the-bridge-between-understanding-and-caring",
    "href": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#the-bridge-between-understanding-and-caring",
    "title": "The one thing missing in your perfect presentation",
    "section": "3 The Bridge Between Understanding and Caring",
    "text": "3 The Bridge Between Understanding and Caring\nSticky ideas bridge the gap between knowing and caring. It’s not enough for your audience to understand your message—they need to feel it. That’s where the SUCCESS framework, from the book Made to Stick, comes into play:\n\nSimple: Strip your message down to its core. Complexity confuses; simplicity sticks.\nUnexpected: Surprise your audience. Breaking expectations grabs attention.\nConcrete: Use vivid examples and details to make your ideas real and relatable.\nCredible: Back up your claims with proof—whether it’s data, expert endorsements, or relatable stories.\nEmotional: Make people feel something. Tap into their values, fears, and desires.\nStories: Wrap your idea in a compelling narrative. Stories stick better than standalone facts.\n\nWhen you combine these principles, you don’t just share an idea — you create an experience that lingers in the mind and moves the heart."
  },
  {
    "objectID": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#moving-beyond-awareness-to-action",
    "href": "posts/made-to-stick/the-one-thing-missing-in-your-perfect-presentation.html#moving-beyond-awareness-to-action",
    "title": "The one thing missing in your perfect presentation",
    "section": "4 Moving Beyond Awareness to Action",
    "text": "4 Moving Beyond Awareness to Action\nThe goal of a sticky idea is action. It’s not just about being remembered; it’s about inspiring change. When your audience cares enough to act, you’ve truly made your message stick.\n\n\n\n\n\n\nTip\n\n\n\nSo, as you craft your next pitch, post, or presentation, ask yourself:\nDoes this make people feel something? Will it inspire them to do something?"
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "",
    "text": "Photo from Unsplash"
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#embracing-a-new-outlook",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#embracing-a-new-outlook",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "1 Embracing a New Outlook",
    "text": "1 Embracing a New Outlook\nWilliam excelled at coding, but social anxiety occasionally held him back. During one important client meeting, technical glitches and nervousness disrupted his presentation, and the startup lost a key account. Gossip about William’s abilities spread, just as he received a challenging health diagnosis.\nTo make matters worse, a coworker named Carl targeted him with hurtful remarks. Despite these setbacks, William sensed an opportunity to grow and redefine himself."
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#the-decision-to-rise",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#the-decision-to-rise",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "2 The Decision to Rise",
    "text": "2 The Decision to Rise\nDetermined not to be shaped by gossip, William resolved to create a more empowering narrative. He focused on being proactive, positive, and open to new ways of connecting with his peers."
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#rewriting-the-narrative",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#rewriting-the-narrative",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "3 Rewriting the Narrative",
    "text": "3 Rewriting the Narrative\n\n3.1 Building Positive Connections\nWhen Sarah, a colleague, struggled with a complex coding puzzle, William stepped in. He not only helped her solve the issue but also taught her new techniques. Soon, Sarah was sharing her upbeat perspective on William, challenging the old, negative chatter.\n\n\n3.2 Humor as a Shield\nCarl’s unkind remarks about William’s health condition escalated, yet William responded with light-hearted quips that showed courage.\nCarl: “How many doctors’ appointments this week, William?”\nWilliam: “Plenty! I’m hoping for a ‘frequent visitor’ discount soon!”\nHis witty reply won the respect of colleagues, who admired his grace under pressure. Carl’s taunts began to fall flat."
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#a-brighter-reputation",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#a-brighter-reputation",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "4 A Brighter Reputation",
    "text": "4 A Brighter Reputation\nAs William continued to rewrite his story through positive actions and clever responses, his reputation transformed. His colleagues began to see him as a skilled, dedicated, and resilient team member. Meanwhile, Carl’s behavior was increasingly seen as inappropriate, leading to his marginalization within the team.\nWilliam didn’t just unstick the negative narrative; he replaced it with one that celebrated his contributions and character."
  },
  {
    "objectID": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#lessons-in-transformation",
    "href": "posts/made-to-stick/from-challenges-to-champions-unsticking-negative-workplace-stories.html#lessons-in-transformation",
    "title": "From Challenges to Champions: Unsticking Negative Workplace Stories",
    "section": "5 Lessons in Transformation",
    "text": "5 Lessons in Transformation\nWilliam’s story reveals that no matter how sticky a negative narrative may feel, we can always shift it to one of triumph. In Made to Stick, this process is called unsticking by transformation.\nThe next time you face criticism or rumors, remember William’s journey. You hold the pen to your own story—and every setback can become a step forward."
  },
  {
    "objectID": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#the-secret",
    "href": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#the-secret",
    "title": "Waterfall management is a strict recipe, while agility is improvisational cooking.",
    "section": "1 The secret",
    "text": "1 The secret\nIs there a door to an unknown world hiding in plain sight?\nImagine your words as travelers, journeying through the vast expanse of your listeners’ minds. All too often, they find themselves lost, unable to find their destination or make a lasting impression. But what if there was a way to guide your words, like a seasoned explorer, leading them to the very heart of your listeners’ understanding? What if it was a matter of simple technique—one you can learn?\nIn a landscape where information is often forgotten as quickly as it’s learned, there’s a powerful connector that bridges the gap between the known and the unknown. It doesn’t just make ideas clear; it reshapes how we think about them.\nI am talking about generative metaphors.\nBy linking new ideas to familiar concepts, generative metaphors unlock the doors of memory, making your message not only accessible but also unforgettable. They’re an exercise in forced prioritization: if you had to distill your message into one sentence, what would it be? By making that sentence simple but meaningful, you open a door for your audience to see the idea in a new light. Get ready to step into the role of a master storyteller, as we uncover the secrets behind the most powerful tool in the art of effective communication."
  },
  {
    "objectID": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#generative-metaphors-connect-the-known-to-the-unknown",
    "href": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#generative-metaphors-connect-the-known-to-the-unknown",
    "title": "Waterfall management is a strict recipe, while agility is improvisational cooking.",
    "section": "2 Generative Metaphors connect the known to the unknown",
    "text": "2 Generative Metaphors connect the known to the unknown\nGenerative metaphors are more than quick comparisons; they serve as cognitive tools that build on what’s already in your audience’s mind—tapping into the “flags” or familiar concepts people carry. When you link a new, complex idea to something they already know, it sticks.\nThese metaphors are called “generative” because they spark fresh perspectives and foster novel ways to solve problems. As Donald Schön suggested, they reshape perception and open the door to new insights. Steve Jobs demonstrated their impact by describing a personal computer as a “bicycle for the mind.” Not only did the phrase sound compact and catchy, it carried substance—showing how a computer could amplify human potential."
  },
  {
    "objectID": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#metaphors-didnt-we-do-that-in-school",
    "href": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#metaphors-didnt-we-do-that-in-school",
    "title": "Waterfall management is a strict recipe, while agility is improvisational cooking.",
    "section": "3 Metaphors, didn’t we do that in school?",
    "text": "3 Metaphors, didn’t we do that in school?\n\n3.1 What’s the difference to normal metaphors?\nWhile both normal (or conventional) metaphors and generative metaphors involve drawing parallels between seemingly unrelated concepts, their purposes and effects differ significantly.\n\n3.1.1 Normal Metaphors\n\nOften used for descriptive purposes: They clarify or highlight aspects of a concept by relating it to something familiar.\nWidely recognized: For example, “time is money.” People grasp these immediately because they’re common.\nReinforce existing thoughts: They rarely challenge us to see a concept in a new way.\n\n\n\n3.1.2 Generative Metaphors\n\nSpark new thinking: They connect disparate domains and invite deeper insights.\nMore unique or original: They require greater engagement and reflection from the audience.\nTransform perspectives: They’re provocative, connecting, and reshaping how we perceive a concept—like Disney calling employees “cast members,” subtly redefining roles and expectations.\n\nLet’s sum it up:\n\nNormal Metaphors: Illustrative, common, reinforcing\nGenerative Metaphors: Provocative, connecting, transformative"
  },
  {
    "objectID": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#my-secret-recipe-to-find-your-doors",
    "href": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#my-secret-recipe-to-find-your-doors",
    "title": "Waterfall management is a strict recipe, while agility is improvisational cooking.",
    "section": "4 My secret recipe to find your doors",
    "text": "4 My secret recipe to find your doors\nCrafting generative metaphors is an exercise in saying more with less—creating a sound bite that carries real weight. Here are some steps:\n\nIdentify the target concept\nPinpoint the complex, abstract, or unfamiliar idea you want to communicate.\nFind a source domain\nChoose a familiar concept or “flag” in your audience’s mind. By connecting to what they already know, you ensure your metaphor has immediate relevance.\nDiscover shared attributes\nLook for overlapping qualities between your target concept and the source domain. These common traits form the heart of your metaphor.\nDevelop the metaphor\nDistill your thoughts into a simple but meaningful sentence—forced prioritization at its best. Make it concrete; if it doesn’t carry a relevant core, it won’t resonate.\nTest the metaphor\nSee if it sparks fresh insights and makes the complex more accessible. If not, refine or choose a new source domain.\nProvide context\nExplain the reasoning behind the metaphor, ensuring your audience grasps its core message and why it matters.\n\nRemember: simplicity and concreteness win. People forget sprawling ideas but remember concise, tangible images. Avoid empty sound bites; aim for what one might call a sound bite with substance.\nLet’s get some practice and look at two examples!"
  },
  {
    "objectID": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#lets-get-some-practice-and-look-at-two-examples",
    "href": "posts/made-to-stick/waterfall-management-is-a-strict-recipe-while-agility-is-improvisational-cooking.html#lets-get-some-practice-and-look-at-two-examples",
    "title": "Waterfall management is a strict recipe, while agility is improvisational cooking.",
    "section": "5 Let’s get some practice and look at two examples!",
    "text": "5 Let’s get some practice and look at two examples!\n\n5.1 Example 1: Business Agility vs. Traditional Waterfall\n\n\n\nIf traditional waterfall management is like following a strict recipe, business agility is like cooking with the freedom to adjust ingredients on the fly.\n\n\nLet’s craft a generative metaphor using the target concept of business agility and the source domain of traditional waterfall project management.\n\nIdentify the target concept: Business agility\nFind a source domain: Traditional waterfall project management\nDiscover shared attributes: Both involve planning and execution, but differ in speed and flexibility.\nDevelop the metaphor: “If traditional waterfall management is like following a strict recipe, business agility is like cooking with the freedom to adjust ingredients on the fly.”\nTest the metaphor: Does this comparison highlight the strictness of waterfall vs. the adaptive nature of agility?\nProvide context: Explain how business agility allows for ongoing adjustments, while waterfall relies on a rigid sequence of steps.\n\n\n\n5.2 Example 2: high performance teams\n\n\n\nIf a basic team is just a well-stocked toolbox, a high-performance team is a fine-tuned machine where every part works seamlessly toward excellence.\n\n\nLet’s create a generative metaphor using the target concept of high-performance teams that take ownership and responsibility, and the source domain of teams as a resource.\n\nIdentify the target concept: Teams that take ownership and responsibility\nFind a source domain: Teams as a resource\nDiscover shared attributes: Both involve collaboration, but high-performance teams emphasize responsibility and exceptional results.\nDevelop the metaphor: “If a basic team is just a well-stocked toolbox, a high-performance team is a fine-tuned machine where every part works seamlessly toward excellence.”\nTest the metaphor: Does it underscore the difference between viewing teams as mere resources and recognizing their potential for high-level performance?\nProvide context: Show how high-performance teams go beyond just having the necessary tools; they actively take ownership, solve problems, and achieve impactful results.\n\nLike all effective metaphors, these examples anchor new insights to familiar ideas. They help people see the difference between rigid and adaptive, or between basic functionality and high-performance potential. When done right, generative metaphors open doors to new worlds of understanding—one clear, powerful sentence at a time."
  },
  {
    "objectID": "posts/made-to-stick/effective-story-spotting.html",
    "href": "posts/made-to-stick/effective-story-spotting.html",
    "title": "Effective Story Spotting",
    "section": "",
    "text": "Discovering the Spark, the Art of Story Spotting\nWorkplace stories can be found everywhere, and spotting these stories can be a transformative experience. It’s all about actively observing your surroundings, taking note of emotions, and discovering patterns in everyday life. Connecting personal experiences to broader concepts allows us to create compelling content that resonates with others. Let me share with you a story I told at our last Christmas party that illustrates this point.\n\nThe spark was lid. Photo by Unsplash\n\n\nOur Journey: The Challenges of Remote Work\nAs we gathered around, enjoying the festive atmosphere, I began to recount our team’s journey at FuturTech Solutions.\nWhen our software development team at FuturTech Solutions first transitioned to remote work, we were initially organized in two locations - Austin, Texas, and Seattle, Washington. But as we continued to expand our team, we started hiring talented developers from various parts of the country. As the team leader, I had the responsibility to ensure that our growing team could communicate and collaborate effectively, despite being scattered across different time zones.\nInitially, our team consisted of myself, Tom, and Maria. As we hired new remote members, such as Ravi from San Francisco and Lisa from Miami, we started experiencing challenges in maintaining clear and effective communication. We attempted to organize video conferences at a fixed time, which proved to be inconvenient for some members, especially those in different time zones. As a result, crucial updates and information were not consistently shared with everyone, causing confusion and misunderstandings.\n\n\nFinding the Right Solution\nTo remedy this, I proposed a rotating meeting schedule to accommodate everyone’s availability. However, this plan led to inconsistencies in communication and left some team members, like Lisa, feeling out of the loop. The team also experienced difficulties in tracking project progress and collaborating on tasks, which led to missed deadlines and increased frustration among team members like Ravi.\nIt was clear that a solution was needed urgently, and I felt the weight of responsibility to turn things around for our team. After seeking feedback from my team and researching best practices for remote communication, I decided to introduce Microsoft Teams as our primary collaboration tool. This platform allowed us to have a centralized space for sharing updates, asking questions, and discussing project-related issues without the need for real-time communication.\n\n\nThe Transformation: Unlocking the Potential of Our Team\nThe transformation was dramatic. With the new asynchronous communication model and the powerful features of Microsoft Teams, our team’s collaboration reached new heights. Not only were we able to keep track of project progress more effectively, but we also found ourselves having more meaningful and focused discussions. The weekly sync-up meetings became a valuable opportunity for everyone to connect, share their insights, and learn from each other’s experiences.\nIn the end, our team at FuturTech Solutions emerged stronger and more cohesive than ever. The experience taught us the importance of adapting to change and finding the right tools to support our work. The once-chaotic world of remote communication had been conquered, and our team was poised to tackle even greater challenges together.\n\n\nThe Power of Shared Memories\nAs I concluded the story, I saw the pride and camaraderie in my colleagues’ faces, reminded of their small yet vital roles in our collective success.\nThe Christmas party served as a testament to our resilience and adaptability, becoming a cherished memory that brought us even closer together throughout the following year.\n\n\nStory Spotting Tips\nNow how do you best spot stories?\nFocus on,\n\nActively observing your surroundings and seeking relatable themes,\nEmbracing the ordinary to find inspiration in mundane moments, and\nPracticing mindfulness, active listening, and fostering a creative environment.\n\nBy staying curious and attentive, we can transform everyday experiences into engaging, relatable, and inspiring content.\nHappy story spotting!"
  },
  {
    "objectID": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html",
    "href": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html",
    "title": "How domain driven design makes software development concrete and abstract",
    "section": "",
    "text": "Domain Driven Design by Eric Evans helps you building abstract software for a concrete problem using concrete techniques."
  },
  {
    "objectID": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#people-will-remember-names.",
    "href": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#people-will-remember-names.",
    "title": "How domain driven design makes software development concrete and abstract",
    "section": "1 People will remember names.",
    "text": "1 People will remember names.\nThink of landscapes in the physical world. The allure of names like “Yosemite” or “The Grand Canyon” turns them into destinations with emotional appeal. Just naming them “canyon 1” would be a dump.\nTechnology is no different. I once worked in a multi-language assembly of a plane. There was a brown switch board, which always caused problems. In French it was called platine choco. In other languages, it had the beautiful sounding name CX115, or something else I do not remember.\nNaming is one of the most important aspect of software development. Naming transforms sterile abstractions into memorable entities."
  },
  {
    "objectID": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#your-memory-is-not-a-computer-storage",
    "href": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#your-memory-is-not-a-computer-storage",
    "title": "How domain driven design makes software development concrete and abstract",
    "section": "2 Your memory is not a computer storage",
    "text": "2 Your memory is not a computer storage\nBut why are names so important? Our brains aren’t file cabinets or computer storage; they’re Velcro, with loops waiting for the right hooks. The stickiest ideas, which can attach, are rich in details and relevance.\nFor instance, “silly things people have done” is an abstraction, but “silly things your child has done” creates vivid imagery, attaching to your personal experiences.\nSoftware design and software management help from this principle. Specific technical scenarios and user stories anchor better in the team’s mind than generalized ideas."
  },
  {
    "objectID": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#the-curse-of-knowledge-engineers-and-abstraction",
    "href": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#the-curse-of-knowledge-engineers-and-abstraction",
    "title": "How domain driven design makes software development concrete and abstract",
    "section": "3 The Curse of Knowledge: Engineers and Abstraction",
    "text": "3 The Curse of Knowledge: Engineers and Abstraction\nEngineers are notorious for crafting elaborate blueprints without addressing the practical problems staring them in the face. While abstraction is necessary to achieve extensible and “soft” products, it needs to be limited for the sake of delivery speed."
  },
  {
    "objectID": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#an-abstract-solution-to-deliver-concreteness-domain-driven-design",
    "href": "posts/made-to-stick/how-domain-driven-design-makes-software-development-concrete-and-abstract.html#an-abstract-solution-to-deliver-concreteness-domain-driven-design",
    "title": "How domain driven design makes software development concrete and abstract",
    "section": "4 An abstract solution to deliver concreteness: Domain-Driven Design",
    "text": "4 An abstract solution to deliver concreteness: Domain-Driven Design\nA better solution to overcrowded designs full of abstraction exists.\nDomain-Driven-Design (DDD) embraces concreteness. By tying software elements to real-world concepts within a specific domain, DDD creates shared language and context among stakeholders. If those elements share something, we can generate an abstraction.\nThis makes it easier to communicate, collaborate, and build. Imagine if every class, function, or service in a system mirrored something tangible from its business domain. Not only does this foster clarity, but it ensures that every abstraction has roots in something real.\nConcreteness forges connections and ensures memory retention. And even software abstraction should have concrete names. Whether you’re naming a software feature, crafting a narrative, or solving a problem, remember: the stickiest ideas are specific."
  },
  {
    "objectID": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html",
    "href": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html",
    "title": "Get huge benefits for minimal costs after reading",
    "section": "",
    "text": "As advertising legend Claude Hopkins advised: “First and foremost, try to get self-interest into every headline you write.” Your messaging should promise huge benefits for minimal costs.\nSpeak directly to your audience’s needs, and make the WIIFY (What’s In It for You) central to every sentence.\nFor example:\n\nSticky: “You’ll enjoy a sense of security when you use Goodyear Tires.”\nForgettable: “People will enjoy a sense of security when they use Goodyear Tires.”"
  },
  {
    "objectID": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#start-with-self-interest",
    "href": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#start-with-self-interest",
    "title": "Get huge benefits for minimal costs after reading",
    "section": "",
    "text": "As advertising legend Claude Hopkins advised: “First and foremost, try to get self-interest into every headline you write.” Your messaging should promise huge benefits for minimal costs.\nSpeak directly to your audience’s needs, and make the WIIFY (What’s In It for You) central to every sentence.\nFor example:\n\nSticky: “You’ll enjoy a sense of security when you use Goodyear Tires.”\nForgettable: “People will enjoy a sense of security when they use Goodyear Tires.”"
  },
  {
    "objectID": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#empathy-through-the-particular",
    "href": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#empathy-through-the-particular",
    "title": "Get huge benefits for minimal costs after reading",
    "section": "2 Empathy Through the Particular",
    "text": "2 Empathy Through the Particular\nAbandon abstract generalizations and focus on specifics. Enforce the particular over the pattern and create empathy and emotional resonance. People connect to individual stories, not statistics. If you work in a data-driven field the art is to connect data to stories."
  },
  {
    "objectID": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#what-doesnt-stick",
    "href": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#what-doesnt-stick",
    "title": "Get huge benefits for minimal costs after reading",
    "section": "3 What Doesn’t Stick",
    "text": "3 What Doesn’t Stick\nNegative framing, like listing what your idea isn’t, dilutes impact. Instead, focus on what it is and why it matters."
  },
  {
    "objectID": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#stickiness-checklist",
    "href": "posts/made-to-stick/get-huge-benefits-for-minimal-costs-after-reading.html#stickiness-checklist",
    "title": "Get huge benefits for minimal costs after reading",
    "section": "4 Stickiness Checklist",
    "text": "4 Stickiness Checklist\nTo create a sticky idea that resonates, incorporate these proven principles:\n\nUse Schemas\nRelate your message to familiar frameworks. People grasp new ideas faster when they can connect them to what they already know. The mind is like Velcro.\nGenerative Analogies and Metaphors\nSimplify complex ideas with vivid comparisons. Make the unfamiliar relatable.\nBreak the Guessing Machine, Then Fix It\nDisrupt expectations to grab attention, then resolve the disruption.\nGap Theory of Curiosity\nHighlight what your audience doesn’t know to spark curiosity and engagement.\nIntroduce Mysteries\nA compelling mystery hooks attention and invites exploration.\nVelcro Theory of Memory\nThe more sensory hooks your idea has, the more it sticks. Use vivid, specific details to boost credibility.\nHuman-Scale Principle\nScale your ideas down to relatable, human-sized narratives.\nAvoid Semantic Stretch\nBe precise with your language. Overused or vague terms lose their punch.\nNo Maslow’s Basement\nAppeal to higher-level needs like purpose, belonging, or self-expression. Avoid staying in the realm of basic survival.\nEnforce the Particular\nHighlight individuals, not groups. Personal stories inspire action.\nSpringboard Stories and Story Schemas\nUse narratives that allow your audience to envision their own transformation.\n\nMore details will follow in Stickiness improvement plan.\n\n\n\n\n\n\n\nTip\n\n\n\nRemember one thing:\nWIIFY (What’s In It for You) is central to your communication"
  },
  {
    "objectID": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html",
    "href": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html",
    "title": "The world requires influential engineers with a passion for stories",
    "section": "",
    "text": "Everyone wants their ideas to strive, even engineers.\nSkip to the end for some tips for your next presentation.\nEngineers are often depicted as uncommunicative cavemen. The talking is best left to other people, isn’t it? Rarely would one assume that a non-lawyer leads a law firm or a non-medicine a hospital.\nI currently write about how storytelling can help to communicate, even engineers.\nMany of the storytelling topics deal with getting people to work together better.\nCurrently, it is fashionable to use the BAPO acronym for business organization.\nIn B, P, and O, it is clear how to use storytelling, but how the A?\nAll software engineers should aim to become better in the business topics, the people, and the organization domain. But in their core domain, are there any benefits to using storytelling? After all, these are often technical topics. They should be as objective as possible. Shouldn’t they?"
  },
  {
    "objectID": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#science-is-truth",
    "href": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#science-is-truth",
    "title": "The world requires influential engineers with a passion for stories",
    "section": "Science is truth",
    "text": "Science is truth\n\nIn school, we are getting taught that information and knowledge should be presented as factual as possible. Natural science focuses on this approach. It seems like a worthy goal, but a drawback is the ability to spread the idea. Many dissertations are pretty dry. In contrast, the best scientific presentations are not. There is a difference."
  },
  {
    "objectID": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#mixing-facts-and-emotions",
    "href": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#mixing-facts-and-emotions",
    "title": "The world requires influential engineers with a passion for stories",
    "section": "Mixing facts and emotions",
    "text": "Mixing facts and emotions\nThis difference often comes from elements that break with the facts. The use of comics and memes is just the tip of the iceberg. In my opinion, one of the reasons for the success of Dilbert is that he plays with factual and emotional context. Uncle Bob also successfully relies on these. He interweaves technical topics with small anecdotes from his life.\nMany technical workers are forced to deal with human-related topics, even though their crucial work is factual. Why is that so?"
  },
  {
    "objectID": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#the-two-screws",
    "href": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#the-two-screws",
    "title": "The world requires influential engineers with a passion for stories",
    "section": "The two screws",
    "text": "The two screws\n\nThere are usually contradicting ideas. Take, for example, the two designs for screws (picture). From a factual level, they both have their advantages and disadvantages. But they are from different inventors. Every inventor wants his idea to win. So to convince, we will address the emotions behind a problem.\nIn this sense, every technical discussion is like a business discussion. The same techniques can be applied. What is different is the currency."
  },
  {
    "objectID": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#tips-for-your-next-technical-presentation",
    "href": "posts/influence-articles/the-world-requires-influential-engineers-with-a-passion-for-stories.html#tips-for-your-next-technical-presentation",
    "title": "The world requires influential engineers with a passion for stories",
    "section": "Tips for your next technical presentation",
    "text": "Tips for your next technical presentation\nThese tips allow you to inflate the importance of every message.\nYou can share a lot fewer details than without this auxiliary information.\n\nbe like the audience: dress more or less formal. Speak similar in language and tone.\npoint out common identity/goal: recall past events\nstress your experience: profit from expert credibility\nengage the audience and trick them into commitment\npresent a complex problem, like climate change/ your primary business goal, then relate your problem artfully to it, show that you can solve it\nstress that the results are the latest and nobody has seen them, creating a feeling of scarcity"
  },
  {
    "objectID": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html",
    "href": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html",
    "title": "Successful cross-functional teams need the luxury of confidence and trust",
    "section": "",
    "text": "“Just separate the participants into groups and let them sit for a while in their own juices. Then mix together over the flame of continued competition. And there you have it: Cross-group hatred at rolling boil.”\n— R. Cialdini\nToday, the cross-functional team and entrepreneurial organization are one of the stock solutions to solve complex problems."
  },
  {
    "objectID": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#the-genesis-of-the-team-identity",
    "href": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#the-genesis-of-the-team-identity",
    "title": "Successful cross-functional teams need the luxury of confidence and trust",
    "section": "1 The genesis of the team identity",
    "text": "1 The genesis of the team identity\nI have yet to come across a genuinely self-organized organization. At least in big companies, there is still some top-down decision structure.\nTeams are set up and staffed by a person who frequently is not even part of the team.\nBut once the team members are there, they pick up the ball and play. As a result, team identity usually starts a life of its own.\nTeams do not act in a vacuum. They usually need to interact with our teams.\nThey quickly become competitive and less productive in achieving an overarching goal.\nComplaints about other teams are the result:\n\n“Team tiger is just not working with us!”\n— Team Winnie"
  },
  {
    "objectID": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#the-environment-fosters-team-competition.",
    "href": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#the-environment-fosters-team-competition.",
    "title": "Successful cross-functional teams need the luxury of confidence and trust",
    "section": "2 The environment fosters team competition.",
    "text": "2 The environment fosters team competition.\nIdentification with a team name goes along with the increased commitment to the team. However, groups with a character can automatically lead to low-level competition amongst teams.\nWhat makes the difference is the environment. If the environment enforces competitive behavior, team identity acts as a multiplier. The competitive character provides a selection criterion for the top-down entity and enables competition.\nToday, the two most competitive environments are school and work.\nIn school, cross-class competition is done in science contests, treasure hunts, or sports events. At work, measuring team performance metrics is a source of constant unrest.\nChildren are usually more open than adults. The disgust of the other school will be phrased quite clearly: “You know class 7b are crazy”.\nThese conflicts are usually only visible at work in a lack of cooperation, blaming, and disapproving remarks: “You know, team lions are always sabotaging our efforts by caring about their own goals.”"
  },
  {
    "objectID": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#provide-a-cooperative-environment",
    "href": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#provide-a-cooperative-environment",
    "title": "Successful cross-functional teams need the luxury of confidence and trust",
    "section": "3 Provide a cooperative environment",
    "text": "3 Provide a cooperative environment\nThe first thing is to avoid measuring metrics across teams and compare and sanctionize. Do not even get into the situation. But what to do if the case has already deteriorated?\nEnter group therapy! Group therapy bears many names. Bring groups together in a pleasant atmosphere and allow people to familiarize themselves with each other.\nYou will hope for a miracle to occur. Alas, the problem continues. No external force will move team members’ disposition in such a setting.\nThe second frequent mistake: “Please work together and figure it out.” At best, there will be some superficial results, and everybody will be happy that they can work alone afterward.\nThe problem to overcome must threaten the entire organization. Cross-team collaboration is the only solution that has a chance to work. The cooperation allows experiencing a rival as a reasonable fellow and friend. It is difficult to uphold hostility if a triumph is shared.\nIn contrast, in group therapy, no real triumph is shared. The victory will be experienced as a false triumph. While therapy might improve the attitudes toward each other, it will not allow lasting success."
  },
  {
    "objectID": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#avoid-getting-into-the-unhealthy-team-competition",
    "href": "posts/influence-articles/successful-crossfunctional-teams-need-the-luxury-of-confidence-and-trust.html#avoid-getting-into-the-unhealthy-team-competition",
    "title": "Successful cross-functional teams need the luxury of confidence and trust",
    "section": "4 Avoid getting into the unhealthy team competition",
    "text": "4 Avoid getting into the unhealthy team competition\n\nDo not force people who do not get along well together.\nInstead, define the problems in such a way that the skills of everybody are required to solve the issue.\nThe real problem comes with people with no skills in the team."
  },
  {
    "objectID": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html",
    "href": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html",
    "title": "Three old but trusted ways to reveal your team’s common story",
    "section": "",
    "text": "Read on to discover how to form the team’s history and find stories at the workplace."
  },
  {
    "objectID": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#lets-have-a-party",
    "href": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#lets-have-a-party",
    "title": "Three old but trusted ways to reveal your team’s common story",
    "section": "1 Let’s have a party",
    "text": "1 Let’s have a party\nEverybody likes a party. And everybody feels afterward connected to other people who attended the party. Why? Because we perform activities together in a pleasant environment.\nIn his book “Influence” R. Cialdini describes how compliance techniques move people. Commitment is such a compliance technique. Commitments that are active, public, and effortful are the most successful.\nA party is just that, active and public. However, it is not necessarily effortful (apart from the next day’s hangover).\n\n1.1 Why group workshops can be destructive\nNow let’s look at your last group workshop. Hopefully, it took place in a pleasant atmosphere. Sometimes the venue alone makes up for memory.\nThe three factors in detail:\n\nActivity: everybody was active. The organizer imposes the activeness, but this does not matter.\nPublicity: Most people were talking in public. Many techniques like feedback boards and break-out sessions are public commitment tools.\nEffort: last but not least, planning is hard work and effort.\n\nBut did you feel fulfilled and energized? I remember many planning sessions that left me bewildered, exhausted or both.\nThe principle of commitment can work against you. A hostile atmosphere from the onset and pressure leads to estranging of the team. Even though you might have initial success, later planning rounds might carry the burden of team internal conflicts. People will be there because they have to be. There will be endless discussions as no one wants to drop his stakes and align with a common cause.\nSo what’s missing?"
  },
  {
    "objectID": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#the-three-silver-bullets",
    "href": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#the-three-silver-bullets",
    "title": "Three old but trusted ways to reveal your team’s common story",
    "section": "2 The three silver bullets",
    "text": "2 The three silver bullets\nOkay, everybody knows there is no silver bullet, but let’s try.\n\n2.1 Start small\nIf you want to foster a feeling of belonging together, let everyone commit to low threshold goals. If these small goals are achieved, everybody will feel good at later planning meetings. The familiarity principle comes to play, and a “We always made a good plan work so far” can become the foundation for more challenging goals.\n\n\n2.2 The coalition of the willing\nLet’s face it. The workplace can sometimes be chaotic. Many people do what they want. Others do not have a clue what is going on. Finally, some give a *****.\nWork-life features its social network. We all orientate ourselves towards each other. We all want to know what Harry is doing, how he is doing it, and who he knows. Team dynamics are governed mainly by the principle of social proof. It relies on\n\ngroup size\nfamiliarity\nand confusion\n\nNew projects launch with small teams, and everybody knows everybody. Team events occur naturally, which further bolsters the team spirit.\nNow you know what you will do in your next greenfield project.\nBut what when your project is already in the taskforce hell? Many projects get on the slippery slope as they struggle to address uncertainty and limit task complexity correctly.\nFocus on the willing people. Try to find similarities between people - their everyday problems. Assemble a coalition of the willing.\n\nDeal with any conflicting points.\nFrom this comes a group strength.\nAnd from strength comes momentum.\nAnd from momentum come the stories that push you forward.\nStories and momentum attract more followers.\n\nConfusion is a critical fact that keeps people from being engaged. Try to show an exact attitude and propose a direction."
  },
  {
    "objectID": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#instant-gratification",
    "href": "posts/influence-articles/three-old-but-trusted-ways-to-reveal-your-teams-common-story.html#instant-gratification",
    "title": "Three old but trusted ways to reveal your team’s common story",
    "section": "3 Instant Gratification",
    "text": "3 Instant Gratification\nLike and like attracts. The same applies to team creation. However, today diversity is king. That means your team has a diverse background. Diversity opposes familiarity, and if you let your group run wild, they will certainly discover their differences and hate each other.\nEnter the “party factor.” Allow the group to get familiar with a calm atmosphere. The book “Peopleware” features a chapter called “A spaghetti dinner.” The team’s first task was to have a nice dinner.\nSimilarly, the luncheon technique connects the memory of a shared meal to a person’s face. We shared a good meal that filled our stomachs and made us feel good. We then identify the other person with this meal.\nSometimes organizing a dinner party is not possible. The key is not the dinner party but the shared experience. This piece of memory will serve as the seed of the group identification. The best experiences are experiences of shared victories. Group workshops try to employ this by letting a team build something or overcome an obstacle.\nWith your coalition of the willing, try to find the smallest possible thing that you can fix quickly."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Dominik Lindner",
    "section": "",
    "text": "About this blog\nI’m a computational engineer and AI practitioner exploring how machine learning, software design, and storytelling intersect.\nI began in mechanical and materials engineering, built a foundation in numerical methods and FEM, and grew into computer vision and ML systems.\nStory Mélange is both a portfolio and a place to write: how we design, reason, and communicate through code.\nYou’ll find experiments, essays, and reflections here — some technical, some philosophical — all built on one belief:\n\n\n\n\n\n\nCode, data, and curiosity are the raw ingredients of meaningful innovation.\n\n\n\nMy thinking is shaped by classics in leadership andsystems design, see Influences & Reading Notes.\nThis blog captures that unique blend, offering insights into real-world problem-solving, leadership, and the human side of the tech industry.\nIf that sparks your curiosity, you’re in the right place.\nGrab a coffee. Read a story."
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "Legal Notice (Impressum)",
    "section": "",
    "text": "Responsible for the content\nDr. Dominik Lindner\nGutenbergstr. 116\n70197 Stuttgart\n\n\n\nE-Mail: info@storymelange.com\n\n\n\nThe European Commission provides a platform for online dispute resolution (ODR): https://ec.europa.eu/consumers/odr/.\nYou can find our email address above in the legal notice.\n\n\n\nWe are neither willing nor obligated to participate in dispute resolution proceedings before a consumer arbitration board."
  },
  {
    "objectID": "impressum.html#content-responsibility",
    "href": "impressum.html#content-responsibility",
    "title": "Legal Notice (Impressum)",
    "section": "",
    "text": "Responsible for the content\nDr. Dominik Lindner\nGutenbergstr. 116\n70197 Stuttgart"
  },
  {
    "objectID": "impressum.html#contact",
    "href": "impressum.html#contact",
    "title": "Legal Notice (Impressum)",
    "section": "",
    "text": "E-Mail: info@storymelange.com"
  },
  {
    "objectID": "impressum.html#eu-dispute-resolution",
    "href": "impressum.html#eu-dispute-resolution",
    "title": "Legal Notice (Impressum)",
    "section": "",
    "text": "The European Commission provides a platform for online dispute resolution (ODR): https://ec.europa.eu/consumers/odr/.\nYou can find our email address above in the legal notice."
  },
  {
    "objectID": "impressum.html#consumer-dispute-resolutionuniversal-arbitration-board",
    "href": "impressum.html#consumer-dispute-resolutionuniversal-arbitration-board",
    "title": "Legal Notice (Impressum)",
    "section": "",
    "text": "We are neither willing nor obligated to participate in dispute resolution proceedings before a consumer arbitration board."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "These are side projects across the fields of machine learning and software design.\nSome are quick espresso experiments, others are slow-brewed prototypes, and a few are already close to an MVP.\n\n\n\n\n\n\n\n\nCan AI fix your shopping list?\n\n9 min\n\nMany shopping apps can create shopping lists. But many apps fail to correctly aggregate similar items. Let’s discover if AI can help.\n\n\n\nNov 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPage Segmentation: The easy and the hard way\n\n13 min\n\nAn OCR scan of a whole page of a complex layout can be done two ways. The easy expensive one using an LLM or the more sophisticated one, which is harder to develop but…\n\n\n\nOct 24, 2025\n\n\n\n\n\n\n\n\n\n\n\nIs training your own classifier really worth it?\n\n3 min\n\nI small update to the longer update. We use a YOLO-doclayout to decide if it is a text or image.\n\n\n\nOct 2, 2025\n\n\n\n\n\n\n\n\n\n\n\nText or Image\n\n5 min\n\nRunning Document digitization pipelines can be expensive. Especially if you pay per API request. A good triage of pages is helping to reduce costs. In this notebook we…\n\n\n\nSep 29, 2025\n\n\n\n\n\n\n\n\n\n\n\nHow Neural Networks Hear Music\n\n19 min\n\nDid you ever wonder how Spotify, Tidal or YouTube work? Why are they suggesting a song to you?. Sometimes the suggestions are quite good. Come with we on a visual journey…\n\n\n\nJul 15, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner - part 2\n\n7 min\n\nBack from the Dead, driven by AI Agent\n\n\n\nJul 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Rebirth of the recipescanner\n\n6 min\n\nPart I: What happened so far\n\n\n\nJul 3, 2025\n\n\n\n\n\n\n\n\n\n\n\nDo you know the hidden paths of your code?\n\n21 min\n\nMost software is complex. Especially with AI-assisted coding, complexity can quickly run out of hands and turn into a nightmare. To never get lost again, let’s create the…\n\n\n\nMay 14, 2025\n\n\n\n\n\n\n\n\n\n\n\nStreet view game - hit the road\n\n7 min\n\nHit the road allows you to sit back and enjoy the scenary when using Google street view. You can look around while you advance. Very much the same as you would in a car.\n\n\n\nApr 26, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe road less travelled - from the dijkstras shortest path to the least visited path\n\n5 min\n\nWhat if you are not interested in getting as fast as possible from A to B. But you always search a new path. A python adventure to discover new places.\n\n\n\nMar 25, 2025\n\n\n\n\n\n\n\n\n\n\n\nWhich cheese are we eating?\n\n11 min\n\nDid you ever wonder what kind of cheese you should buy? They all look the same. And then the embarrasement when you can just point and say: that one. Meet the cheese…\n\n\n\nMar 13, 2025\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\nMore prototypes and experiments can be found on this page."
  }
]